{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with RSS Feeds Lab\n",
    "\n",
    "Complete the following set of exercises to solidify your knowledge of parsing RSS feeds and extracting information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use feedparser to parse the following RSS feed URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://feeds.feedburner.com/oreilly/radar/atom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bozo': False, 'entries': [{'title': 'Ad Networks and Content Marketing', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Ad Networks and Content Marketing'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/'}], 'link': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/', 'comments': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/#respond', 'published': 'Tue, 16 Aug 2022 11:21:21 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=16, tm_hour=11, tm_min=21, tm_sec=21, tm_wday=1, tm_yday=228, tm_isdst=0), 'authors': [{'name': 'Q McCallum'}], 'author': 'Q McCallum', 'author_detail': {'name': 'Q McCallum'}, 'tags': [{'term': 'Operations', 'scheme': None, 'label': None}, {'term': 'Deep Dive', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14688', 'guidislink': False, 'summary': 'In a recent Radar piece, I explored N-sided marketplaces and the middlemen who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend weighing in at $763 billion in 2021 revenues. Most [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'In a recent Radar piece, I explored N-sided marketplaces and the middlemen who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend weighing in at $763 billion in 2021 revenues. Most [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>In a recent Radar piece, I explored <a href=\"https://www.oreilly.com/radar/building-a-better-middleman/\" rel=\"noreferrer noopener\" target=\"_blank\">N-sided marketplaces and the middlemen</a> who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend <a href=\"https://www.statista.com/topics/990/global-advertising-market/#dossierKeyfigures\" rel=\"noreferrer noopener\" target=\"_blank\">weighing in at $763 <em>billion</em> in 2021 revenues</a>.</p>\\n\\n\\n\\n<p>Most of that money is <a href=\"https://www.emarketer.com/content/worldwide-digital-ad-spending-2021\" rel=\"noreferrer noopener\" target=\"_blank\">spent on digital ads</a>, like the ones that follow you across websites to offer you deals on items you&#8217;ve just bought. Those are typically based on your online activity. Ad networks trail behind you as you browse the web, trying to get an idea of who you are and what you&#8217;re likely to buy, so they can pair you with hopeful merchants.</p>\\n\\n\\n\\n<p>While merchants are clearly happy with targeted ads—at least, I&#8217;d hope so, given how much they&#8217;re spending—consumers have, understandably, expressed concerns over personal privacy.\\xa0Apple took note, and <a href=\"https://www.cnbc.com/2022/02/02/facebook-says-apple-ios-privacy-change-will-cost-10-billion-this-year.html\" rel=\"noreferrer noopener\" target=\"_blank\">limited iOS apps&#8217; ability to track users</a> across sites. Google has announced <a href=\"https://www.cnet.com/tech/computing/google-chromes-privacy-changes-will-hit-the-web-later-this-year/\" rel=\"noreferrer noopener\" target=\"_blank\">changes that would further limit advertisers&#8217; reach</a>. Who knows? Maybe the next step will be that the ad industry gets stronger regulations.</p>\\n\\n\\n\\n<p>There&#8217;s also the <a href=\"https://thecorrespondent.com/100/the-new-dot-com-bubble-is-here-its-called-online-advertising\" rel=\"noreferrer noopener\" target=\"_blank\">question of whether targeted advertising even works</a>.&nbsp; While the ad networks aren&#8217;t required to disclose their stats, there are even people inside those companies who think that <a href=\"https://theintercept.com/2020/12/24/facebook-ad-targeting-small-business/\" rel=\"noreferrer noopener\" target=\"_blank\">their product is &#8220;almost all crap.&#8221;</a></p>\\n\\n\\n\\n<p>Maybe it&#8217;s time for a different approach?\\xa0Recently, Disney&#8217;s video streaming service, Disney+, threw its hat into the advertising ring by announcing a new ad-supported plan. (Credit where it&#8217;s due: I originally <a href=\"https://www.lesechos.fr/tech-medias/medias/disney-va-lancer-une-offre-avec-de-la-publicite-1391472\" rel=\"noreferrer noopener\" target=\"_blank\">found this in <em>Les Echos</em></a>, which may be paywalled. Here&#8217;s the official, English-language <a href=\"https://thewaltdisneycompany.com/disney-to-introduce-an-ad-supported-subscription-offering-in-late-2022/\" rel=\"noreferrer noopener\" target=\"_blank\">press release from Disney</a>.)</p>\\n\\n\\n\\n<p>It may be easy to disregard this Disney+ move, since so much of the online world is ad-supported these days. But I think this merits more attention than it may seem on the surface.</p>\\n\\n\\n\\n<p>To be clear: I have no inside information here. But it at least <em>looks like</em> Disney+ can run its ad platform in a fairly low-tech fashion while also preserving privacy. That&#8217;s a pretty big deal for Disney, for consumers, and for the wider space of online advertising.</p>\\n\\n\\n\\n<h3>Everything old is new again</h3>\\n\\n\\n\\n<p>To understand why, let&#8217;s first consider the idea of <em>&#8220;content marketing.&#8221;</em> This is a new term for the age-old practice of selling ad space next to curated content that aligns with a particular theme. For example, let&#8217;s say you&#8217;ve created a magazine about cars. Motoring enthusiasts will read your magazine, which means advertisers (merchants) who want to reach them will place ads in your pages. The content is what draws readers and advertisers to the same spot.</p>\\n\\n\\n\\n<p>What&#8217;s nice about content marketing is that the ad&#8217;s placement is based on the <em>content,</em> not the <em>specific person reading it.</em></p>\\n\\n\\n\\n<p>This addresses the privacy concern at the core of targeted advertising, because content marketing doesn&#8217;t require that you build a detailed profile of a person based on their every browsing habit. You&#8217;re not pairing an ad to a person; you&#8217;re pairing an ad to a piece of content. So you shift your analytical focus from the reader to what they&#8217;re reading.</p>\\n\\n\\n\\n<h3>The mouse has a large library</h3>\\n\\n\\n\\n<p>Now, consider Disney: its catalog spans decades&#8217; worth of cartoons, tween sitcoms, and movies. Its recent acquisition of the Star Wars franchise gives it access to an even wider fanbase. And don&#8217;t forget that Disney owns ESPN, which adds sports content to the portfolio. It now makes that content available through its video-on-demand (VOD) platform of Disney+.</p>\\n\\n\\n\\n<p>Disney already has to keep track of that catalog of content as part of its day-to-day business, which means we can reasonably assume that every show, movie, and sporting event on Disney+ has been assigned some number of descriptive tags or labels.</p>\\n\\n\\n\\n<p>From the perspective of content marketing, all of this adds up to Disney+ being able to place ads on that content without having to do much extra work. The parent company, Disney, already owns the content and it&#8217;s already been tagged. The depth and breadth of the video catalog will certainly attract a large number and wide variety of viewers. That shifts the heavy lifting to the ad-matching system, which connects advertisers with the content.</p>\\n\\n\\n\\n<h3>Tracking your ad budget</h3>\\n\\n\\n\\n<p>You&#8217;ve likely heard the John Wanamaker adage: &#8220;Half the money I spend on advertising is wasted; the trouble is, I don&#8217;t know which half.&#8221; It&#8217;s a well-founded complaint about billboard or magazine advertising, since an advertiser can&#8217;t really tell how many people saw a given ad.</p>\\n\\n\\n\\n<p>(Some early advertising pioneers, David Ogilvy among them, learned to supply coupons with print ads so stores could track which one had resonated the most. While this added a new level of analytical rigor to the field, it still wasn&#8217;t a perfect solution to Wanamaker&#8217;s plight.)</p>\\n\\n\\n\\n<p>Delivering content-based ads through a well-curated streaming platform addresses that somewhat. Disney+ can provide an advertiser a detailed analysis of their ad spend without revealing any individual&#8217;s identity: <em>&#8220;N number of people watched Variant V, your ad for Product P, during Show S, with the following breakdowns for time of day&#8230;&#8221;</em></p>\\n\\n\\n\\n<p>And that leads me to my next point:</p>\\n\\n\\n\\n<h3>Minimal ML/AI</h3>\\n\\n\\n\\n<p>When you review the setup—a curated and labeled catalog, with broad-brush marketing characteristics—Disney+ has the ability to run this ad service using minimal ML/AI.</p>\\n\\n\\n\\n<p>(Once again: I&#8217;m speculating from the outside here. I don&#8217;t know for sure how much ML/AI Disney+ is using or plans to use. I&#8217;m working through one hypothetical-yet-seemingly-plausible scenario.)</p>\\n\\n\\n\\n<p>Disney+ can use those content labels—&#8221;pro football,&#8221; &#8220;tween comedy,&#8221; &#8220;gen-X cartoon&#8221;—to pair a piece of content with an advertisement. They may not get a <em>perfect</em> hit rate on these ads; but given that they&#8217;re building on top of work they&#8217;ve already done (the catalog and the streaming platform) then the ad system can run at a relatively low cost. And providing stats to advertisers is a matter of counting. Since those calculations are so trivial, I expect the toughest part of that BI will be scaling it to Disney&#8217;s audience size.</p>\\n\\n\\n\\n<p>Can Disney+ still use ML/AI in places? They most certainly <em>can,</em> but they don&#8217;t <em>have to.</em> Disney+ has the option to run this using a smaller team of data scientists and a far smaller data analysis infrastructure. Whether you call this &#8220;smaller budget&#8221; or &#8220;higher margins,&#8221; the net effect is the same: the company ends the day with money in its pocket.</p>\\n\\n\\n\\n<p>Disney+ can task that ML team with building models that better tag content, or that improve matches between content and advertisers. They don&#8217;t have to spend money analyzing the specific actions of a specific individual in the hopes of placing ads.</p>\\n\\n\\n\\n<h3>Future-proofing the ad system</h3>\\n\\n\\n\\n<p>Assuming that the Disney+ ad system will indeed run on a content marketing concept, that means the company has one more card to play: They have just sidestepped potential future privacy laws that limit the use of personal information.</p>\\n\\n\\n\\n<p>Yes, Disney+ can get a person&#8217;s contact information when they subscribe to the service. Yes, the company can track customer behavior on- and off-platform, through a mix of first- and third-party data. But, contrary to targeted advertising, they don&#8217;t <em>need</em> all of that to run ads. All the company needs is to pair content with an advertisement. Given that this is the modern-day equivalent of a billboard or newspaper article, I imagine it would be difficult for Disney+ to run afoul of any present-day or upcoming privacy regulation with such an ad setup.</p>\\n\\n\\n\\n<h3>There&#8217;s still some room for trouble&#8230;</h3>\\n\\n\\n\\n<p>Going back to our car magazine example, Disney&#8217;s library is the equivalent of hundreds or even thousands of magazines. And if a single magazine is a hint as to a single interest, what can a larger number of magazines tell us?</p>\\n\\n\\n\\n<p>By tracking what content a person watches, how they watch it (phone, tablet, TV), and what time of day, Disney+ could infer quite a bit about that person and household: the number and age of adults; marital or relationship status; age and number of children; whether this is a multi-generational household; and even some clues as to viewers&#8217; gender. (I emphasize the term &#8220;infer&#8221; here, since it would hardly be perfect.)</p>\\n\\n\\n\\n<p>In turn, Disney <em>could</em> use this for ad targeting, or to provide even more-detailed breakdowns to advertisers, or even find ways to share the data with other companies. This could get creepy quickly, so let&#8217;s hope they don&#8217;t take this route. And based on what we&#8217;ve covered thus far, Disney+ has every opportunity to run an ad network that preserves a reasonable amount of privacy.</p>\\n\\n\\n\\n<h3>Could the tail someday wag the dog?</h3>\\n\\n\\n\\n<p>Another possible wrinkle would be in how advertising weighs on future content.</p>\\n\\n\\n\\n<p>Disney already has a good eye for what people will want to watch. And right now, those viewers are Disney&#8217;s customers. But when Disney+ becomes an ad marketplace, they&#8217;ll officially be a middleman, which means they&#8217;ll have to keep both sides of the ad equation happy. At what point does Disney use the Disney+ advertising as a compass, feeding back into decisions around what content to create?</p>\\n\\n\\n\\n<p>And would Disney ever stretch beyond its own character lines, to build TV and movies around someone <em>else&#8217;s</em> toys?&nbsp; It&#8217;s not too far-fetched of an idea. In <em>The Great Beanie Baby Bubble,</em> author Zac Bisonette points out that:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>[A TV show deal] was the kind of product-based programming that was responsible for billions per year in sales and could turn toys that no one wanted into hits through sheer exposure. Lines such as He-Man, My Little Pony, and the ThunderCats had all become hundred-million-dollar brands with the help of the product-based TV shows that accompanied their launches.</p></blockquote>\\n\\n\\n\\n<p>Creating content in one side of the businesses while running ads in the other, it&#8217;s not unlike running an investment bank and retail bank under one roof: sure, it can lead to all kinds of interesting business opportunities.&nbsp; It can also lead to trouble.</p>\\n\\n\\n\\n<p>When it comes to content marketing, you need to strike a balance: you want to create evergreen content, so you can continue to run ads. And when that content is going into the Disney catalog—some of which currently spans multiple generations—it has to be absolutely timeless. Giving in to the whims of a single advertiser, or a single fad, can lead to short-term gains but also short-lived content.</p>\\n\\n\\n\\n<h3>Beyond the Magic Kingdom</h3>\\n\\n\\n\\n<p>Despite those challenges, content marketing has huge potential for generating revenue, preserving privacy, and avoiding future regulation that could hinder targeted advertising. By building this system on BI and content tagging, Disney could do so at a smaller price tag than an AI-based, targeted-ad marketplace.</p>\\n\\n\\n\\n<p>And this isn&#8217;t just a Disney opportunity. I&#8217;ve focused on them in this piece but other VOD providers have already seen the benefit in monetizing their catalog. <a href=\"https://www.bloomberg.com/news/newsletters/2022-04-10/the-phone-company-didn-t-destroy-hbo-will-the-cable-guy\" rel=\"noreferrer noopener\" target=\"_blank\">According to Jason Kilar</a>, former CEO of WarnerMedia, &#8220;Close to 50% of every new [HBO Max] subscriber is choosing the ad tier. Hulu, the last stat they shared publicly, is they are north of 60%.&#8221; Amazon will rename its ad-supported IMDb TV service to Freevee. (I first saw this in <a href=\"https://www.spiegel.de/netzwelt/freevee-amazon-kuendigt-deutschland-start-von-kostenlosem-streamingdienst-an-a-4bfbd854-34ca-476b-95b7-3ff5763d3966\" rel=\"noreferrer noopener\" target=\"_blank\">Der Spiegel</a>; I&#8217;ve since found a <a href=\"https://apnews.com/article/technology-business-amazoncom-inc-netflix-jennifer-salke-84b0978c4880366ea6bd8dfff7e77af0\" rel=\"noreferrer noopener\" target=\"_blank\">US&nbsp; press release</a>.)&nbsp; And Netflix, long a holdout in the ad-supported space, hinted at <a href=\"https://www.bloomberg.com/news/articles/2022-04-19/netflix-plans-lower-priced-service-with-ads-marking-big-shift\" rel=\"noreferrer noopener\" target=\"_blank\">plans for a similar offering</a>.</p>\\n\\n\\n\\n<p>To be clear, content marketing at this scale is not exactly a get-rich-quick scheme.\\xa0It works best for groups that already have a large amount of content—video, image, text, audio—that they can monetize. This certainly holds true for the platforms I&#8217;ve just mentioned. Maybe it&#8217;s also true for your company?</p>\\n\\n\\n\\n<p>It may require getting creative as you comb through your attic. And maybe there&#8217;s an option for a new kind of ad marketplace, one that groups people with a small amount of content into a larger content ecosystem.&nbsp;Sort of like what <a href=\"https://www.ethicalads.io/\" rel=\"noreferrer noopener\" target=\"_blank\">EthicalAds</a> does for developer documentation. If low-cost, non-invasive content marketing is an option, it can&#8217;t hurt to try.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<p>Many thanks to <a href=\"https://www.oreilly.com/people/chris-butler/\" rel=\"noreferrer noopener\" target=\"_blank\">Chris Butler</a> for reviewing an early draft of this article. I always appreciate his insights. The section on the tail wagging the dog was based on his idea and I give him full credit for pointing this out to me.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/feed/', 'slash_comments': '0'}, {'title': 'On Technique', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'On Technique'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/on-technique/'}], 'link': 'https://www.oreilly.com/radar/on-technique/', 'comments': 'https://www.oreilly.com/radar/on-technique/#respond', 'published': 'Tue, 09 Aug 2022 11:12:22 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=9, tm_hour=11, tm_min=12, tm_sec=22, tm_wday=1, tm_yday=221, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14669', 'guidislink': False, 'summary': 'In a previous article, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'In a previous article, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>In a <a href=\"https://www.oreilly.com/radar/artificial-creativity-2/\" rel=\"noreferrer noopener\" target=\"_blank\">previous article</a>, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, “Make me a picture of a lion attacking a horse,” and it will happily generate one. Maybe not as good as the one that <a href=\"https://collections.britishart.yale.edu/catalog/tms:32\" rel=\"noreferrer noopener\" target=\"_blank\">hangs in an art museum</a>, but you don’t need to know anything about canvas, paints, and brushes, nor do you need to get your clothes covered with paint. </p>\\n\\n\\n\\n<p>This raises some important questions, though. What is the connection between expertise and ideation? Does technique help you form ideas? (The Victorian artist William Morris is often <a href=\"https://books.google.com/books?id=Til0DwAAQBAJ&amp;pg=PT292&amp;lpg=PT292&amp;dq=%E2%80%9CYou+can%E2%80%99t+have+art,%E2%80%9D+said+William+Morris,+the+designer,+poet,+and+master+craftsman+of+the+Victorians,+%E2%80%9Cwithout+resistance+in+the+material.%E2%80%9D&amp;source=bl&amp;ots=WYX6uA9wTq&amp;sig=ACfU3U3M2qyEIEsf1rrjKJ3poWb8CWIj9g&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj0-JHhlo35AhUVjIkEHYP-AT0Q6AF6BAgCEAM#v=onepage&amp;q=%E2%80%9CYou%20can%E2%80%99t%20have%20art%2C%E2%80%9D%20said%20William%20Morris%2C%20the%20designer%2C%20poet%2C%20and%20master%20craftsman%20of%20the%20Victorians%2C%20%E2%80%9Cwithout%20resistance%20in%20the%20material.%E2%80%9D&amp;f=false\" rel=\"noreferrer noopener\" target=\"_blank\">quoted</a> as saying “You can’t have art without resistance in the materials,” though he may only have been talking about his hatred of typewriters.) And what kinds of user interfaces will be effective for collaborations between humans and computers, where the computers supply the technique and we supply the ideas? Designing the prompts to get DALL-E to do something extraordinary requires a new kind of technique that’s very different from understanding pigments and brushes. What kinds of creativity does that new technique enable? How are these works different from what came before?</p>\\n\\n\\n\\n<p>As interesting as it is to talk about art, there’s an area where these questions are more immediate. GitHub Copilot (based on a model named <a href=\"https://openai.com/blog/openai-codex/\" rel=\"noreferrer noopener\" target=\"_blank\">Codex</a>, which is derived from GPT-3) generates code in a number of programming languages, based on comments that the user writes. Going in the other direction, GPT-3 has proven to be surprisingly good at <a href=\"https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/\" rel=\"noreferrer noopener\" target=\"_blank\">explaining code</a>. Copilot users still need to be programmers; they need to know whether the code that Copilot supplies is correct, and they need to know how to test it. The prompts themselves are really a sort of pseudo-code; even if the programmers don’t need to remember details of the language’s syntax or the names of library functions, they still need to think like programmers. But it’s obvious where this is trending. We need to ask ourselves how much “technique” we will ask of future programmers: in the 2030s or 2040s, will people just be able to tell some future Copilot what they want a program to be? More to the point, what sort of higher-order knowledge will future programmers need? Will they be able to focus more on the nature of what they want to accomplish, and less on the syntactic details of writing code?</p>\\n\\n\\n\\n<p>It’s easy to imagine a lot of software professionals saying, “Of course you’ll have to know C. Or Java. Or Python. Or Scala.” But I don’t know if that’s true. We’ve been here before. In the 1950s, computers were programmed in machine language. (And before that, with cables and plugs.) It’s hard to imagine now, but the introduction of the first programming languages–Fortran, COBOL, and the like–was met with resistance from programmers who thought you needed to understand the machine. Now almost no one works in machine language or assembler. Machine language is reserved for a few people who need to work on some specialized areas of operating system internals, or who need to write some kinds of embedded systems code.</p>\\n\\n\\n\\n<p>What would be necessary for another transformation? Tools like Copilot, useful as they may be, are nowhere near ready to take over. What capabilities will they need? At this point, programmers still have to decide whether or not code generated by Copilot is correct.&nbsp;We don’t (generally) have to decide whether the output of a C or Java compiler is correct, nor do we have to worry about whether, given the same source code, the compiler will generate identical output. Copilot doesn’t make that guarantee–and, even if it did, any change to the model (for example, to incorporate new StackOverflow questions or GitHub repositories) would be very likely to change its output.&nbsp;While we can certainly imagine compiling a program from a series of Copilot prompts, I can’t imagine a program that would be likely to stop working if it was recompiled without changes to the source code. Perhaps the only exception would be a library that could be developed once, then tested, verified, and used without modification–but the development process would have to re-start from ground zero whenever a bug or a security vulnerability was found. That wouldn’t be acceptable; we’ve never written programs that don’t have bugs, or that never need new features. A key principle behind much modern software development is minimizing the amount of code that has to change to fix bugs or add features.</p>\\n\\n\\n\\n<p>It’s easy to think that programming is all about creating new code. It isn’t; one thing that every professional learns quickly is that most of the work goes into maintaining old code. A new generation of programming tools must take that into account, or we’ll be left in a weird situation where a tool like Copilot can be used to write new code, but programmers will still have to understand that code in detail because it can only be maintained by hand. (It is possible–even likely–that we will have AI-based tools that help programmers research software supply chains, discover vulnerabilities, and possibly even suggest fixes.) Writing about AI-generated art, Raphaël Millière <a href=\"https://www.wired.com/story/dalle-art-curation-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">says</a>, “No prompt will produce the exact same result twice”; that may be desirable for artwork, but is destructive for programming. Stability and consistency is a requirement for next-generation programming tools; we can’t take a step backwards.</p>\\n\\n\\n\\n<p>The need for greater stability might drive tools like Copilot from free-form English language prompts to some kind of more formal language. A book about <a href=\"https://dallery.gallery/the-dalle-2-prompt-book/\" rel=\"noreferrer noopener\" target=\"_blank\">prompt engineering for DALL-E</a> already exists; in a way, that’s trying to reverse-engineer a formal language for generating images. A formal language for prompts is a move back in the direction of traditional programming, though possibly with a difference. Current programming languages are all about describing, step by step, what you want the computer to do in great detail. Over the years, we’ve gradually progressed to higher levels of abstraction. Could building a language model into a compiler facilitate the creation of a simpler language, one in which programmers just described what they wanted to do, and let the machine worry about the implementation, while providing guarantees of stability? Remember that it was possible to build applications with graphical interfaces, and for those applications to communicate about the Internet, before the Web. The Web (and, specifically, HTML) added a new formal language that encapsulated tasks that used to require programming.</p>\\n\\n\\n\\n<p>Now let’s move up a level or two: from lines of code to functions, modules, libraries, and systems. Everyone I know who has worked with Copilot has said that, while you don’t need to remember the details of the programming libraries you’re using, you have to be even more aware of what you’re trying to accomplish. You have to know what you want to do; you have to have a design in mind. Copilot is good at low-level coding; does a programmer need to be in touch with the craft of low-level coding to think about the high-level design? Up until now that’s certainly been true, but largely out of necessity: you wouldn’t let someone design a large system who hasn’t built smaller systems. It is true (as Dave Thomas and Andy Hunt argued in <a href=\"https://learning.oreilly.com/library/view/the-pragmatic-programmer/9780135956977/\" rel=\"noreferrer noopener\" target=\"_blank\">The Pragmatic Programmer</a>) that knowing different programming languages gives you different tools and approaches for solving problems.&nbsp; Is the craft of software architecture different from the craft of programming?</p>\\n\\n\\n\\n<p>We don’t really have a good language for describing software design. Attempts like UML have been partially successful at best. UML was both over- and under-specified, too precise and not precise enough; tools that generated source code scaffolding from UML diagrams exist, but aren’t commonly used these days. The scaffolding defined interfaces, classes, and methods that could then be implemented by programmers. While automatically generating the structure of a system sounds like a good idea, in practice it may have made things more difficult: if the high-level specification changed, so did the scaffolding, obsoleting any work that had been put into implementing with the scaffold. This is similar to the compiler’s stability problem, modulated into a different key. Is this an area where AI could help?</p>\\n\\n\\n\\n<p>I suspect we still don’t want source code scaffolding, at least as UML envisioned it; that’s bound to change with any significant change in the system’s description. Stability will continue to be a problem. But it might be valuable to have a AI-based design tool that can take a verbal description of a system’s requirements, then generate some kind of design based on a large library of software systems–like Copilot, but at a higher level. Then the problem would be integrating that design with implementations of the design, some of which could be created (or at least suggested) by a system like Copilot. The problem we’re facing is that software development takes place on two levels: high level design and mid-level programming. Integrating the two is a hard problem that hasn’t been solved convincingly.&nbsp; Can we imagine taking a high-level design, adding our descriptions to it, and going directly from the high-level design with mid-level details to an executable program? That programming environment would need the ability to partition a large project into smaller pieces, so teams of programmers could collaborate. It would need to allow changes to the high-level descriptions, without disrupting work on the objects and methods that implement those descriptions. It would need to be integrated with a version control system that is effective for the English-language descriptions as it is for lines of code. This wouldn’t be thinkable without guarantees of stability.</p>\\n\\n\\n\\n<p>It was fashionable for a while to talk about programming as “craft.”&nbsp; I think that fashion has waned, probably for the better; “code as craft” has always seemed a bit precious to me. But the idea of “craft” is still useful: it is important for us to think about how the craft may change, and how fundamental those changes can’t be.&nbsp;It’s clear that we are a long way from a world where only a few specialists need to know languages like C or Java or Python. But it’s also possible that developments like Copilot give us a glimpse of what the next step might be. Lamenting the state of programing tools, which haven’t changed much since the 1960s, Alan Kay <a href=\"https://www.quora.com/What-was-the-last-breakthrough-in-computer-programming\" rel=\"noreferrer noopener\" target=\"_blank\">wrote on Quora</a> that “the next significant threshold that programming must achieve is for programs and programming systems to have a much deeper understanding of both what they are trying to do, and what they are actually doing.” A new craft of programming that is focused less on syntactic details, and more on understanding what the systems we are building are trying to accomplish, is the goal we should be aiming for.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/on-technique/feed/', 'slash_comments': '0'}, {'title': 'Scaling False Peaks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Scaling False Peaks'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/scaling-false-peaks/'}], 'link': 'https://www.oreilly.com/radar/scaling-false-peaks/', 'comments': 'https://www.oreilly.com/radar/scaling-false-peaks/#respond', 'published': 'Thu, 04 Aug 2022 11:12:44 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=4, tm_hour=11, tm_min=12, tm_sec=44, tm_wday=3, tm_yday=216, tm_isdst=0), 'authors': [{'name': 'Kevlin Henney'}], 'author': 'Kevlin Henney', 'author_detail': {'name': 'Kevlin Henney'}, 'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14661', 'guidislink': False, 'summary': 'Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns out to be a lower peak or simply a contour that, from lower down, looked like a peak. You thought you made it–or were at least close–but there&#8217;s still a long way to go.</p>\\n\\n\\n\\n<p>The story of AI is a story of punctuated progress, but it is also the story of (many) false summits.</p>\\n\\n\\n\\n<p>In the 1950s, machine translation of Russian into English was considered to be no more complex than dictionary lookups and templated phrases. Natural language processing has come a very long way since then, having burnt through a good few paradigms to get to something we can use on a daily basis. In the 1960s, Marvin Minsky and Seymour Papert proposed the Summer Vision Project for undergraduates: connect a TV camera to a computer and identify objects in the field of view. Computer vision is now something that is commodified for specific tasks, but it continues to be a work in progress and, worldwide, has taken more than a few summers (and AI winters) and many more than a few undergrads.</p>\\n\\n\\n\\n<p>We can find many more examples across many more decades that reflect naiveté and optimism and–if we are honest–no small amount of ignorance and hubris. The two general lessons to be learned here are not that machine translation involves more than lookups and that computer vision involves more than edge detection, but that when we are confronted by complex problems in unfamiliar domains, we should be cautious of anything that looks simple at first sight, and that when we have successful solutions to a specific sliver of a complex domain, we should not assume those solutions are generalizable. This kind of humility is likely to deliver more meaningful progress and a more measured understanding of such progress. It is also likely to reduce the number of pundits in the future who mock past predictions and ambitions, along with the recurring irony of machine-learning experts who seem unable to learn from the past trends in their own field.</p>\\n\\n\\n\\n<p>All of which brings us to <a href=\"https://www.deepmind.com/publications/a-generalist-agent\" rel=\"noreferrer noopener\" target=\"_blank\">DeepMind&#8217;s Gato</a> and the claim that the summit of artificial general intelligence (AGI) is within reach. The hard work has been done and reaching AGI is now a simple matter of scaling. At best, this is a false summit on the right path; at worst, it&#8217;s a local maximum far from AGI, which lies along a very different route in a different range of architectures and thinking.</p>\\n\\n\\n\\n<p>DeepMind&#8217;s Gato is an AI model that can be taught to carry out many different kinds of tasks based on a single transformer neural network. The 604 tasks Gato was trained on vary from playing Atari video games to chat, from navigating simulated 3D environments to following instructions, from captioning images to real-time, real-world robotics. The achievement of note is that it’s underpinned by a single model trained across all tasks rather than different models for different tasks and modalities. Learning how to ace Space Invaders does not interfere with or displace the ability to carry out a chat conversation.</p>\\n\\n\\n\\n<p><a href=\"https://arxiv.org/pdf/2205.06175.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">Gato was intended to</a> &#8220;test the hypothesis that training an agent which is generally capable on a large number of tasks is possible; and that this general agent can be adapted with little extra data to succeed at an even larger number of tasks.&#8221; In this, it succeeded. But how far can this success be generalized in terms of loftier ambitions? The <a href=\"https://twitter.com/NandoDF/status/1525397036325019649\" rel=\"noreferrer noopener\" target=\"_blank\">tweet</a> that provoked a wave of responses (this one included) came from DeepMind&#8217;s research director, Nando de Freitas: &#8220;It&#8217;s all about scale now! The game is over!&#8221;</p>\\n\\n\\n\\n<p>The game in question is the quest for AGI, which is closer to what science fiction and the general public think of as AI than the narrower but applied, task-oriented, statistical approaches that constitute commercial machine learning (ML) in practice.</p>\\n\\n\\n\\n<p>The claim is that AGI is now simply a matter of improving performance, both in hardware and software, and making models bigger, using more data and more kinds of data across more modes. Sure, there&#8217;s <a href=\"https://twitter.com/NandoDF/status/1525398087203983360\" rel=\"noreferrer noopener\" target=\"_blank\">research work</a> to be done, but now it&#8217;s all about turning the dials up to 11 and beyond and, voilà, we&#8217;ll have scaled the north face of the AGI to plant a flag on the summit.</p>\\n\\n\\n\\n<p>It&#8217;s easy to get breathless at altitude.</p>\\n\\n\\n\\n<p>When we look at other systems and scales, it&#8217;s easy to be drawn to superficial similarities in the small and project them into the large. For example, if we look at water swirling down a plughole and then out into the cosmos at spiral galaxies, we see a similar structure. But these spirals are more closely bound in our desire to see connection than they are in physics. In looking at scaling specific AI to AGI, it&#8217;s easy to focus on tasks as the basic unit of intelligence and ability. What we know of intelligence and learning systems in nature, however, suggests the relationships between tasks, intelligence, systems, and adaptation is more complex and more subtle. Simply scaling up one dimension of ability may simply scale up one dimension of ability without triggering emergent generalization.</p>\\n\\n\\n\\n<p>If we look closely at software, society, physics or life, we see that scaling is usually accompanied by fundamental shifts in organizing principle and process. Each scaling of an existing approach is successful up to a point, beyond which a different approach is needed. You can run a small business using office tools, such as spreadsheets, and a social media page. Reaching Amazon-scale is not a matter of bigger spreadsheets and more pages. Large systems have radically different architectures and properties to either the smaller systems they are built from or the simpler systems that came before them.</p>\\n\\n\\n\\n<p>It may be that artificial general intelligence is a far more significant challenge than taking task-based models and increasing data, speed, and number of tasks. We typically underappreciate how complex such systems are. We divide and simplify, make progress as a result, only to discover, as we push on, that the simplification was just that; a new model, paradigm, architecture, or schedule is needed to make further progress. Rinse and repeat. Put another way, just because you got to basecamp, what makes you think you can make the summit using the same approach? And what if you can&#8217;t see the summit? If you don&#8217;t know what you&#8217;re aiming for, it&#8217;s difficult to plot a course to it.</p>\\n\\n\\n\\n<p>Instead of assuming the answer, we need to ask: <a href=\"https://www.oreilly.com/radar/closer-to-agi/\" rel=\"noreferrer noopener\" target=\"_blank\">How do we define AGI</a>? Is AGI simply task-based AI for N tasks and a sufficiently large value of N? And, even if the answer to that question is <em>yes</em>, is the path to AGI necessarily task-centric? How much of AGI is performance? How much of AGI is big/bigger/biggest data?</p>\\n\\n\\n\\n<p>When we look at life and existing learning systems, we learn that scale matters, but not in the sense suggested by a simple multiplier. It may well be that the trick to cracking AGI is to be found in scaling–but down rather than up.</p>\\n\\n\\n\\n<p>Doing more with less looks to be more important than doing more with more. For example, the GPT-3 language model is based on a network of 175 billion parameters. The first version of DALL-E, the prompt-based image generator, used a 12-billion parameter version of GPT-3; the second, improved version used only 3.5 billion parameters. And then there&#8217;s Gato, which achieves its multitask, multimodal abilities with only 1.2 billion.</p>\\n\\n\\n\\n<p>These reductions hint at the direction, but it&#8217;s not clear that Gato&#8217;s, GPT-3&#8217;s or any other contemporary architecture is necessarily the right vehicle to reach the destination. For example, how many training examples does it take to learn something? For biological systems, the answer is, in general, not many; for machine learning, the answer is, in general, very many. GPT-3, for example, developed its language model based on 45TB of text. Over a lifetime, a human reads and hears of the order of a billion words; a child is exposed to ten million or so before starting to talk. Mosquitoes can learn to avoid a particular pesticide after a <a href=\"https://www.nature.com/articles/s41598-022-05754-2\" rel=\"noreferrer noopener\" target=\"_blank\">single non-lethal exposure</a>. When you learn a new game–whether video, sport, board or card–you generally only need to be told the rules and then play, perhaps with a game or two for practice and rule clarification, to make a reasonable go of it. Mastery, of course, takes far more practice and dedication, but general intelligence is not about mastery.</p>\\n\\n\\n\\n<p>And when we look at the hardware and its needs, consider that while the brain is one of the most power-hungry organs of the human body, it still has a modest power consumption of <a href=\"https://www.scientificamerican.com/article/thinking-hard-calories/\" rel=\"noreferrer noopener\" target=\"_blank\">around 12 watts</a>. Over a life the brain will consume up to 10 MWh; training the GPT-3 language model took an estimated 1 GWh.</p>\\n\\n\\n\\n<p>When we talk about scaling, the game is only just beginning.</p>\\n\\n\\n\\n<p>While hardware and data matter, the architectures and processes that support general intelligence may be necessarily quite different to the architectures and processes that underpin current ML systems. Throwing faster hardware and all the world&#8217;s data at the problem is likely to see diminishing returns, although that may well let us scale a false summit from which we can see the real one.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/scaling-false-peaks/feed/', 'slash_comments': '0'}, {'title': 'The Metaverse Is Not a Place', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The Metaverse Is Not a Place'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/'}], 'link': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/', 'comments': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/#respond', 'published': 'Tue, 02 Aug 2022 18:38:46 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=2, tm_hour=18, tm_min=38, tm_sec=46, tm_wday=1, tm_yday=214, tm_isdst=0), 'authors': [{'name': 'Tim O’Reilly'}], 'author': 'Tim O’Reilly', 'author_detail': {'name': 'Tim O’Reilly'}, 'tags': [{'term': 'Metaverse', 'scheme': None, 'label': None}, {'term': 'Research', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14641', 'guidislink': False, 'summary': 'The metaphors we use to describe new technology constrain how we think about it, and, like an out-of-date map, often lead us astray. So it is with the metaverse. Some people seem to think of it as a kind of real estate, complete with land grabs and the attempt to bring traffic to whatever bit [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The metaphors we use to describe new technology constrain how we think about it, and, like an out-of-date map, often lead us astray. So it is with the metaverse. Some people seem to think of it as a kind of real estate, complete with land grabs and the attempt to bring traffic to whatever bit [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>The metaphors we use to describe new technology constrain how we think about it, and, <a href=\"https://www.linkedin.com/pulse/20121029141916-16553-language-is-a-map\" rel=\"noreferrer noopener\" target=\"_blank\">like an out-of-date map</a>, often lead us astray. So it is with the metaverse. Some people seem to think of it as <a href=\"https://news.bitcoin.com/metaverse-real-estate-sales-to-grow-by-5-billion-by-2026/\" rel=\"noreferrer noopener\" target=\"_blank\">a kind of real estate</a>, complete with land grabs and the attempt to bring traffic to whatever bit of virtual property they’ve created.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14642\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_01.png\" /></figure>\\n\\n\\n\\n<p>Seen through the lens of the real estate metaphor, the metaverse becomes a natural successor not just to <a href=\"https://en.wikipedia.org/wiki/Second_Life\" rel=\"noreferrer noopener\" target=\"_blank\">Second Life</a> but to the World Wide Web and to social media feeds, which can be thought of as a set of places (sites) to visit. Virtual Reality headsets will make these places more immersive, we imagine.</p>\\n\\n\\n\\n<p>But what if, instead of thinking of the metaverse as a set of interconnected virtual places, we think of it as a communications medium? Using this metaphor, we see the metaverse as a continuation of a line that passes through messaging and email to “rendezvous”-type social apps like Zoom, Google Meet, Microsoft Teams, and, for wide broadcast, Twitch + Discord. This is a progression from text to images to video, and from store-and-forward networks to real time (and, for broadcast, “stored time,” which is a useful way of thinking about recorded video), but in each case, the interactions are not place based but happening in the ether between two or more connected people. The occasion is more the point than the place.</p>\\n\\n\\n\\n<p>In an interview with Lex Fridman, Mark Zuckerberg disclaimed the notion of the metaverse as a place, but in the same sentence <a href=\"https://youtu.be/5zOHSysMmH0?t=1019\" rel=\"noreferrer noopener\" target=\"_blank\">described its future in a very place-based way</a>:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>A lot of people think that the Metaverse is about a place, but one definition of this is it&#8217;s about a time when basically immersive digital worlds become the primary way that we live our lives and spend our time.</em></p></blockquote>\\n\\n\\n\\n<p>Think how much more plausible this statement might be if it read:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>A lot of people think that the Metaverse is about a place, but one definition of this is it&#8217;s about a time when immersive digital worlds become the primary way that we communicate and share digital experiences.</em></p></blockquote>\\n\\n\\n\\n<p>My personal metaverse prototype moment does not involve VR at all, but Zoom. My wife Jen and I join our friend Sabrina over Zoom each weekday morning to exercise together. Sabrina leads the sessions by sharing her Peloton app, which includes live and recorded exercise videos. Our favorites are the strength training videos with <a href=\"https://www.onepeloton.com/instructors/peloton_r\" rel=\"noreferrer noopener\" target=\"_blank\">Rad Lopez</a> and the 15-minute abs videos with <a href=\"https://www.onepeloton.com/instructors/bike/robin\" rel=\"noreferrer noopener\" target=\"_blank\">Robin Arzón</a>. We usually start with Rad and end with Robin, for a vigorous 45-minute workout.</p>\\n\\n\\n\\n<p>Think about this for a moment: Jen and I are in our home. Sabrina is in hers. Rad and Robin recorded their video tracks from their studios on the other side of the county. Jen and Sabrina and I are there in real time. Rad and Robin are there in stored time. We have joined five people in four different places and three different times into one connected moment and one connected place, “the place between” the participants.</p>\\n\\n\\n\\n<p>Sabrina also works out on her own on her Peloton bike, and that too has this shared quality, with multiple participants at various “thicknesses” of connection. While Jen and Sabrina and I are “enhancing” the sharing using real-time Zoom video, Sabrina’s “solo” bike workouts use the intrinsic sharing in the Peloton app, which lets participants see real-time stats from others doing the same ride.</p>\\n\\n\\n\\n<p>This is the true internet—the network of networks, with dynamic interconnections. If the metaverse is to inherit that mantle, it has to have that same quality. <em>Connection</em>.</p>\\n\\n\\n\\n<p>Hacker News user <a href=\"https://news.ycombinator.com/item?id=29083271\" rel=\"noreferrer noopener\" target=\"_blank\">kibwen put it beautifully</a> when they wrote:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>A metaverse involves some kind of shared space and shared experience across a networked medium. Not only is it more than just doing things in VR, a metaverse doesn&#8217;t even require VR.</em></p></blockquote>\\n\\n\\n\\n<h3>The metaverse as a vector</h3>\\n\\n\\n\\n<p>It’s useful to look at technology trends (lines of technology progression toward the future, and inheritance from the past) as vectors—quantities that can only be fully described by both a magnitude and a direction and that can be summed or multiplied to get a sense of how they might cancel, amplify, or redirect possible pathways to the future.</p>\\n\\n\\n\\n<p>I wrote about this idea back in 2020, in a piece called “<a href=\"https://www.oreilly.com/tim/21stcentury/\" rel=\"noreferrer noopener\" target=\"_blank\">Welcome to the 21st Century</a>,” in the context of using <a href=\"https://www.wired.com/1995/11/how-to-build-scenarios/\" rel=\"noreferrer noopener\" target=\"_blank\">scenario planning</a> to imagine the post-COVID future. It’s worth recapping here:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>Once you’ve let loose your imagination, observe the world around you and watch for what scenario planners sometimes call “news from the future”—data points that tell you that the world is trending in the direction of one or another of your imagined scenarios. As with any scatter plot, data points are all over the map, but when you gather enough of them, you can start to see the trend line emerge.…</em><br /><br /><em>If you think of trends as vectors, new data points can be seen as extending and thickening the trend lines and showing whether they are accelerating or decelerating. And as you see how trend lines affect each other, or that new ones need to be added, you can continually update your scenarios (or as those familiar with Bayesian statistics might put it, you can </em><a href=\"https://en.wikipedia.org/wiki/Prior_probability\" rel=\"noreferrer noopener\" target=\"_blank\"><em>revise your priors</em></a><em>). This can be a relatively unconscious process. Once you’ve built mental models of the world as it might be, the news that you read will slot into place and either reinforce or dismantle your imagined future.</em></p></blockquote>\\n\\n\\n\\n<p>Here’s how my thinking about the metaverse was formed by “news from the future” accreting around a technology-development vector:</p>\\n\\n\\n\\n<ol><li>I had a prior belief, <a href=\"https://web.archive.org/web/20000711041545/http://www.oreillynet.com/pub/a/network/2000/06/09/java_keynote.html\" rel=\"noreferrer noopener\" target=\"_blank\">going back decades</a>, that the internet is a tool for connection and communication, and that advances along that vector will be important. I’m always looking with soft focus for evidence that the tools for connection and communication are getting richer, trying to understand <em>how</em> they are getting richer and how they are changing society.&nbsp;</li><li>I’ve been looking at VR for years, trying various headsets and experiences, but they are mostly solo and feel more like stand-alone games or if shared, awkward and cartoonish. Then I read a thoughtful piece by my friend Craig Mod in which he noted that while he lives his physical life in a small town in Japan or <a href=\"https://craigmod.com/essays/walk_japan/\" rel=\"noreferrer noopener\" target=\"_blank\">walking its ancient footpaths</a>, he also has a work life in which he spends time daily with people all over the world. I believe he made the explicit connection to the metaverse, but neither he nor I can find the piece that planted this thought to confirm that. In any case, I think of Craig’s newsletter as where the notion that the metaverse is a continuation of the communications technologies of the internet took hold for me.</li><li>I began to see the connection to Zoom when friends started using interesting backgrounds, some of which make them appear other than where they are and others that make clear just where they are. (For example, my friend Hermann uses as a background the beach behind his home in New Zealand, which is more vividly place based than his home office, which could be anywhere.) That then brought my exercise sessions with Sabrina and Jen into focus as part of this evolving story.</li><li>I talked to <a href=\"https://www.sequoiacap.com/article/phil-libin-mmhmm-spotlight/\" rel=\"noreferrer noopener\" target=\"_blank\">Phil Libin</a> about his brilliant service <a href=\"https://www.mmhmm.app/\" rel=\"noreferrer noopener\" target=\"_blank\">mmhmm</a>, which makes it easy to create and deliver richer, more interactive presentations over Zoom and similar apps. The speaker literally gets to occupy the space of the presentation. Phil’s presentation on “<a href=\"https://www.youtube.com/watch?v=mBKIMhGO8WA\" rel=\"noreferrer noopener\" target=\"_blank\">The Out of Office World</a>” was where it all clicked. He talks about the hierarchy of communication and the tools for modulating it. (IMO this is a must-watch piece for anyone thinking about the future of internet apps. I’m surprised how few people seem to have watched it.)<br /></li></ol>\\n\\n\\n\\n<figure class=\"wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\\n\\n</div></figure>\\n\\n\\n\\n<ol start=\"5\"><li>Trying <a href=\"https://www.getsupernatural.com/\">Supernatural</a> using the Meta Quest 2 headset completed the connection between my experience using Zoom and Peloton for fitness with friends and the VR-dominant framing of the metaverse. Here I was, standing on the edge of one of the lava lakes at <a href=\"https://www.atlasobscura.com/places/erta-ale\">Erta Ale</a> in Ethiopia, an astonishing volcano right out of central casting for Mount Doom in <em>The Lord of the Rings</em>, working through warm-up exercises with a video of a fitness instructor green-screened into the scene, before launching into a boxing training game. Coach Susie was present in stored time, just like Robin and Rad. All that was missing was Jen and Sabrina. I’m sure that such shared experiences in remarkable places are very much part of the VR future.</li></ol>\\n\\n\\n\\n<p></p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><a href=\"https://www.youtube.com/watch?v=jufCUdibP4c\" rel=\"noreferrer noopener\" target=\"_blank\"><img alt=\"\" class=\"wp-image-14643\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_02.png\" /></a></figure>\\n\\n\\n\\n<p>That kind of shared experience is central to Mark Zuckerberg’s vision of <a href=\"https://www.youtube.com/watch?v=b9vWShsmE20\" rel=\"noreferrer noopener\" target=\"_blank\">socializing in the metaverse</a>.</p>\\n\\n\\n\\n<figure class=\"wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\\n\\n</div></figure>\\n\\n\\n\\n<p>In that video, Zuck shows off lavishly decorated personal spaces, photorealistic and cartoon avatars, and an online meeting interrupted by a live video call. He says:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>It&#8217;s a ways off but you can start to see some of the fundamental building blocks take shape. First the feeling of presence. This is the defining quality of the metaverse. You&#8217;re going to really feel like you&#8217;re there with other people. You&#8217;ll see their facial expressions, you&#8217;ll see their body language, maybe figure out if they&#8217;re actually holding a winning hand—all the subtle ways that we communicate that today&#8217;s technology can&#8217;t quite deliver.</em></p></blockquote>\\n\\n\\n\\n<p>I totally buy the idea that presence is central. But Meta’s vision seems to miss the mark in its focus on avatars. Embedded video delivers more of that feeling of presence with far less effort on the part of the user than learning to create avatars that mimic our gestures and expressions.</p>\\n\\n\\n\\n<p>Chris Milk, the CEO of Within, the company that created Supernatural, both agreed and disagreed about avatars when explaining the company’s origin story to me in a phone conversation a few months ago:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>What we learned early on was that photorealism matters a lot in terms of establishing presence and human connection. Humans, captured using photorealistic methods like immersive video, allow for a deeper connection between the audience and the people recorded in the immersive VR experience. The audience feels present in the story with them. But it&#8217;s super hard to do from a technical standpoint and you give up a bunch of other things. The trade-off is that you can have photorealism but sacrifice interactivity, as the photorealistic humans need to be prerecorded. Alternatively, you can have lots of interactivity and human-to-human communication, but you give up on anyone looking real. In the latter, the humans need to be real-time-rendered avatars, and those, for the moment, don’t look remotely like real humans.</em></p></blockquote>\\n\\n\\n\\n<p>At the same time, Milk pointed out that humans are able to read a lot into even crude avatars, especially when they’re accompanied by real-time communication using voice.</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>Especially if it’s someone you already know, then the human connection can overcome a lot of missing visual realism. We did an experiment back in 2014 or 2015, probably. Aaron [Koblin, the cofounder of Within] was living in San Francisco, and I was in Los Angeles. We had built a VR prototype where we each had a block for the head and two blocks for our hands. I got into my headset in LA, and Aaron&#8217;s blocks were sitting over on the floor across from me as his headset and hand controllers were sitting on his floor in San Francisco. All of a sudden the three blocks jumped up off the ground into the air as he picked up his headset and put it on. The levitating cubes “walked” up to me, waved, and said, “Hey.” Immediately, before I even heard the voice, I recognized the person in those blocks as Aaron. I recognized through the posture and gait the spirit of Aaron in these three cubes moving through space. The resolution, or any shred of photorealism, was completely absent, but the humanity still showed through. And when his voice came out of them, my brain just totally accepted that the soul of Aaron now resides in these three floating cubes. Nothing was awkward about communicating back and forth. My brain just accepted it instantly. </em></p></blockquote>\\n\\n\\n\\n<p>And that’s where we get back to vectors. Understanding the future of photorealism in the metaverse depends on the speed and direction of progress in AI. In many ways, a photorealistic avatar is a kind of <a href=\"https://en.wikipedia.org/wiki/Deepfake\" rel=\"noreferrer noopener\" target=\"_blank\">deepfake</a>, and we know how computationally expensive their creation is today. How long will it be before the creation of deepfakes is cheap enough and fast enough that hundreds of millions of people can be creating and using them in real time? I suspect it will be a while.</p>\\n\\n\\n\\n<p>Mmhmm’s blending of video and virtual works really well, using today’s technology. It’s ironic that in Meta’s video about the future, video is only shown on a screen in the virtual space rather than as an integral part of it. Meta could learn a lot from mmhmm.</p>\\n\\n\\n\\n<p>On the other hand, creating a vast library of immersive 3D still images of amazing places into which either avatars or green-screened video images can be inserted seems much closer to realization. It’s still hard, but the problem is orders of magnitude smaller. The virtual spaces offered by Supernatural and other VR developers give an amazing taste of what’s possible here.</p>\\n\\n\\n\\n<p>In this regard, an interesting sidenote came from a virtual session that we held earlier this year at the Social Science Foo Camp (an event put together annually by O’Reilly, Meta, and Sage) using the <a href=\"https://engagevr.io/\" rel=\"noreferrer noopener\" target=\"_blank\">ENGAGE</a> virtual media conferencing app. The group began their discussion in one of the default meeting spaces, but one of the attendees, Adam Flaherty, proposed that they have it in a more appropriate place. They moved to a beautifully rendered version of <a href=\"https://en.wikipedia.org/wiki/Bodleian_Library\" rel=\"noreferrer noopener\" target=\"_blank\">Oxford’s Bodleian Library</a>, and attendees reported that the entire tenor of the conversation changed.</p>\\n\\n\\n\\n<p>Two other areas worth thinking about:</p>\\n\\n\\n\\n<ol><li>Social media evolved from a platform for real-time interaction (real-time status updates, forums, conversations, and groups) to one that’s often dominated by stored-time interaction (posts, stories, reels, et al). Innovation in formats for stored-time communications is at the heart of future social media competition, as TikTok has so forcefully reminded Facebook. There’s a real opportunity for developers and influencers to pioneer new formats as the metaverse unfolds.</li><li>Bots are likely to play a big role in the metaverse, just as they do in today’s gaming environments. Will we be able to distinguish bots from humans? Chris Hecker’s indie game <a href=\"http://www.spyparty.com/\" rel=\"noreferrer noopener\" target=\"_blank\"><em>SpyParty</em></a>, prototyped in 2009, made this a central feature of <a href=\"https://en.wikipedia.org/wiki/SpyParty\" rel=\"noreferrer noopener\" target=\"_blank\">its game play</a>, requiring two human players (one spy and one sniper) to find or evade each other among a party crowded with bots (what game developers call non-player characters or NPCs). Bots and deepfakes are already transforming our social experiences on the internet; expect this to happen on steroids in the metaverse. Some bots will be helpful, but others will be malevolent and disruptive. We will need to tell the difference.</li></ol>\\n\\n\\n\\n<h3>The need for interoperability</h3>\\n\\n\\n\\n<p>There’s one thing that a focus on communications as the heart of the metaverse story reminds us: communication, above all, depends on interoperability. A balkanized metaverse in which a few big providers engage in a winner-takes-all competition to create the Meta- or Apple- or whatever-owned metaverse will take far longer to develop than one that allows developers to create great environments and experiences and connect them bit by bit with the innovations of others. It would be far better if the metaverse were an extension of the internet (“the network of networks”) rather than an attempt to replace it with a walled garden.</p>\\n\\n\\n\\n<p>Some things that it would be great to have be interoperable:</p>\\n\\n\\n\\n<ul><li><strong>Identity.</strong> We should be able to use the digital assets that represent who we are across platforms, apps, and places offered by different companies.</li><li><strong>Sensors.</strong> Smartwatches, rings, and so forth are increasingly being used to collect physiological signals. This technology can be built into VR-specific headsets, but we would do better if it were easily shared between devices from different providers.</li><li><strong>Places.</strong> (Yes, places are part of this after all.) Rather than having a single provider (say Meta) become the ur-repository of photorealistic 360-degree immersive spaces, it would be great to have an interoperability layer that allows their reuse.</li><li><strong>Bot identification.</strong> Might NFTs end up becoming the basis for a nonrepudiable form of identity that must be produced by both humans and bots? (I suspect we can only force bots to identify themselves as such if we also require humans to do so.)</li></ul>\\n\\n\\n\\n<h3>Foundations of the metaverse</h3>\\n\\n\\n\\n<p>You can continue this exercise by thinking about the metaverse as the combination of multiple technology trend vectors progressing at different speeds and coming from different directions, and pushing the overall vector forward (or backward) accordingly. No new technology is the product of a single vector.</p>\\n\\n\\n\\n<p>So rather than settling on just “the metaverse is a communications medium,” think about the various technology vectors besides real-time communications that are coming together in the current moment. What news from the future might we be looking for?</p>\\n\\n\\n\\n<ul><li><strong>Virtual Reality/Augmented Reality. </strong>Lighter and less obtrusive headsets. Advances in 3D video recording. Advances in sensors, including eye-tracking, expression recognition, physiological monitoring, even <a href=\"https://www.cnbc.com/2019/09/23/facebook-announces-acquisition-of-brain-computing-start-up-ctrl-labs.html\" rel=\"noreferrer noopener\" target=\"_blank\">brain-control interfaces</a>. Entrepreneurial innovations in the balance between AR and VR. (Why do we think of them as mutually exclusive rather than on a continuum?)</li><li><strong>Social media. </strong>Innovations in connections between influencers and fans. How does stored time become more real time?</li><li><strong>Gaming. </strong>Richer integration between games and communications. What’s the next Twitch + Discord?</li><li><strong>AI. </strong>Not just deepfakes but the proliferation of AIs and bots as participants in social media and other communications. NPCs becoming a routine part of our online experience outside of gaming. Standards for identification of bots versus humans in online communities.</li><li><strong>Cryptocurrencies and “Web3.”</strong>&nbsp;Does crypto/Web3 provide new business models for the metaverse? (BTW, I enjoyed the way that Neal Stephenson, in <a href=\"https://en.wikipedia.org/wiki/Reamde\" rel=\"noreferrer noopener\" target=\"_blank\"><em>Reamde</em></a>, had his character design the business model and money flows for his online game before he designed anything else. Many startups just try to get users and assume the business model will follow, but that has led us down the dead end of advertising and <a href=\"https://en.wikipedia.org/wiki/Surveillance_capitalism\" rel=\"noreferrer noopener\" target=\"_blank\">surveillance capitalism</a>.) </li><li><strong>Identity. </strong>Most of today’s identity systems are centralized in one way or another, with identity supplied by a trusted provider or verifier. Web3 proponents, however, are exploring a variety of systems for decentralized “<a href=\"https://en.wikipedia.org/wiki/Self-sovereign_identity\" rel=\"noreferrer noopener\" target=\"_blank\">self-sovereign identity</a>,” including Vitalik Buterin’s “<a href=\"https://vitalik.eth.limo/general/2022/01/26/soulbound.html\" rel=\"noreferrer noopener\" target=\"_blank\">soulbound tokens</a>.” The vulnerability of crypto systems to <a href=\"https://en.wikipedia.org/wiki/Sybil_attack\">Sybil attacks</a> in the absence of verifiable identity is driving a lot of innovation in the identity space. <a href=\"https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/\" rel=\"noreferrer noopener\" target=\"_blank\">Molly White’s skeptical survey of these various initiatives</a> is a great overview of the problem and the difficulties in overcoming it. Gordon Brander’s “<a href=\"https://subconscious.substack.com/p/soulbinding-like-a-state\" rel=\"noreferrer noopener\" target=\"_blank\">Soulbinding Like A State</a>,” a riff on Molly White’s post and James C. Scott’s <a href=\"https://en.wikipedia.org/wiki/Seeing_Like_a_State\" rel=\"noreferrer noopener\" target=\"_blank\"><em>Seeing Like A State</em></a>, provides a further warning: “Scott’s framework reveals…that the dangers of legibility are not related to the sovereignty of an ID. There are many reasons self-sovereignty is valuable, but the function of a self-sovereign identity is still to make the bearer legible. What’s measured gets managed. What’s legible gets controlled.” As is often the case, no perfect solution will be found, but society will adopt an imperfect solution by making trade-offs that are odious to some, very profitable to others, and that the great mass of users will passively accept.</li></ul>\\n\\n\\n\\n<p>There’s a lot more we ought to be watching. I’d love your thoughts in the comments.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/feed/', 'slash_comments': '0'}, {'title': 'Radar Trends to Watch: August 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: August 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/#respond', 'published': 'Tue, 02 Aug 2022 11:18:24 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=2, tm_hour=11, tm_min=18, tm_sec=24, tm_wday=1, tm_yday=214, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14631', 'guidislink': False, 'summary': 'The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to explain JavaScript code.</p>\\n\\n\\n\\n<p>On other fronts, NIST has released the first proposed standard for post-quantum cryptography (i.e., cryptography that can’t be broken by quantum computers). CRISPR has been used in human trials to re-engineer a patient’s DNA to reduce cholesterol. And a surprising number of cities are paying high tech remote workers to move there.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li>Regardless of where a company is based, to avoid legal problems later, it’s a good idea to build AI and other data-based systems that <a href=\"https://thenextweb.com/news/european-or-not-make-sure-your-ai-business-sticks-to-eu-data-laws\" rel=\"noreferrer noopener\" target=\"_blank\">observe the EU’s data laws</a>.</li><li><a href=\"https://openai.com/blog/dall-e-now-available-in-beta/\" rel=\"noreferrer noopener\" target=\"_blank\">Public (beta) access to DALL-E is beginning</a>! It might take a while to get in because there are over a million on the waitlist. Accepted users get 50 free credits the first month, 15/month thereafter; a credit allows you to give one prompt, which returns 4 images. Users can buy additional credits.</li><li>Researchers have used reinforcement learning to build a <a href=\"https://www.technologyreview.com/2022/07/18/1056059/robot-dog-ai-reinforcement/\" rel=\"noreferrer noopener\" target=\"_blank\">robotic dog that learns to walk on its own</a> in the real world (i.e., without prior training and use of a simulator).</li><li>Princeton held a <a href=\"https://sites.google.com/princeton.edu/rep-workshop/\" rel=\"noreferrer noopener\" target=\"_blank\">workshop</a> on the <a href=\"https://twitter.com/random_walker/status/1542879397245423616\" rel=\"noreferrer noopener\" target=\"_blank\">reproducibility crisis</a> that the use of machine learning is causing in science. Evaluating the accuracy of results from machine learning is a problem that most scientific disciplines aren’t yet equipped to deal with.</li><li>Microsoft has revised its <a href=\"https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">Responsible AI standard</a>, making recommendations more concrete, particularly in the areas of accountability, transparency, fairness, safety, privacy, and inclusiveness. Microsoft also provides <a href=\"https://www.microsoft.com/en-us/ai/responsible-ai-resources\" rel=\"noreferrer noopener\" target=\"_blank\">tools and resources</a> to help developers build responsible AI systems.</li><li>The Dallery Gallery has published a <a href=\"https://dallery.gallery/the-dalle-2-prompt-book/\" rel=\"noreferrer noopener\" target=\"_blank\">Prompt Engineering Guide to DALL-E</a>. (DALL-E is maintaining a <a href=\"https://help.openai.com/en/articles/4936794-is-dall-e-available-yet\" rel=\"noreferrer noopener\" target=\"_blank\">waitlist</a> for free trial accounts.)</li><li>Simon Willison has successfully used GPT-3 to <a href=\"https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/\" rel=\"noreferrer noopener\" target=\"_blank\">explain how code works</a>. It is amazingly good and, as Simon pointed out, works both on code that he understands, and code that he doesn’t.</li><li><a href=\"https://huggingface.co/bigscience/bloom\" rel=\"noreferrer noopener\" target=\"_blank\">Bloom</a>, the open and transparent large language model developed by the BigScience group, is <a href=\"https://bigscience.huggingface.co/blog/bloom\" rel=\"noreferrer noopener\" target=\"_blank\">finished</a>!&nbsp; You can try it out, download it, and read its specifications. Unlike all other large language models, Bloom was developed in public, and is open to the public.</li><li>Radiologists outperform AI systems operating by themselves at detecting breast cancer from mammograms. However, a <a href=\"https://www.technologyreview.com/2022/07/11/1055677/ai-diagnose-breast-cancer-mammograms/\" rel=\"noreferrer noopener\" target=\"_blank\">system designed to collaborate</a> with radiologists in making decisions is better than either radiologists or AI alone. (The big question is whether these results hold up when taken to other hospitals.)</li><li>You liked Copilot? Try <a href=\"https://www.autoregex.xyz/\" rel=\"noreferrer noopener\" target=\"_blank\">Autoregex</a>: GPT-3 to generate regular expressions from natural language descriptions.</li><li><a href=\"https://github.com/facebookresearch/fairseq/tree/nllb\" rel=\"noreferrer noopener\" target=\"_blank\">No Language Left Behind</a> (NLLB) is a Meta AI project that translates text directly between any pair of over 200 languages. Benchmarks, training code, and models are all open source.</li><li><a href=\"https://www.nature.com/articles/s41562-022-01383-x\" rel=\"noreferrer noopener\" target=\"_blank\">Democratic AI</a> is an experiment in human-in-the-loop design that enables an AI system to design a social mechanism with human collaboration. </li><li>The Allen Institute, Microsoft, and others have developed a tool to <a href=\"https://www.technologyreview.com/2022/07/06/1055458/ai-research-emissions-energy-efficient/\" rel=\"noreferrer noopener\" target=\"_blank\">measure the energy use and emissions generated by training AI models</a> on Azure. They have found that emissions can be reduced substantially by training during periods when renewable power is at its peak.</li><li><a href=\"https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html\" rel=\"noreferrer noopener\" target=\"_blank\">Minerva</a> is a large language model that Google has trained to solve quantitative reasoning (i.e., mathematics) problems, generating simple proofs in addition to answers. The problem domain extends through pre-calculus, including algebra and geometry, roughly at a high school level. Minerva has also been trained and tested in chemistry and physics.  </li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Perhaps the scariest exploit in security would be a <a href=\"https://arstechnica.com/information-technology/2022/07/researchers-unpack-unkillable-uefi-rootkit-that-survives-os-reinstalls/\" rel=\"noreferrer noopener\" target=\"_blank\">rootkit that cannot be detected or removed</a>, even by wiping the disk and reinstalling the operating system.&nbsp;Such rootkits were recently discovered (one is named CosmicStrand); they have apparently been in the wild since 2016.</li><li>AWS is offering some customers a free <a href=\"https://thenewstack.io/aws-customers-can-now-order-a-free-mfa-security-key/\" rel=\"noreferrer noopener\" target=\"_blank\">multi factor authentication</a> (MFA) security key.</li><li>Lost passwords are an important <a href=\"https://arstechnica.com/information-technology/2022/07/malware-circulating-online-wrangles-industrial-systems-into-a-botnet/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">attack vector for industrial systems</a>. A system is installed; the default password is changed; the person who changed the password leaves; the password is lost; the company installs password recovery software, which is often malware-infested, to recover the password.</li><li>A <a href=\"https://www.wired.com/story/web-deanonymization-side-channel-attack-njit/\" rel=\"noreferrer noopener\" target=\"_blank\">new technique for browser de-anonymization</a> is based on correlating users’ activities on different websites.</li><li><a href=\"https://www.bleepingcomputer.com/news/security/ransomware-gang-now-lets-you-search-their-stolen-data/\" rel=\"noreferrer noopener\" target=\"_blank\">Ransomware companies are now using search engines</a> to allow their users to search the data they have stolen.</li><li>Ransomware doesn’t get as much attention in the news as it did last year, but in the past week one ransomware operation has shut down and released its decryptors, and two new ones (RedAlert and omega) <a href=\"https://www.bleepingcomputer.com/news/security/the-week-in-ransomware-july-8th-2022-one-down-many-to-go/\" rel=\"noreferrer noopener\" target=\"_blank\">have started</a>.</li><li>Apple has added “<a href=\"https://www.apple.com/newsroom/2022/07/apple-expands-commitment-to-protect-users-from-mercenary-spyware/\" rel=\"noreferrer noopener\" target=\"_blank\">lockdown mode</a>” to iOS.&nbsp; Lockdown mode provides an extreme degree of privacy; it is intended for people who believe they are being targeted by state-sponsored mercenary spyware.</li><li>The <a href=\"https://openssf.org/oss-security-mobilization-plan/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Source Security Mobilization Plan</a> is an initiative that aims to address major areas of open source security, including education, risk assessment, digital signatures, memory safety, incident response, and software supply chain management.</li><li>Mitre has released their annual list of the <a href=\"https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html\" rel=\"noreferrer noopener\" target=\"_blank\">25 most dangerous software weaknesses</a> (bugs, flaws, vulnerabilities).</li><li>Patches for the Log4J vulnerability were released back in February, 2022, but <a href=\"https://thenewstack.io/log4shell-hacks-on-and-on/\" rel=\"noreferrer noopener\" target=\"_blank\">many organizations have not applied them</a>, and remain vulnerable to attack.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Microsoft and Oracle have announced <a href=\"https://www.oracle.com/news/announcement/oracle-database-service-for-microsoft-azure-2022-07-20/\" rel=\"noreferrer noopener\" target=\"_blank\">Oracle Data Service</a>, which allows applications running on Azure to manage and use data in Oracle’s cloud. It’s a multicloud strategy that’s enabled by the cloud providers.</li><li>Google has announced a new programming language, <a href=\"https://9to5google.com/2022/07/19/carbon-programming-language-google-cpp/\" rel=\"noreferrer noopener\" target=\"_blank\">Carbon</a>, that is intended to be the successor to C++. One goal is complete interoperability between Carbon and existing C++ code and libraries.</li><li><a href=\"https://theburningmonk.com/2022/07/the-best-ways-to-save-money-on-lambda/\" rel=\"noreferrer noopener\" target=\"_blank\">How to save money on AWS Lambda</a>: watch your memory!&nbsp; Don’t over-allocate memory. This probably only applies to a few of your functions, but those functions are what drive the cost up.</li><li><a href=\"https://www.technologyreview.com/2022/07/14/1055894/us-military-sofware-linux-kernel-open-source/\" rel=\"noreferrer noopener\" target=\"_blank\">SocialCyber</a> is a <a href=\"https://www.darpa.mil/program/hybrid-ai-to-protect-integrity-of-open-source-code\" rel=\"noreferrer noopener\" target=\"_blank\">DARPA program</a> to understand the internals of open source software, along with the communities that create the software. They plan to use machine learning heavily, both to understand the code and to map and analyze communications within the communities. They are concerned about potential vulnerabilities in the software that the US military depends on.</li><li><a href=\"https://thenewstack.io/whats-next-in-webassembly/\" rel=\"noreferrer noopener\" target=\"_blank\">WebAssembly in the cloud</a>? Maybe it isn’t just a client-side technology. As language support grows, so do the kinds of applications Wasm can support.</li><li>A <a href=\"https://tidelift.com/2022-open-source-software-supply-chain-survey\" rel=\"noreferrer noopener\" target=\"_blank\">surveyreports</a> that 62% of its respondents were only “somewhat confident” that open source software was “secure, up-to-date, and well-maintained.”&nbsp; Disappointing as this may be, it’s actually an improvement over prior results.</li><li>Is <a href=\"https://thenewstack.io/infrastructure-as-code-goes-low-code-no-code/\" rel=\"noreferrer noopener\" target=\"_blank\">low-code infrastructure as code</a> the future of cloud operations?</li><li><a href=\"https://lunduke.substack.com/p/tiny-core-linux-130-full-linux-desktop\" rel=\"noreferrer noopener\" target=\"_blank\">Tiny Core Linux</a> is amazingly small: a 22MB download, and runs in 48MB of RAM. As a consequence, it’s also amazingly fast. With a few exceptions, making things small has not been a trend over the past few years.&nbsp;We hope to see more of this.</li><li>Yet another JavaScript web framework? <a href=\"https://thenewstack.io/denos-fresh-uses-server-side-rendering-for-faster-apps/\" rel=\"noreferrer noopener\" target=\"_blank\">Fresh</a> does server-side rendering, and is based on Deno rather than NodeJS.</li></ul>\\n\\n\\n\\n<h2>Web</h2>\\n\\n\\n\\n<ul><li>Facebook is considering whether to <a href=\"https://arstechnica.com/tech-policy/2022/07/meta-thinks-facebook-may-need-more-harmful-health-misinformation/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">rescind its bans on health misinformation</a>. The pandemic is over, after all. Except that it isn’t. However, being a conduit for health misinformation is clearly profitable.</li><li><a href=\"https://www.etsy.com/codeascraft/priority-hints-what-your-browser-doesnt-know-yet\" rel=\"noreferrer noopener\" target=\"_blank\">Priority Hints</a> are a way for web developers to tell the browser <a href=\"https://web.dev/priority-hints/\" rel=\"noreferrer noopener\" target=\"_blank\">which parts of the page are most important</a>, so that they can be rendered quickly. They are currently supported by the Chrome and Edge browsers.</li><li><a href=\"https://hotwired.dev/\" rel=\"noreferrer noopener\" target=\"_blank\">Hotwire</a>, <a href=\"https://htmx.org/\" rel=\"noreferrer noopener\" target=\"_blank\">HTMX</a>, and <a href=\"https://unpoly.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Unpoly</a> are frameworks for building complex web applications while minimizing the need for complex Javascript. Are they an alternative to heavyweight JavaScript frameworks like React? Could a return to server-side web applications lead to a resurgence of platforms like <a href=\"https://thenewstack.io/turbocharging-ruby-on-rails-with-html-over-the-wire/\" rel=\"noreferrer noopener\" target=\"_blank\">Ruby on Rails</a>?</li><li>Facebook has started <a href=\"https://www.ghacks.net/2022/07/17/facebook-has-started-to-encrypt-links-to-counter-privacy-improving-url-stripping/\" rel=\"noreferrer noopener\" target=\"_blank\">encrypting the portions of URLs that are used to track users</a>, preventing the Firefox and Brave browsers from stripping the tracking portion of the URL.</li><li><a href=\"https://www.technologyreview.com/2022/07/15/1056042/chinese-novel-censored-before-shared/\" rel=\"noreferrer noopener\" target=\"_blank\">A priori censorship?</a>&nbsp; A popular cloud-based word processor in China has been observed censoring content upon the creation of a link for sharing the content. The document is locked; it cannot be edited or even opened by the author.</li><li>The <a href=\"http://pilimi.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Pirate Library Mirror</a> is exactly what it says: a mirror of libraries of pirated books. It is focused on the preservation of human knowledge. There is no search engine, and it is only accessible by using BitTorrent over TOR.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://arstechnica.com/gaming/2022/07/minecraft-blocks-the-blockchain-from-its-block-game/\" rel=\"noreferrer noopener\" target=\"_blank\">Minecraft has decided that they will not “support or allow” the integration of NFTs</a> into their virtual worlds. They object to “digital ownership based on scarcity and exclusion.”</li><li><a href=\"https://arstechnica.com/information-technology/2022/07/usage-of-crypto-mixers-for-stymying-blockchain-investigations-hits-all-time-high/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">Mixers</a> are cryptocurrency services that randomize the currency you use; rather than pay with your own coin, you deposit money in a mixer and pay with randomly selected coins from other users. It’s similar to a traditional bank in that you never withdraw the same money you deposited.</li><li>So much for privacy. Coinbase, one of the largest cryptocurrency exchanges, <a href=\"https://theintercept.com/2022/06/29/crypto-coinbase-tracer-ice/\" rel=\"noreferrer noopener\" target=\"_blank\">sells geolocation data to ICE</a> (the US Immigration and Customs Enforcement agency).</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://phys.org/news/2022-07-quantum.html\" rel=\"noreferrer noopener\" target=\"_blank\">Quantum computers aren’t limited to binary</a>: That limit is imposed by analogy to traditional computers, but some quantum computers have access to more state, and taking advantage of those states may make applications like simulating physical or biological systems easier.</li><li>Is quantum-aided computing for some industrial applications just around the corner? <a href=\"https://thenewstack.io/quantum-computing-use-cases-how-viable-is-it-really/\" rel=\"noreferrer noopener\" target=\"_blank\">IonQ and GE have announced a results from a hybrid system</a> for risk management. The quantum computer does random sampling from probability distributions, which are computationally expensive for classical computers; the rest of the computation is classical.</li><li><a href=\"https://phys.org/news/2022-07-entanglement-quantum-memories.html\" rel=\"noreferrer noopener\" target=\"_blank\">Quantum networking</a> is becoming real: researchers have created entangled qubits via a 33-mile fiber optic connection. In addition to their importance for secure communications, quantum networks may be a crucial step in building quantum computers at scale. </li><li>NIST has announced <a href=\"https://arstechnica.com/information-technology/2022/07/nist-selects-quantum-proof-algorithms-to-head-off-the-coming-cryptopocalypse/\" rel=\"noreferrer noopener\" target=\"_blank\">four candidate algorithms for post-quantum cryptography</a>. While it may be years before quantum computing can break current algorithms, many organizations are anxious to start the transition from current algorithms. </li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>Not long ago (2020), DeepMind released AlphaFold, which used AI to solve protein folding problems. In 2021, they announced a public database containing the structure of a million proteins. With their latest additions, that database now contains the structure of <a href=\"https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe\" rel=\"noreferrer noopener\" target=\"_blank\">over 200 million</a> proteins, almost every protein known to science.</li><li>A <a href=\"https://www.nature.com/articles/s41586-022-04910-y\" rel=\"noreferrer noopener\" target=\"_blank\">motor made of DNA</a>!&nbsp; This nanoscale motor uses ideas from origami to fold DNA in a way that causes it to rotate when an electrical field is applied. </li><li>An <a href=\"https://www.bloomberg.com/news/articles/2022-07-18/brain-computer-interface-company-implants-new-type-of-device?sref=htOHjx5Y\" rel=\"noreferrer noopener\" target=\"_blank\">electrode has been implanted into the brain of an ALS patient</a> that will allow them to communicate thoughts via computer. The patient has otherwise lost the ability to move or speak.</li><li>Genetic editing with <a href=\"https://www.technologyreview.com/2022/07/12/1055773/crispr-gene-editing-cholesterol/\" rel=\"noreferrer noopener\" target=\"_blank\">CRISPR was tested in a human</a> to permanently lower LDL (“bad cholesterol”) levels. If this works, it could make heart attacks much rarer, and could be the first widespread use of CRISPR in humans.</li></ul>\\n\\n\\n\\n<h2>Energy</h2>\\n\\n\\n\\n<ul><li>Researchers in India have developed a carbon-negative process for <a href=\"https://techxplore.com/news/2022-07-green-hydrogen-biomass-abundant-renewable.html\" rel=\"noreferrer noopener\" target=\"_blank\">generating Hydrogen from biomass</a>. </li></ul>\\n\\n\\n\\n<h2>Work</h2>\\n\\n\\n\\n<ul><li>Some cities (largely in the US South and Midwest) are giving <a href=\"https://thenewstack.io/us-cities-try-luring-remote-tech-workers-with-cash/\" rel=\"noreferrer noopener\" target=\"_blank\">cash bonuses to tech worker</a>s who are willing to move there and work remotely.</li><li>The <a href=\"https://www.zdnet.com/article/fbi-warning-crooks-are-are-using-deepfakes-to-apply-for-remote-tech-jobs/\" rel=\"noreferrer noopener\" target=\"_blank\">FBI is warning employers</a> that they are seeing an increasing number of fraudulent applications for remote work in which the application uses stolen personal information and deepfake imagery.</li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/feed/', 'slash_comments': '0'}, {'title': 'SQL: The Universal Solvent for REST APIs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'SQL: The Universal Solvent for REST APIs'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/'}], 'link': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/', 'comments': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/#respond', 'published': 'Tue, 19 Jul 2022 11:16:39 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=7, tm_mday=19, tm_hour=11, tm_min=16, tm_sec=39, tm_wday=1, tm_yday=200, tm_isdst=0), 'authors': [{'name': 'Jon Udell'}], 'author': 'Jon Udell', 'author_detail': {'name': 'Jon Udell'}, 'tags': [{'term': 'Data', 'scheme': None, 'label': None}, {'term': 'Deep Dive', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14612', 'guidislink': False, 'summary': 'Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need to do it a page at a time, but pagination works differently from one API to the next. So does unpacking the resulting JSON structures. HTTP and JSON are low-level standards, and REST is a loosely-defined framework, but nothing guarantees absolute simplicity, never mind consistency across APIs.</p>\\n\\n\\n\\n<p>What if there were a way of reading from APIs that abstracted all the low-level grunt work and worked the same way everywhere? Good news! That is exactly what\\xa0<a href=\"https://steampipe.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Steampipe</a>\\xa0does. It&#8217;s a tool that translates REST API calls directly into SQL tables. Here are three examples of questions that you can ask and answer using Steampipe.</p>\\n\\n\\n\\n<h3>1. Twitter: What are recent tweets that mention PySpark?</h3>\\n\\n\\n\\n<p>Here&#8217;s a SQL query to ask that question:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>select\\n  id,\\n  text\\nfrom\\n  twitter_search_recent\\nwhere\\n  query = \\'pyspark\\'\\norder by\\n  created_at desc\\nlimit 5;</code></pre>\\n\\n\\n\\n<p>Here&#8217;s the answer:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>+---------------------+------------------------------------------------------------------------------------------------&gt;\\n| id                  | text                                                                                           &gt;\\n+---------------------+------------------------------------------------------------------------------------------------&gt;\\n| 1526351943249154050 | @dump Tenho trabalhando bastante com Spark, mas especificamente o PySpark. Vale a pena usar um &gt;\\n| 1526336147856687105 | RT @MitchellvRijkom: PySpark Tip &#x26a1;                                                            &gt;\\n|                     |                                                                                                &gt;\\n|                     | When to use what StorageLevel for Cache / Persist?                                             &gt;\\n|                     |                                                                                                &gt;\\n|                     | StorageLevel decides how and where data should be s…                                           &gt;\\n| 1526322757880848385 | Solve challenges and exceed expectations with a career as a AWS Pyspark Engineer. https://t.co/&gt;\\n| 1526318637485010944 | RT @JosMiguelMoya1: #pyspark #spark #BigData curso completo de Python y Spark con PySpark      &gt;\\n|                     |                                                                                                &gt;\\n|                     | https://t.co/qf0gIvNmyx                                                                        &gt;\\n| 1526318107228524545 | RT @money_personal: PySpark &amp;amp; AWS: Master Big Data With PySpark and AWS                    &gt;\\n|                     | #ApacheSpark #AWSDatabases #BigData #PySpark #100DaysofCode                                    &gt;\\n|                     | -&amp;gt; http…                                                                                    &gt;\\n+---------------------+------------------------------------------------------------------------------------------------&gt;</code></pre>\\n\\n\\n\\n<p>The table that&#8217;s being queried here,&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent\" rel=\"noreferrer noopener\" target=\"_blank\">twitter_search_recent</a>, receives the output from Twitter&#8217;s&nbsp;<a href=\"https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\" rel=\"noreferrer noopener\" target=\"_blank\">/2/tweets/search/recent</a>&nbsp;endpoint and formulates it as a table with&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent#inspect\" rel=\"noreferrer noopener\" target=\"_blank\">these columns</a>. You don&#8217;t have to make an HTTP call to that API endpoint or unpack the results, you just write a SQL query that refers to the documented columns. One of those columns,&nbsp;<code>query</code>, is special: it encapsulates Twitter&#8217;s&nbsp;<a href=\"https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\" rel=\"noreferrer noopener\" target=\"_blank\">query syntax</a>. Here, we are just looking for tweets that match&nbsp;<em>PySpark</em>&nbsp;but we could as easily refine the query by pinning it to specific users, URLs, types (<code>is:retweet</code>,&nbsp;<code>is:reply</code>), properties (<code>has:mentions</code>,&nbsp;<code>has_media</code>), etc. That query syntax is the same no matter how you&#8217;re accessing the API: from Python, from R, or from Steampipe. It&#8217;s plenty to think about, and all you should really need to know when crafting queries to mine Twitter data.</p>\\n\\n\\n\\n<h3>2. GitHub: What are repositories that mention PySpark?</h3>\\n\\n\\n\\n<p>Here&#8217;s a SQL query to ask that question:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>select \\n  name, \\n  owner_login, \\n  stargazers_count \\nfrom \\n  github_search_repository \\nwhere \\n  query = \\'pyspark\\' \\norder by stargazers_count desc \\nlimit 10;</code></pre>\\n\\n\\n\\n<p>Here&#8217;s the answer:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>+----------------------+-------------------+------------------+\\n| name                 | owner_login       | stargazers_count |\\n+----------------------+-------------------+------------------+\\n| SynapseML            | microsoft         | 3297             |\\n| spark-nlp            | JohnSnowLabs      | 2725             |\\n| incubator-linkis     | apache            | 2524             |\\n| ibis                 | ibis-project      | 1805             |\\n| spark-py-notebooks   | jadianes          | 1455             |\\n| petastorm            | uber              | 1423             |\\n| awesome-spark        | awesome-spark     | 1314             |\\n| sparkit-learn        | lensacom          | 1124             |\\n| sparkmagic           | jupyter-incubator | 1121             |\\n| data-algorithms-book | mahmoudparsian    | 1001             |\\n+----------------------+-------------------+------------------+</code></pre>\\n\\n\\n\\n<p>This looks very similar to the first example! In this case, the table that&#8217;s being queried,&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository\">github_search_repository</a>, receives the output from GitHub&#8217;s&nbsp;<a href=\"https://docs.github.com/en/rest/search#search-repositories\" rel=\"noreferrer noopener\" target=\"_blank\">/search/repositories</a>&nbsp;endpoint and formulates it as a table with&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository#inspect\" rel=\"noreferrer noopener\" target=\"_blank\">these columns</a>.</p>\\n\\n\\n\\n<p>In both cases the Steampipe documentation not only shows you the schemas that govern the mapped tables, it also gives examples (<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent#examples\" rel=\"noreferrer noopener\" target=\"_blank\">Twitter</a>,&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository#examples\" rel=\"noreferrer noopener\" target=\"_blank\">GitHub</a>) of SQL queries that use the tables in various ways.</p>\\n\\n\\n\\n<p>Note that these are just two of many available tables. The Twitter API is mapped to&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables\" rel=\"noreferrer noopener\" target=\"_blank\">7 tables</a>, and the GitHub API is mapped to&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables\" rel=\"noreferrer noopener\" target=\"_blank\">41 tables</a>.</p>\\n\\n\\n\\n<h3>3. Twitter + GitHub: What have owners of PySpark-related repositories tweeted lately?</h3>\\n\\n\\n\\n<p>To answer this question we need to consult two different APIs, then join their results. That&#8217;s even harder to do, in a consistent way, when you&#8217;re reasoning over REST payloads in Python or R. But this is the kind of thing SQL was born to do. Here&#8217;s one way to ask the question in SQL.</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>-- find pyspark repos\\nwith github_repos as (\\n  select \\n    name, \\n    owner_login, \\n    stargazers_count \\n  from \\n    github_search_repository \\n  where \\n    query = \\'pyspark\\' and name ~ \\'pyspark\\'\\n  order by stargazers_count desc \\n  limit 50\\n),\\n\\n-- find twitter handles of repo owners\\ngithub_users as (\\n  select\\n    u.login,\\n    u.twitter_username\\n  from\\n    github_user u\\n  join\\n    github_repos r\\n  on\\n    r.owner_login = u.login\\n  where\\n    u.twitter_username is not null\\n),\\n\\n-- find corresponding twitter users\\n  select\\n    id\\n  from\\n    twitter_user t\\n  join\\n    github_users g\\n  on\\n    t.username = g.twitter_username\\n)\\n\\n-- find tweets from those users\\nselect\\n  t.author-&gt;&gt;\\'username\\' as twitter_user,\\n  \\'https://twitter.com/\\' || (t.author-&gt;&gt;\\'username\\') || \\'/status/\\' || t.id as url,\\n  t.text\\nfrom\\n  twitter_user_tweet t\\njoin\\n  twitter_userids u\\non\\n  t.user_id = u.id\\nwhere\\n  t.created_at &gt; now()::date - interval \\'1 week\\'\\norder by\\n  t.author\\nlimit 5</code></pre>\\n\\n\\n\\n<p>Here is the answer:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>+----------------+---------------------------------------------------------------+-------------------------------------&gt;\\n| twitter_user   | url                                                           | text                                &gt;\\n+----------------+---------------------------------------------------------------+-------------------------------------&gt;\\n| idealoTech     | https://twitter.com/idealoTech/status/1524688985649516544     | Are you able to find creative soluti&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | Join our @codility Order #API Challe&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | #idealolife #codility #php          &gt;\\n| idealoTech     | https://twitter.com/idealoTech/status/1526127469706854403     | Our #ProductDiscovery team at idealo&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | Think you can solve it? &#x1f60e;          &gt;\\n|                |                                                               | &#x27a1;  https://t.co/ELfUfp94vB https://t&gt;/\\n| ioannides_alex | https://twitter.com/ioannides_alex/status/1525049398811574272 | RT @scikit_learn: scikit-learn 1.1 i&gt;\\n|                |                                                               | What\\'s new? You can check the releas&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | pip install -U…                     &gt;\\n| andfanilo      | https://twitter.com/andfanilo/status/1524999923665711104      | @edelynn_belle Thanks! Sometimes it &gt;\\n| andfanilo      | https://twitter.com/andfanilo/status/1523676489081712640      | @juliafmorgado Good luck on the reco&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | My advice: power through it + a dead&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | I hated my first few short videos bu&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | Looking forward to the video &#x1f642;</code></pre>\\n\\n\\n\\n<p>When APIs frictionlessly become tables, you can devote your full attention to reasoning over the abstractions represented by those APIs. Larry Wall, the creator of Perl, famously said: &#8220;Easy things should be easy, hard things should be possible.&#8221; The first two examples are things that should be, and are, easy: each is just 10 lines of simple, straight-ahead SQL that requires no wizardry at all.</p>\\n\\n\\n\\n<p>The third example is a harder thing. It would be hard in any programming language. But SQL makes it possible in several nice ways. The solution is made of concise stanzas (CTEs, Common Table Expressions) that form a pipeline. Each phase of the pipeline handles one clearly-defined piece of the problem. You can validate the output of each phase before proceeding to the next. And you can do all this with the most mature and widely-used grammar for selection, filtering, and recombination of data.</p>\\n\\n\\n\\n<h4>Do I have to use SQL?</h4>\\n\\n\\n\\n<p>No! If you like the idea of mapping APIs to tables, but you would rather reason over those tables in Python or R dataframes, then Steampipe can oblige. Under the covers it&#8217;s Postgres, enhanced with&nbsp;<a href=\"https://wiki.postgresql.org/wiki/Foreign_data_wrappers\" rel=\"noreferrer noopener\" target=\"_blank\">foreign data wrappers</a>&nbsp;that handle the API-to-table transformation. Anything that can connect to Postgres can connect to Steampipe, including SQL drivers like Python&#8217;s&nbsp;<code>psycopg2</code>&nbsp;and R&#8217;s&nbsp;<code>RPostgres</code>&nbsp;as well as business-intelligence tools like Metabase, Tableau, and PowerBI. So you can use Steampipe to frictionlessly consume APIs into dataframes, then reason over the data in Python or R.</p>\\n\\n\\n\\n<p>But if you haven&#8217;t used SQL in this way before, it&#8217;s worth a look. Consider this comparison of SQL to Pandas from&nbsp;<a href=\"https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e\" rel=\"noreferrer noopener\" target=\"_blank\">How to rewrite your SQL queries in Pandas</a>.</p>\\n\\n\\n\\n<figure class=\"wp-block-table\"><table class=\"\"><thead><tr><th class=\"has-text-align-center\">SQL</th><th class=\"has-text-align-center\">Pandas</th></tr></thead><tbody><tr><td class=\"has-text-align-center\">select * from airports</td><td class=\"has-text-align-center\">airports</td></tr><tr><td class=\"has-text-align-center\">select * from airports limit 3</td><td class=\"has-text-align-center\">airports.head(3)</td></tr><tr><td class=\"has-text-align-center\">select id from airports where ident = &#8216;KLAX&#8217;</td><td class=\"has-text-align-center\">airports[airports.ident == &#8216;KLAX&#8217;].id</td></tr><tr><td class=\"has-text-align-center\">select distinct type from airport</td><td class=\"has-text-align-center\">airports.type.unique()</td></tr><tr><td class=\"has-text-align-center\">select * from airports where iso_region = &#8216;US-CA&#8217; and type = &#8216;seaplane_base&#8217;</td><td class=\"has-text-align-center\">airports[(airports.iso_region == &#8216;US-CA&#8217;) &amp; (airports.type == &#8216;seaplane_base&#8217;)]</td></tr><tr><td class=\"has-text-align-center\">select ident, name, municipality from airports where iso_region = &#8216;US-CA&#8217; and type = &#8216;large_airport&#8217;</td><td class=\"has-text-align-center\">airports[(airports.iso_region == &#8216;US-CA&#8217;) &amp; (airports.type == &#8216;large_airport&#8217;)][[&#8216;ident&#8217;, &#8216;name&#8217;, &#8216;municipality&#8217;]]</td></tr></tbody></table></figure>\\n\\n\\n\\n<p>We can argue the merits of one style versus the other, but there&#8217;s no question that SQL is the most universal and widely-implemented way to express these operations on data. So no, you don&#8217;t have to use SQL to its fullest potential in order to benefit from Steampipe. But you might find that you want to.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/feed/', 'slash_comments': '0'}, {'title': 'Artificial Creativity?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Artificial Creativity?'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/artificial-creativity-2/'}], 'link': 'https://www.oreilly.com/radar/artificial-creativity-2/', 'comments': 'https://www.oreilly.com/radar/artificial-creativity-2/#respond', 'published': 'Tue, 12 Jul 2022 13:24:16 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=7, tm_mday=12, tm_hour=13, tm_min=24, tm_sec=16, tm_wday=1, tm_yday=193, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14604', 'guidislink': False, 'summary': 'There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&#160; As with the discussion of sentience, authors are [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&#160; As with the discussion of sentience, authors are [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&nbsp; As with the discussion of sentience, authors are being misled by a very human will to believe. And in being misled, they’re missing out on what’s important.</p>\\n\\n\\n\\n<p>It’s impressive to see AI-generated pictures of an <a href=\"https://twitter.com/OpenAI/status/1511714545529614338?ref_src=twsrc%5Etfw\" rel=\"noreferrer noopener\" target=\"_blank\">astronaut riding a horse</a>, or a <a href=\"https://www.thedailybeast.com/googles-new-text-to-image-generator-imagen-is-scary-accurate\" rel=\"noreferrer noopener\" target=\"_blank\">dog riding a bike in Times Square</a>. But where’s the creativity?&nbsp; Is it in the prompt or in the product?&nbsp; I couldn’t draw a picture of a dog riding a bike; I’m not that good an artist. Given a few pictures of dogs, Times Square, and whatnot, I could probably photoshop my way into something passable, but not very good. &nbsp;(To be clear: these AI systems are not automating photoshop.) So the AI is doing something that many, perhaps most humans, wouldn’t be able to do. That’s important. Very few humans (if any) can play Go at the level of AlphaGo. We’re getting used to being second-best.</p>\\n\\n\\n\\n<p>However, a computer replacing a human’s limited photoshop skills isn’t creativity. It took a human to say “create a picture of a dog riding a bike.” An AI couldn’t do that of its own volition. That’s creativity.&nbsp;But before writing off the creation of the picture, let’s think more about what that really means. Works of art really have two sources: the idea itself and the technique required to instantiate that idea. You can have all the ideas you want, but if you can’t paint like Rembrandt, you’ll never generate a Dutch master. Throughout history, painters have learned technique by copying the works of masters. What’s interesting about DALL-E, Imagen, and their relatives is that they supply the technique. Using DALL-E or Imagen, I could create a painting of a tarsier eating an anaconda without knowing how to paint.</p>\\n\\n\\n\\n<p>That distinction strikes me as very important. In the 20th and 21st centuries we’ve become very impatient with technique. We haven’t become impatient with creating good ideas. (Or at least strange ideas.) The “age of mechanical reproduction” seems to have made technique less relevant; after all, we’re heirs of the poet Ezra Pound, who famously said, “Make it new.”</p>\\n\\n\\n\\n<p>But does that quote mean what we think? Pound’s “Make it new” has been <a href=\"https://www.guernicamag.com/the-making-of-making-it-new/\" rel=\"noreferrer noopener\" target=\"_blank\">traced back</a> to 18th century China, and from there to the 12th century, something that’s not at all surprising if you’re familiar with Pound’s fascination with Chinese literature. What’s interesting, though, is that Chinese art has always focused on technique to a level that’s almost inconceivable to the European tradition. And “Make it new” has, within it, the acknowledgment that what’s new first has to be made. Creativity and technique don’t come apart that easily.</p>\\n\\n\\n\\n<p>We can see that in other art forms. Beethoven broke Classical music and put it back together again, but different-–he’s the most radical composer in the Western tradition (except for, perhaps, Thelonious Monk). And it’s worth asking how we get from what’s old to what’s new.&nbsp; AI has been used to <a href=\"https://www.classicfm.com/composers/beethoven/unfinished-tenth-symphony-completed-by-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">complete Beethoven’s 10th symphony</a>, for which Beethoven left a number of sketches and notes at the time of his death. The result is pretty good, better than the human attempts I’ve heard at completing the 10th.&nbsp;It sounds Beethoven-like; its flaw is that it goes on and on, repeating Beethoven-like riffs but without the tremendous forward-moving force that you get in Beethoven’s compositions. But completing the 10th isn’t the problem we should be looking at. How did we get Beethoven in the first place?&nbsp; If you trained an AI on the music Beethoven was trained on, would you eventually get the 9th symphony?&nbsp;Or would you get something that sounds a lot like Mozart and Haydn?</p>\\n\\n\\n\\n<p>I’m betting the latter. The progress of art isn’t unlike the structure of scientific revolutions, and Beethoven indeed took everything that was known, broke it apart, and put it back together differently. Listen to the <a href=\"https://www.youtube.com/watch?v=HljSXSm6v9M\" rel=\"noreferrer noopener\" target=\"_blank\">opening of Beethoven’s 9th symphony</a>: what is happening? Where’s the theme? It sounds like the orchestra is tuning up. When the first theme finally arrives, it’s not the traditional “melody” that pre-Beethoven listeners would have expected, but something that dissolves back into the sound of instruments tuning, then gets reformed and reshaped. Mozart would never do this. Or listen again to <a href=\"https://www.youtube.com/watch?v=a9UApyClFKA\" rel=\"noreferrer noopener\" target=\"_blank\">Beethoven’s 5th symphony</a>, probably the most familiar piece of orchestral music in the world. That opening duh-duh-duh-DAH–what kind of theme is that? Beethoven builds this movement by taking that four note fragment, moving it around, changing it, breaking it into even smaller bits and reassembling them. You can’t imagine a witty, urbane, polite composer like Haydn writing music like this. But I don’t want to worship some notion of Beethoven’s “genius” that privileges creativity over technique. Beethoven could never have gotten beyond Mozart and Haydn (with whom Beethoven studied) without extensive knowledge of the technique of composing; he would have had some good ideas, but he would never have known how to realize them. Conversely, the realization of radical ideas as actual works of art inevitably changes the technique. Beethoven did things that weren’t conceivable to Mozart or Haydn, and they changed the way music was written: those changes made the music of Schubert, Schumann, and Brahms possible, along with the rest of the 19th century. </p>\\n\\n\\n\\n<p>That brings us back to the question of computers, creativity, and craft. Systems like DALL-E and Imagen break apart the idea and the technique, or the execution of the idea. Does that help us be more creative, or less? I could tell Imagen to “paint a picture of a 15th century woman with an enigmatic smile,” and after a few thousand tries I might get something like the Mona Lisa. I don’t think that anyone would care, really.&nbsp; But this isn’t creating something new; it’s reproducing something old. If I magically appeared early in the 20th century, along with a computer capable of running Imagen (though only trained on art through 1900), would I be able to tell it to create a Picasso or a Dali? I have no idea how to do that. Nor do I have any idea what the next step for art is now, in the 21st century, or how I’d ask Imagen to create it. It sure isn’t Bored Apes. And if I could ask Imagen or DALL-E to create a painting from the 22nd century, how would that change the AI’s conception of technique?</p>\\n\\n\\n\\n<p>At least part of what I lack is the technique, for technique isn’t just mechanical ability; it’s also the ability to think the way great artists do. And that gets us to the big question:</p>\\n\\n\\n\\n<p>Now that we have abstracted technique away from the artistic process, can we build interfaces between the creators of ideas and the machines of technique in a way that allows the creators to “make it new”?&nbsp; That’s what we really want from creativity: something that didn’t exist, and couldn’t have existed, before.</p>\\n\\n\\n\\n<p>Can artificial intelligence help us to be creative? That’s the important question, and it’s a question about user interfaces, not about who has the biggest model.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/artificial-creativity-2/feed/', 'slash_comments': '0'}, {'title': 'Radar Trends to Watch: July 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: July 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/#respond', 'published': 'Tue, 05 Jul 2022 11:09:04 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=7, tm_mday=5, tm_hour=11, tm_min=9, tm_sec=4, tm_wday=1, tm_yday=186, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14591', 'guidislink': False, 'summary': 'This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask. The most important issue facing technology might now be [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask. The most important issue facing technology might now be [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask.</p>\\n\\n\\n\\n<p>The most important issue facing technology might now be the protection of privacy. While that’s not a new concern, it’s a concern that most computer users have been willing to ignore, and that most technology companies have been willing to let them ignore. New state laws that criminalize having abortions out of state and the stockpiling of location information by antiabortion groups have made privacy an issue that can’t be ignored.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.nature.com/articles/d41586-022-01705-z\" rel=\"noreferrer noopener\" target=\"_blank\">Big Science has almost finished training</a> its open source <a href=\"https://bigscience.huggingface.co/blog/model-training-launched\" rel=\"noreferrer noopener\" target=\"_blank\">BLOOM language model</a>, which was developed by volunteer researchers and trained using public funds. Bloom will provide an open, public platform for research into the capabilities of large language models and, specifically,&nbsp; issues like avoiding bias and toxic language. </li><li>AI tools like AlphaFold2 can <a href=\"https://colbyford.medium.com/am-i-hallucinating-or-can-ai-now-design-cancer-curing-antibodies-3ef1bef92106\" rel=\"noreferrer noopener\" target=\"_blank\">create new proteins</a>, not just analyze existing ones; the unexpected creation of new artifacts by an AI system is playfully called “hallucination.” The proteins designed so far probably aren’t useful; still, this is a major step forward in drug design.</li><li>Microsoft is <a href=\"https://www.theverge.com/2022/6/21/23177016/microsoft-retires-emotion-recognition-azure-ai-tool-api\" rel=\"noreferrer noopener\" target=\"_blank\">limiting or removing access</a> to some features in its face recognition service, Azure Face. Organizations will have to tell Microsoft how and why facial recognition will be used in their systems; and services like emotion recognition will be removed completely.</li><li>Amazon plans to <a href=\"https://www.reuters.com/technology/amazon-has-plan-make-alexa-mimic-anyones-voice-2022-06-22/\" rel=\"noreferrer noopener\" target=\"_blank\">give Alexa the ability to imitate anyone’s voice</a>, using under a minute of audio. They give the example of a (possibly dead) grandmother “reading” a book to a child. Other AI vendors (most notably <a href=\"https://thenextweb.com/news/openai-punished-dev-used-gpt-3-to-resurrect-dead-ethics\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAI/Microsoft</a>) have considered such mimicry unethical.</li><li><a href=\"https://github.com/dolthub/dolt\" rel=\"noreferrer noopener\" target=\"_blank\">Dolt</a> is a SQL database that lets you version data using git commands, You can clone, push, pull, fork, branch, and merge just as with git; you access data using standard SQL.</li><li>It’s sadly unsurprising that a robot incorporating a widely-used neural network (OpenAI CLIP) learns <a href=\"https://techxplore.com/news/2022-06-robots-racist-sexist-flawed-ai.html\" rel=\"noreferrer noopener\" target=\"_blank\">racist and sexist biases</a>, and that these biases affect its performance on tasks.</li><li>Building <a href=\"https://techxplore.com/news/2022-06-technology-self-driving-cars-memories.html\" rel=\"noreferrer noopener\" target=\"_blank\">autonomous vehicles with memory</a>, so that they can learn about objects on the routes they drive, may be an important step in making AV practical. In real life, most people drive over routes they are already familiar with. Autonomous vehicles should have the same advantage.</li><li>The argument about whether Google’s LaMDA is “sentient” continues, with a Google engineer placed on administrative leave for <a href=\"https://www.theguardian.com/technology/2022/jun/12/google-engineer-ai-bot-sentient-blake-lemoine\" rel=\"noreferrer noopener\" target=\"_blank\">publishing transcripts of conversations</a> that he claimed demonstrate sentience. Or are large language models just <a href=\"https://twitter.com/janellecshane/status/1535835610396692480\" rel=\"noreferrer noopener\" target=\"_blank\">squirrels</a>?</li><li>For <a href=\"https://techxplore.com/news/2022-06-ai-future-art.html\" rel=\"noreferrer noopener\" target=\"_blank\">artists working in collaboration with AI</a>, the possibilities and imperfections of AI are a means of extending their creativity.</li><li>Pete Warden’s proposal for <a href=\"https://petewarden.com/2022/06/09/what-are-ml-sensors/\" rel=\"noreferrer noopener\" target=\"_blank\">ML Sensors</a> could make developing embedded ML systems much simpler: push the machine learning into the sensors themselves.</li><li>Researchers using DALL-E 2 discovered that <a href=\"https://theconversation.com/do-ai-systems-really-have-their-own-secret-language-184335\" rel=\"noreferrer noopener\" target=\"_blank\">the model has a “secret vocabulary”</a> that’s not human language, but that can be used somewhat reliably to create consistent pictures. It may be an artifact of the model’s inability to say “I didn’t understand that”; given nonsense input, it is pulled towards similar words in the training corpus.</li><li>HuggingFace has made an <a href=\"https://huggingface.co/blog/hugging-face-endpoints-on-azure\" rel=\"noreferrer noopener\" target=\"_blank\">agreement</a> with Microsoft that will allow Azure customers to <a href=\"https://thenextweb.com/news/what-hugging-face-and-microsofts-collaboration-means-for-applied-ai\" rel=\"noreferrer noopener\" target=\"_blank\">run HuggingFace language models on the Azure platform</a>.</li><li>The startup <a href=\"https://predibase.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Predibase</a> has built a <a href=\"https://thenewstack.io/predibase-takes-declarative-approach-to-automl/\" rel=\"noreferrer noopener\" target=\"_blank\">declarative low-code platform</a> for building AI systems. In a declarative system, you describe the outcome you want, rather than the process for creating the outcome. The system figures out the process.</li><li>Researchers are developing AI models that implement <a href=\"https://techxplore.com/news/2022-06-artificial-intelligence-human.html\" rel=\"noreferrer noopener\" target=\"_blank\">metamemory</a>: the ability to remember whether or not you know something.</li><li>As the population ages, it will be more important to diagnose diseases like Alzheimer’s early, when treatment is still meaningful. AI is <a href=\"https://www.technologyreview.com/2022/06/02/1052942/evaluating-brain-mri-scans-with-the-help-of-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">providing tools</a> to help doctors analyze MRI images more accurately than humans. These tools don’t attempt diagnosis; they provide data about brain features.</li><li>Google has <a href=\"https://www.bleepingcomputer.com/news/technology/google-quietly-bans-deepfake-training-projects-on-colab/\" rel=\"noreferrer noopener\" target=\"_blank\">banned the training of Deepfakes</a> on Colab, its free Jupyter-based cloud programming platform.</li></ul>\\n\\n\\n\\n<h2>Metaverse</h2>\\n\\n\\n\\n<ul><li>Samsung and RedHat are working on <a href=\"https://thenewstack.io/samsung-red-hat-to-work-on-linux-drivers-for-future-tech/\" rel=\"noreferrer noopener\" target=\"_blank\">new memory architectures and device drivers</a> that will be adequate to the demands of a 3D-enabled, cloud-based metaverse.</li><li>The <a href=\"https://metaverse-standards.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Metaverse Standards Forum</a> is a new industry group with the goal of solving interoperability problems for the Metaverse. It views the Metaverse as the outgrowth of the Web, and plans to coordinate work between existing standards groups (like the W3C) relevant to the Metaverse.</li><li>Can the “<a href=\"https://thenewstack.io/how-the-open-metaverse-will-transform-our-online-identities/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Metaverse</a>” be the future of the Internet?&nbsp; The <a href=\"https://github.com/omigroup/omigroup/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Metaverse Interoperability Group</a> is building vendor-independent standards for social graphs, identities, and other elements of a Metaverse.</li><li><a href=\"https://techxplore.com/news/2022-06-augmented-reality-head-up-next-gen.html\" rel=\"noreferrer noopener\" target=\"_blank\">Holographic heads-up displays</a> allow for 3D augmented reality: the ability to project 3D images onto the real world (for example, onto a car’s windshield).</li><li>Google’s <a href=\"https://medium.com/@bilawal/new-google-api-turns-the-world-into-a-3d-canvas-for-augmented-reality-developers-on-ios-android-5c541a705800\" rel=\"noreferrer noopener\" target=\"_blank\">Visual Position Service</a> uses the data they’ve collected through Street View to provide high-accuracy positioning data for augmented reality applications. (This may be related to Niantic’s VPS, or they may just be using the same acronym.)</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>With the end of Roe v. Wade, <a href=\"https://www.siliconvalley.com/2022/06/27/search-histories-location-data-text-messages-how-personal-data-could-be-used-to-enforce-anti-abortion-laws/\" rel=\"noreferrer noopener\" target=\"_blank\">personal data, including search histories and location data, could be used to prosecute women who have abortions</a>. Data brokers already collect and sell this data. It is unclear how large Internet companies that also collect this data will respond. (Google has announced that they will <a href=\"https://blog.google/technology/safety-security/protecting-peoples-privacy-on-health-topics/\" rel=\"noreferrer noopener\" target=\"_blank\">delete location histories</a> that include visits to sensitive locations.)</li><li>Security researchers have identified over <a href=\"https://www.bleepingcomputer.com/news/security/over-900-000-kubernetes-instances-found-exposed-online/\" rel=\"noreferrer noopener\" target=\"_blank\">900,000 Kubernetes clusters that are exposed (and possibly vulnerable) to malicious scans</a>. 65% of them are in the US.</li><li>Sonatype has discovered a number of <a href=\"https://blog.sonatype.com/python-packages-upload-your-aws-keys-env-vars-secrets-to-web\" rel=\"noreferrer noopener\" target=\"_blank\">modules in the Python’s PyPI repository that steal AWS credentials</a> and other important data. Supply chain security will continue to be a problem for developers, regardless of the programming language or problem domain.</li><li><a href=\"https://blogs.microsoft.com/on-the-issues/2022/06/22/defending-ukraine-early-lessons-from-the-cyber-war/\" rel=\"noreferrer noopener\" target=\"_blank\">Microsoft’s analysis of Russia’s cyberwar efforts</a> show that they have increasingly attacked resources in countries allied with Ukraine (most notably the US), and that government computers that are on-premises are especially vulnerable.</li><li>Working with Fastly and Cloudflare, Apple has developed a service called <a href=\"https://thenextweb.com/news/apple-ios-16-banish-captchas\" rel=\"noreferrer noopener\" target=\"_blank\">Automatic Verification</a> that eliminates the need for Captchas. According to rumors, it will be enabled by default in the beta of iOS16.</li><li>A surprisingly small botnet (only 5,000 hosts) generated a <a href=\"https://arstechnica.com/information-technology/2022/06/tsunami-of-junk-traffic-that-broke-ddos-records-delivered-by-tiniest-of-botnets/\" rel=\"noreferrer noopener\" target=\"_blank\">record-setting DDOS attack</a> that peaked at 26M HTTPS requests per second. The botnet was so powerful because most of its devices belonged to cloud providers. Cloudflare’s free service was able to mitigate the attack.</li><li>A different kind of attack against neural networks: present them with <a href=\"https://ieeexplore.ieee.org/document/9581273\" rel=\"noreferrer noopener\" target=\"_blank\">inputs that drive worst-case energy consumption</a>, forcing processors to reduce their clock speed or even overheat. </li><li>A new attack called Hertzbleed uses <a href=\"https://arstechnica.com/tech-policy/2022/06/cryptocurrency-plunges-as-crypto-bank-celsius-suspends-withdrawals/\" rel=\"noreferrer noopener\" target=\"_blank\">small variations in a processor’s clock speed</a> while it is processing encryption keys to guess those keys. Intel and AMD CPUs are vulnerable. While this attack may never be seen in the wild, it shows how the complexity of modern processors creates vulnerabilities.</li><li><a href=\"https://www.bleepingcomputer.com/news/security/new-symbiote-malware-infects-all-running-processes-on-linux-systems/\" rel=\"noreferrer noopener\" target=\"_blank\">Symbiote is a new kind of malware that attacks Linux</a>, injects software into all running processes, and uses Berkeley packet filters (eBPF) to steal data and create covert communications channels. Symbiote uses <a href=\"https://thenewstack.io/the-symbiote-malware-what-we-know-so-far/\" rel=\"noreferrer noopener\" target=\"_blank\">dynamic linker hijacking</a> to link executables to modified system libraries at run time.</li><li>In the first quarter of 2022, the <a href=\"https://www.bleepingcomputer.com/news/security/ransomware-gangs-now-give-victims-time-to-save-their-reputation/\" rel=\"noreferrer noopener\" target=\"_blank\">number of known ransomware attacks was down 40%</a>, largely due to the disappearance of the Conti ransomware group. This drop is probably only temporary. Tactics also changed; attackers aren’t announcing the names of their victims publicly, preferring to negotiate a ransom privately. </li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Amazon has launched <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\" rel=\"noreferrer noopener\" target=\"_blank\">CodeWhisperer</a>, a direct competitor to GitHub Copilot.</li><li>Linus Torvalds predicts that <a href=\"https://thenewstack.io/rust-in-the-linux-kernel-by-2023-linus-torvalds-predicts/\" rel=\"noreferrer noopener\" target=\"_blank\">Rust will be used in the Linux kernel by 2023</a>.</li><li>GitHub Copilot is now <a href=\"https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/\" rel=\"noreferrer noopener\" target=\"_blank\">generally available</a> (for a price); it’s free to students and open source maintainers. Corporate licenses will be available later this year.</li><li>WebAssembly is making inroads. The universal WebAssembly runtime, <a href=\"https://wasmer.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Wasmer</a>, runs any code, on any platform. Impressive, if it delivers.</li><li><a href=\"https://thenewstack.io/when-webassembly-replaces-docker/\" rel=\"noreferrer noopener\" target=\"_blank\">Can WebAssembly replace Docker?</a> Maybe, in some applications. WASM provides portability and eliminates some security issues (possibly introducing its own); Docker sets up environments.</li><li>Mozilla’s <a href=\"https://blog.mozilla.org/en/mozilla/local-translation-add-on-project-bergamot/\" rel=\"noreferrer noopener\" target=\"_blank\">Project Bergamot</a> is an automated translation tool designed for use on the Web. It can be used to build multilingual forms and other web pages. Unlike most other AI technologies, Bergamot runs in the browser using WASM. No data is sent to the cloud.</li><li>Microsoft has <a href=\"https://thenewstack.io/microsoft-talks-collaborative-apps-at-build-conference/\" rel=\"noreferrer noopener\" target=\"_blank\">released</a> a framework called <a href=\"https://fluidframework.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Fluid</a> for building collaborative apps, such as Slack, Discord, and Teams. Microsoft will also be releasing <a href=\"https://docs.microsoft.com/en-us/azure/azure-fluid-relay/\" rel=\"noreferrer noopener\" target=\"_blank\">Azure Fluid Relay</a> to support Fluid-based applications.</li><li><a href=\"https://github.com/dragonflydb/dragonfly\" rel=\"noreferrer noopener\" target=\"_blank\">Dragonfly</a> is a new in-memory database that claims significantly faster performance than memcached and Redis.</li><li>The Chinese government has <a href=\"https://www.technologyreview.com/2022/05/30/1052879/censoring-china-open-source-backfire/\" rel=\"noreferrer noopener\" target=\"_blank\">blocked access to open source code</a> on Gitee, the Chinese equivalent to GitHub, saying that all code must be reviewed by the government before it can be released to the public.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://blog.trailofbits.com/2022/06/21/are-blockchains-decentralized/\" rel=\"noreferrer noopener\" target=\"_blank\">Is Blockchain Decentralized?</a> <a href=\"https://assets-global.website-files.com/5fd11235b3950c2c1a3b6df4/62af6c641a672b3329b9a480_Unintended_Centralities_in_Distributed_Ledgers.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">A study commissioned by DARPA</a> investigates whether a blockchain is truly immutable, or whether it can be modified without exploiting cryptographic vulnerabilities, but by attacking the blockchain’s implementation, networking, and consensus protocols. This is the most comprehensive examination of blockchain security that we’ve seen. </li><li>Jack Dorsey has announced that he’s working on <a href=\"https://cryptobriefing.com/jack-dorsey-tbd-build-web5-on-bitcoin/\" rel=\"noreferrer noopener\" target=\"_blank\">Web5</a>, which will be focused on identity management and be based on Bitcoin.</li><li>Molly White’s post questioning the possibility of <a href=\"https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/\" rel=\"noreferrer noopener\" target=\"_blank\">acceptably non-dystopian self-sovereign identity</a> is a must-read; she has an excellent summary and critique of just about all the work going on in the field.</li><li>Cryptographer Matthew Green makes an important <a href=\"https://blog.cryptographyengineering.com/2022/06/09/in-defense-of-cryptocurrency/\" rel=\"noreferrer noopener\" target=\"_blank\">argument for the technologies behind cryptocurrency</a> (though not for the current implementations).</li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>The Innovative Genomics Institute is trying to <a href=\"https://www.technologyreview.com/2022/06/14/1053843/carbon-capture-crispr-crops/\" rel=\"noreferrer noopener\" target=\"_blank\">use CRISPR gene editing to optimize plants for carbon storage</a>.</li><li>A printed artificial skin with embedded transistors may <a href=\"https://techxplore.com/news/2022-06-artificial-skin-capable-pain-touch-sensitive.html\" rel=\"noreferrer noopener\" target=\"_blank\">allow robots to feel pain</a>. That’s one step closer to dreaming of electric sheep.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://techxplore.com/news/2022-06-potential-p-computers.html\" rel=\"noreferrer noopener\" target=\"_blank\">Probabilistic computers</a>, built from probabilistic bits (p-bits), may provide a significant step forward for probabilistic decision making. This sounds esoteric, but it’s essentially what we’re asking AI systems to do. P-bits may also be able to simulate q-bits and quantum computing.</li><li>A system that <a href=\"https://thenextweb.com/news/eureka-scientists-just-linked-two-time-crystals-together-first-time\" rel=\"noreferrer noopener\" target=\"_blank\">links two time crystals</a> could be the basis for a new form of quantum computing. Time crystals can exist at room temperature, and remain coherent for much longer than existing qubit technologies.</li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/feed/', 'slash_comments': '0'}, {'title': '2022 Cloud Salary Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '2022 Cloud Salary Survey'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/'}], 'link': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/', 'comments': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/#respond', 'published': 'Wed, 22 Jun 2022 11:21:41 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=22, tm_hour=11, tm_min=21, tm_sec=41, tm_wday=2, tm_yday=173, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Cloud', 'scheme': None, 'label': None}, {'term': 'Radar Column', 'scheme': None, 'label': None}, {'term': 'Research', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14547', 'guidislink': False, 'summary': 'Last year, our&#160;report on cloud adoption&#160;concluded that adoption was proceeding rapidly; almost all organizations are using cloud services. Those findings confirmed the results we got in&#160;2020: everything was “up and to the right.” That’s probably still true—but saying “everything is still up and to the right” would be neither interesting nor informative. So rather than [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Last year, our&#160;report on cloud adoption&#160;concluded that adoption was proceeding rapidly; almost all organizations are using cloud services. Those findings confirmed the results we got in&#160;2020: everything was “up and to the right.” That’s probably still true—but saying “everything is still up and to the right” would be neither interesting nor informative. So rather than [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Last year, our&nbsp;<a href=\"https://learning.oreilly.com/library/view/the-cloud-in/9781492096733\" rel=\"noreferrer noopener\" target=\"_blank\">report on cloud adoption</a>&nbsp;concluded that adoption was proceeding rapidly; almost all organizations are using cloud services. Those findings confirmed the results we got in&nbsp;<a href=\"https://learning.oreilly.com/library/view/cloud-adoption-in/9781492088042\">2020</a>: everything was “up and to the right.” That’s probably still true—but saying “everything is still up and to the right” would be neither interesting nor informative. So rather than confirming the same results for a third year, we decided to do something different.</p>\\n\\n\\n\\n<p>This year’s survey asked questions about compensation for “cloud professionals”: the software developers, operations staff, and others who build cloud-based applications, manage a cloud platform, and use cloud services. We limited the survey to residents of the United States because salaries from different countries aren’t directly comparable; in addition to fluctuating exchange rates, there are different norms for appropriate compensation. This survey ran from April 4 through April 15, 2022, and was publicized via email to recipients of our&nbsp;<a href=\"https://www.oreilly.com/emails/newsletters\" rel=\"noreferrer noopener\" target=\"_blank\"><em>Infrastructure &amp; Ops Newsletter</em></a>&nbsp;whom we could identify as residing in the United States or whose location was unknown.</p>\\n\\n\\n\\n<div class=\"wp-block-group has-very-light-gray-background-color has-background\"><div class=\"wp-block-group__inner-container\">\\n<h4>Executive Summary</h4>\\n\\n\\n\\n<ul><li>Survey respondents earn an average salary of $182,000.</li><li>The average salary increase over the past year was 4.3%.</li><li>20% of respondents reported changing employers in the past year.</li><li>25% of respondents are planning to change employers because of compensation.</li><li>The average salary for women is 7% lower than the average salary for men.</li><li>63% of respondents work remotely all the time; 94% work remotely at least one day a week.</li><li>Respondents who participated in 40 or more hours of training in the past year received higher salary increases.</li></ul>\\n</div></div>\\n\\n\\n\\n<p>Of the 1,408 responses we initially received, 468 were disqualified. Respondents were disqualified (and the survey terminated) if the respondent said they weren’t a US resident or if they were under 18 years old; respondents were also disqualified if they said they weren’t involved with their organization’s use of cloud services. Another 162 respondents filled out part of the survey but didn’t complete it; we chose to include only complete responses. That left us with 778 responses. Participants came from 43 states plus Washington, DC. As with our other surveys, the respondents were a relatively senior group: the average age was 47 years old, and while the largest number identified themselves as programmers (43%), 14% identified as executives and 33% as architects.</p>\\n\\n\\n\\n<h2>The Big Picture</h2>\\n\\n\\n\\n<p>Cloud professionals are well paid. That’s not a surprise in itself. We expected salaries (including bonuses) to be high, and they were. The cloud professionals who responded to our survey earn an average salary of $182,000; the most common salary range among respondents was $150,000 to $175,000 per year (16% of the total), as shown in&nbsp;Figure 1. The peak was fairly broad: 68% of the respondents earn between $100,000 and $225,000 per year. And there was a significant “long tail” in the compensation stratosphere: 7% of the respondents earn over $300,000 per year, and 2.4% over $400,000 per year.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14550\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0101-2-1048x762.png\" /><figcaption>Figure 1. <em>Annual salary by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>We believe that job changes are part of what’s driving high salaries. After all, we’ve heard about talent shortages in almost every field, with many employers offering very high salaries to attract the staff they need. By staying with their current employer, an employee may get an annual salary increase of 4%. But if they change jobs, they might get a significantly higher offer—20% or more—plus a signing bonus.</p>\\n\\n\\n\\n<p>20% of the respondents reported that they changed employers in the past year. That number isn’t high in and of itself, but it looks a lot higher when you add it to the 25% who are planning to leave jobs over compensation. (Another 20% of the respondents declined to answer this question.) It’s also indicative that 19% of the respondents received promotions. There was some overlap between those who received promotions and those who changed jobs (5% of the total said “yes” to both questions, or roughly one quarter of those who changed jobs). When you look at the number of respondents who left their employer, are planning to leave their employer, or got a promotion and a salary increase, it’s easy to see why salary budgets are under pressure. Right now, qualified candidates have the power in the job market, though with the stock market correction that began in March 2022 and significant layoffs from some large technology-sector companies, that may be changing.</p>\\n\\n\\n\\n<p>These conclusions are borne out when you look at the salaries of those who were promoted, changed jobs, or intend to change jobs. A promotion roughly doubled respondents’ year-over-year salary increase. On the average, those who were promoted received a 7% raise; those who weren’t promoted received a 3.7% increase. The result was almost exactly the same for those who changed jobs: those who changed averaged a 6.8% salary increase, while those who remained averaged 3.7%. We also see a difference in the salaries of those who intend to leave because of compensation: their average salary is $171,000, as opposed to $188,000 for those who didn’t plan to leave. That’s a $17,000 difference, or roughly 10%.</p>\\n\\n\\n\\n<h2>Salaries by Gender</h2>\\n\\n\\n\\n<p>One goal of this survey was to determine whether women are being paid fairly. Last year’s&nbsp;<a href=\"https://learning.oreilly.com/library/view/2021-data-ai-salary/9781098118662\" rel=\"noreferrer noopener\" target=\"_blank\">salary survey for data and AI</a>&nbsp;found a substantial difference between men’s and women’s salaries: women were paid 16% less than men. Would we see the same here?</p>\\n\\n\\n\\n<p>The quick answer is “yes,” but the difference was smaller. Average salaries for women are 7% lower than for men ($172,000 as opposed to $185,000). But let’s take a step back before looking at salaries in more detail. We asked our respondents what pronouns they use. Only 8.5% said “she,” while 79% chose “he.” That’s still only 87% of the total. Where are the rest? 12% preferred not to say; this is a larger group than those who used “she.” 0.5% chose &#8220;other,&#8221; and 0.7% chose &#8220;they.&#8221; (That&#8217;s only four and six respondents, respectively.) Compared to results from our survey on the data/AI industry, the percentage of cloud professionals who self-identified as women appears to be much smaller (8.5%, as opposed to 14%). But there’s an important difference between the surveys: “I prefer not to answer” wasn’t an option for the Data/AI Salary Survey. We can’t do much with those responses. When we eyeballed the data for the “prefer not to say” group, we saw somewhat higher salaries than for women, but still significantly less (5% lower) than for men.</p>\\n\\n\\n\\n<p>The difference between men’s and women’s salaries is smaller than we expected, given the results of last year’s Data/AI Salary Survey. But it’s still a real difference, and it begs the question: Is compensation improving for women? Talent shortages are driving compensation up in many segments of the software industry. Furthermore, the average reported salaries for both men and women in our survey are high. Again, is that a consequence of the talent shortage? Or is it an artifact of our sample, which appears to be somewhat older, and rich in executives? We can’t tell from a single year’s data, and the year-over-year comparison we made above is based on a different industry segment. But the evidence suggests that the salary gap is closing, and progress is being made. And that is indeed a good thing.</p>\\n\\n\\n\\n<p>Salaries for respondents who answered “other” to the question about the pronouns they use are 31% lower than salaries for respondents who chose “he.” Likewise, salaries for respondents who chose “they” are 28% lower than men’s average salaries. However, both of these groups are extremely small, and in both groups, one or two individuals pulled the averages down. We could make the average salaries higher by calling these individuals “outliers” and removing their data; after all, outliers can have outsized effects on small groups. That’s a step we won’t take. Whatever the reason, the outliers are there; they’re part of the data. Professionals all across the spectrum have low-paying jobs—sometimes by choice, sometimes out of necessity. Why does there appear to be a concentration of them among people who don’t use “he” or “she” as their pronouns? The effect probably isn’t quite as strong as our data indicates, but we won’t try to explain our data away. It’s certainly indicative that the groups that use “they” or another pronoun than &#8220;he&#8221; or &#8220;she&#8221; showed a salary penalty. We have to conclude that respondents who use nonbinary pronouns earn lower salaries, but without more data, we don’t know why, nor do we know how much lower their salaries are or whether this difference would disappear with a larger sample.</p>\\n\\n\\n\\n<p>To see more about the differences between men&#8217;s and women&#8217;s salaries, we looked at the men and women in each salary range. The overall shapes of the salary distributions are clear: a larger percentage of women earn salaries between $0 and $175,000, and (with two exceptions) a larger percentage of men earn salaries over $175,000. However, a slightly larger percentage of women earn supersize salaries ($400,000 or more), and a significantly larger percentage earn salaries between $225,000 and $250,000 (Figure 2).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14551\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0102-1-807x1048.png\" /><figcaption>Figure 2. <em>Men’s and women’s salaries by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>We can get some additional information by looking at salary increases (Figure 3). On average, women’s salary increases were higher than men’s: $9,100 versus $8,100. That doesn’t look like a big difference, but it’s over 10%. We can read that as a sign that women’s salaries are certainly catching up. But the signals are mixed. Men’s salaries increased more than women’s in almost every segment, with two big exceptions: 12% of women received salary increases over $30,000, while only 8% of men did the same. Likewise, 17% of women received increases between $10,000 and $15,000, but only 9% of men did. These differences might well disappear with more data.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14553\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0103-1-1048x874.png\" /><figcaption>Figure 3. <em>Salary increases for women and men by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>When we look at salary increases as a percentage of salary, we again see mixed results (Figure 4). Women’s salary increases were much larger than men’s in three bands: over $325,000 (with the exception of $375,000–$400,000, where there were no women respondents), $275,000–$300,000, and $150,000–$175,000. For those with very large salaries, women’s salary increases were much higher than men’s. Furthermore, the $150,000–$175,000 band had the largest number of women. While there was a lot of variability, salary increases are clearly an important factor driving women&#8217;s salaries toward parity with men’s.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14554\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0104-1-754x1048.png\" /><figcaption>Figure 4. <em>Salary increases as a percentage of salary</em></figcaption></figure>\\n\\n\\n\\n<h3>The Effect of Education</h3>\\n\\n\\n\\n<p>The difference between men’s and women’s salaries is significant at almost every educational level (Figure 5). The difference is particularly high for respondents who are self-taught, where women earned 39% less ($112,000 versus $184,000), and for students (45% less, $87,000 versus $158,000). However, those were relatively small groups, with only two women in each group. It’s more important that for respondents with bachelor’s degrees, women’s salaries were 4% higher than men’s ($184,000 versus $176,000)—and this was the largest group in our survey. For respondents with advanced degrees, women with doctorates averaged a 15% lower salary than men with equivalent education; women with master’s degrees averaged 10% lower. The difference between women’s and men’s salaries appears to be greatest at the extremes of the educational spectrum.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14555\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0105-1-1048x756.png\" /><figcaption>Figure 5. <em>Men’s and women’s salaries by degree</em></figcaption></figure>\\n\\n\\n\\n<h2>Salaries by State</h2>\\n\\n\\n\\n<p>Participants in the survey come from 43 states plus Washington, DC. Looking at salaries by state creates some interesting puzzles. The highest salaries are found in Oklahoma; South Dakota is third, following California. And the top of the list is an interesting mix of states where we expected high salaries (like New York) and states where we expected salaries to be lower. So what’s happening?</p>\\n\\n\\n\\n<p>The average salary from Oklahoma is $225,000—but that only reflects two respondents, both of whom work remotely 100% of the time. (We’ll discuss remote work later in this report.) Do they work for a Silicon Valley company and get a Silicon Valley salary? We don’t know, but that’s certainly a possibility. The average salary for South Dakota is $212,000, but we shouldn’t call it an “average,” because we only had one response, and this respondent reported working remotely 1–4 days per week. Likewise, Vermont had a single respondent, who works remotely and who also had an above-average salary. Many other states have high average salaries but a very small number of respondents.</p>\\n\\n\\n\\n<p>So the first conclusion that we can draw is that remote work might be making it possible for people in states without big technology industries to get high salaries. Or it could be the opposite: there’s no state without some businesses using the cloud, and the possibility of remote work puts employers in those states in direct competition with Silicon Valley salaries: they need to pay much higher salaries to get the expertise they need. And those job offers may include the opportunity to work remotely full or part time—even if the employer is local. Both of those possibilities no doubt hold true for individuals, if not for geographical regions as a whole.</p>\\n\\n\\n\\n<p>Outliers aside, salaries are highest in California ($214,000), New York ($212,000), Washington ($203,000), Virginia ($195,000), and Illinois ($191,000). Massachusetts comes next at $189,000. At $183,000, average salaries in Texas are lower than we’d expect, but they’re still slightly above the national average ($182,000). States with high average salaries tended to have the largest numbers of respondents—with the important exceptions that we’ve already noted. The lowest salaries are found in West Virginia ($87,000) and New Mexico ($84,000), but these reflected a small number of respondents (one and four, respectively). These two states aside, the average salary in every state was over $120,000 (Figure 6).</p>\\n\\n\\n\\n<p>So, is remote work equalizing salaries between different geographical regions? It’s still too early to say. We don’t think there will be a mass exodus from high-salary states to more rural states, but it’s clear that professionals who want to make that transition can, and that companies that aren’t in high-salary regions will need to offer salaries that compete in the nationwide market. Future surveys will tell us whether this pattern holds true.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14556\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0106-1-558x1048.png\" /><figcaption>Figure 6. <em>Average salary by state</em></figcaption></figure>\\n\\n\\n\\n<h2>Salaries by Age</h2>\\n\\n\\n\\n<p>The largest group of respondents to our survey were between 45 and 54 years old (Figure 7). This group also had the highest average salary ($196,000). Salaries for respondents between 55 and 65 years old were lower (averaging $173,000), and salaries dropped even more for respondents over 65 ($139,000). Salaries for the 18- to 24-year-old age range were low, averaging $87,000. These lower salaries are no surprise because this group includes both students and those starting their first jobs after college.</p>\\n\\n\\n\\n<p>It’s worth noting that our respondents were older than we expected; 29% were between 35 and 44 years old, 36% were between 45 and 54, and 22% were between 55 and 64. Data from our learning platform shows that this distribution isn’t indicative of the field as a whole, or of our audience. It may be an artifact of the survey itself. Are our newsletter readers older, or are older people more likely to respond to surveys? We don’t know.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14557\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0107-1-1048x420.png\" /><figcaption>Figure 7. <em>Average salary by age</em></figcaption></figure>\\n\\n\\n\\n<p>The drop in salaries after age 55 is surprising. Does seniority count for little? It’s easy to make hypotheses: Senior employees are less likely to change jobs, and we’ve seen that changing jobs drives higher salaries. But it’s also worth noting that AWS launched in 2002, roughly 20 years ago. People who are now 45 to 54 years old started their careers in the first years of Amazon’s rollout. They “grew up” with the cloud; they’re the real cloud natives, and that appears to be worth something in today’s market.</p>\\n\\n\\n\\n<h2>Job Titles and Roles</h2>\\n\\n\\n\\n<p>Job titles are problematic. There’s no standardized naming system, so a programming lead at one company might be an architect or even a CTO at another. So we ask about job titles at a fairly high level of abstraction. We offered respondents a choice of four “general” roles: executive, director, manager, or associate. We also allowed respondents to write in their own job titles; roughly half chose this option. The write-in titles were more descriptive and, as expected, inconsistent. We were able to group them into some significant clusters by looking for people whose write-in title used the words “engineer,” “programmer,” “developer,” “architect,” “consultant,” or “DevOps.” We also looked at two modifiers: “senior” and “lead.” There’s certainly room for overlap: someone could be a “senior DevOps engineer.” But in practice, overlap was small. (For example, no respondents used both “developer” and “architect” in a write-in job title.) There was no overlap between the titles submitted by respondents and the general titles we offered on the survey: our respondents had to choose one or the other.</p>\\n\\n\\n\\n<p>So what did we see? As shown in&nbsp;Figure 8, the highest salaries go to those who classified themselves as directors ($235,000) or executives ($231,000). Salaries for architects, “leads,” and managers are on the next tier ($196,000, $190,000, and $188,000, respectively). People who identified as engineers earn slightly lower salaries ($175,000). Associates, a relatively junior category, earn an average of $140,000 per year. Those who used “programmer” in their job title are a puzzle. There were only three of them, which is a surprise in itself, and all have salaries in the $50,000 to $100,000 range (average $86,000). Consultants also did somewhat poorly, with an average salary of $129,000.</p>\\n\\n\\n\\n<p>Those who identified as engineers (19%) made up the largest group of respondents, followed by associates (18%). Directors and managers each comprised 15% of the respondents. That might be a bias in our survey, since it’s difficult to believe that 30% of cloud professionals have directorial or managerial roles. (That fits the observation that our survey results may skew toward older participants.) Architects were less common (7%). And relatively few respondents identified themselves with the terms “DevOps” (2%), “consultant” (2%), or “developer” (2%). The small number of people who identify with DevOps is another puzzle. It’s often been claimed that the cloud makes operations teams unnecessary; “NoOps” shows up in discussions from time to time. But we’ve never believed that. Cloud deployments still have a significant operational component. While the cloud may allow a smaller group to oversee a huge number of virtual machines, managing those machines has become more complex—particularly with cloud orchestration tools like Kubernetes.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14558\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0108-1-1048x807.png\" /><figcaption>Figure 8. <em>Average salary by job title</em></figcaption></figure>\\n\\n\\n\\n<p>We also tried to understand what respondents are doing at work by asking about job roles, decoupling responsibilities from titles (Figure 9). So in another question, we asked respondents to choose between marketing, sales, product, executive, programmer, and architect roles, with no write-in option. Executives earn the highest salaries ($237,000) but were a relatively small group (14%). Architects are paid $188,000 per year on average; they were 33% of respondents. And for this question, respondents didn’t hesitate to identify as programmers: this group was the largest (43%), with salaries somewhat lower than architects ($163,000). This is roughly in agreement with the data we got from job titles. (And we should have asked about operations staff. Next year, perhaps.)</p>\\n\\n\\n\\n<p>The remaining three groups—marketing, sales, and product—are relatively small. Only five respondents identified their role as marketing (0.6%), but they were paid well ($187,000). 1.5% of the respondents identified as sales, with an average salary of $186,000. And 8% of the respondents identified themselves with product, with a somewhat lower average salary of $162,000.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14559\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0109-1-1048x387.png\" /><figcaption>Figure 9. <em>Average salary by role</em></figcaption></figure>\\n\\n\\n\\n<h2>Working from Home</h2>\\n\\n\\n\\n<p>When we were planning this survey, we were very curious about&nbsp;<em>where</em>&nbsp;people worked. Many companies have moved to a fully remote work model (as O’Reilly has), and many more are taking a hybrid approach. But just how common is remote work? And what consequences does it have for the employees who work from home rather than in an office?</p>\\n\\n\\n\\n<p>It turns out that remote work is surprisingly widespread (Figure 10). We found that only 6% of respondents answered no to the question “Do you work remotely?” More than half (63%) said that they work remotely all the time, and the remainder (31%) work remotely 1–4 days per week.</p>\\n\\n\\n\\n<p>Working remotely is also associated with higher salaries: the average salary for people who work remotely 1–4 days a week is $188,000. It’s only slightly less ($184,000) for people who work remotely all the time. Salaries are sharply lower for people who never work remotely (average $131,000).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14560\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0110-1-1048x223.png\" /><figcaption>Figure 10. <em>Salaries and remote work</em></figcaption></figure>\\n\\n\\n\\n<p>Salary increases show roughly the same pattern (Figure 11). While salaries are slightly higher for respondents who occasionally work in the office, salary increases were higher for those who are completely remote: the average increase was $8,400 for those who are remote 100% of the time, while those who work from home 1–4 days per week only averaged a $7,800 salary increase. We suspect that given time, these two groups would balance out. Salary changes for those who never work remotely were sharply lower ($4,500).</p>\\n\\n\\n\\n<p>Of all jobs in the computing industry, cloud computing is probably the most amenable to remote work. After all, you’re working with systems that are remote by definition. You’re not reliant on your own company’s data center. If the application crashes in the middle of the night, nobody will be rushing to the machine room to reboot the server. A laptop and a network connection are all you need.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14561\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0111-1-1048x228.png\" /><figcaption>Figure 11. <em>Salary increases and remote work</em></figcaption></figure>\\n\\n\\n\\n<p>We’re puzzled by the relatively low salaries and salary increases for those who never work remotely. While there were minor differences, as you’d expect, there were no “smoking guns”: no substantial differences in education or job titles or roles. Does this difference reflect old-school companies that don’t trust their staff to be productive at home? And do they pay correspondingly lower salaries? If so, they’d better be forewarned: it’s very easy for employees to change jobs in the current labor market.</p>\\n\\n\\n\\n<p>As the pandemic wanes (if indeed it wanes—despite what people think,&nbsp;<a href=\"https://covid.cdc.gov/covid-data-tracker/#datatracker-home\" rel=\"noreferrer noopener\" target=\"_blank\">that’s not what the data shows</a>), will companies stick with remote work or will they require employees to come back to the office? Some companies have already asked their employees to return. But we believe that the trend toward remote work will be hard, if not impossible, to reverse, especially in a job market where employers are competing for talent. Remote work certainly raises issues about onboarding new hires, training, group dynamics, and more. And it’s not without problems for the employees themselves: childcare, creating appropriate work spaces, etc. These challenges notwithstanding, it’s difficult to imagine people who have eliminated a lengthy commute from their lives going back to the office on a permanent basis.</p>\\n\\n\\n\\n<h2>Certifications and Training</h2>\\n\\n\\n\\n<p>Nearly half (48%) of our respondents participated in technical training or certification programs in the last year. 18% of them obtained one or more certifications, suggesting that 30% participated in training or some other form of professional development that wasn’t tied to a certification program.</p>\\n\\n\\n\\n<p>The most common reasons for participating in training were learning new technologies (42%) and improving existing skills (40%). (Percentages are relative to the total number of respondents, which was 778.) 21% wanted to work on more interesting projects. The other possible responses were chosen less frequently: 9% of respondents wanted to move into a leadership role, and 12% were required to take training. Job security was an issue for 4% of the respondents, a very small minority. That’s consistent with our observation that employees have the upper hand in the labor market and are more concerned with advancement than with protecting their status quo.</p>\\n\\n\\n\\n<p>Survey participants obtained a very broad range of certifications. We asked specifically about 11 cloud certifications that we identified as being particularly important. Most were specific to one of the three major cloud vendors: Microsoft Azure, Amazon Web Services, and Google Cloud. However, the number of people who obtained any specific certification was relatively small. The most popular certifications were AWS Certified Cloud Practitioner and Solutions Architect (both 4% of the total number of respondents). However, 8% of respondents answered “other” and provided a write-in answer. That’s 60 respondents—and we got 55 different write-ins. Obviously, there was very little duplication. The only submissions with multiple responses were CKA (Certified Kubernetes Administrator) and CKAD (Certified Kubernetes Application Developer). The range of training in this “other” group was extremely broad, spanning various forms of Agile training, security, machine learning, and beyond. Respondents were pursuing many vendor-specific certifications, and even academic degrees. (It’s worth noting that our&nbsp;<em>2021 Data/AI Salary Survey</em>report also concluded that earning a certification for one of the major cloud providers was a useful tool for career advancement.)</p>\\n\\n\\n\\n<p>Given the number of certifications that are available, this isn’t surprising. It’s somewhat more surprising that there isn’t any consensus on which certifications are most important. When we look at salaries, though, we see some signals&#8230;at least among the leading certifications. The largest salaries are associated with Google Cloud Certified Professional Cloud Architect ($231,000). People who earned this certification also received a substantial salary increase (7.1%). Those who obtained an AWS Certified Solutions Architect &#8211; Professional, AWS Certified Solutions Architect &#8211; Associate, or Microsoft Certified: Azure Solutions Architect Expert certification also earn very high salaries ($212,000, $201,000, and $202,000, respectively), although these three received smaller salary increases (4.6%, 4.4%, and 4.0%, respectively). Those who earned the CompTIA Cloud+ certification receive the lowest salary ($132,000) and got a relatively small salary increase (3.5%). The highest salary increase went to those who obtained the Google Cloud Certified Professional Cloud DevOps Engineer certification (9.7%), with salaries in the middle of the range ($175,000).</p>\\n\\n\\n\\n<p>We can’t draw any conclusions about the salaries or salary increases corresponding to the many certifications listed among the “other” responses; most of those certifications only appeared once. But it seems clear that the largest salaries and salary increases go to those who are certified for one of the big three platforms: Google Cloud, AWS, and Microsoft Azure (Figures&nbsp;12&nbsp;and&nbsp;13).</p>\\n\\n\\n\\n<p>The salaries and salary increases for the two Google certifications are particularly impressive. Given that Google Cloud is the least widely used of the major platforms, and that the number of respondents for these certifications was relatively small, we suspect that talent proficient with Google’s tools and services is harder to find and drives the salaries up.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14562\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0112-1-1048x708.png\" /><figcaption>Figure 12. <em>Average salary by certification</em></figcaption></figure>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14563\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0113-1-1048x770.png\" /><figcaption>Figure 13. <em>Average salary increase by certification</em></figcaption></figure>\\n\\n\\n\\n<p>Our survey respondents engaged in many different types of training. The most popular were watching videos and webinars (41%), reading books (39%), and reading blogs and industry articles (34%). 30% of the respondents took classes online. Given the pandemic, it isn’t at all surprising that only 1.7% took classes in person. 23% attended conferences, either online or in person. (We suspect that the majority attended online.) And 24% participated in company-offered training.</p>\\n\\n\\n\\n<p>There’s surprisingly little difference between the average salaries associated with each type of learning. That’s partly because respondents were allowed to choose more than one response. But it’s also notable that the average salaries for most types of learning are lower than the average salary for the respondents as a whole. The average salary by type of learning ranges from $167,000 (in-person classes) to $184,000 (company-provided educational programs). These salaries are on the low side compared to the overall average of $182,000. Lower salaries may indicate that training is most attractive to people who want to get ahead in their field. This fits the observation that most of the people who participated in training did so to obtain new skills or to improve current ones. After all, to many companies “the cloud” is still relatively new, and they need to retrain their current workforces.</p>\\n\\n\\n\\n<p>When we look at the time that respondents spent in training (Figure 14), we see that the largest group spent 20–39 hours in the past year (13% of all the respondents). 12% spent 40–59 hours; and 10% spent over 100 hours. No respondents reported spending 10–19 hours in training. (There were also relatively few in the 80–99 hour group, but we suspect that’s an artifact of “bucketing”: if you’ve taken 83 hours of training, you’re likely to think, “I don’t know how much time I spent in training, but it was a lot,” and choose 100+.) The largest salary increases went to those who spent 40–59 hours in training, followed by those who spent over 100 hours; the smallest salary increases, and the lowest salaries, went to those who only spent 1–9 hours in training. Managers take training into account when planning compensation, and those who skimp on training shortchange themselves.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14564\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0114-1-1048x514.png\" /><figcaption>Figure 14. <em>Percentage salary increase by time spent in training</em></figcaption></figure>\\n\\n\\n\\n<h2>The Cloud Providers</h2>\\n\\n\\n\\n<p>A survey of this type wouldn’t be complete without talking about the major cloud providers. There’s no really big news here (Figure 15). Amazon Web Services has the most users, at 72%, followed by Microsoft Azure (42%) and Google Cloud (31%). Compared to the cloud survey we did last year, it looks like Google Cloud and Azure have dropped slightly compared to AWS. But the changes aren’t large. Oracle’s cloud offering was surprisingly strong at 6%, and 4% of the respondents use IBM Cloud.</p>\\n\\n\\n\\n<p>When we look at the biggest cloud providers that aren’t based in the US, we find that they’re still a relatively small component of cloud usage: 0.6% of respondents use Alibaba, while 0.3% use Tencent. Because there are so few users among our respondents, the percentages don’t mean much: a few more users, and we might see something completely different. That said, we expected to see more users working with Alibaba; it’s possible that tensions between the United States and China have made it a less attractive option.</p>\\n\\n\\n\\n<p>20% of the respondents reported using a private cloud. While it’s not entirely clear what the term “private cloud” means—for some, it just means a traditional data center—almost all the private cloud users also reported using one of the major cloud providers. This isn’t surprising; private clouds make the most sense as part of a hybrid or multicloud strategy, where the private cloud holds data that must be kept on premises for security or compliance reasons.</p>\\n\\n\\n\\n<p>6% of the respondents reported using a cloud provider that we didn’t list. These answers were almost entirely from minor cloud providers, which had only one or two users among the survey&nbsp;participants. And surprisingly, 4% of the respondents reported that they weren’t using any cloud provider.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14565\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0115-1-1048x595.png\" /><figcaption>Figure 15. <em>Cloud provider usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>There’s little difference between the salaries reported by people using the major providers (Figure 16). Tencent stands out; the average salary for its users is $275,000. But there were so few Tencent users among the survey respondents that we don’t believe this average is meaningful. There appears to be a slight salary premium for users of Oracle ($206,000) and Google ($199,000); since these cloud providers aren’t as widely used, it’s easy to assume that organizations committed to them are willing to pay slightly more for specialized talent, a phenomenon we’ve observed elsewhere. Almost as a footnote, we see that the respondents who don’t use a cloud have significantly lower salaries ($142,000).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14566\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0116-1-1048x598.png\" /><figcaption>Figure 16. <em>Average salary by cloud provider</em></figcaption></figure>\\n\\n\\n\\n<p>Cloud providers offer many services, but their basic services fall into a few well-defined classes (Figure 17). 75% of the survey respondents reported using virtual instances (for example, AWS EC2), and 74% use bucket storage (for example, AWS S3). These are services that are offered by every cloud provider. Most respondents use an SQL database (59%). Somewhat smaller numbers reported using a NoSQL database (41%), often in conjunction with an SQL database. 49% use container orchestration services; 45% use “serverless,” which suggests that serverless is more popular than we’ve seen in our other recent surveys.</p>\\n\\n\\n\\n<p>Only 11% reported using some kind of AutoML—again, a service that’s provided by all the major cloud providers, though under differing names. And again, we saw no significant differences in salary based on what services were in use. That makes perfect sense; you wouldn’t pay a carpenter more for using a hammer than for using a saw.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14567\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0117-1-1048x456.png\" /><figcaption>Figure 17. <em>Basic cloud services usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<h2>The Work Environment</h2>\\n\\n\\n\\n<p>Salaries aside, what are cloud developers working with? What programming languages and tools are they using?</p>\\n\\n\\n\\n<h3>Languages</h3>\\n\\n\\n\\n<p>Python is the most widely used language (59% of respondents), followed by SQL (49%), JavaScript (45%), and Java (32%). It’s somewhat surprising that only a third of the respondents use Java, given that programming language surveys done by TIOBE and RedMonk almost always have Java, Python, and JavaScript in a near tie for first place. Java appears not to have adapted well to the cloud (Figure 18).</p>\\n\\n\\n\\n<p>Salaries also follow a pattern that we’ve seen before. Although the top four languages are in high demand, they don’t command particularly high salaries: $187,000 for Python, $179,000 for SQL, $181,000 for JavaScript, and $188,000 for Java (Figure 19). These are all “table stakes” languages: they’re necessary and they’re what most programmers use on the job, but the programmers who use them don’t stand out. And despite the necessity, there’s a lot of talent available to fill these roles. As we saw in last year’s&nbsp;<em>Data/AI Salary Survey</em>&nbsp;report, expertise in Scala, Rust, or Go commands a higher salary ($211,000, $202,000, and $210,000, respectively). While the demand for these languages isn’t as high, there’s a lot less available expertise. Furthermore, fluency in any of these languages shows that a programmer has gone considerably beyond basic competence. They’ve done the work necessary to pick up additional skills.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14568\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0118-1-1048x887.png\" /><figcaption>Figure 18. <em>Programming language usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>The lowest salaries were reported by respondents using PHP ($155,000). Salaries for C, C++, and C# are also surprisingly low ($170,000, $172,000, and $170,000, respectively); given the importance of C and C++ for software development in general and the importance of C# for the Microsoft world, we find it hard to understand why.</p>\\n\\n\\n\\n<p>Almost all of the respondents use multiple languages. If we had to make a recommendation for someone who wanted to move into cloud development or operations, or for someone planning a cloud strategy from scratch, it would be simple: focus on SQL plus one of the other table stakes languages (Java, JavaScript, or Python). If you want to go further, pick one of the languages associated with the highest salaries. We think Scala is past its peak, but because of its strong connection to the Java ecosystem, Scala makes sense for Java programmers. For Pythonistas, we’d recommend choosing Go or Rust.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14569\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0119-1-1048x879.png\" /><figcaption>Figure 19. <em>Average salary by programming language</em></figcaption></figure>\\n\\n\\n\\n<h3>Operating Systems</h3>\\n\\n\\n\\n<p>We asked our survey participants which operating systems they used so we could test something we’ve heard from several people who hire software developers: Linux is a must. That appears to be the case: 80% of respondents use Linux (Figure 20). Even though Linux really hasn’t succeeded in the desktop market (sorry), it’s clearly the operating system for most software that runs in the cloud. If Linux isn’t a requirement, it’s awfully close.</p>\\n\\n\\n\\n<p>67% of the respondents reported using macOS, but we suspect that’s mostly as a desktop or laptop operating system. Of the major providers, only AWS offers macOS virtual instances, and they’re not widely used. (Apple’s license only allows macOS to run on Apple hardware, and only AWS provides Apple servers.) 57% of the respondents reported using some version of Windows. While we suspect that Windows is also used primarily as a desktop or laptop operating system, Windows virtual instances are available from all the major providers, including Oracle and IBM.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14570\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0120-1-1048x227.png\" /><figcaption>Figure 20. <em>Operating system usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<h3>Tools</h3>\\n\\n\\n\\n<p>We saw little variation in salary from tool to tool. This lack of variation makes sense. As we said above, we don’t expect a carpenter who uses a hammer to be paid more than a carpenter who uses a saw. To be a competent carpenter, you need to use both, along with levels, squares, and a host of other tools.</p>\\n\\n\\n\\n<p>However, it is interesting to know what tools are commonly in use (Figure 21). There aren’t any real surprises. Docker is almost universal, used by 76% of the respondents. Kubernetes use is very widespread, by 61% of the respondents. Other components of the Kubernetes ecosystem didn’t fare as well: 27% of respondents reported using Helm, and 12% reported using Istio, which has been widely criticized for being too complex.</p>\\n\\n\\n\\n<p>Alternatives to this core cluster of tools don’t appear to have much traction. 10% of the respondents reported using OpenShift, the IBM/Red Hat package that includes Kubernetes and other core components. Our respondents seem to prefer building their tooling environment themselves. Podman, an alternative to Docker and a component of OpenShift, is only used by 8% of the respondents. Unfortunately, we didn’t ask about Linkerd, which appears to be establishing itself as a service mesh that’s simpler to configure than Istio. However, it didn’t show up among the write-in responses, and the number of respondents who said “other” was relatively small (9%).</p>\\n\\n\\n\\n<p>The HashiCorp tool set (Terraform, Consul, and Vault) appears to be more widely used: 41% of the respondents reported using Terraform, 17% use Vault, and 8% use Consul. However, don’t view these as alternatives to Kubernetes. Terraform is a tool for building and configuring cloud infrastructure, and Vault is a secure repository for secrets. Only Consul competes directly.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14571\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0121-1-1048x657.png\" /><figcaption>Figure 21. <em>Tool usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<h2>The Biggest Impact</h2>\\n\\n\\n\\n<p>Finally, we asked the respondents what would have the biggest impact on compensation and promotion. The least common answer was “data tools” (6%). This segment of our audience clearly isn’t working directly with data science or AI—though we’d argue that might change as more machine learning applications reach production. “Programming languages” was second from the bottom. The lack of concern about programming languages reflects reality. While we observed higher salaries for respondents who used Scala, Rust, or Go, if you’re solidly grounded in the basics (like Python and SQL), you’re in good shape. There’s limited value in pursuing additional languages once you have the table stakes.</p>\\n\\n\\n\\n<p>The largest number of respondents said that knowledge of “cloud and containers” would have the largest effect on compensation. Again, containers are table stakes, as we saw in the previous section. Automation, security, and machine learning were also highly rated (18%, 15%, and 16%, respectively). It’s not clear why machine learning was ranked highly but data tools wasn’t. Perhaps our respondents interpreted “data tools” as software like Excel, R, and pandas.</p>\\n\\n\\n\\n<p>11% of the respondents wrote in an answer. As usual with write-ins, the submissions were scattered, and mostly singletons. However, many of the write-in answers pointed toward leadership and management skills. Taken all together, these varied responses add up to about 2% of the total respondents. Not a large number, but still a signal that some part of our audience is thinking seriously about IT leadership.</p>\\n\\n\\n\\n<h2>Confidence in the Future</h2>\\n\\n\\n\\n<p>“Cloud adoption is up and to the right”? No, we already told you we weren’t going to conclude that. Though it’s no doubt true; we don’t see cloud adoption slowing in the near future.</p>\\n\\n\\n\\n<p>Salaries are high. That’s good for employees and difficult for employers. It’s common for staff to jump to another employer offering a higher salary and a generous signing bonus. The current stock market correction may put a damper on that trend. There are signs that Silicon Valley’s money supply is starting to dry up, in part because of higher interest rates but also because investors are nervous about how the online economy will respond to regulation, and impatient with startups whose business plan is to lose billions “buying” a market before they figure out how to make money. Higher interest rates and nervous investors could mean an end to skyrocketing salaries.</p>\\n\\n\\n\\n<p>The gap between women’s and men’s salaries has narrowed, but it hasn’t closed. While we don’t have a direct comparison for the previous year, last year’s&nbsp;<em>Data/AI Salary Survey</em>report showed a 16% gap. In this survey, the gap has been cut to 7%, and women are receiving salary increases that are likely to close that gap even further. It’s anyone’s guess how this will play out in the future. Talent is in short supply, and that puts upward pressure on salaries. Next year, will we see women’s salaries on par with men’s? Or will the gap widen again when the talent shortage isn’t so acute?</p>\\n\\n\\n\\n<p>While we aren’t surprised by the trend toward remote work, we are surprised at how widespread remote work has become: as we saw, only 10% of our survey respondents never work remotely, and almost two-thirds work remotely full time. Remote work may be easier for cloud professionals, because part of their job is inherently remote. However, after seeing these results, we&#8217;d predict similar numbers for other industry sectors. Remote work is here to stay.</p>\\n\\n\\n\\n<p>Almost half of our survey respondents participated in some form of training in the past year. Training on the major cloud platforms (AWS, Azure, and Google Cloud) was associated with higher salaries. However, our participants also wrote in 55 “other” kinds of training and certifications, of which the most popular was CKA (Certified Kubernetes Administrator).</p>\\n\\n\\n\\n<p>Let’s end by thinking a bit more about the most common answer to the question “What area do you feel will have the biggest impact on compensation and promotion in the next year?”: cloud and containers. Our first reaction is that this is a poorly phrased option; we should have just asked about containers. Perhaps that’s true, but there’s something deeper hidden in this answer. If you want to get ahead in cloud computing, learn more about the cloud. It’s tautological, but it also shows some real confidence in where the industry is heading. Cloud professionals may be looking for their next employer, but they aren’t looking to jump ship to the “next big thing.” Businesses aren’t jumping away from the cloud to “the next big thing” either; whether it’s AI, the “metaverse,” or something else, their next big thing will be built in the cloud. And containers are the building blocks of the cloud; they’re the foundation on which the future of cloud computing rests. Salaries are certainly “up and to the right,” and we don’t see demand for cloud-capable talent dropping any time in the near future.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/feed/', 'slash_comments': '0'}, {'title': '“Sentience” is the Wrong Question', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '“Sentience” is the Wrong Question'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/'}], 'link': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/', 'comments': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/#respond', 'published': 'Tue, 21 Jun 2022 13:30:35 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=21, tm_hour=13, tm_min=30, tm_sec=35, tm_wday=1, tm_yday=172, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14576', 'guidislink': False, 'summary': 'On June 6, Blake Lemoine, a Google engineer, was suspended by Google for disclosing a series of conversations he had with LaMDA, Google’s impressive large model, in violation of his NDA. Lemoine’s claim that LaMDA has achieved “sentience” was widely publicized–and criticized–by almost every AI expert. And it’s only two weeks after Nando deFreitas, tweeting [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'On June 6, Blake Lemoine, a Google engineer, was suspended by Google for disclosing a series of conversations he had with LaMDA, Google’s impressive large model, in violation of his NDA. Lemoine’s claim that LaMDA has achieved “sentience” was widely publicized–and criticized–by almost every AI expert. And it’s only two weeks after Nando deFreitas, tweeting [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>On June 6, Blake Lemoine, a Google engineer, was suspended by Google for disclosing a <a href=\"https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917\">series of conversations he had with LaMDA</a>, Google’s impressive large model, in violation of his NDA. Lemoine’s claim that LaMDA has achieved “sentience” was widely publicized–and criticized–by almost every AI expert. And it’s only two weeks after Nando deFreitas, <a href=\"https://twitter.com/NandoDF/status/1525397036325019649\">tweeting</a> about DeepMind’s new Gato model, claimed that artificial general intelligence is only a matter of scale. I’m with the experts; I think Lemoine was taken in by his own willingness to believe, and I believe DeFreitas is <a href=\"https://www.oreilly.com/radar/closer-to-agi/\">wrong about general intelligence</a>. But I also think that “sentience” and “general intelligence” aren’t the questions we ought to be discussing.</p>\\n\\n\\n\\n<p>The latest generation of models is good enough to convince some people that they are intelligent, and whether or not those people are deluding themselves is beside the point. What we should be talking about is what responsibility the researchers building those models have to the general public. I recognize Google’s right to require employees to sign an NDA; but when a technology has implications as potentially far-reaching as general intelligence, are they right to keep it under wraps?&nbsp; Or, looking at the question from the other direction, will developing that technology in public breed misconceptions and panic where none is warranted?</p>\\n\\n\\n\\n<p>Google is one of the three major actors driving AI forward, in addition to OpenAI and Facebook. These three have demonstrated different attitudes towards openness. Google communicates largely through academic papers and press releases; we see gaudy announcements of its accomplishments, but the number of people who can actually experiment with its models is extremely small. OpenAI is much the same, though it has also made it possible to test-drive models like GPT-2 and GPT-3, in addition to building new products on top of its APIs–GitHub Copilot is just one example. Facebook has <a href=\"https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/\">open sourced its largest model, OPT-175B</a>, along with several smaller pre-built models and a voluminous set of notes describing how OPT-175B was trained.</p>\\n\\n\\n\\n<p>I want to look at these different versions of “openness” through the lens of the scientific method. (And I’m aware that this research really is a matter of engineering, not science.)&nbsp; Very generally speaking, we ask three things of any new scientific advance:</p>\\n\\n\\n\\n<ul><li>It can reproduce past results. It’s not clear what this criterion means in this context; we don’t want an AI to reproduce the poems of Keats, for example. We would want a newer model to perform at least as well as an older model.</li><li>It can predict future phenomena. I interpret this as being able to produce new texts that are (as a minimum) convincing and readable. It’s clear that many AI models can accomplish this.</li><li>It is reproducible. Someone else can do the same experiment and get the same result. Cold fusion fails this test badly. What about large language models?</li></ul>\\n\\n\\n\\n<p>Because of their scale, large language models have a significant problem with reproducibility. You can download the source code for Facebook’s OPT-175B, but you won’t be able to train it yourself on any hardware you have access to. It’s too large even for universities and other research institutions. You still have to take Facebook’s word that it does what it says it does.&nbsp;</p>\\n\\n\\n\\n<p>This isn’t just a problem for AI. One of our authors from the 90s went from grad school to a professorship at Harvard, where he researched large-scale distributed computing. A few years after getting tenure, he left Harvard to join Google Research. Shortly after arriving at Google, he blogged that he was “<a href=\"http://matt-welsh.blogspot.com/2010/11/why-im-leaving-harvard.html\">working on problems that are orders of magnitude larger and more interesting than I can work on at any university</a>.” That raises an important question: what can academic research mean when it can’t scale to the size of industrial processes? Who will have the ability to replicate research results on that scale? This isn’t just a problem for computer science; many recent experiments in high-energy physics require energies that can only be reached at the Large Hadron Collider (LHC).&nbsp;Do we trust results if there’s only one laboratory in the world where they can be reproduced?</p>\\n\\n\\n\\n<p>That’s exactly the problem we have with large language models. OPT-175B can’t be reproduced at Harvard or MIT. It probably can’t even be reproduced by Google and OpenAI, even though they have sufficient computing resources. I would bet that OPT-175B is too closely tied to Facebook’s infrastructure (including custom hardware) to be reproduced on Google’s infrastructure. I would bet the same is true of LaMDA, GPT-3, and other very large models, if you take them out of the environment in which they were built.&nbsp; If Google released the source code to LaMDA, Facebook would have trouble running it on its infrastructure. The same is true for GPT-3.&nbsp;</p>\\n\\n\\n\\n<p>So: what can “reproducibility” mean in a world where the infrastructure needed to reproduce important experiments can’t be reproduced?&nbsp; The answer is to provide free access to outside researchers and early adopters, so they can ask their own questions and see the wide range of results. Because these models can only run on the infrastructure where they’re built, this access will have to be via public APIs.</p>\\n\\n\\n\\n<p>There are lots of impressive examples of text produced by large language models. LaMDA’s are the best I’ve seen. But we also know that, for the most part, these examples are heavily cherry-picked. And there are many examples of failures, which are certainly also cherry-picked.&nbsp; I’d argue that, if we want to build safe, usable systems, paying attention to the failures (cherry-picked or not) is more important than applauding the successes. Whether it’s sentient or not, we care more about a self-driving car crashing than about it navigating the streets of San Francisco safely at rush hour. That’s not just our (sentient) propensity for drama;&nbsp; if you’re involved in the accident, one crash can ruin your day. If a natural language model has been trained not to produce racist output (and that’s still very much a research topic), its failures are more important than its successes.&nbsp;</p>\\n\\n\\n\\n<p>With that in mind, OpenAI has done well by allowing others to use GPT-3–initially, through a limited free trial program, and now, as a commercial product that customers access through APIs. While we may be legitimately concerned by GPT-3’s ability to generate pitches for conspiracy theories (or just plain marketing), at least we know those risks.&nbsp; For all the useful output that GPT-3 creates (whether deceptive or not), we’ve also seen its errors. Nobody’s claiming that GPT-3 is sentient; we understand that its output is a function of its input, and that if you steer it in a certain direction, <a href=\"https://www.oreilly.com/radar/ai-powered-misinformation-and-manipulation-at-scale-gpt-3/\">that’s the direction it takes</a>. When GitHub Copilot (built from OpenAI Codex, which itself is built from GPT-3) was first released, I saw lots of speculation that it will cause programmers to lose their jobs. Now that we’ve seen Copilot, we understand that it’s a useful tool within its limitations, and discussions of job loss have dried up.&nbsp;</p>\\n\\n\\n\\n<p>Google hasn’t offered that kind of visibility for LaMDA. It’s irrelevant whether they’re concerned about intellectual property, liability for misuse, or inflaming public fear of AI. Without public experimentation with LaMDA, our attitudes towards its output–whether fearful or ecstatic–are based at least as much on fantasy as on reality. Whether or not we put appropriate safeguards in place, research done in the open, and the ability to play with (and even build products from) systems like GPT-3, have made us aware of the consequences of “deep fakes.” Those are realistic fears and concerns. With LaMDA, we can’t have realistic fears and concerns. We can only have imaginary ones–which are inevitably worse. In an area where reproducibility and experimentation are limited, allowing outsiders to experiment may be the best we can do.&nbsp;</p>\\n\\n\\n\\n<p></p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/feed/', 'slash_comments': '0'}, {'title': 'Closer to AGI?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Closer to AGI?'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/closer-to-agi/'}], 'link': 'https://www.oreilly.com/radar/closer-to-agi/', 'comments': 'https://www.oreilly.com/radar/closer-to-agi/#respond', 'published': 'Tue, 07 Jun 2022 11:09:16 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=7, tm_hour=11, tm_min=9, tm_sec=16, tm_wday=1, tm_yday=158, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14516', 'guidislink': False, 'summary': 'DeepMind’s new model, Gato, has sparked a debate on whether artificial general intelligence (AGI) is nearer–almost at hand–just a matter of scale.&#160; Gato is a model that can solve multiple unrelated problems: it can play a large number of different games, label images, chat, operate a robot, and more.&#160; Not so many years ago, one [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'DeepMind’s new model, Gato, has sparked a debate on whether artificial general intelligence (AGI) is nearer–almost at hand–just a matter of scale.&#160; Gato is a model that can solve multiple unrelated problems: it can play a large number of different games, label images, chat, operate a robot, and more.&#160; Not so many years ago, one [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>DeepMind’s new model, Gato, has sparked a debate on whether artificial general intelligence (AGI) is nearer–almost at hand–just a matter of scale.&nbsp; Gato is a model that can solve multiple unrelated problems: it can <a href=\"https://www.deepmind.com/publications/a-generalist-agent\" rel=\"noreferrer noopener\" target=\"_blank\">play a large number of different games, label images, chat, operate a robot, and more</a>.&nbsp; Not so many years ago, one problem with AI <a href=\"https://www.oreilly.com/radar/what-is-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">was that AI systems were only good at one thing</a>. After IBM’s Deep Blue defeated Garry Kasparov in chess,&nbsp; it was easy to say “But the ability to play chess isn’t really what we mean by intelligence.” A model that plays chess can’t also play space wars. That’s obviously no longer true; we can now have models capable of doing many different things. 600 things, in fact, and future models will no doubt do more.</p>\\n\\n\\n\\n<p>So, are we on the verge of artificial general intelligence, as <a href=\"https://twitter.com/NandoDF/status/1525397036325019649\" rel=\"noreferrer noopener\" target=\"_blank\">Nando de Frietas (research director at DeepMind) claims? That the only problem left is scale?</a> I don’t think so.&nbsp; It seems inappropriate to be talking about AGI when <a href=\"https://www.oreilly.com/radar/artificial-intelligence-human-inhuman/\" rel=\"noreferrer noopener\" target=\"_blank\">we don’t really have a good definition of “intelligence.”</a> If we had AGI, how would we know it? We have a lot of vague notions about the Turing test, but in the final analysis, Turing wasn’t offering a definition of machine intelligence; he was probing the question <a href=\"https://aeon.co/essays/why-we-should-remember-alan-turing-as-a-philosopher\" rel=\"noreferrer noopener\" target=\"_blank\">of what human intelligence means</a>.</p>\\n\\n\\n\\n<p>Consciousness and intelligence seem to require <a href=\"https://www.oreilly.com/radar/intelligence-and-comprehension/\" rel=\"noreferrer noopener\" target=\"_blank\">some sort of agency</a>.&nbsp; An AI can’t choose what it wants to learn, neither can it say “I don’t want to play Go, I’d rather play Chess.” Now that we have computers that can do both, can they “want” to play one game or the other? One reason we know our children (and, for that matter, our pets) are intelligent and not just automatons is that they’re capable of disobeying. A child can refuse to do homework; a dog can refuse to sit. And that refusal is as important to intelligence as the ability to solve differential equations, or to play chess. Indeed, the path towards artificial intelligence is as much about teaching us what intelligence isn’t (as Turing knew) as it is about building an AGI.</p>\\n\\n\\n\\n<p>Even if we accept that Gato is a huge step on the path towards AGI, and that scaling is the only problem that’s left, it is more than a bit problematic to think that scaling is a problem that’s easily solved. We don’t know how much power it took to train Gato, but GPT-3 required about <a href=\"https://info.deeplearning.ai/the-batch-recognizing-distracted-drivers-training-fighter-pilots-dominating-the-bridge-table-training-trillions-of-parameters\" rel=\"noreferrer noopener\" target=\"_blank\">1.3 Gigawatt-hours</a>: roughly 1/1000th the energy it takes to <a href=\"https://home.cern/resources/faqs/facts-and-figures-about-lhc#:~:text=What%20is%20the%20LHC%20power,is%20750%20GWh%20per%20year.\" rel=\"noreferrer noopener\" target=\"_blank\">run the Large Hadron Collider</a> for a year. Granted, Gato is much smaller than GPT-3, though <a href=\"https://www.zdnet.com/article/deepminds-gato-is-mediocre-so-why-did-they-build-it/\" rel=\"noreferrer noopener\" target=\"_blank\">it doesn’t work as well</a>; Gato’s performance is generally inferior to that of single-function models. And granted, a lot can be done to optimize training (and <a href=\"https://arxiv.org/pdf/2203.15556.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">DeepMind has done a lot of work</a> on models that require less energy). But Gato has just over 600 capabilities, focusing on natural language processing, image classification, and game playing. These are only a few of many tasks an AGI will need to perform. How many tasks would a machine be able to perform to qualify as a “general intelligence”? Thousands?&nbsp; Millions? Can those tasks even be enumerated? At some point, the project of training an artificial general intelligence sounds like something from Douglas Adams’ novel <a href=\"https://en.wikipedia.org/wiki/The_Hitchhiker\\'s_Guide_to_the_Galaxy\" rel=\"noreferrer noopener\" target=\"_blank\"><em>The Hitchhiker’s Guide to the Galaxy</em></a>, in which the Earth is a computer designed by an AI called Deep Thought to answer the question “What is the question to which 42 is the answer?”</p>\\n\\n\\n\\n<p>Building bigger and bigger models in hope of somehow achieving general intelligence may be an interesting research project, but AI may already have achieved a level of performance that suggests specialized training on top of existing <a href=\"https://arxiv.org/abs/2108.07258\" rel=\"noreferrer noopener\" target=\"_blank\">foundation models</a> will reap far more short term benefits. A foundation model trained to recognize images can be trained further to be part of a self-driving car, or <a href=\"https://www.resetera.com/threads/midjourney-is-lighting-up-the-ai-generated-art-community.586463/\" rel=\"noreferrer noopener\" target=\"_blank\">to create generative art</a>. A foundation model like GPT-3 trained to understand and speak human language can be <a href=\"https://copilot.github.com/\" rel=\"noreferrer noopener\" target=\"_blank\">trained more deeply to write computer code</a>.</p>\\n\\n\\n\\n<p>Yann LeCun posted a <a href=\"https://m.alpha.facebook.com/story.php?story_fbid=10158256523332143&amp;id=722677142\" rel=\"noreferrer noopener\" target=\"_blank\">Twitter thread about general intelligence (consolidated on Facebook)</a> stating some “simple facts.” First, LeCun says that there is no such thing as “general intelligence.” LeCun also says that “human level AI” is a useful goal–acknowledging that human intelligence itself is something less than the type of general intelligence sought for AI. All humans are specialized to some extent. I’m human; I’m arguably intelligent; I can play Chess and Go, but not <a href=\"https://en.wikipedia.org/wiki/Xiangqi\" rel=\"noreferrer noopener\" target=\"_blank\">Xiangqi</a> (often called Chinese Chess) or Golf. I could presumably learn to play other games, but I don’t have to learn them all. I can also play the piano, but not the violin. I can speak a few languages. Some humans can speak dozens, but none of them speak every language.</p>\\n\\n\\n\\n<p>There’s an important point about expertise hidden in here: we expect our AGIs to be “experts” (to beat top-level Chess and Go players), but as a human, I’m only fair at chess and poor at Go. Does human intelligence require expertise? (Hint: re-read <a href=\"https://academic.oup.com/mind/article/LIX/236/433/986238\" rel=\"noreferrer noopener\" target=\"_blank\">Turing’s original paper</a> about the Imitation Game, and check the computer’s answers.) And if so, what kind of expertise? Humans are capable of broad but limited expertise in many areas, combined with deep expertise in a small number of areas. So this argument is really about terminology: could Gato be a step towards human-level intelligence (limited expertise for a large number of tasks), but not general intelligence?</p>\\n\\n\\n\\n<p>LeCun agrees that we are missing some “fundamental concepts,” and we don’t yet know what those fundamental concepts are. In short, we can’t adequately define intelligence. More specifically, though, he mentions that “a few others believe that symbol-based manipulation is necessary.” That’s an allusion to the debate (<a href=\"https://twitter.com/garymarcus/status/1411401507610796032\" rel=\"noreferrer noopener\" target=\"_blank\">sometimes on Twitter</a>) between LeCun and Gary Marcus, who has argued many times that <a href=\"https://nautil.us/deep-learning-is-hitting-a-wall-14467/\" rel=\"noreferrer noopener\" target=\"_blank\">combining deep learning with symbolic reasoning</a> is the only way for AI to progress. (In his response to the Gato announcement, Marcus labels this school of thought “<a href=\"https://garymarcus.substack.com/p/the-new-science-of-alt-intelligence\" rel=\"noreferrer noopener\" target=\"_blank\">Alt-intelligence</a>.”) That’s an important point: impressive as models like GPT-3 and <a href=\"https://arxiv.org/abs/2112.06905\" rel=\"noreferrer noopener\" target=\"_blank\">GLaM</a> are, they make a lot of mistakes. Sometimes those are <a href=\"https://www.linkedin.com/pulse/gpt-3-does-understand-what-saying-steve-shwartz/\" rel=\"noreferrer noopener\" target=\"_blank\">simple mistakes of fact</a>, such as when GPT-3 wrote an article about the United Methodist Church that got a number of basic facts wrong. Sometimes, the mistakes reveal a horrifying (or hilarious, they’re often the same) <a href=\"https://www.tidio.com/blog/how-smart-are-gpt-3-chatbots/\" rel=\"noreferrer noopener\" target=\"_blank\">lack of what we call “common sense.”</a> Would you sell your children for refusing to do their homework? (To give GPT-3 credit, it points out that selling your children is illegal in most countries, and that there are better forms of discipline.)</p>\\n\\n\\n\\n<p>It’s not clear, at least to me, that these problems can be solved by “scale.” How much more text would you need to know that humans don’t, normally, sell their children? I can imagine “selling children” showing up in sarcastic or frustrated remarks by parents, along with texts discussing slavery. I suspect there are few texts out there that actually state that selling your children is a bad idea.&nbsp;Likewise, how much more text would you need to know that Methodist general conferences take place every four years, not annually? The general conference in question generated some press coverage, but not a lot; it’s reasonable to assume that GPT-3 had most of the facts that were available. What additional data would a large language model need to avoid making these mistakes? Minutes from prior conferences, documents about Methodist rules and procedures, and a few other things.&nbsp;As modern datasets go, it’s probably not very large; a few gigabytes, at most. But then the question becomes “How many specialized datasets would we need to train a general intelligence so that it’s accurate on any conceivable topic?”&nbsp; Is that answer a million?&nbsp; A billion?&nbsp; What are all the things we might want to know about? Even if any single dataset is relatively small, we’ll soon find ourselves building the successor to Douglas Adams’ Deep Thought.</p>\\n\\n\\n\\n<p>Scale isn’t going to help. But in that problem is, I think, a solution. If I were to build an artificial therapist bot, would I want a general language model?&nbsp; Or would I want a language model that had some broad knowledge, but has received some special training to give it deep expertise in psychotherapy? Similarly, if I want a system that writes news articles about religious institutions, do I want a fully general intelligence? Or would it be preferable to train a general model with data specific to religious institutions? The latter seems preferable–and it’s certainly more similar to real-world human intelligence, which is broad, but with areas of deep specialization.&nbsp;Building such an intelligence is a problem we’re already on the road to solving, by using large “foundation models” with additional training to customize them for special purposes. GitHub’s <a href=\"https://copilot.github.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Copilot</a> is one such model; <a href=\"https://www.oreilly.com/online-learning/article-answers.html\" rel=\"noreferrer noopener\" target=\"_blank\">O’Reilly Answers</a> is another.</p>\\n\\n\\n\\n<p>If a “general AI” is no more than “a model that can do lots of different things,” do we really need it, or is it just an academic curiosity?&nbsp; What’s clear is that we need better models for specific tasks. If the way forward is to build specialized models on top of foundation models, and if this process generalizes from language models like GPT-3 and O’Reilly Answers to other models for different kinds of tasks, then we have a different set of questions to answer. First, rather than trying to build a general intelligence by making an even bigger model, we should ask whether we can build a good foundation model that’s smaller, cheaper, and more easily distributed, perhaps as open source. Google has done <a href=\"https://info.deeplearning.ai/the-batch-recognizing-distracted-drivers-training-fighter-pilots-dominating-the-bridge-table-training-trillions-of-parameters\" rel=\"noreferrer noopener\" target=\"_blank\">some excellent work at reducing power consumption, though it remains huge</a>, and Facebook has released their <a href=\"https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/\" rel=\"noreferrer noopener\" target=\"_blank\">OPT model with an open source license</a>. Does a foundation model actually require anything more than the ability to parse and create sentences that are grammatically correct and stylistically reasonable?&nbsp; Second, we need to know how to specialize these models effectively.&nbsp; We can obviously do that now, but I suspect that training these subsidiary models can be optimized. These specialized models might also incorporate symbolic manipulation, as Marcus suggests; for two of our examples, psychotherapy and religious institutions, symbolic manipulation would probably be essential. If we’re going to build an AI-driven therapy bot, I’d rather have a bot that can do that one thing well than a bot that makes mistakes that are much subtler than <a href=\"https://www.artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/\" rel=\"noreferrer noopener\" target=\"_blank\">telling patients to commit suicide</a>. I’d rather have a bot that can collaborate intelligently with humans than one that needs to be watched constantly to ensure that it doesn’t make any egregious mistakes.</p>\\n\\n\\n\\n<p>We need the ability to combine models that perform different tasks, and we need the ability to interrogate those models about the results. For example, I can see the value of a chess model that included (or was integrated with) a language model that would enable it to answer questions like “What is the significance of Black’s 13th move in the 4th game of FischerFisher vs. Spassky?” Or “You’ve suggested Qc5, but what are the alternatives, and why didn’t you choose them?” Answering those questions doesn’t require a model with 600 different abilities. It requires two abilities: chess and language. Moreover, it requires the ability to explain why the AI&nbsp;rejected certain alternatives in its decision-making process. As far as I know, little has been done on this latter question, though the ability to expose other alternatives <a href=\"http://radar.oreilly.com/2011/02/watson-machine-learning.html\" rel=\"noreferrer noopener\" target=\"_blank\">could be important in applications like medical diagnosis</a>. “What solutions did you reject, and why did you reject them?” seems like important information we should be able to get from an AI, whether or not it’s “general.”</p>\\n\\n\\n\\n<p>An AI that can answer those questions seems more relevant than an AI that can simply do a lot of different things.</p>\\n\\n\\n\\n<p>Optimizing the specialization process is crucial because we’ve turned a technology question into an economic question. How many specialized models, like Copilot or O’Reilly Answers, can the world support? We’re no longer talking about a massive AGI that takes terawatt-hours to train, but about specialized training for a huge number of smaller models. A psychotherapy bot might be able to pay for itself–even though it would need the ability to retrain itself on current events, for example, to deal with patients who are anxious about, say, the invasion of Ukraine. (There is <a href=\"https://arxiv.org/pdf/2106.06297.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">ongoing research</a> on models that can incorporate new information as needed.) It’s not clear that a specialized bot for producing news articles about religious institutions would be economically viable. That’s the third question we need to answer about the future of AI: what kinds of economic models will work? Since AI models are essentially cobbling together answers from other sources that have their own licenses and business models, how will our future agents compensate the sources from which their content is derived? How should these models deal with issues like attribution and license compliance?</p>\\n\\n\\n\\n<p>Finally, projects like Gato don’t help us understand how AI systems should collaborate with humans. Rather than just building bigger models, researchers and entrepreneurs need to be exploring different kinds of interaction between humans and AI. That question is out of scope for Gato, but it is something we need to address regardless of whether the future of artificial intelligence is general or narrow but deep. Most of our current AI systems are oracles: you give them a prompt, they produce an output.&nbsp; Correct or incorrect, you get what you get, take it or leave it. Oracle interactions don’t take advantage of human expertise, and risk wasting human time on “obvious” answers, where the human says “I already know that; I don’t need an AI to tell me.”</p>\\n\\n\\n\\n<p>There are some exceptions to the oracle model. Copilot places its suggestion in your code editor, and changes you make can be fed back into the engine to improve future suggestions. <a href=\"https://boingboing.net/2022/03/24/midjourney-sharpens-style-of-ai-art.html\" rel=\"noreferrer noopener\" target=\"_blank\">Midjourney</a>, a platform for AI-generated art that is currently in closed beta, also incorporates a feedback loop.</p>\\n\\n\\n\\n<p>In the next few years, we will inevitably rely more and more on machine learning and artificial intelligence. If that interaction is going to be productive, we will need a lot from AI. We will need interactions between humans and machines, a better understanding of how to train specialized models, the ability to distinguish between correlations and facts–and that’s only a start. Products like Copilot and O’Reilly Answers give a glimpse of what’s possible, but they’re only the first steps. AI has made dramatic progress in the last decade, but we won’t get the products we want and need merely by scaling.&nbsp;We need to learn to think differently.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/closer-to-agi/feed/', 'slash_comments': '0'}, {'title': 'Radar Trends to Watch: June 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: June 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/#respond', 'published': 'Wed, 01 Jun 2022 11:54:59 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=1, tm_hour=11, tm_min=54, tm_sec=59, tm_wday=2, tm_yday=152, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14510', 'guidislink': False, 'summary': 'The explosion of large models continues.&#160;Several developments are especially noteworthy. DeepMind’s Gato model is unique in that it’s a single model that’s trained for over 600 different tasks; whether or not it’s a step towards general intelligence (the ensuing debate may be more important than the model itself), it’s an impressive achievement. Google Brain’s Imagen [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The explosion of large models continues.&#160;Several developments are especially noteworthy. DeepMind’s Gato model is unique in that it’s a single model that’s trained for over 600 different tasks; whether or not it’s a step towards general intelligence (the ensuing debate may be more important than the model itself), it’s an impressive achievement. Google Brain’s Imagen [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>The explosion of large models continues.&nbsp;Several developments are especially noteworthy. DeepMind’s Gato model is unique in that it’s a single model that’s trained for over 600 different tasks; whether or not it’s a step towards general intelligence (the ensuing debate may be more important than the model itself), it’s an impressive achievement. Google Brain’s Imagen creates photorealistic images that are impressive, even after you’ve seen what DALL-E 2 can do. And Allen AI’s Macaw (surely an allusion to Emily Bender and Timnit Gebru’s <a href=\"https://dl.acm.org/doi/10.1145/3442188.3445922\">Stochastic Parrots</a> paper) is open source, one tenth the size of GPT-3, and claims to be more accurate. Facebook/Meta is also releasing an open source large language model, including the model’s training log, which records in detail the work required to train it.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li>Is thinking of autonomous vehicles as AI systems rather than as robots the next step forward? <a href=\"https://www.technologyreview.com/2022/05/27/1052826/ai-reinforcement-learning-self-driving-cars-autonomous-vehicles-wayve-waabi-cruise/\" rel=\"noreferrer noopener\" target=\"_blank\">A new wave of startups is trying techniques such as reinforcement learning</a> to train AVs to drive safely.</li><li><a href=\"https://yoshuabengio.org/2022/03/05/generative-flow-networks/\" rel=\"noreferrer noopener\" target=\"_blank\">Generative Flow Networks</a> may be the next major step in building better AI systems.</li><li>The <a href=\"https://thenextweb.com/news/openai-punished-dev-used-gpt-3-to-resurrect-dead-ethics\" rel=\"noreferrer noopener\" target=\"_blank\">ethics of building AI bots that mimic real dead people</a> seems like an academic question, until someone does it: using GPT-3, a developer created a bot based on his deceased fiancée. OpenAI objected, stating that building such a bot was a violation of its terms of service.</li><li>Cortical Labs and other startups are building computers that <a href=\"https://theconversation.com/tech-firms-are-making-computer-chips-with-human-cells-is-it-ethical-183394\" rel=\"noreferrer noopener\" target=\"_blank\">incorporate human neurons</a>.&nbsp;It’s claimed that these systems can be trained to perform game-playing tasks significantly faster than traditional AI.</li><li>Google Brain has built a new text-to-image generator called <a href=\"https://imagen.research.google/\" rel=\"noreferrer noopener\" target=\"_blank\">Imagen</a> that <a href=\"https://www.theverge.com/2022/5/24/23139297/google-imagen-text-to-image-ai-system-examples-paper\" rel=\"noreferrer noopener\" target=\"_blank\">creates photorealistic images</a>. Although images generated by projects like this are always cherry-picked, the image quality is impressive; the developers claim that it is better than DALL-E 2.</li><li>DeepMind has created a new “generalist” model called <a href=\"https://www.deepmind.com/publications/a-generalist-agent\" rel=\"noreferrer noopener\" target=\"_blank\">Gato</a>. It is a single model that can solve many different kinds of tasks: playing multiple games, labeling images, and so on. It has prompted a <a href=\"https://twitter.com/NandoDF/status/1525397036325019649?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1525397036325019649%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fthenextweb.com%2Fnews%2Fdeepmind-researcher-claims-new-gato-ai-could-lead-to-agi-says-game-is-over\">debate</a><a href=\"https://twitter.com/ylecun/status/1526672565233758213?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1526672787187941376%7Ctwgr%5E%7Ctwcon%5Es2_&amp;ref_url=http%3A%2F%2Fnew-savanna.blogspot.com%2F2022%2F05%2Fwhere-we-are-now-no-such-thing-as-agi.html\"> </a><a href=\"https://twitter.com/ylecun/status/1526672565233758213?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1526672787187941376%7Ctwgr%5E%7Ctwcon%5Es2_&amp;ref_url=http%3A%2F%2Fnew-savanna.blogspot.com%2F2022%2F05%2Fwhere-we-are-now-no-such-thing-as-agi.html\" rel=\"noreferrer noopener\" target=\"_blank\">on whether</a> Artificial General Intelligence is simply a matter of scale.</li><li>AI in autonomous vehicles can be used to <a href=\"https://techxplore.com/news/2022-05-artificial-intelligence-autonomous-vehicles-idling.html\" rel=\"noreferrer noopener\" target=\"_blank\">eliminate waiting at traffic lights</a>, increase travel speed, and reduce fuel consumption and carbon emissions. Surprisingly, if only 25% of the vehicles are autonomous, you get 50% of the benefit.</li><li><a href=\"https://github.com/allenai/macaw\" rel=\"noreferrer noopener\" target=\"_blank\">Macaw</a> is a language model developed by Allen AI (<a href=\"https://allenai.org/\" rel=\"noreferrer noopener\" target=\"_blank\">AI2</a>). It is freely available and open-source. <a href=\"https://blog.allenai.org/general-purpose-question-answering-with-macaw-84cd7e3af0f7\" rel=\"noreferrer noopener\" target=\"_blank\">Macaw is 1/10th the size of GPT-3</a> and roughly 10% more accurate at answering questions, though (like GPT-3) it tends to fail at questions that require common sense or involve logical tricks.</li><li><a href=\"https://theconversation.com/is-ai-generated-art-really-creative-it-depends-on-the-presentation-181663\" rel=\"noreferrer noopener\" target=\"_blank\">Ai-da is an AI-driven robot that can paint portraits</a>–but is it art? Art is as much about human perception as it is about creation. What social cues prompt us to think that a robot is being creative?</li><li>Facebook/Meta has created a large language model called <a href=\"https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/\" rel=\"noreferrer noopener\" target=\"_blank\">OPT</a> that is similar in size and performance to GPT-3. Using the model is free for non-commercial work; the code is being released open source, along with documents describing how the model was trained.</li><li><a href=\"https://github.com/project-alice-assistant/ProjectAlice\" rel=\"noreferrer noopener\" target=\"_blank\">Alice</a> is a modular and extensible open source virtual assistant (think Alexa) that can run completely offline. It is private by default, though it can be configured to use Amazon or Google as backups. Alice can identify different users (for whom it can develop “likes” or “dislikes,” based on interactions).</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li><a href=\"https://thenewstack.io/nosql-nomq-palo-alto-networks-new-event-streaming-paradigm/\" rel=\"noreferrer noopener\" target=\"_blank\">High volume event streaming without a message queue</a>: Palo Alto Networks has built a system for processing terabytes of security events per day without using a message queue, just a NoSQL database.</li><li>New tools allow <a href=\"https://medium.com/short-bits/layer-a-new-tool-for-spreadsheet-management-6f45278c1cf7\" rel=\"noreferrer noopener\" target=\"_blank\">workflow management across groups of spreadsheets</a>. Spreadsheets are the original “low code”; these tools seem to offer spreadsheet users many of the features that software developers get from tools like git.</li><li><a href=\"https://www.portainer.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Portainer</a> is a container management tool that lets you <a href=\"https://thenewstack.io/how-to-create-and-use-container-volumes-within-portainer/\" rel=\"noreferrer noopener\" target=\"_blank\">mount Docker containers as persistent filesystems</a>.</li><li><a href=\"https://www.bleepingcomputer.com/news/linux/nvidia-has-open-sourced-its-linux-gpu-kernel-drivers/\" rel=\"noreferrer noopener\" target=\"_blank\">NVIDIA has open-sourced its Linux device drivers</a>. The code is <a href=\"https://github.com/NVIDIA/open-gpu-kernel-modules\" rel=\"noreferrer noopener\" target=\"_blank\">available</a> on GitHub. This is a significant change for a company that historically has avoided open source.</li><li>A startup named Buoyant is building tools to <a href=\"https://thenewstack.io/buoyant-wants-to-make-linkerd-easier-to-use-and-manage/\" rel=\"noreferrer noopener\" target=\"_blank\">automate management of Linkerd</a>. <a href=\"https://linkerd.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Linkerd</a>, in turn, is a service mesh that is easier to manage and more appropriate for small to medium businesses, than Istio.</li><li>Are we entering the “third age of JavaScript”? An intriguing <a href=\"https://thenewstack.io/the-third-age-of-javascript-an-update-from-reactathon/\" rel=\"noreferrer noopener\" target=\"_blank\">article</a> suggests that we are. In this view of the future, static site generation disappears, incremental rendering and edge routing become more important, and Next.js becomes a dominant platform.</li><li><a href=\"https://github.com/rowyio/rowy\" rel=\"noreferrer noopener\" target=\"_blank\">Rowy</a> is a low-code programming environment that intends to <a href=\"https://thenewstack.io/rowy-takes-on-the-limits-of-airtable-with-low-code-cloud-collaboration/\" rel=\"noreferrer noopener\" target=\"_blank\">escape the limitations of Airtable</a> and other low-code collaboration services. The interface is like a spreadsheet, but it’s built on top of the Google Cloud Firestore document database.</li><li><a href=\"https://www.anaconda.com/blog/pyscript-python-in-the-browser\" rel=\"noreferrer noopener\" target=\"_blank\">PyScript</a> is framework for running Python in the browser, mixed with HTML (in some ways, not unlike PHP). It is based on Pyodide (a WASM implementation of Python), integrates well with JavaScript, and might support other languages in the future.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Machine learning raises the possibility of <a href=\"https://thenextweb.com/news/machine-learning-has-an-alarming-threat-undetectable-backdoors\" rel=\"noreferrer noopener\" target=\"_blank\">undetectable backdoor attacks</a>, malicious attacks that can affect the output of a model but don’t measurably detect its performance. Security issues for machine learning aren’t well understood, and aren’t getting a lot of attention.</li><li>In a <a href=\"https://www.bleepingcomputer.com/news/security/popular-python-and-php-libraries-hijacked-to-steal-aws-keys/\" rel=\"noreferrer noopener\" target=\"_blank\">new supply chain attack</a>, two widely used libraries (Python’s ctx and PHP’s PHPass) have been compromised to steal AWS credentials. The attacker now claims that these exploits were “<a href=\"https://www.bleepingcomputer.com/news/security/hacker-says-hijacking-libraries-stealing-aws-keys-was-ethical-research/\" rel=\"noreferrer noopener\" target=\"_blank\">ethical research</a>,” possibly with the goal of winning bounties for reporting exploits.</li><li>While it is not yet accurate enough to work in practice, a <a href=\"https://techxplore.com/news/2022-05-method-cyberattacks.html\" rel=\"noreferrer noopener\" target=\"_blank\">new method for detecting cyber attacks</a> can detect and stop attacks in under one second.</li><li>The <a href=\"https://www.bleepingcomputer.com/news/security/eternity-malware-kit-offers-stealer-miner-worm-ransomware-tools/\" rel=\"noreferrer noopener\" target=\"_blank\">Eternity Project</a> is a new malware-as-a-service organization that offers many different kinds of tools for data theft, ransomware, and many other exploits. It’s possible that the project is itself a scam, but it appears to be genuine.</li><li>Palo Alto Networks has published a <a href=\"https://unit42.paloaltonetworks.com/iam-cloud-threat-research/\" rel=\"noreferrer noopener\" target=\"_blank\">study</a> showing that <a href=\"https://thenewstack.io/unused-credentials-key-culprits-in-cloud-attacks-study-says/\" rel=\"noreferrer noopener\" target=\"_blank\">most cloud identity and access management policies are too permissive</a>, and that 90% of the permissions granted are never used. Overly-permissive policies are a major vulnerability for cloud users.</li><li>NIST has just published a massive guide to <a href=\"https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-161r1.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">supply chain security</a>. For organizations that can’t digest this 326-page document, they plan to publish a quick-start guide.</li><li>The <a href=\"https://arstechnica.com/gadgets/2022/05/apple-google-and-microsoft-want-bluetooth-proximity-to-replace-the-password/\" rel=\"noreferrer noopener\" target=\"_blank\">Passkey</a> standard, supported by Google, Apple, and Microsoft, replaces passwords with other forms of authentication. An application makes an authentication request to the device, which can then respond using any authentication method it supports. Passkey is operating system-independent, and supports both Bluetooth in addition to Internet protocols.</li><li>Google and Mandiant both report significant year-over-year increases in the <a href=\"https://www.schneier.com/blog/archives/2022/04/zero-day-vulnerabilities-are-on-the-rise.html\" rel=\"noreferrer noopener\" target=\"_blank\">number of 0-day vulnerabilities</a> discovered in 2021.</li><li>Interesting <a href=\"https://www.bleepingcomputer.com/news/security/ransom-payment-is-roughly-15-percent-of-the-total-cost-of-ransomware-attacks/\" rel=\"noreferrer noopener\" target=\"_blank\">statistics about ransomware</a> attacks: The ransom is usually only 15% of the total cost of the attack; and on average, the ransom is 2.8% of net revenue (with discounts of up to 25% for prompt payment).</li><li><a href=\"https://www.bleepingcomputer.com/news/security/conti-revil-lockbit-ransomware-bugs-exploited-to-block-encryption/\" rel=\"noreferrer noopener\" target=\"_blank\">Bugs in the most widely used ransomware software</a>, including REvil and Conti, can be used to prevent the attacker from encrypting your data.</li></ul>\\n\\n\\n\\n<h2>Web and Web3</h2>\\n\\n\\n\\n<ul><li>DeviantArt is allowing anyone to use its tool to <a href=\"https://www.deviantartprotect.com/\" rel=\"noreferrer noopener\" target=\"_blank\">detect NFTs that are created without the artist’s permission</a>.</li><li>A <a href=\"https://www.vice.com/en/article/akvmke/facebook-doesnt-know-what-it-does-with-your-data-or-where-it-goes\" rel=\"noreferrer noopener\" target=\"_blank\">leaked Facebook document obtained by Motherboard</a> reveals that they do not have an “adequate level of control” over data use, and thus “can’t confidently make controlled policy changes … such as ‘we will not use X data for Y purpose.’” A lack of data governance and lineage makes it impossible to comply with regulation, both current and forthcoming.</li></ul>\\n\\n\\n\\n<h2>VR/AR/Metaverse</h2>\\n\\n\\n\\n<ul><li>Niantic is building VPS (Visual Positioning System), an <a href=\"https://www.theverge.com/2022/5/24/23138313/niantic-lightship-augmented-reality-ar-platform-social-network-gaming\" rel=\"noreferrer noopener\" target=\"_blank\">augmented reality map of the world</a>, as part of its Lightship platform. VPS allows games and other AR products to be grounded to the physical world.</li><li><a href=\"https://livingcities.xyz/\" rel=\"noreferrer noopener\" target=\"_blank\">LivingCities</a> is building a <a href=\"https://medium.com/@mattmiesnieks/reality-is-scarce-68be119dace2\" rel=\"noreferrer noopener\" target=\"_blank\">digital twin of the real world</a> as a platform for experiencing the world in extended reality. That experience includes history, a place’s textures and feelings, and, of course, a new kind of social media.</li><li><a href=\"https://techxplore.com/news/2022-05-haptics-device-realistic-virtual-textures.html\" rel=\"noreferrer noopener\" target=\"_blank\">New research in haptics</a> allows the creation of realistic virtual textures by measuring how people feel things.&nbsp;Humans are extremely sensitive to the textures of materials, so creating good textures is important for everything from video games to telesurgery.</li><li><a href=\"https://techxplore.com/news/2022-05-google-remaking-tiktok.html\" rel=\"noreferrer noopener\" target=\"_blank\">Google is upgrading its search engine for augmented reality</a>: they are integrating images more fully into searches, creating multi-modal searches that incorporate images, text, and audio, and generating search results that can be explored through AR.</li><li><a href=\"https://thenewstack.io/babylon-js-hints-that-microsoft-metaverse-will-be-web-based/\" rel=\"noreferrer noopener\" target=\"_blank\">BabylonJS</a> is an open source 3D engine, based on WebGL and WebGPU, that Microsoft developed. It is a strong hint that Microsoft’s version of the Metaverse will be web-based. It will support WebXR.</li><li>The <a href=\"https://thenewstack.io/the-fediverse-points-to-our-social-media-future-post-musk/\" rel=\"noreferrer noopener\" target=\"_blank\">fediverse</a> is an ensemble of microblogging social media sites (such as Mastodon) that communicate with each other.&nbsp;Will they become a viable alternative to Elon Musk’s Twitter?</li><li><a href=\"https://varjo.com/blog/varjo-teleportation/\" rel=\"noreferrer noopener\" target=\"_blank\">Varjo</a> is building a “reality cloud”: a 3D mixed reality streaming service that allows photorealistic “virtual teleportation.” It’s not about weird avatars in a fake 3D world; they record your actions in your actual environment.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li><a href=\"https://techxplore.com/news/2022-05-smart-human-machine-interaction.html\" rel=\"noreferrer noopener\" target=\"_blank\">“Smart films</a>” could allow developers to build interactive touch interfaces into screens, objects, and even clothing.</li><li>Fairphone is a <a href=\"https://thenextweb.com/news/fairphone-sustainable-phone-repair-modules-interview\" rel=\"noreferrer noopener\" target=\"_blank\">cell phone that is designed to last for years</a> and be easily repairable. Three quarters of the CO2 emissions associated with the lifecycle of a device come from manufacturing; increasing device longevity is a key to sustainability.</li><li>An extremely lightweight drone that is <a href=\"https://techxplore.com/news/2022-05-tiny-drone-based-maple-seed.html\" rel=\"noreferrer noopener\" target=\"_blank\">based on the maple tree’s seeds</a> weighs under 100 grams and can hover for 40 minutes. The drone is capable of carrying small payloads.</li><li><a href=\"https://thenextweb.com/news/drones-can-help-reforest-reseed-fight-dengue-fever\" rel=\"noreferrer noopener\" target=\"_blank\">Seed-firing drones can help fight deforestation</a>. They drop seed pods that are complete packages including the water and minerals the seeds need to survive. The drones can monitor the success of the areas that they’ve replanted.</li><li>Researchers have developed an optoelectronic system for <a href=\"https://theconversation.com/weve-created-a-device-that-could-allow-instant-disease-diagnosis-while-fitting-inside-your-phone-lens-181342\" rel=\"noreferrer noopener\" target=\"_blank\">diagnosing disease that could be integrated into a cell phone lens</a>.</li><li><a href=\"https://techcrunch.com/2022/04/28/snap-announces-a-mini-drone-called-pixy/\" rel=\"noreferrer noopener\" target=\"_blank\">Pixy</a> is a small drone that follows you around, taking video for posting to Snapchat.</li></ul>\\n\\n\\n\\n<h2>Design</h2>\\n\\n\\n\\n<ul><li>Ethical design starts with a <a href=\"https://alistapart.com/article/redefine-success-first/\" rel=\"noreferrer noopener\" target=\"_blank\">redefinition of success</a>: well-being, equity, and sustainability, with good metrics for measuring your progress.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li>QICK is a new <a href=\"https://arxiv.org/abs/2110.00557\" rel=\"noreferrer noopener\" target=\"_blank\">standardized control plane</a> for quantum devices. The design of the control plane, including software, is all open source. A large part of the cost of building a quantum device is building the electronics to control it. QICK will greatly reduce the cost of quantum experimentation.</li><li>Researchers have built <a href=\"https://phys.org/news/2022-05-error-free-quantum-real.html\" rel=\"noreferrer noopener\" target=\"_blank\">logical gates using error-corrected quantum bits</a>. This is a significant step towards building a useful quantum computer. </li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/feed/', 'slash_comments': '0'}, {'title': 'Building a Better Middleman', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Building a Better Middleman'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/building-a-better-middleman-2/'}], 'link': 'https://www.oreilly.com/radar/building-a-better-middleman-2/', 'comments': 'https://www.oreilly.com/radar/building-a-better-middleman-2/#respond', 'published': 'Tue, 17 May 2022 10:58:32 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=5, tm_mday=17, tm_hour=10, tm_min=58, tm_sec=32, tm_wday=1, tm_yday=137, tm_isdst=0), 'authors': [{'name': 'Q McCallum'}], 'author': 'Q McCallum', 'author_detail': {'name': 'Q McCallum'}, 'tags': [{'term': 'Operations', 'scheme': None, 'label': None}, {'term': 'Deep Dive', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14497', 'guidislink': False, 'summary': 'In the previous article, I explored the role of the middleman in a two-sided marketplace.&#160; The term &#8220;middleman&#8221; has a stigma to it. Mostly because, when you sit between two parties that want to interact, it&#8217;s easy to get greedy. Greed will bring you profits in the short term. Probably in the long term, as [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'In the previous article, I explored the role of the middleman in a two-sided marketplace.&#160; The term &#8220;middleman&#8221; has a stigma to it. Mostly because, when you sit between two parties that want to interact, it&#8217;s easy to get greedy. Greed will bring you profits in the short term. Probably in the long term, as [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>In <a href=\"https://www.oreilly.com/radar/building-a-better-middleman/\" rel=\"noreferrer noopener\" target=\"_blank\">the previous article</a>, I explored the role of the middleman in a two-sided marketplace.&nbsp; The term &#8220;middleman&#8221; has a stigma to it. Mostly because, when you sit between two parties that want to interact, it&#8217;s easy to get greedy.</p>\\n\\n\\n\\n<p>Greed will bring you profits in the short term. Probably in the long term, as well.&nbsp; As a middleman, though, your greed is an existential threat.&nbsp; When you abuse your position and mistreat the parties you connect–when your cost outweighs your value–they&#8217;ll find a way to replace you. Maybe not today, maybe not tomorrow, but it will happen.</p>\\n\\n\\n\\n<p>Luckily, you can make money as a middleman and still keep everyone happy.&nbsp; Here&#8217;s how to create that win-win-win triangle:</p>\\n\\n\\n\\n<h3>Keep refining your platform</h3>\\n\\n\\n\\n<p>Running a marketplace is a game of continuous improvement. You need to keep asking yourself: <em>how can I make this better for the people who interact through the marketplace?</em></p>\\n\\n\\n\\n<p>To start, you can look for ways to make your platform more attractive to existing customers. I emphasize <em>both</em> customers, not just one side of the marketplace. Mistreating one side to favor the other may work for a time, but it will eventually fall through. Frustration has a way of helping people overcome switching costs.</p>\\n\\n\\n\\n<p>Some stock exchanges designate <em>market makers</em> (&#8220;specialists,&#8221; if you&#8217;re old-school)<em>,</em> firms that are always ready to both buy and sell shares of a given stock. If I want to offload a thousand shares and there&#8217;s no one who wants to buy them from me, the market maker steps in to play the role of the buyer. By guaranteeing that there will always be <em>someone</em> on the other side of the bid or ask, exchanges keep everyone happy.</p>\\n\\n\\n\\n<p>If you constantly review how the two parties interact, you can look for opportunities to mitigate their risk, create new services, or otherwise reduce friction. Most platforms connect strangers, right?&nbsp; So if you look at your business through the lens of safety, you&#8217;ll find a lot of work to do. Note how eBay&#8217;s review system provides extra assurance for buyers and sellers to trade with people they&#8217;ve never met.&nbsp; Similarly, in the early days of online commerce, credit card issuers limited shoppers&#8217; fraud risk to just $50 per purchase.&nbsp; This improved consumers&#8217; trust in online shopping, which helped make e-commerce the everyday norm that it is today.</p>\\n\\n\\n\\n<p>Safety improvements also extend to communications. Do the parties really <em>need</em> to swap e-mail addresses or phone numbers?&nbsp; If they&#8217;re just confirming a rideshare pickup or flirting through a dating app, probably not.&nbsp; As a middleman, you are perfectly positioned to serve as the conduit;&nbsp; one that provides an appropriate level of masking or pseudonymity.&nbsp; And the money you invest in deploying a custom messaging system or temporary phone numbers (Twilio, anyone?) will pay off in terms of improved adoption and retention.</p>\\n\\n\\n\\n<h3>Design new products and services</h3>\\n\\n\\n\\n<p>If you understand how your parties interact and what they want to achieve, you&#8217;re in a position to spot new product opportunities that will make your customers happy.</p>\\n\\n\\n\\n<p>From a conversation with Cyril Nigg, Director of Analytics at Reverb, the music-gear marketplace was &#8220;founded by music makers, for music makers.&#8221;&nbsp; Musicians like to try new gear, but they want to offload it if it doesn&#8217;t pan out. Reverb has therefore built tools around pricing assistance to help musicians with their product listings: <em>You want to sell this distortion pedal within 7 days? List it as $X.</em> This extra assurance that they&#8217;ll be able to resell a piece of equipment, in short order, reduces apprehensions about buying. (Going back to the point about keeping both sides of the marketplace happy: Cyril also pointed out that a Reverb customer may act as both buyer and seller across different transactions.&nbsp; That means the company can&#8217;t skimp on one side of the experience.)</p>\\n\\n\\n\\n<p>People on a dating site want to communicate, so an easy win there is to keep an eye on new communications tools. Maybe your platform started out with an asynchronous, text-based tool that resembled e-mail.&nbsp; Can you add an option for real-time chat?&nbsp; What would it take to move up to voice? And ultimately, video? Each step in the progression requires advances in technology, so you may have to wait before you can actually deploy something. But if you can envision the system you want, you can keep an eye on the tech and be poised to pounce when it is generally available.</p>\\n\\n\\n\\n<p>Unlike dating sites, financial exchanges are marketplaces for opposing views. One person thinks that some event will happen, they seek a counterpart who thinks that it will not, and fate determines the winner.&nbsp; This can be as vanilla as people buying or selling shares of stock, where the counterparties believe the share price will rise or fall, respectively.&nbsp; You also see situations that call for more exotic tools.&nbsp; In the lead-up to what would become the 2008 financial crisis, investors wanted to stake claims around mortgage-backed securities but there wasn&#8217;t a way to express the belief that those prices would fall. In response to this desire, a group of banks dusted off the credit default swap (CDS) concept and devised a standard, easily-tradable contract.&nbsp; Now there was a way for people to take either side of the trade, and for the banks to collect fees in the middle.&nbsp; A win-win-win situation.</p>\\n\\n\\n\\n<p>(Well, the actual <em>trade</em> was a win-win-win. The long-term <em>outcome</em> was more of a lose-lose-win. Mortgage defaults rose, sending prices for the associated mortgage-backed securities into decline, leading to big payouts for the &#8220;I told you this was going to happen&#8221; side of each CDS contract. The banks that served double-duty as both market participant <em>and</em> middleman took on sizable losses as a result. Let this be a lesson to you: part of why a middleman makes money is precisely because they have no stake in the long-term outcome of putting the parties together. Stay in the middle if you want to play it safe.)</p>\\n\\n\\n\\n<p>Granted, you don&#8217;t have to roll out every possible product or feature on your first day. You have to let the marketplace grow and mature somewhat, to see what will actually be useful. Still, you want to plan ahead. As you watch the marketplace, you will spot opportunities well in advance, so you can position yourself to implement them before the need is urgent.</p>\\n\\n\\n\\n<h3>Focus on your business</h3>\\n\\n\\n\\n<p>Besides making things easier for customers, being a better middleman means improving how your business runs.</p>\\n\\n\\n\\n<p>To start, identify and eliminate inefficiencies in your operations.&nbsp;I don&#8217;t mean that you should cut corners, as that will come back to bite you later.&nbsp; I mean that you can check for genuine money leaks. The easy candidates will be right there on your balance sheet: have you actually used Service ABC in the last year?&nbsp; If not, maybe it&#8217;s time to cut it. Is there an equivalent to Service XYZ at a lower price? Once you&#8217;ve confirmed that the cheaper service is indeed a suitable replacement, it&#8217;s time to make the switch.</p>\\n\\n\\n\\n<p>A more subtle candidate is your codebase.&nbsp;Custom code is a weird form of debt. It requires steady, ongoing maintenance just like payments in a loan. It may also require disruptive changes if you encounter a bug. (Imagine that your mortgage lender occasionally demanded a surprise lump sum in mid-month.) Can you replace that home-grown system with an off-the-shelf tool or a third-party service, for a cheaper and more predictable payment schedule?</p>\\n\\n\\n\\n<p>You also want to check on the size of your total addressable market (TAM).&nbsp; What happens when you&#8217;ve reached everyone who will ever join? It&#8217;s emotionally reassuring to tell yourself that the entire planet will use your service, sure.&nbsp;But do you really want to base revenue projections on customers you can&#8217;t realistically acquire or retain? At some point, your customer numbers will plateau (and, after that, sink). You need to have a difficult conversation with yourself, your leadership team, and your investors around how you&#8217;ll handle that. And you need to have that conversation well in advance. Once you hit that limit on your TAM, you&#8217;ll need to be ready to deliver improvements that reduce churn.&nbsp;Perhaps you can offer new services, which may extend your addressable market into new territory, but even that has its limits.</p>\\n\\n\\n\\n<p>What are you doing for risk management?&nbsp;A risk represents a possible future entry on your balance sheet, one of indeterminate size. Maybe it&#8217;s a code bug that spirals out of control under an edge case.&nbsp;Or a lingering complaint that blossoms into a full-scale PR issue. To be blunt: good risk management will save you money. Possibly lots of money.&nbsp;While it&#8217;s tempting to let some potential problems linger, understand that it&#8217;s easier and cheaper to address them early and on your own schedule.&nbsp;That&#8217;s much nicer than being under pressure to fix a surprise in real-time.</p>\\n\\n\\n\\n<p>Sharp-eyed readers will catch that subtle tradeoff between &#8220;addressing inefficiencies&#8221; and &#8220;proactively mitigating risks.&#8221;&nbsp;Risk management often requires that you leave extra slack in the system, such as higher staff headcount, or extra machines that mostly sit idle.&nbsp;This slack serves as a cushion in the event of a surge in customer activity but it also costs money.&nbsp; There&#8217;s no easy answer here. It&#8217;s a blend of art and science to spot the difference between slack and waste.</p>\\n\\n\\n\\n<p>Most of all, as a marketplace, you want to mature with your customers and the field overall. The term &#8220;innovate&#8221; gets some much-deserved flack, but it&#8217;s not complete hogwash. Be prepared to invest in research so you can see what changes are on the horizon, and then adapt accordingly. Also, keep an eye on the new features your customers are asking for, or the complaints they raise about your service.&nbsp;You&#8217;ll&nbsp; otherwise fall into the very trap described in <em>The Innovator&#8217;s Dilemma</em>. Don&#8217;t become the slow-moving, inattentive behemoth that some nimble upstart will work to unseat.</p>\\n\\n\\n\\n<h3>Use technology as a force multiplier</h3>\\n\\n\\n\\n<p>Bad middlemen squeeze the parties they connect; good middlemen squeeze technology.</p>\\n\\n\\n\\n<p>Done well, technology is a source of asymmetric advantage. Putting code in the right places allows you to accomplish more work, more consistently, with fewer people, and in less time. All of the efficiencies you get through code will leave more money to split between yourself and your customers.&nbsp; That is a solid retention strategy.</p>\\n\\n\\n\\n<p>To start, you can apply software to real and artificial scarcity that exists in other middlemen.&nbsp;A greenfield operation can start with lower headcount, less (or zero!) office space, and so on.</p>\\n\\n\\n\\n<p>Tech staffing, for example, is a matching problem at its core.&nbsp;A smart staffing firm would start with self-service search tools so a company could easily find people to match their open roles. No need to interact with a human recruiter. It could also standardize contract language to reduce legal overhead (no one wants a thousand slightly-different contracts laying around, anyway) and use electronic signatures to make it easier to store paperwork for future reference.</p>\\n\\n\\n\\n<p>You don&#8217;t even have to do anything fancy. Sometimes, the very act of putting something online is a huge step up from the incumbent solution. Craigslist, simply by running classified ads on a website, gave people a much-improved experience over the print-newspaper version. People had more space to write (goodbye, obscure acronyms), had search functionality (why skim all the listings to find what you&#8217;re after?), and could pull their ad when it had been resolved (no more getting phone calls for an extra week just because the print ad is still visible).</p>\\n\\n\\n\\n<p>Technology also makes it easier to manage resources. Love or loathe them, rideshare companies like Lyft and Uber can scale to a greater number of drivers and riders than the old-school taxi companies that rely on radio dispatch and flag-pulls. And they can do it with less friction. Why call a company and tell them your pickup location, when an app can use your phone&#8217;s GPS? And why should that dispatcher have to radio around in search of a driver? To arrange a ride, you need to match three elements–pickup location, dropoff location, and number of passengers–to an available driver. This is a trivial effort for a computer. Throw in mobile apps for drivers and passengers, and you have a system that can scale very well.</p>\\n\\n\\n\\n<p>(Some may argue that the rideshare companies get extra scale because their drivers are classified as independent contractors, and because they don&#8217;t require expensive taxi medallions. I don&#8217;t disagree. I just want to point out that the companies&#8217; technology is also a strong enabler.)</p>\\n\\n\\n\\n<p>Being at the center of the marketplace means you get to see the entire system at once. You can analyze the data around customer activity, and pass on insights to market participants to make their lives easier. Airbnb, for example, has deep insight into how different properties perform. Their research team determined that listings with high-quality photos tend to earn more revenue. They publicized this information to help hosts and, to sweeten the deal, the company then built a <a href=\"https://www.airbnb.com/d/pro-photography\" rel=\"noreferrer noopener\" target=\"_blank\">service to connect hosts with professional photographers</a>.</p>\\n\\n\\n\\n<p>What about ML/AI? While I hardly believe that it&#8217;s ready to eat <em>every</em> job, I do see <a href=\"https://qethanm.cc/2021/10/18/human-ai-interaction-exoskeletons-sidekicks-and-blinking-lights/\" rel=\"noreferrer noopener\" target=\"_blank\">opportunities for AI to make a smaller team of people more effective</a>.&nbsp;ML models are well-suited for decisions that are too fuzzy or cumbersome to be expressed as hard rules in software, but not so nuanced that they require human judgment.&nbsp;Putting AI in the seat for those decisions frees up your team for things that genuinely merit a human&#8217;s eyes and expertise.</p>\\n\\n\\n\\n<p>I&#8217;ve argued before that a lot of machine learning is high-powered matching. What is &#8220;classification,&#8221; if not rating one item&#8217;s similarity to an archetype?&nbsp; A marketplace that deals in the long tail of goods can use ML to help with that matching.</p>\\n\\n\\n\\n<p>Take Reverb, where most pieces of gear are unique but still similar to other items. They&#8217;re neither completely fungible, nor completely non-fungible.&nbsp; They&#8217;re sort of <em>semi-</em>fungible. To simplify search, then, Director of Analytics Cyril Nigg says that the company groups related items into ML-based <em>canonical products</em> (where some specific Product X is really part of a wider Canonical Product Y).&nbsp;&#8220;[We use] ML to match listings to a product–say, matching on title, price point, or some other attribute. This tells us, with a high degree of confidence, that a seller&#8217;s used Fender guitar is actually an American Standard Stratocaster. Now that we know the make and model, a buyer can easily compare all the different listings within that product to help them find the best option. This ML system learns over time, so that a seller can upload a listing and the system can file it under the proper canonical product.&#8221;</p>\\n\\n\\n\\n<p>Machine-based matching works for food as well as guitars. Resham Sarkar heads up data science at Slice, which gives local pizzerias the tools, technology and guidance they need to thrive. In a 2021 interview, she told me how her team applies ML to answer the age-old question: <em>will Person X enjoy Pizza Y at Restaurant Z?</em> Slice&#8217;s recommendations give eaters the confidence to try a new flavor in a new location, which helps them (maybe they&#8217;ll develop a new favorite) and also helps pizzerias (they get new customers).\\xa0This is especially useful when a pizza lover lands in a new city and doesn&#8217;t know where to get their fix.</p>\\n\\n\\n\\n<p>Any discussion of technology wouldn&#8217;t be complete without a nod to emerging tech. Yes, keeping up with the Shiny New Thing of the Moment means having to wade through plenty of hype. But if you look closely, you may also find some real game-changers for your business. This was certainly true of the 1990s internet boom. We&#8217;ve seen it in the past decade of what we now call AI, <a href=\"https://www.oreilly.com/radar/rebranding-data/\" rel=\"noreferrer noopener\" target=\"_blank\">across all of its rebrandings</a>. And yes, I expect that blockchain technologies will prove more useful than the curmudgeons want to let on.&nbsp; (Even NFTs. Or, <em>especially</em> NFTs.)</p>\\n\\n\\n\\n<p>Skip past the success stories and vendor pitches, though. Do your own homework on what the new technology really is and what it can do. Then, engage an expert to help you fill in the gaps and sort out what is possible with <em>your</em> business. The way a new technology addresses your challenges may not align with whatever is being hyped in the news, but who cares? All that matters is that it drives improvements for your use cases.</p>\\n\\n\\n\\n<h3>Watch your tech</h3>\\n\\n\\n\\n<p>Technology is a double-edged sword. It&#8217;s like using leverage in the stock market: employing software or AI exposes you to higher highs when things go right, but also lower lows when things unravel.</p>\\n\\n\\n\\n<p>One benefit to employing people to perform a task is that they can notice when something is wrong and then stop working. A piece of code, by comparison, has no idea that it is operating out of its depth. The same tools that let you do so much more, with far fewer people, also expose you to a sizable risk: one bug or environmental disconnect can trigger a series of errors, at machine speeds, cascading into a massive failure.</p>\\n\\n\\n\\n<p>All it takes is for a few smaller problems to collide. Consider the case of Knight Capital. This experienced, heavyweight market-maker once managed $21BN in daily transaction volume on the NYSE. One day in 2012, an inconsistent software deployment met a branch of old code, which in turn collided with a new order type on the exchange. This led to a <a href=\"https://www.henricodolfing.com/2019/06/project-failure-case-study-knight-capital.html\" rel=\"noreferrer noopener\" target=\"_blank\">meltdown</a> in which <a href=\"https://www.sec.gov/litigation/admin/2013/34-70694.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">Knight Capital lost $440M in under an hour</a>.</p>\\n\\n\\n\\n<p>The lesson here is that some of the money you save from reduced headcount should be reinvested in the company in the form of people and tools to keep an eye on the larger system. You&#8217;ll want to separate responsibilities in order to provide checks and balances, such as assigning someone who is not a developer to manage and review code deployments. Install monitors that provide fine-grained information about the state of your systems. Borrowing a line from a colleague: you can almost never have too many dimensions of data when troubleshooting.</p>\\n\\n\\n\\n<p>You&#8217;ll also need people to step in when someone gets caught in your web of automation. Have you ever called a company&#8217;s customer service line, only to wind up in a phone-tree dead-end? That can be very frustrating. You don&#8217;t want that for <em>your</em> customers, so you need to build escape hatches that route them to a person. That holds for your AI-driven chatbot as much as your self-help customer service workflows. And especially for any place where people can report a bug or an emergency situation.</p>\\n\\n\\n\\n<p>Most of all, this level of automation requires a high-caliber team. Don&#8217;t skimp on hiring. Pay a premium for very experienced people to build and manage your technology. If you can, hire someone who has built trading systems on Wall St.&nbsp;That culture is wired to identify and handle risk in complex, automated systems where there is a lot of real money at stake.&nbsp; And they have seen technology fail in ways that you cannot imagine.</p>\\n\\n\\n\\n<h3>Markets, everywhere</h3>\\n\\n\\n\\n<p>I&#8217;ve often said that problems in technology are rarely tech-related; they&#8217;re people-related.&nbsp;The same holds for building a marketplace, where the big problem is really human greed.</p>\\n\\n\\n\\n<p>Don&#8217;t fall for the greed trap. You can certainly run the business in a way that brings you revenue, keeps customers happy, and attracts new prospects. Identify inefficiencies in your business operations, and keep thinking of ways to make the platform better for your customers. That&#8217;s it.&nbsp; A proper application of software and AI, risk management, and research into emerging technologies should help you with both. And the money you save, you can split with your user base.</p>\\n\\n\\n\\n<p>If you&#8217;re willing to blur the lines a little, you will probably find markets in not-so-obvious places. An airline sits between passengers and destinations. Grocery stores sit between shoppers and suppliers. Employers sit between employees and clients. And so on. Once you find the right angle, you can borrow ideas from the established, well-run middlemen to improve your business.</p>\\n\\n\\n\\n<p>(Many thanks to <a href=\"https://www.oreilly.com/people/chris-butler/\" rel=\"noreferrer noopener\" target=\"_blank\">Chris Butler</a> for his thoughtful and insightful feedback on early drafts of this article.)</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/building-a-better-middleman-2/feed/', 'slash_comments': '0'}, {'title': 'Quantum Computing without the Hype', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Quantum Computing without the Hype'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/'}], 'link': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/', 'comments': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/#respond', 'published': 'Tue, 10 May 2022 11:45:05 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=5, tm_mday=10, tm_hour=11, tm_min=45, tm_sec=5, tm_wday=1, tm_yday=130, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Big Data Tools and Pipelines', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14492', 'guidislink': False, 'summary': 'Several weeks ago, I had a great conversation with Sebastian Hassinger about the state of quantum computing. It’s exciting–but also, not what a lot of people are expecting. I’ve seen articles in the trade press telling people to invest in quantum computing now or they’ll be hopelessly behind. That’s silly. There are too many people [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Several weeks ago, I had a great conversation with Sebastian Hassinger about the state of quantum computing. It’s exciting–but also, not what a lot of people are expecting. I’ve seen articles in the trade press telling people to invest in quantum computing now or they’ll be hopelessly behind. That’s silly. There are too many people [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Several weeks ago, I had a great conversation with Sebastian Hassinger about the state of quantum computing. It’s exciting–but also, not what a lot of people are expecting.</p>\\n\\n\\n\\n<p>I’ve seen articles in the trade press telling people to invest in quantum computing now or they’ll be hopelessly behind. That’s silly. There are too many people in the world who think that a quantum computer is just a fast mainframe. It isn’t; quantum programming is completely different, and right now, the number of algorithms we know that will work on quantum computers is very small. You can count them on your fingers and toes. While it’s probably important to prepare for quantum computers that can decrypt current cryptographic codes, those computers won’t be around for 10-20 years. While there is still debate on how many physical qubits will be needed for error correction, and even on the meaning of a “logical” (error-corrected) qubit, the most common&nbsp; estimates are that it will require on the order of 1,000 error corrected qubits to break current encryption systems, and that it will take 1,000 physical qubits to make one error corrected qubit. So we’ll need an order of 1 million qubits, and current quantum computers are all in the area of 100 qubits. Figuring out how to scale our current quantum computers by 5 orders of magnitude may well be the biggest problem facing researchers, and there’s no solution in sight.</p>\\n\\n\\n\\n<p>So what can quantum computers do now that’s interesting? First, they are excellent tools for simulating quantum behavior: the behavior of subatomic particles and atoms that make up everything from semiconductors to bridges to proteins. Most, if not all, modeling in these areas is based on numerical methods–and modern digital computers are great at that. But it’s time to think again about non-numerical methods: can a quantum computer simulate directly what happens when two atoms interact? Can it figure out what kind of molecules will be formed, and what their shapes will be? This is the next step forward in quantum computing, and while it’s still research, It’s a significant way forward. We live in a quantum world. We can’t observe quantum behavior directly, but it’s what makes your laptop work and your bridges stay up. If we can model that behavior directly with quantum computers, rather than through numeric analysis, we’ll make a huge step forward towards finding new kinds of materials, new treatments for disease, and more. In a way, it’s like the difference between analog and digital computers. Any engineer knows that digital computers spend a lot of time finding approximate numeric solutions to complicated differential equations. But until digital computers got sufficiently large and fast, the behavior of those systems could be modeled directly on analog computers. Perhaps the earliest known examples of analog computers are <a href=\"https://en.wikipedia.org/wiki/Stonehenge\" rel=\"noreferrer noopener\" target=\"_blank\">Stonehenge</a> and the <a href=\"https://en.wikipedia.org/wiki/Antikythera_mechanism\" rel=\"noreferrer noopener\" target=\"_blank\">Antikythera mechanism</a>, both of which were used to predict astronomical positions. Thousands of years before digital computers existed, these analog computers modeled the behavior of the cosmos, solving equations that their makers couldn’t have understood–and that we now solve numerically on digital computers.</p>\\n\\n\\n\\n<p>Recently, researchers have developed a <a href=\"https://arxiv.org/abs/2110.00557\" rel=\"noreferrer noopener\" target=\"_blank\">standardized control plane</a> that should be able to work with all kinds of quantum devices. The design of the control plane, including software, is all open source. This should greatly decrease the cost of experimentation, allowing researchers to focus on the quantum devices themselves, instead of designing the circuitry needed to manage the qubits.&nbsp; It’s not unlike the dashboard of a car: relatively early in automotive history, we developed a fairly standard set of tools for displaying data and controlling the machinery.&nbsp; If we hadn’t, the development of automobiles would have been set back by decades: every automaker would need to design its own controls, and you’d need fairly extensive training on your specific car before you could drive it. <a href=\"https://en.wikipedia.org/wiki/Quantum_programming\" rel=\"noreferrer noopener\" target=\"_blank\">Programming languages for quantum devices</a> also need to standardize; fortunately, there has already been a lot of work in that direction.&nbsp; Open source development kits that provide libraries that can be called from Python to perform quantum operations (<a href=\"https://github.com/Qiskit\" rel=\"noreferrer noopener\" target=\"_blank\">Qiskit</a>, <a href=\"https://searchaws.techtarget.com/definition/Amazon-Braket\" rel=\"noreferrer noopener\" target=\"_blank\">Braket</a>, and <a href=\"https://quantumai.google/cirq\" rel=\"noreferrer noopener\" target=\"_blank\">Cirq</a> are some examples), and <a href=\"https://github.com/Qiskit/openqasm\" rel=\"noreferrer noopener\" target=\"_blank\">OpenQASM</a> is an open source “quantum assembly language” that lets programmers write (virtual) machine-level code that can be mapped to instructions on a physical machine.</p>\\n\\n\\n\\n<p>Another approach to simulating quantum behavior won’t help probe quantum behavior, but might help researchers to develop algorithms for numerical computing. <a href=\"https://arxiv.org/abs/1809.04028\" rel=\"noreferrer noopener\" target=\"_blank\">P-bits</a>, or probabilistic bits, behave probabilistically but don’t depend on quantum physics: they’re traditional electronics that work at room temperature. P-bits have some of the behavior of qubits, but they’re much easier to build; the developers call them “poor man’s qubits.” Will p-bits make it easier to develop a quantum future?&nbsp; Possibly.</p>\\n\\n\\n\\n<p>It’s important not to get over-excited about quantum computing. The best way to avoid a “trough of disillusionment” is to be realistic about your expectations in the first place. Most of what computers currently do will remain unchanged. There will be some breakthroughs in areas like cryptography, search, and a few other areas where we’ve developed algorithms. Right now, “preparing for quantum computing” means evaluating your cryptographic infrastructure. Given that infrastructure changes are difficult, expensive, and slow, it makes sense to prepare for quantum-safe cryptography now. (Quantum-safe cryptography is cryptography that can’t be broken by quantum computers–it does not require quantum computers.)&nbsp; Quantum computers may still be 20 years in the future, but infrastructure upgrades could easily take that long.</p>\\n\\n\\n\\n<p>Practical (numeric) quantum computing at significant scale could be 10 to 20 years away, but a few breakthroughs could shorten that time drastically.&nbsp; In the meantime, a lot of work still needs to be done on discovering quantum algorithms. And a lot of important work can already be done by using quantum computers as tools for investigating quantum behavior. It is an exciting time; it’s just important to be excited by the right things, and not misled by the hype.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/feed/', 'slash_comments': '0'}, {'title': 'Radar trends to watch: May 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar trends to watch: May 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/#respond', 'published': 'Tue, 03 May 2022 11:19:02 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=5, tm_mday=3, tm_hour=11, tm_min=19, tm_sec=2, tm_wday=1, tm_yday=123, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14482', 'guidislink': False, 'summary': 'April was the month for large language models. There was one announcement after another; most new models were larger than the previous ones, several claimed to be significantly more energy efficient. The largest (as far as we know) is Google’s GLAM, with 1.2 trillion parameters–but requiring significantly less energy to train than GPT-3. Chinchilla has [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'April was the month for large language models. There was one announcement after another; most new models were larger than the previous ones, several claimed to be significantly more energy efficient. The largest (as far as we know) is Google’s GLAM, with 1.2 trillion parameters–but requiring significantly less energy to train than GPT-3. Chinchilla has [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>April was the month for large language models. There was one announcement after another; most new models were larger than the previous ones, several claimed to be significantly more energy efficient. The largest (as far as we know) is Google’s GLAM, with 1.2 trillion parameters–but requiring significantly less energy to train than GPT-3. Chinchilla has ¼ as many parameters as GPT-3, but claims to outperform it. It’s not clear where the race to bigger and bigger models will end, or where it will lead us. The PaLM model claims to be able to reason about cause and effect (in addition to being more efficient than other large models); we don’t yet have thinking machines (and we may never), but we’re getting closer. It’s also good to see that energy efficiency has become part of the conversation.</p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li>Google has created <a href=\"https://arxiv.org/abs/2112.06905\" rel=\"noreferrer noopener\" target=\"_blank\">GLAM</a> a 1.2 trillion parameter model (7 times the size of GPT-3).\\xa0 Training GLAM required <a href=\"https://info.deeplearning.ai/the-batch-recognizing-distracted-drivers-training-fighter-pilots-dominating-the-bridge-table-training-trillions-of-parameters\" rel=\"noreferrer noopener\" target=\"_blank\">456 megawatt-hours</a>,\\xa0 ⅓ the energy of GPT-3. GLAM uses a <a href=\"https://arxiv.org/abs/1701.06538\" rel=\"noreferrer noopener\" target=\"_blank\">Mixture-of-Experts</a> (MoE) model, in which different subsets of the neural network are used, depending on the input.</li><li>Google has released a <a href=\"https://arxiv.org/abs/2204.11918\" rel=\"noreferrer noopener\" target=\"_blank\">dataset of 3D-scanned household items</a>.\\xa0 This will be invaluable for anyone working on AI for virtual reality.</li><li>FOMO (Faster Objects, More Objects) is a <a href=\"https://thenextweb.com/news/fomo-tinyml-neural-network-object-detection\" rel=\"noreferrer noopener\" target=\"_blank\">machine learning model for object detection</a> in real time that requires less than 200KB of memory. It’s part of the TinyML movement: machine learning for small embedded systems.</li><li><a href=\"https://laion.ai/#about\" rel=\"noreferrer noopener\" target=\"_blank\">LAION</a> (Large Scale Artificial Intelligence Open Network) is a non-profit, free, and open organization that is creating large models and making them available to the public. It’s what OpenAI was supposed to be. The first model is a set of image-text pairs for training models similar to DALL-E.</li><li>NVidia is <a href=\"https://www.hpcwire.com/2022/04/18/nvidia-rd-chief-on-how-ai-is-improving-chip-design/\" rel=\"noreferrer noopener\" target=\"_blank\">using AI to automate the design of their latest GPU chips</a>.\\xa0 </li><li>Using <a href=\"https://techxplore.com/news/2022-04-ai-tool-efficiency-uk-sewer.html\" rel=\"noreferrer noopener\" target=\"_blank\">AI to inspect sewer pipes</a> is one example of an “unseen” AI application. It’s infrastructural, it doesn’t risk incorporating biases or significant ethical problems, and (if it works) it improves the quality of human life.</li><li>Large language models are generally based on text. Facebook is working on <a href=\"https://medium.com/product-ai/textless-nlp-the-future-of-speech-generation-31a6c713cb2d\" rel=\"noreferrer noopener\" target=\"_blank\">building a language model from spoken language</a>, which is a much more difficult problem.</li><li><a href=\"https://marhamilresearch4.blob.core.windows.net/stego-public/stego_paper.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">STEGO</a> is a new <a href=\"https://techxplore.com/news/2022-04-scientists-algorithm-assign-pixel-world.html\" rel=\"noreferrer noopener\" target=\"_blank\">algorithm for automatically labeling image data</a>. It uses transformers to understand relationships between objects, allowing it to segment and label objects without human input.</li><li>A researcher has developed a model for <a href=\"https://techxplore.com/news/2022-04-algorithm-opinions.html\" rel=\"noreferrer noopener\" target=\"_blank\">predicting first impressions and stereotypes</a>, based on a photograph.\\xa0 They’re careful to say that this model could easily be used to fine-tune fakes for maximum impact, and that “first impressions” don’t actually say anything about a person.</li><li>A group building <a href=\"https://www.technologyreview.com/2022/04/22/1050394/artificial-intelligence-for-the-people/\" rel=\"noreferrer noopener\" target=\"_blank\">language models for the Maori people</a> shows that AI for indigenous languages require different ways of thinking about artificial intelligence, data, and data rights.</li><li>A21 is a new company offering a <a href=\"https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1\" rel=\"noreferrer noopener\" target=\"_blank\">large language model “as a service.”</a> They allow customers to train custom versions of their model, and they claim to make humans and machines “thought partners.”</li><li>Researchers have found a method for <a href=\"https://techxplore.com/news/2022-04-method-bots-toxic-language.html\" rel=\"noreferrer noopener\" target=\"_blank\">reducing toxic text</a> generated by language models. It sounds like a GAN (generative adversarial network), in which a model trained to produce toxic text “plays against” a model being trained to detect and reject toxicity.</li><li>More bad applications of AI: companies are using AI to <a href=\"https://www.protocol.com/enterprise/emotion-ai-sales-virtual-zoom\" rel=\"noreferrer noopener\" target=\"_blank\">monitor your mood</a> during sales calls.\\xa0 This questionable feature will soon be coming to Zoom.</li><li><a href=\"http://primer.ai/\" rel=\"noreferrer noopener\" target=\"_blank\">Primer</a> has developed a tool that uses AI to <a href=\"https://www.wired.com/story/russia-ukraine-war-ai-surveillance/\" rel=\"noreferrer noopener\" target=\"_blank\">transcribe, translate, and analyze</a> intercepted communications in the war between Russia and Ukraine.</li><li>Deep Mind claims that another new large language model, <a href=\"https://www.marktechpost.com/2022/04/09/check-out-this-deepminds-new-language-model-chinchilla-70b-parameters-which-significantly-outperforms-gopher-280b-and-gpt-3-175b-on-a-large-range-of-downstream-evaluation-tasks/\" rel=\"noreferrer noopener\" target=\"_blank\">Chinchilla, outperforms GPT-3</a> and Gopher with roughly ¼th the number of parameters. It was trained on roughly 4 times as much data, but with fewer parameters, it requires less energy to train and fine-tune.</li><li><a href=\"https://thenewstack.io/its-time-for-data-reliability-engineering/\" rel=\"noreferrer noopener\" target=\"_blank\">Data Reliability Engineering</a> (DRE) borrows ideas from SRE and DevOps as a framework to provide higher-quality data for machine learning applications while reducing the manual labor required. It’s closely related to <a href=\"https://datacentricai.org/\" rel=\"noreferrer noopener\" target=\"_blank\">data-centric AI</a>.</li><li><a href=\"https://openai.com/dall-e-2/\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAI’s DALL-E 2</a> is a new take on their system (DALL-E) for generating images from natural language descriptions. It is also capable of modifying existing artworks based on natural language descriptions of the modifications.\\xa0OpenAI plans to open DALL-E 2 to the public, on terms similar to GPT-3.</li><li>Google’s new <a href=\"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\" rel=\"noreferrer noopener\" target=\"_blank\">Pathways Language Model</a> (PaLM) is more efficient, can understand concepts, and reason about cause and effect, in addition to being relatively energy-efficient. It’s another step forward towards AI that actually appears to think.</li><li><a href=\"https://www.sandboxaq.com/post/sandbox-aq-test-post-two\" rel=\"noreferrer noopener\" target=\"_blank\">SandboxAQ</a> is an Alphabet startup that is using AI to build technologies needed for a post-quantum world.\\xa0 They’re not doing quantum computing as such, but solving problems such as protocols for post-quantum cryptography.</li><li>IBM has open sourced the <a href=\"https://thenewstack.io/ibms-open-source-gt4sd-generates-ideas-for-scientists/\" rel=\"noreferrer noopener\" target=\"_blank\">Generative Toolkit for Scientific Discovery (GT4SD)</a>, which is a generative model designed to produce new ideas for scientific research, both in machine learning and in areas like biology and materials science.</li><li>Waymo (Alphabet’s self-driving car company) now offers <a href=\"https://blog.waymo.com/2022/03/taking-our-next-step-in-city-by-bay.html\" rel=\"noreferrer noopener\" target=\"_blank\">driverless service in San Francisco</a>.\\xa0 San Francisco is a more challenging environment than Phoenix, where Waymo has offered driverless service since 2020. Participation is limited to members of their Trusted Tester program.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.pcmag.com/news/more-users-flock-to-mastodon-after-musks-twitter-acquisition-bid\" rel=\"noreferrer noopener\" target=\"_blank\">Mastodon</a>, a decentralized social network, appears to be benefitting from Elon Musk’s takeover of Twitter.</li><li><a href=\"https://thenewstack.io/ontologys-web3-reputation-and-identity-management-solutions/\" rel=\"noreferrer noopener\" target=\"_blank\">Reputation and identity management</a> for web3 is a significant problem: how do you verify identity and reputation without giving applications more information than they should have?&nbsp; A startup called <a href=\"https://ont.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Ontology</a> claims to have solved it.</li><li>A virtual <a href=\"https://oncyber.io/6529om\" rel=\"noreferrer noopener\" target=\"_blank\">art museum for NFTs</a> is still under construction, but it exists, and you can visit it. It’s probably a better experience in VR.</li><li>2022 promises to be an even bigger year for cryptocrime than 2021. Attacks are <a href=\"https://blog.chainalysis.com/reports/2022-defi-hacks/\" rel=\"noreferrer noopener\" target=\"_blank\">increasingly focused on decentralized finance (DeFi) platforms</a>.</li><li>Could a <a href=\"https://thenextweb.com/news/web3-developers-building-decentralized-wikipedia-evade-russian-censorship\" rel=\"noreferrer noopener\" target=\"_blank\">web3 version of Wikipedia</a> evade Russia’s demands that they remove “prohibited information”?&nbsp; Or will it lead to a Wikipedia that’s <a href=\"https://theoutline.com/post/2369/everipedia-is-the-wikipedia-for-being-wrong\" rel=\"noreferrer noopener\" target=\"_blank\">distorted by economic incentives</a> (like past attempts to build a blockchain-based encyclopedia)?</li><li>The <a href=\"https://blog.helium.com/elevating-the-helium-network-with-new-helium-inc-name-series-d-46d8266fb7\" rel=\"noreferrer noopener\" target=\"_blank\">Helium Network</a> is a decentralized public wide area network using LoRaWAN that pays access point operators in cryptocurrency. The network has over 700,000 hotspots, and coverage in most of the world’s major metropolitan areas.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Do we really need another shell scripting language?\\xa0 The developers of <a href=\"https://hush-shell.github.io/foreword.html\" rel=\"noreferrer noopener\" target=\"_blank\">hush</a> think we do.\\xa0 Hush is based on <a href=\"https://www.lua.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Lua</a>, and claims to make shell scripting more robust and maintainable.</li><li>Web Assembly is making inroads; here’s a <a href=\"https://reneeshah.medium.com/how-webassembly-gets-used-the-18-most-exciting-startups-building-with-wasm-939474e951db\" rel=\"noreferrer noopener\" target=\"_blank\">list of startups using wasm</a> for everything from client-side media editing to building serverless platforms, smart data pipelines, and other server-side infrastructure.</li><li>QR codes are awful. Are they less awful when they’re <a href=\"https://www.bleepingcomputer.com/news/technology/animated-qr-codes-how-do-they-work-and-how-to-create-your-own/\" rel=\"noreferrer noopener\" target=\"_blank\">animated</a>? It doesn’t sound like it should work, but playing games with the error correction built into the standard allows the construction of animated QR codes.</li><li>Build your own quantum computer (in simulation)?\\xa0 <a href=\"https://quantumai.google/education/thequbitgame\" rel=\"noreferrer noopener\" target=\"_blank\">The Qubit Game</a> lets players “build” a quantum computer, starting with a single qubit.</li><li>One of Docker’s founders is developing a new product, <a href=\"https://medium.com/@Aaron-007/docker-founder-launches-new-devops-platform-dagger-which-has-secured-hundreds-of-millions-in-19bfde266191\" rel=\"noreferrer noopener\" target=\"_blank\">Dagger</a>, that will help developers manage DevOps pipelines.</li><li>Can applications use “<a href=\"https://www.theverge.com/2022/4/15/23026074/google-little-signals-concept-diy-build-ambient-notifications\" rel=\"noreferrer noopener\" target=\"_blank\">ambient notifications</a>” (like a breeze, a gentle tap, or a shift in shadows) rather than intrusive beeps and gongs?\\xa0 Google has published <a href=\"https://experiments.withgoogle.com/little-signals\" rel=\"noreferrer noopener\" target=\"_blank\">Little Signals</a>, six experiments with ambient notifications that includes code, electronics, and 3D models for hardware.</li><li><a href=\"https://aws.amazon.com/blogs/aws/announcing-aws-lambda-function-urls-built-in-https-endpoints-for-single-function-microservices/?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform\" rel=\"noreferrer noopener\" target=\"_blank\">Lambda Function URLs</a> automate the configuration of an API endpoint for single-function microservices on AWS. They make the process of mapping a URL to a serverless function simple.</li><li>GitHub has added a <a href=\"https://www.bleepingcomputer.com/news/security/github-can-now-alert-of-supply-chain-bugs-in-new-dependencies/\" rel=\"noreferrer noopener\" target=\"_blank\">dependency review</a> feature that inspects the consequences of a pull request and warns of vulnerabilities that were introduced by new dependencies.</li><li>Google has proposed <a href=\"https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform\" rel=\"noreferrer noopener\" target=\"_blank\">Supply Chain Levels for Software Artifacts</a> (SLSA) as a framework for\\xa0 ensuring the integrity of the software supply chain.\\xa0 It is a set of security guidelines that can be used to generate metadata; the metadata can be audited and tracked to ensure that software components have not been tampered with and have traceable provenance.</li><li>Harvard and the Linux Foundation have produced <a href=\"https://linuxfoundation.org/tools/census-ii-of-free-and-open-source-software-application-libraries/\" rel=\"noreferrer noopener\" target=\"_blank\">Census II</a>, which <a href=\"https://thenewstack.io/secure-your-code-with-census-ii-open-source-libraries/\" rel=\"noreferrer noopener\" target=\"_blank\">lists thousands of the most popular open source libraries</a> and attempts to rank their usage.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>The <a href=\"https://www.bleepingcomputer.com/news/security/revils-tor-sites-come-alive-to-redirect-to-new-ransomware-operation/\" rel=\"noreferrer noopener\" target=\"_blank\">REvil ransomware has returned</a> (maybe). Although there’s a lot of speculation, it isn’t yet clear what this means or who is behind it. Nevertheless, they appear to be looking for business partners.</li><li>Attackers used stolen OAuth tokens to <a href=\"https://github.blog/2022-04-15-security-alert-stolen-oauth-user-tokens/\" rel=\"noreferrer noopener\" target=\"_blank\">compromise GitHub</a> and download data from a number of organizations, most notably npm.</li><li>The NSA, Department of Energy, and other federal agencies have <a href=\"https://arstechnica.com/information-technology/2022/04/us-uncovers-swiss-army-knife-for-hacking-industrial-control-systems/\" rel=\"noreferrer noopener\" target=\"_blank\">discovered a new malware toolkit</a> named “pipedream” that is designed to disable power infrastructure. It&#8217;s adaptable to other critical infrastructure systems.\\xa0It doesn’t appear to have been used yet.</li><li>A <a href=\"https://www.bleepingcomputer.com/news/security/sandworm-hackers-fail-to-take-down-ukrainian-energy-provider/\" rel=\"noreferrer noopener\" target=\"_blank\">Russian state-sponsored group known as Sandworm</a> failed in an attempt to bring down the Ukraine&#8217;s power grid. They used new versions of Industroyer (for attacking industrial control systems) and Caddywiper (for cleaning up after the attack).</li><li>Re-use of IP addresses by a cloud provider can lead to “<a href=\"https://techxplore.com/news/2022-04-cloud-server-leasing-sensitive.html\" rel=\"noreferrer noopener\" target=\"_blank\">cloud squatting</a>,” where an organization that is assigned a previously used IP address receives data intended for the previous addressee. Address assignment has become highly dynamic; DNS wasn’t designed for that.</li><li>Pete Warden wants to build a coalition of researchers that will discuss ways of <a href=\"https://petewarden.com/2022/04/11/is-google-spying-on-your-conversations/\" rel=\"noreferrer noopener\" target=\"_blank\">verifying the privacy of devices</a> that have cameras and microphones (not limited to phones).</li><li>Cyber warfare on the home front: The FBI remotely accessed devices at some US companies to <a href=\"https://arstechnica.com/information-technology/2022/04/fbi-accesses-us-servers-to-dismantle-botnet-malware-installed-by-russian-spies/\" rel=\"noreferrer noopener\" target=\"_blank\">remove Russian botnet malware</a>. The malware targets WatchGuard firewalls and Asus routers. The Cyclops Blink botnet was developed by the Russia-sponsored Sandworm group.</li><li>Ransomware attacks have been seen that <a href=\"https://blog.aquasec.com/python-ransomware-jupyter-notebook\" rel=\"noreferrer noopener\" target=\"_blank\">target Jupyter Notebooks</a> on notebook servers where <a href=\"https://blog.jupyter.org/please-dont-disable-authentication-in-jupyter-servers-dd197206e7f6\" rel=\"noreferrer noopener\" target=\"_blank\">authentication has been disabled</a>. There doesn’t appear to be a significant vulnerability in Jupyter itself; just don&#8217;t disable authentication!</li><li>By using a version of <a href=\"https://techxplore.com/news/2022-03-tool-privacy-surveillance-footage.html\" rel=\"noreferrer noopener\" target=\"_blank\">differential privacy on video feeds</a>, surveillance cameras can provide a limited kind of privacy. Users can ask questions about the image, but can’t identify individuals. (Whether anyone wants a surveillance camera with privacy features is another question.)</li></ul>\\n\\n\\n\\n<h2>Biology and Neuroscience</h2>\\n\\n\\n\\n<ul><li>A <a href=\"https://arstechnica.com/science/2022/04/bci-lets-completely-locked-in-man-communicate-with-his-son-ask-for-a-beer/\" rel=\"noreferrer noopener\" target=\"_blank\">brain-computer interface</a> has allowed an ALS patient who was completely “locked in” to communicate with the outside world.&nbsp; Communication is slow, but it goes well beyond simple yes/no requests.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li>CAT scans aren’t just for radiology. <a href=\"https://www.lumafield.com/products\" rel=\"noreferrer noopener\" target=\"_blank\">Lumafield</a> has produced a table-sized CT-scan machine that can be used in small shops and offices, with the image analysis done in their cloud.</li><li>Boston Dynamics has a second robot on the market: <a href=\"https://arstechnica.com/gadgets/2022/04/boston-dynamics-stretch-robot-hits-production-and-its-already-sold-out/\" rel=\"noreferrer noopener\" target=\"_blank\">Stretch</a>, a box-handling robot designed to perform tasks like unloading trucks and shipping containers.</li><li>A startup claims it has the ability to put <a href=\"https://www.technologyreview.com/2022/03/31/1048672/roswell-molecular-electronics-revival/\" rel=\"noreferrer noopener\" target=\"_blank\">thousands of single-molecule biosensors on a silicon chip</a> that can be mass-produced. They intend to have a commercial product by the end of 2022. </li></ul>\\n\\n\\n\\n<h2>Metaverse</h2>\\n\\n\\n\\n<ul><li>Meta is releasing tools that will <a href=\"https://www.theverge.com/2022/4/11/23020684/meta-horizon-worlds-test-creators-sell-virtual-items-monetization\" rel=\"noreferrer noopener\" target=\"_blank\">allow creators to sell virtual merchandise</a> in Horizon Worlds, Meta’s virtual world platform. Meta will take a significant cut of the payment.</li><li>Meta is planning a <a href=\"https://thenextweb.com/news/meta-f8-cancel-zuck-bucks-analysis\" rel=\"noreferrer noopener\" target=\"_blank\">digital currency for its Metaverse</a>. It won’t be a cryptocurrency, and won’t be backed by a blockchain. It will probably be similar to an in-game currency. It might be used as compensation for posts in Facebook groups or Instagram. And it probably has little relationship to Facebook’s failed <a href=\"https://en.wikipedia.org/wiki/Diem_(digital_currency)\" rel=\"noreferrer noopener\" target=\"_blank\">Diem</a> cryptocurrency.</li><li>Pixar’s <a href=\"https://github.com/PixarAnimationStudios/USD\" rel=\"noreferrer noopener\" target=\"_blank\">Universal Scene Description</a> (USD) provides a way to <a href=\"https://medium.com/@nvidiaomniverse/plumbing-for-the-metaverse-with-universal-scene-description-usd-856a863d9b12\" rel=\"noreferrer noopener\" target=\"_blank\">share and collaborate in virtual worlds</a>.</li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/feed/', 'slash_comments': '0'}], 'feed': {'title': 'Radar', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar'}, 'links': [{'href': 'https://www.oreilly.com/radar/feed/', 'rel': 'self', 'type': 'application/rss+xml'}, {'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar'}], 'link': 'https://www.oreilly.com/radar', 'subtitle': 'Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology', 'subtitle_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology'}, 'updated': 'Tue, 16 Aug 2022 15:37:30 +0000', 'updated_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=16, tm_hour=15, tm_min=37, tm_sec=30, tm_wday=1, tm_yday=228, tm_isdst=0), 'language': 'en-US', 'sy_updateperiod': 'hourly', 'sy_updatefrequency': '1', 'generator_detail': {'name': 'https://wordpress.org/?v=5.3.12'}, 'generator': 'https://wordpress.org/?v=5.3.12'}, 'headers': {'content-type': 'text/xml; charset=utf-8', 'vary': 'Sec-Fetch-Dest, Sec-Fetch-Mode, Sec-Fetch-Site', 'feedburnerv2': '', 'cache-control': 'no-cache, no-store, max-age=0, must-revalidate', 'pragma': 'no-cache', 'expires': 'Mon, 01 Jan 1990 00:00:00 GMT', 'date': 'Mon, 22 Aug 2022 20:59:20 GMT', 'cross-origin-opener-policy': 'same-origin; report-to=\"RaichuFeedServer\"', 'permissions-policy': 'ch-ua-arch=*, ch-ua-bitness=*, ch-ua-full-version=*, ch-ua-full-version-list=*, ch-ua-model=*, ch-ua-platform=*, ch-ua-platform-version=*', 'cross-origin-resource-policy': 'same-site', 'content-security-policy': \"script-src 'report-sample' 'nonce-Zx4-3HKFoQUbSQjpx8oZ8Q' 'unsafe-inline';object-src 'none';base-uri 'self';report-uri /_/RaichuFeedServer/cspreport;worker-src 'self'\", 'accept-ch': 'Sec-CH-UA-Arch, Sec-CH-UA-Bitness, Sec-CH-UA-Full-Version, Sec-CH-UA-Full-Version-List, Sec-CH-UA-Model, Sec-CH-UA-Platform, Sec-CH-UA-Platform-Version', 'report-to': '{\"group\":\"RaichuFeedServer\",\"max_age\":2592000,\"endpoints\":[{\"url\":\"https://csp.withgoogle.com/csp/report-to/RaichuFeedServer/external\"}]}', 'content-encoding': 'gzip', 'transfer-encoding': 'chunked', 'x-content-type-options': 'nosniff', 'x-xss-protection': '1; mode=block', 'server': 'GSE', 'connection': 'close'}, 'href': 'http://feeds.feedburner.com/oreilly/radar/atom', 'status': 200, 'encoding': 'utf-8', 'version': 'rss20', 'namespaces': {'content': 'http://purl.org/rss/1.0/modules/content/', 'wfw': 'http://wellformedweb.org/CommentAPI/', 'dc': 'http://purl.org/dc/elements/1.1/', '': 'http://www.w3.org/2005/Atom', 'sy': 'http://purl.org/rss/1.0/modules/syndication/', 'slash': 'http://purl.org/rss/1.0/modules/slash/'}}\n"
     ]
    }
   ],
   "source": [
    "oreilly = feedparser.parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Obtain a list of components (keys) that are available for this feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bozo', 'entries', 'feed', 'headers', 'href', 'status', 'encoding', 'version', 'namespaces']\n"
     ]
    }
   ],
   "source": [
    "oreilly_components = list(oreilly.keys())\n",
    "print(oreilly_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obtain a list of components (keys) that are available for the *feed* component of this RSS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'title_detail', 'links', 'link', 'subtitle', 'subtitle_detail', 'updated', 'updated_parsed', 'language', 'sy_updateperiod', 'sy_updatefrequency', 'generator_detail', 'generator']\n",
      "{'title': 'Radar', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar'}, 'links': [{'href': 'https://www.oreilly.com/radar/feed/', 'rel': 'self', 'type': 'application/rss+xml'}, {'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar'}], 'link': 'https://www.oreilly.com/radar', 'subtitle': 'Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology', 'subtitle_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology'}, 'updated': 'Tue, 16 Aug 2022 15:37:30 +0000', 'updated_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=16, tm_hour=15, tm_min=37, tm_sec=30, tm_wday=1, tm_yday=228, tm_isdst=0), 'language': 'en-US', 'sy_updateperiod': 'hourly', 'sy_updatefrequency': '1', 'generator_detail': {'name': 'https://wordpress.org/?v=5.3.12'}, 'generator': 'https://wordpress.org/?v=5.3.12'}\n"
     ]
    }
   ],
   "source": [
    "oreilly_feed_components = list(oreilly.feed.keys())\n",
    "print(oreilly_feed_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract and print the feed title, subtitle, author, and link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Radar', 'Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology', 'https://www.oreilly.com/radar')\n"
     ]
    }
   ],
   "source": [
    "# WARNING: THERE'S NO 'AUTHOR' COMPONENT IN FEED\n",
    "\n",
    "oreilly_feed_components_selected = (oreilly.feed.title, oreilly.feed.subtitle, oreilly.feed.link)\n",
    "print(oreilly_feed_components_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Count the number of entries that are contained in this RSS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "[{'title': 'Ad Networks and Content Marketing', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Ad Networks and Content Marketing'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/'}], 'link': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/', 'comments': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/#respond', 'published': 'Tue, 16 Aug 2022 11:21:21 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=16, tm_hour=11, tm_min=21, tm_sec=21, tm_wday=1, tm_yday=228, tm_isdst=0), 'authors': [{'name': 'Q McCallum'}], 'author': 'Q McCallum', 'author_detail': {'name': 'Q McCallum'}, 'tags': [{'term': 'Operations', 'scheme': None, 'label': None}, {'term': 'Deep Dive', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14688', 'guidislink': False, 'summary': 'In a recent Radar piece, I explored N-sided marketplaces and the middlemen who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend weighing in at $763 billion in 2021 revenues. Most [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'In a recent Radar piece, I explored N-sided marketplaces and the middlemen who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend weighing in at $763 billion in 2021 revenues. Most [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>In a recent Radar piece, I explored <a href=\"https://www.oreilly.com/radar/building-a-better-middleman/\" rel=\"noreferrer noopener\" target=\"_blank\">N-sided marketplaces and the middlemen</a> who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend <a href=\"https://www.statista.com/topics/990/global-advertising-market/#dossierKeyfigures\" rel=\"noreferrer noopener\" target=\"_blank\">weighing in at $763 <em>billion</em> in 2021 revenues</a>.</p>\\n\\n\\n\\n<p>Most of that money is <a href=\"https://www.emarketer.com/content/worldwide-digital-ad-spending-2021\" rel=\"noreferrer noopener\" target=\"_blank\">spent on digital ads</a>, like the ones that follow you across websites to offer you deals on items you&#8217;ve just bought. Those are typically based on your online activity. Ad networks trail behind you as you browse the web, trying to get an idea of who you are and what you&#8217;re likely to buy, so they can pair you with hopeful merchants.</p>\\n\\n\\n\\n<p>While merchants are clearly happy with targeted ads—at least, I&#8217;d hope so, given how much they&#8217;re spending—consumers have, understandably, expressed concerns over personal privacy.\\xa0Apple took note, and <a href=\"https://www.cnbc.com/2022/02/02/facebook-says-apple-ios-privacy-change-will-cost-10-billion-this-year.html\" rel=\"noreferrer noopener\" target=\"_blank\">limited iOS apps&#8217; ability to track users</a> across sites. Google has announced <a href=\"https://www.cnet.com/tech/computing/google-chromes-privacy-changes-will-hit-the-web-later-this-year/\" rel=\"noreferrer noopener\" target=\"_blank\">changes that would further limit advertisers&#8217; reach</a>. Who knows? Maybe the next step will be that the ad industry gets stronger regulations.</p>\\n\\n\\n\\n<p>There&#8217;s also the <a href=\"https://thecorrespondent.com/100/the-new-dot-com-bubble-is-here-its-called-online-advertising\" rel=\"noreferrer noopener\" target=\"_blank\">question of whether targeted advertising even works</a>.&nbsp; While the ad networks aren&#8217;t required to disclose their stats, there are even people inside those companies who think that <a href=\"https://theintercept.com/2020/12/24/facebook-ad-targeting-small-business/\" rel=\"noreferrer noopener\" target=\"_blank\">their product is &#8220;almost all crap.&#8221;</a></p>\\n\\n\\n\\n<p>Maybe it&#8217;s time for a different approach?\\xa0Recently, Disney&#8217;s video streaming service, Disney+, threw its hat into the advertising ring by announcing a new ad-supported plan. (Credit where it&#8217;s due: I originally <a href=\"https://www.lesechos.fr/tech-medias/medias/disney-va-lancer-une-offre-avec-de-la-publicite-1391472\" rel=\"noreferrer noopener\" target=\"_blank\">found this in <em>Les Echos</em></a>, which may be paywalled. Here&#8217;s the official, English-language <a href=\"https://thewaltdisneycompany.com/disney-to-introduce-an-ad-supported-subscription-offering-in-late-2022/\" rel=\"noreferrer noopener\" target=\"_blank\">press release from Disney</a>.)</p>\\n\\n\\n\\n<p>It may be easy to disregard this Disney+ move, since so much of the online world is ad-supported these days. But I think this merits more attention than it may seem on the surface.</p>\\n\\n\\n\\n<p>To be clear: I have no inside information here. But it at least <em>looks like</em> Disney+ can run its ad platform in a fairly low-tech fashion while also preserving privacy. That&#8217;s a pretty big deal for Disney, for consumers, and for the wider space of online advertising.</p>\\n\\n\\n\\n<h3>Everything old is new again</h3>\\n\\n\\n\\n<p>To understand why, let&#8217;s first consider the idea of <em>&#8220;content marketing.&#8221;</em> This is a new term for the age-old practice of selling ad space next to curated content that aligns with a particular theme. For example, let&#8217;s say you&#8217;ve created a magazine about cars. Motoring enthusiasts will read your magazine, which means advertisers (merchants) who want to reach them will place ads in your pages. The content is what draws readers and advertisers to the same spot.</p>\\n\\n\\n\\n<p>What&#8217;s nice about content marketing is that the ad&#8217;s placement is based on the <em>content,</em> not the <em>specific person reading it.</em></p>\\n\\n\\n\\n<p>This addresses the privacy concern at the core of targeted advertising, because content marketing doesn&#8217;t require that you build a detailed profile of a person based on their every browsing habit. You&#8217;re not pairing an ad to a person; you&#8217;re pairing an ad to a piece of content. So you shift your analytical focus from the reader to what they&#8217;re reading.</p>\\n\\n\\n\\n<h3>The mouse has a large library</h3>\\n\\n\\n\\n<p>Now, consider Disney: its catalog spans decades&#8217; worth of cartoons, tween sitcoms, and movies. Its recent acquisition of the Star Wars franchise gives it access to an even wider fanbase. And don&#8217;t forget that Disney owns ESPN, which adds sports content to the portfolio. It now makes that content available through its video-on-demand (VOD) platform of Disney+.</p>\\n\\n\\n\\n<p>Disney already has to keep track of that catalog of content as part of its day-to-day business, which means we can reasonably assume that every show, movie, and sporting event on Disney+ has been assigned some number of descriptive tags or labels.</p>\\n\\n\\n\\n<p>From the perspective of content marketing, all of this adds up to Disney+ being able to place ads on that content without having to do much extra work. The parent company, Disney, already owns the content and it&#8217;s already been tagged. The depth and breadth of the video catalog will certainly attract a large number and wide variety of viewers. That shifts the heavy lifting to the ad-matching system, which connects advertisers with the content.</p>\\n\\n\\n\\n<h3>Tracking your ad budget</h3>\\n\\n\\n\\n<p>You&#8217;ve likely heard the John Wanamaker adage: &#8220;Half the money I spend on advertising is wasted; the trouble is, I don&#8217;t know which half.&#8221; It&#8217;s a well-founded complaint about billboard or magazine advertising, since an advertiser can&#8217;t really tell how many people saw a given ad.</p>\\n\\n\\n\\n<p>(Some early advertising pioneers, David Ogilvy among them, learned to supply coupons with print ads so stores could track which one had resonated the most. While this added a new level of analytical rigor to the field, it still wasn&#8217;t a perfect solution to Wanamaker&#8217;s plight.)</p>\\n\\n\\n\\n<p>Delivering content-based ads through a well-curated streaming platform addresses that somewhat. Disney+ can provide an advertiser a detailed analysis of their ad spend without revealing any individual&#8217;s identity: <em>&#8220;N number of people watched Variant V, your ad for Product P, during Show S, with the following breakdowns for time of day&#8230;&#8221;</em></p>\\n\\n\\n\\n<p>And that leads me to my next point:</p>\\n\\n\\n\\n<h3>Minimal ML/AI</h3>\\n\\n\\n\\n<p>When you review the setup—a curated and labeled catalog, with broad-brush marketing characteristics—Disney+ has the ability to run this ad service using minimal ML/AI.</p>\\n\\n\\n\\n<p>(Once again: I&#8217;m speculating from the outside here. I don&#8217;t know for sure how much ML/AI Disney+ is using or plans to use. I&#8217;m working through one hypothetical-yet-seemingly-plausible scenario.)</p>\\n\\n\\n\\n<p>Disney+ can use those content labels—&#8221;pro football,&#8221; &#8220;tween comedy,&#8221; &#8220;gen-X cartoon&#8221;—to pair a piece of content with an advertisement. They may not get a <em>perfect</em> hit rate on these ads; but given that they&#8217;re building on top of work they&#8217;ve already done (the catalog and the streaming platform) then the ad system can run at a relatively low cost. And providing stats to advertisers is a matter of counting. Since those calculations are so trivial, I expect the toughest part of that BI will be scaling it to Disney&#8217;s audience size.</p>\\n\\n\\n\\n<p>Can Disney+ still use ML/AI in places? They most certainly <em>can,</em> but they don&#8217;t <em>have to.</em> Disney+ has the option to run this using a smaller team of data scientists and a far smaller data analysis infrastructure. Whether you call this &#8220;smaller budget&#8221; or &#8220;higher margins,&#8221; the net effect is the same: the company ends the day with money in its pocket.</p>\\n\\n\\n\\n<p>Disney+ can task that ML team with building models that better tag content, or that improve matches between content and advertisers. They don&#8217;t have to spend money analyzing the specific actions of a specific individual in the hopes of placing ads.</p>\\n\\n\\n\\n<h3>Future-proofing the ad system</h3>\\n\\n\\n\\n<p>Assuming that the Disney+ ad system will indeed run on a content marketing concept, that means the company has one more card to play: They have just sidestepped potential future privacy laws that limit the use of personal information.</p>\\n\\n\\n\\n<p>Yes, Disney+ can get a person&#8217;s contact information when they subscribe to the service. Yes, the company can track customer behavior on- and off-platform, through a mix of first- and third-party data. But, contrary to targeted advertising, they don&#8217;t <em>need</em> all of that to run ads. All the company needs is to pair content with an advertisement. Given that this is the modern-day equivalent of a billboard or newspaper article, I imagine it would be difficult for Disney+ to run afoul of any present-day or upcoming privacy regulation with such an ad setup.</p>\\n\\n\\n\\n<h3>There&#8217;s still some room for trouble&#8230;</h3>\\n\\n\\n\\n<p>Going back to our car magazine example, Disney&#8217;s library is the equivalent of hundreds or even thousands of magazines. And if a single magazine is a hint as to a single interest, what can a larger number of magazines tell us?</p>\\n\\n\\n\\n<p>By tracking what content a person watches, how they watch it (phone, tablet, TV), and what time of day, Disney+ could infer quite a bit about that person and household: the number and age of adults; marital or relationship status; age and number of children; whether this is a multi-generational household; and even some clues as to viewers&#8217; gender. (I emphasize the term &#8220;infer&#8221; here, since it would hardly be perfect.)</p>\\n\\n\\n\\n<p>In turn, Disney <em>could</em> use this for ad targeting, or to provide even more-detailed breakdowns to advertisers, or even find ways to share the data with other companies. This could get creepy quickly, so let&#8217;s hope they don&#8217;t take this route. And based on what we&#8217;ve covered thus far, Disney+ has every opportunity to run an ad network that preserves a reasonable amount of privacy.</p>\\n\\n\\n\\n<h3>Could the tail someday wag the dog?</h3>\\n\\n\\n\\n<p>Another possible wrinkle would be in how advertising weighs on future content.</p>\\n\\n\\n\\n<p>Disney already has a good eye for what people will want to watch. And right now, those viewers are Disney&#8217;s customers. But when Disney+ becomes an ad marketplace, they&#8217;ll officially be a middleman, which means they&#8217;ll have to keep both sides of the ad equation happy. At what point does Disney use the Disney+ advertising as a compass, feeding back into decisions around what content to create?</p>\\n\\n\\n\\n<p>And would Disney ever stretch beyond its own character lines, to build TV and movies around someone <em>else&#8217;s</em> toys?&nbsp; It&#8217;s not too far-fetched of an idea. In <em>The Great Beanie Baby Bubble,</em> author Zac Bisonette points out that:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>[A TV show deal] was the kind of product-based programming that was responsible for billions per year in sales and could turn toys that no one wanted into hits through sheer exposure. Lines such as He-Man, My Little Pony, and the ThunderCats had all become hundred-million-dollar brands with the help of the product-based TV shows that accompanied their launches.</p></blockquote>\\n\\n\\n\\n<p>Creating content in one side of the businesses while running ads in the other, it&#8217;s not unlike running an investment bank and retail bank under one roof: sure, it can lead to all kinds of interesting business opportunities.&nbsp; It can also lead to trouble.</p>\\n\\n\\n\\n<p>When it comes to content marketing, you need to strike a balance: you want to create evergreen content, so you can continue to run ads. And when that content is going into the Disney catalog—some of which currently spans multiple generations—it has to be absolutely timeless. Giving in to the whims of a single advertiser, or a single fad, can lead to short-term gains but also short-lived content.</p>\\n\\n\\n\\n<h3>Beyond the Magic Kingdom</h3>\\n\\n\\n\\n<p>Despite those challenges, content marketing has huge potential for generating revenue, preserving privacy, and avoiding future regulation that could hinder targeted advertising. By building this system on BI and content tagging, Disney could do so at a smaller price tag than an AI-based, targeted-ad marketplace.</p>\\n\\n\\n\\n<p>And this isn&#8217;t just a Disney opportunity. I&#8217;ve focused on them in this piece but other VOD providers have already seen the benefit in monetizing their catalog. <a href=\"https://www.bloomberg.com/news/newsletters/2022-04-10/the-phone-company-didn-t-destroy-hbo-will-the-cable-guy\" rel=\"noreferrer noopener\" target=\"_blank\">According to Jason Kilar</a>, former CEO of WarnerMedia, &#8220;Close to 50% of every new [HBO Max] subscriber is choosing the ad tier. Hulu, the last stat they shared publicly, is they are north of 60%.&#8221; Amazon will rename its ad-supported IMDb TV service to Freevee. (I first saw this in <a href=\"https://www.spiegel.de/netzwelt/freevee-amazon-kuendigt-deutschland-start-von-kostenlosem-streamingdienst-an-a-4bfbd854-34ca-476b-95b7-3ff5763d3966\" rel=\"noreferrer noopener\" target=\"_blank\">Der Spiegel</a>; I&#8217;ve since found a <a href=\"https://apnews.com/article/technology-business-amazoncom-inc-netflix-jennifer-salke-84b0978c4880366ea6bd8dfff7e77af0\" rel=\"noreferrer noopener\" target=\"_blank\">US&nbsp; press release</a>.)&nbsp; And Netflix, long a holdout in the ad-supported space, hinted at <a href=\"https://www.bloomberg.com/news/articles/2022-04-19/netflix-plans-lower-priced-service-with-ads-marking-big-shift\" rel=\"noreferrer noopener\" target=\"_blank\">plans for a similar offering</a>.</p>\\n\\n\\n\\n<p>To be clear, content marketing at this scale is not exactly a get-rich-quick scheme.\\xa0It works best for groups that already have a large amount of content—video, image, text, audio—that they can monetize. This certainly holds true for the platforms I&#8217;ve just mentioned. Maybe it&#8217;s also true for your company?</p>\\n\\n\\n\\n<p>It may require getting creative as you comb through your attic. And maybe there&#8217;s an option for a new kind of ad marketplace, one that groups people with a small amount of content into a larger content ecosystem.&nbsp;Sort of like what <a href=\"https://www.ethicalads.io/\" rel=\"noreferrer noopener\" target=\"_blank\">EthicalAds</a> does for developer documentation. If low-cost, non-invasive content marketing is an option, it can&#8217;t hurt to try.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<p>Many thanks to <a href=\"https://www.oreilly.com/people/chris-butler/\" rel=\"noreferrer noopener\" target=\"_blank\">Chris Butler</a> for reviewing an early draft of this article. I always appreciate his insights. The section on the tail wagging the dog was based on his idea and I give him full credit for pointing this out to me.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/feed/', 'slash_comments': '0'}, {'title': 'On Technique', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'On Technique'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/on-technique/'}], 'link': 'https://www.oreilly.com/radar/on-technique/', 'comments': 'https://www.oreilly.com/radar/on-technique/#respond', 'published': 'Tue, 09 Aug 2022 11:12:22 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=9, tm_hour=11, tm_min=12, tm_sec=22, tm_wday=1, tm_yday=221, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14669', 'guidislink': False, 'summary': 'In a previous article, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'In a previous article, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>In a <a href=\"https://www.oreilly.com/radar/artificial-creativity-2/\" rel=\"noreferrer noopener\" target=\"_blank\">previous article</a>, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, “Make me a picture of a lion attacking a horse,” and it will happily generate one. Maybe not as good as the one that <a href=\"https://collections.britishart.yale.edu/catalog/tms:32\" rel=\"noreferrer noopener\" target=\"_blank\">hangs in an art museum</a>, but you don’t need to know anything about canvas, paints, and brushes, nor do you need to get your clothes covered with paint. </p>\\n\\n\\n\\n<p>This raises some important questions, though. What is the connection between expertise and ideation? Does technique help you form ideas? (The Victorian artist William Morris is often <a href=\"https://books.google.com/books?id=Til0DwAAQBAJ&amp;pg=PT292&amp;lpg=PT292&amp;dq=%E2%80%9CYou+can%E2%80%99t+have+art,%E2%80%9D+said+William+Morris,+the+designer,+poet,+and+master+craftsman+of+the+Victorians,+%E2%80%9Cwithout+resistance+in+the+material.%E2%80%9D&amp;source=bl&amp;ots=WYX6uA9wTq&amp;sig=ACfU3U3M2qyEIEsf1rrjKJ3poWb8CWIj9g&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj0-JHhlo35AhUVjIkEHYP-AT0Q6AF6BAgCEAM#v=onepage&amp;q=%E2%80%9CYou%20can%E2%80%99t%20have%20art%2C%E2%80%9D%20said%20William%20Morris%2C%20the%20designer%2C%20poet%2C%20and%20master%20craftsman%20of%20the%20Victorians%2C%20%E2%80%9Cwithout%20resistance%20in%20the%20material.%E2%80%9D&amp;f=false\" rel=\"noreferrer noopener\" target=\"_blank\">quoted</a> as saying “You can’t have art without resistance in the materials,” though he may only have been talking about his hatred of typewriters.) And what kinds of user interfaces will be effective for collaborations between humans and computers, where the computers supply the technique and we supply the ideas? Designing the prompts to get DALL-E to do something extraordinary requires a new kind of technique that’s very different from understanding pigments and brushes. What kinds of creativity does that new technique enable? How are these works different from what came before?</p>\\n\\n\\n\\n<p>As interesting as it is to talk about art, there’s an area where these questions are more immediate. GitHub Copilot (based on a model named <a href=\"https://openai.com/blog/openai-codex/\" rel=\"noreferrer noopener\" target=\"_blank\">Codex</a>, which is derived from GPT-3) generates code in a number of programming languages, based on comments that the user writes. Going in the other direction, GPT-3 has proven to be surprisingly good at <a href=\"https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/\" rel=\"noreferrer noopener\" target=\"_blank\">explaining code</a>. Copilot users still need to be programmers; they need to know whether the code that Copilot supplies is correct, and they need to know how to test it. The prompts themselves are really a sort of pseudo-code; even if the programmers don’t need to remember details of the language’s syntax or the names of library functions, they still need to think like programmers. But it’s obvious where this is trending. We need to ask ourselves how much “technique” we will ask of future programmers: in the 2030s or 2040s, will people just be able to tell some future Copilot what they want a program to be? More to the point, what sort of higher-order knowledge will future programmers need? Will they be able to focus more on the nature of what they want to accomplish, and less on the syntactic details of writing code?</p>\\n\\n\\n\\n<p>It’s easy to imagine a lot of software professionals saying, “Of course you’ll have to know C. Or Java. Or Python. Or Scala.” But I don’t know if that’s true. We’ve been here before. In the 1950s, computers were programmed in machine language. (And before that, with cables and plugs.) It’s hard to imagine now, but the introduction of the first programming languages–Fortran, COBOL, and the like–was met with resistance from programmers who thought you needed to understand the machine. Now almost no one works in machine language or assembler. Machine language is reserved for a few people who need to work on some specialized areas of operating system internals, or who need to write some kinds of embedded systems code.</p>\\n\\n\\n\\n<p>What would be necessary for another transformation? Tools like Copilot, useful as they may be, are nowhere near ready to take over. What capabilities will they need? At this point, programmers still have to decide whether or not code generated by Copilot is correct.&nbsp;We don’t (generally) have to decide whether the output of a C or Java compiler is correct, nor do we have to worry about whether, given the same source code, the compiler will generate identical output. Copilot doesn’t make that guarantee–and, even if it did, any change to the model (for example, to incorporate new StackOverflow questions or GitHub repositories) would be very likely to change its output.&nbsp;While we can certainly imagine compiling a program from a series of Copilot prompts, I can’t imagine a program that would be likely to stop working if it was recompiled without changes to the source code. Perhaps the only exception would be a library that could be developed once, then tested, verified, and used without modification–but the development process would have to re-start from ground zero whenever a bug or a security vulnerability was found. That wouldn’t be acceptable; we’ve never written programs that don’t have bugs, or that never need new features. A key principle behind much modern software development is minimizing the amount of code that has to change to fix bugs or add features.</p>\\n\\n\\n\\n<p>It’s easy to think that programming is all about creating new code. It isn’t; one thing that every professional learns quickly is that most of the work goes into maintaining old code. A new generation of programming tools must take that into account, or we’ll be left in a weird situation where a tool like Copilot can be used to write new code, but programmers will still have to understand that code in detail because it can only be maintained by hand. (It is possible–even likely–that we will have AI-based tools that help programmers research software supply chains, discover vulnerabilities, and possibly even suggest fixes.) Writing about AI-generated art, Raphaël Millière <a href=\"https://www.wired.com/story/dalle-art-curation-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">says</a>, “No prompt will produce the exact same result twice”; that may be desirable for artwork, but is destructive for programming. Stability and consistency is a requirement for next-generation programming tools; we can’t take a step backwards.</p>\\n\\n\\n\\n<p>The need for greater stability might drive tools like Copilot from free-form English language prompts to some kind of more formal language. A book about <a href=\"https://dallery.gallery/the-dalle-2-prompt-book/\" rel=\"noreferrer noopener\" target=\"_blank\">prompt engineering for DALL-E</a> already exists; in a way, that’s trying to reverse-engineer a formal language for generating images. A formal language for prompts is a move back in the direction of traditional programming, though possibly with a difference. Current programming languages are all about describing, step by step, what you want the computer to do in great detail. Over the years, we’ve gradually progressed to higher levels of abstraction. Could building a language model into a compiler facilitate the creation of a simpler language, one in which programmers just described what they wanted to do, and let the machine worry about the implementation, while providing guarantees of stability? Remember that it was possible to build applications with graphical interfaces, and for those applications to communicate about the Internet, before the Web. The Web (and, specifically, HTML) added a new formal language that encapsulated tasks that used to require programming.</p>\\n\\n\\n\\n<p>Now let’s move up a level or two: from lines of code to functions, modules, libraries, and systems. Everyone I know who has worked with Copilot has said that, while you don’t need to remember the details of the programming libraries you’re using, you have to be even more aware of what you’re trying to accomplish. You have to know what you want to do; you have to have a design in mind. Copilot is good at low-level coding; does a programmer need to be in touch with the craft of low-level coding to think about the high-level design? Up until now that’s certainly been true, but largely out of necessity: you wouldn’t let someone design a large system who hasn’t built smaller systems. It is true (as Dave Thomas and Andy Hunt argued in <a href=\"https://learning.oreilly.com/library/view/the-pragmatic-programmer/9780135956977/\" rel=\"noreferrer noopener\" target=\"_blank\">The Pragmatic Programmer</a>) that knowing different programming languages gives you different tools and approaches for solving problems.&nbsp; Is the craft of software architecture different from the craft of programming?</p>\\n\\n\\n\\n<p>We don’t really have a good language for describing software design. Attempts like UML have been partially successful at best. UML was both over- and under-specified, too precise and not precise enough; tools that generated source code scaffolding from UML diagrams exist, but aren’t commonly used these days. The scaffolding defined interfaces, classes, and methods that could then be implemented by programmers. While automatically generating the structure of a system sounds like a good idea, in practice it may have made things more difficult: if the high-level specification changed, so did the scaffolding, obsoleting any work that had been put into implementing with the scaffold. This is similar to the compiler’s stability problem, modulated into a different key. Is this an area where AI could help?</p>\\n\\n\\n\\n<p>I suspect we still don’t want source code scaffolding, at least as UML envisioned it; that’s bound to change with any significant change in the system’s description. Stability will continue to be a problem. But it might be valuable to have a AI-based design tool that can take a verbal description of a system’s requirements, then generate some kind of design based on a large library of software systems–like Copilot, but at a higher level. Then the problem would be integrating that design with implementations of the design, some of which could be created (or at least suggested) by a system like Copilot. The problem we’re facing is that software development takes place on two levels: high level design and mid-level programming. Integrating the two is a hard problem that hasn’t been solved convincingly.&nbsp; Can we imagine taking a high-level design, adding our descriptions to it, and going directly from the high-level design with mid-level details to an executable program? That programming environment would need the ability to partition a large project into smaller pieces, so teams of programmers could collaborate. It would need to allow changes to the high-level descriptions, without disrupting work on the objects and methods that implement those descriptions. It would need to be integrated with a version control system that is effective for the English-language descriptions as it is for lines of code. This wouldn’t be thinkable without guarantees of stability.</p>\\n\\n\\n\\n<p>It was fashionable for a while to talk about programming as “craft.”&nbsp; I think that fashion has waned, probably for the better; “code as craft” has always seemed a bit precious to me. But the idea of “craft” is still useful: it is important for us to think about how the craft may change, and how fundamental those changes can’t be.&nbsp;It’s clear that we are a long way from a world where only a few specialists need to know languages like C or Java or Python. But it’s also possible that developments like Copilot give us a glimpse of what the next step might be. Lamenting the state of programing tools, which haven’t changed much since the 1960s, Alan Kay <a href=\"https://www.quora.com/What-was-the-last-breakthrough-in-computer-programming\" rel=\"noreferrer noopener\" target=\"_blank\">wrote on Quora</a> that “the next significant threshold that programming must achieve is for programs and programming systems to have a much deeper understanding of both what they are trying to do, and what they are actually doing.” A new craft of programming that is focused less on syntactic details, and more on understanding what the systems we are building are trying to accomplish, is the goal we should be aiming for.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/on-technique/feed/', 'slash_comments': '0'}, {'title': 'Scaling False Peaks', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Scaling False Peaks'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/scaling-false-peaks/'}], 'link': 'https://www.oreilly.com/radar/scaling-false-peaks/', 'comments': 'https://www.oreilly.com/radar/scaling-false-peaks/#respond', 'published': 'Thu, 04 Aug 2022 11:12:44 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=4, tm_hour=11, tm_min=12, tm_sec=44, tm_wday=3, tm_yday=216, tm_isdst=0), 'authors': [{'name': 'Kevlin Henney'}], 'author': 'Kevlin Henney', 'author_detail': {'name': 'Kevlin Henney'}, 'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14661', 'guidislink': False, 'summary': 'Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns out to be a lower peak or simply a contour that, from lower down, looked like a peak. You thought you made it–or were at least close–but there&#8217;s still a long way to go.</p>\\n\\n\\n\\n<p>The story of AI is a story of punctuated progress, but it is also the story of (many) false summits.</p>\\n\\n\\n\\n<p>In the 1950s, machine translation of Russian into English was considered to be no more complex than dictionary lookups and templated phrases. Natural language processing has come a very long way since then, having burnt through a good few paradigms to get to something we can use on a daily basis. In the 1960s, Marvin Minsky and Seymour Papert proposed the Summer Vision Project for undergraduates: connect a TV camera to a computer and identify objects in the field of view. Computer vision is now something that is commodified for specific tasks, but it continues to be a work in progress and, worldwide, has taken more than a few summers (and AI winters) and many more than a few undergrads.</p>\\n\\n\\n\\n<p>We can find many more examples across many more decades that reflect naiveté and optimism and–if we are honest–no small amount of ignorance and hubris. The two general lessons to be learned here are not that machine translation involves more than lookups and that computer vision involves more than edge detection, but that when we are confronted by complex problems in unfamiliar domains, we should be cautious of anything that looks simple at first sight, and that when we have successful solutions to a specific sliver of a complex domain, we should not assume those solutions are generalizable. This kind of humility is likely to deliver more meaningful progress and a more measured understanding of such progress. It is also likely to reduce the number of pundits in the future who mock past predictions and ambitions, along with the recurring irony of machine-learning experts who seem unable to learn from the past trends in their own field.</p>\\n\\n\\n\\n<p>All of which brings us to <a href=\"https://www.deepmind.com/publications/a-generalist-agent\" rel=\"noreferrer noopener\" target=\"_blank\">DeepMind&#8217;s Gato</a> and the claim that the summit of artificial general intelligence (AGI) is within reach. The hard work has been done and reaching AGI is now a simple matter of scaling. At best, this is a false summit on the right path; at worst, it&#8217;s a local maximum far from AGI, which lies along a very different route in a different range of architectures and thinking.</p>\\n\\n\\n\\n<p>DeepMind&#8217;s Gato is an AI model that can be taught to carry out many different kinds of tasks based on a single transformer neural network. The 604 tasks Gato was trained on vary from playing Atari video games to chat, from navigating simulated 3D environments to following instructions, from captioning images to real-time, real-world robotics. The achievement of note is that it’s underpinned by a single model trained across all tasks rather than different models for different tasks and modalities. Learning how to ace Space Invaders does not interfere with or displace the ability to carry out a chat conversation.</p>\\n\\n\\n\\n<p><a href=\"https://arxiv.org/pdf/2205.06175.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">Gato was intended to</a> &#8220;test the hypothesis that training an agent which is generally capable on a large number of tasks is possible; and that this general agent can be adapted with little extra data to succeed at an even larger number of tasks.&#8221; In this, it succeeded. But how far can this success be generalized in terms of loftier ambitions? The <a href=\"https://twitter.com/NandoDF/status/1525397036325019649\" rel=\"noreferrer noopener\" target=\"_blank\">tweet</a> that provoked a wave of responses (this one included) came from DeepMind&#8217;s research director, Nando de Freitas: &#8220;It&#8217;s all about scale now! The game is over!&#8221;</p>\\n\\n\\n\\n<p>The game in question is the quest for AGI, which is closer to what science fiction and the general public think of as AI than the narrower but applied, task-oriented, statistical approaches that constitute commercial machine learning (ML) in practice.</p>\\n\\n\\n\\n<p>The claim is that AGI is now simply a matter of improving performance, both in hardware and software, and making models bigger, using more data and more kinds of data across more modes. Sure, there&#8217;s <a href=\"https://twitter.com/NandoDF/status/1525398087203983360\" rel=\"noreferrer noopener\" target=\"_blank\">research work</a> to be done, but now it&#8217;s all about turning the dials up to 11 and beyond and, voilà, we&#8217;ll have scaled the north face of the AGI to plant a flag on the summit.</p>\\n\\n\\n\\n<p>It&#8217;s easy to get breathless at altitude.</p>\\n\\n\\n\\n<p>When we look at other systems and scales, it&#8217;s easy to be drawn to superficial similarities in the small and project them into the large. For example, if we look at water swirling down a plughole and then out into the cosmos at spiral galaxies, we see a similar structure. But these spirals are more closely bound in our desire to see connection than they are in physics. In looking at scaling specific AI to AGI, it&#8217;s easy to focus on tasks as the basic unit of intelligence and ability. What we know of intelligence and learning systems in nature, however, suggests the relationships between tasks, intelligence, systems, and adaptation is more complex and more subtle. Simply scaling up one dimension of ability may simply scale up one dimension of ability without triggering emergent generalization.</p>\\n\\n\\n\\n<p>If we look closely at software, society, physics or life, we see that scaling is usually accompanied by fundamental shifts in organizing principle and process. Each scaling of an existing approach is successful up to a point, beyond which a different approach is needed. You can run a small business using office tools, such as spreadsheets, and a social media page. Reaching Amazon-scale is not a matter of bigger spreadsheets and more pages. Large systems have radically different architectures and properties to either the smaller systems they are built from or the simpler systems that came before them.</p>\\n\\n\\n\\n<p>It may be that artificial general intelligence is a far more significant challenge than taking task-based models and increasing data, speed, and number of tasks. We typically underappreciate how complex such systems are. We divide and simplify, make progress as a result, only to discover, as we push on, that the simplification was just that; a new model, paradigm, architecture, or schedule is needed to make further progress. Rinse and repeat. Put another way, just because you got to basecamp, what makes you think you can make the summit using the same approach? And what if you can&#8217;t see the summit? If you don&#8217;t know what you&#8217;re aiming for, it&#8217;s difficult to plot a course to it.</p>\\n\\n\\n\\n<p>Instead of assuming the answer, we need to ask: <a href=\"https://www.oreilly.com/radar/closer-to-agi/\" rel=\"noreferrer noopener\" target=\"_blank\">How do we define AGI</a>? Is AGI simply task-based AI for N tasks and a sufficiently large value of N? And, even if the answer to that question is <em>yes</em>, is the path to AGI necessarily task-centric? How much of AGI is performance? How much of AGI is big/bigger/biggest data?</p>\\n\\n\\n\\n<p>When we look at life and existing learning systems, we learn that scale matters, but not in the sense suggested by a simple multiplier. It may well be that the trick to cracking AGI is to be found in scaling–but down rather than up.</p>\\n\\n\\n\\n<p>Doing more with less looks to be more important than doing more with more. For example, the GPT-3 language model is based on a network of 175 billion parameters. The first version of DALL-E, the prompt-based image generator, used a 12-billion parameter version of GPT-3; the second, improved version used only 3.5 billion parameters. And then there&#8217;s Gato, which achieves its multitask, multimodal abilities with only 1.2 billion.</p>\\n\\n\\n\\n<p>These reductions hint at the direction, but it&#8217;s not clear that Gato&#8217;s, GPT-3&#8217;s or any other contemporary architecture is necessarily the right vehicle to reach the destination. For example, how many training examples does it take to learn something? For biological systems, the answer is, in general, not many; for machine learning, the answer is, in general, very many. GPT-3, for example, developed its language model based on 45TB of text. Over a lifetime, a human reads and hears of the order of a billion words; a child is exposed to ten million or so before starting to talk. Mosquitoes can learn to avoid a particular pesticide after a <a href=\"https://www.nature.com/articles/s41598-022-05754-2\" rel=\"noreferrer noopener\" target=\"_blank\">single non-lethal exposure</a>. When you learn a new game–whether video, sport, board or card–you generally only need to be told the rules and then play, perhaps with a game or two for practice and rule clarification, to make a reasonable go of it. Mastery, of course, takes far more practice and dedication, but general intelligence is not about mastery.</p>\\n\\n\\n\\n<p>And when we look at the hardware and its needs, consider that while the brain is one of the most power-hungry organs of the human body, it still has a modest power consumption of <a href=\"https://www.scientificamerican.com/article/thinking-hard-calories/\" rel=\"noreferrer noopener\" target=\"_blank\">around 12 watts</a>. Over a life the brain will consume up to 10 MWh; training the GPT-3 language model took an estimated 1 GWh.</p>\\n\\n\\n\\n<p>When we talk about scaling, the game is only just beginning.</p>\\n\\n\\n\\n<p>While hardware and data matter, the architectures and processes that support general intelligence may be necessarily quite different to the architectures and processes that underpin current ML systems. Throwing faster hardware and all the world&#8217;s data at the problem is likely to see diminishing returns, although that may well let us scale a false summit from which we can see the real one.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/scaling-false-peaks/feed/', 'slash_comments': '0'}, {'title': 'The Metaverse Is Not a Place', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The Metaverse Is Not a Place'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/'}], 'link': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/', 'comments': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/#respond', 'published': 'Tue, 02 Aug 2022 18:38:46 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=2, tm_hour=18, tm_min=38, tm_sec=46, tm_wday=1, tm_yday=214, tm_isdst=0), 'authors': [{'name': 'Tim O’Reilly'}], 'author': 'Tim O’Reilly', 'author_detail': {'name': 'Tim O’Reilly'}, 'tags': [{'term': 'Metaverse', 'scheme': None, 'label': None}, {'term': 'Research', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14641', 'guidislink': False, 'summary': 'The metaphors we use to describe new technology constrain how we think about it, and, like an out-of-date map, often lead us astray. So it is with the metaverse. Some people seem to think of it as a kind of real estate, complete with land grabs and the attempt to bring traffic to whatever bit [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The metaphors we use to describe new technology constrain how we think about it, and, like an out-of-date map, often lead us astray. So it is with the metaverse. Some people seem to think of it as a kind of real estate, complete with land grabs and the attempt to bring traffic to whatever bit [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>The metaphors we use to describe new technology constrain how we think about it, and, <a href=\"https://www.linkedin.com/pulse/20121029141916-16553-language-is-a-map\" rel=\"noreferrer noopener\" target=\"_blank\">like an out-of-date map</a>, often lead us astray. So it is with the metaverse. Some people seem to think of it as <a href=\"https://news.bitcoin.com/metaverse-real-estate-sales-to-grow-by-5-billion-by-2026/\" rel=\"noreferrer noopener\" target=\"_blank\">a kind of real estate</a>, complete with land grabs and the attempt to bring traffic to whatever bit of virtual property they’ve created.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14642\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_01.png\" /></figure>\\n\\n\\n\\n<p>Seen through the lens of the real estate metaphor, the metaverse becomes a natural successor not just to <a href=\"https://en.wikipedia.org/wiki/Second_Life\" rel=\"noreferrer noopener\" target=\"_blank\">Second Life</a> but to the World Wide Web and to social media feeds, which can be thought of as a set of places (sites) to visit. Virtual Reality headsets will make these places more immersive, we imagine.</p>\\n\\n\\n\\n<p>But what if, instead of thinking of the metaverse as a set of interconnected virtual places, we think of it as a communications medium? Using this metaphor, we see the metaverse as a continuation of a line that passes through messaging and email to “rendezvous”-type social apps like Zoom, Google Meet, Microsoft Teams, and, for wide broadcast, Twitch + Discord. This is a progression from text to images to video, and from store-and-forward networks to real time (and, for broadcast, “stored time,” which is a useful way of thinking about recorded video), but in each case, the interactions are not place based but happening in the ether between two or more connected people. The occasion is more the point than the place.</p>\\n\\n\\n\\n<p>In an interview with Lex Fridman, Mark Zuckerberg disclaimed the notion of the metaverse as a place, but in the same sentence <a href=\"https://youtu.be/5zOHSysMmH0?t=1019\" rel=\"noreferrer noopener\" target=\"_blank\">described its future in a very place-based way</a>:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>A lot of people think that the Metaverse is about a place, but one definition of this is it&#8217;s about a time when basically immersive digital worlds become the primary way that we live our lives and spend our time.</em></p></blockquote>\\n\\n\\n\\n<p>Think how much more plausible this statement might be if it read:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>A lot of people think that the Metaverse is about a place, but one definition of this is it&#8217;s about a time when immersive digital worlds become the primary way that we communicate and share digital experiences.</em></p></blockquote>\\n\\n\\n\\n<p>My personal metaverse prototype moment does not involve VR at all, but Zoom. My wife Jen and I join our friend Sabrina over Zoom each weekday morning to exercise together. Sabrina leads the sessions by sharing her Peloton app, which includes live and recorded exercise videos. Our favorites are the strength training videos with <a href=\"https://www.onepeloton.com/instructors/peloton_r\" rel=\"noreferrer noopener\" target=\"_blank\">Rad Lopez</a> and the 15-minute abs videos with <a href=\"https://www.onepeloton.com/instructors/bike/robin\" rel=\"noreferrer noopener\" target=\"_blank\">Robin Arzón</a>. We usually start with Rad and end with Robin, for a vigorous 45-minute workout.</p>\\n\\n\\n\\n<p>Think about this for a moment: Jen and I are in our home. Sabrina is in hers. Rad and Robin recorded their video tracks from their studios on the other side of the county. Jen and Sabrina and I are there in real time. Rad and Robin are there in stored time. We have joined five people in four different places and three different times into one connected moment and one connected place, “the place between” the participants.</p>\\n\\n\\n\\n<p>Sabrina also works out on her own on her Peloton bike, and that too has this shared quality, with multiple participants at various “thicknesses” of connection. While Jen and Sabrina and I are “enhancing” the sharing using real-time Zoom video, Sabrina’s “solo” bike workouts use the intrinsic sharing in the Peloton app, which lets participants see real-time stats from others doing the same ride.</p>\\n\\n\\n\\n<p>This is the true internet—the network of networks, with dynamic interconnections. If the metaverse is to inherit that mantle, it has to have that same quality. <em>Connection</em>.</p>\\n\\n\\n\\n<p>Hacker News user <a href=\"https://news.ycombinator.com/item?id=29083271\" rel=\"noreferrer noopener\" target=\"_blank\">kibwen put it beautifully</a> when they wrote:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>A metaverse involves some kind of shared space and shared experience across a networked medium. Not only is it more than just doing things in VR, a metaverse doesn&#8217;t even require VR.</em></p></blockquote>\\n\\n\\n\\n<h3>The metaverse as a vector</h3>\\n\\n\\n\\n<p>It’s useful to look at technology trends (lines of technology progression toward the future, and inheritance from the past) as vectors—quantities that can only be fully described by both a magnitude and a direction and that can be summed or multiplied to get a sense of how they might cancel, amplify, or redirect possible pathways to the future.</p>\\n\\n\\n\\n<p>I wrote about this idea back in 2020, in a piece called “<a href=\"https://www.oreilly.com/tim/21stcentury/\" rel=\"noreferrer noopener\" target=\"_blank\">Welcome to the 21st Century</a>,” in the context of using <a href=\"https://www.wired.com/1995/11/how-to-build-scenarios/\" rel=\"noreferrer noopener\" target=\"_blank\">scenario planning</a> to imagine the post-COVID future. It’s worth recapping here:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>Once you’ve let loose your imagination, observe the world around you and watch for what scenario planners sometimes call “news from the future”—data points that tell you that the world is trending in the direction of one or another of your imagined scenarios. As with any scatter plot, data points are all over the map, but when you gather enough of them, you can start to see the trend line emerge.…</em><br /><br /><em>If you think of trends as vectors, new data points can be seen as extending and thickening the trend lines and showing whether they are accelerating or decelerating. And as you see how trend lines affect each other, or that new ones need to be added, you can continually update your scenarios (or as those familiar with Bayesian statistics might put it, you can </em><a href=\"https://en.wikipedia.org/wiki/Prior_probability\" rel=\"noreferrer noopener\" target=\"_blank\"><em>revise your priors</em></a><em>). This can be a relatively unconscious process. Once you’ve built mental models of the world as it might be, the news that you read will slot into place and either reinforce or dismantle your imagined future.</em></p></blockquote>\\n\\n\\n\\n<p>Here’s how my thinking about the metaverse was formed by “news from the future” accreting around a technology-development vector:</p>\\n\\n\\n\\n<ol><li>I had a prior belief, <a href=\"https://web.archive.org/web/20000711041545/http://www.oreillynet.com/pub/a/network/2000/06/09/java_keynote.html\" rel=\"noreferrer noopener\" target=\"_blank\">going back decades</a>, that the internet is a tool for connection and communication, and that advances along that vector will be important. I’m always looking with soft focus for evidence that the tools for connection and communication are getting richer, trying to understand <em>how</em> they are getting richer and how they are changing society.&nbsp;</li><li>I’ve been looking at VR for years, trying various headsets and experiences, but they are mostly solo and feel more like stand-alone games or if shared, awkward and cartoonish. Then I read a thoughtful piece by my friend Craig Mod in which he noted that while he lives his physical life in a small town in Japan or <a href=\"https://craigmod.com/essays/walk_japan/\" rel=\"noreferrer noopener\" target=\"_blank\">walking its ancient footpaths</a>, he also has a work life in which he spends time daily with people all over the world. I believe he made the explicit connection to the metaverse, but neither he nor I can find the piece that planted this thought to confirm that. In any case, I think of Craig’s newsletter as where the notion that the metaverse is a continuation of the communications technologies of the internet took hold for me.</li><li>I began to see the connection to Zoom when friends started using interesting backgrounds, some of which make them appear other than where they are and others that make clear just where they are. (For example, my friend Hermann uses as a background the beach behind his home in New Zealand, which is more vividly place based than his home office, which could be anywhere.) That then brought my exercise sessions with Sabrina and Jen into focus as part of this evolving story.</li><li>I talked to <a href=\"https://www.sequoiacap.com/article/phil-libin-mmhmm-spotlight/\" rel=\"noreferrer noopener\" target=\"_blank\">Phil Libin</a> about his brilliant service <a href=\"https://www.mmhmm.app/\" rel=\"noreferrer noopener\" target=\"_blank\">mmhmm</a>, which makes it easy to create and deliver richer, more interactive presentations over Zoom and similar apps. The speaker literally gets to occupy the space of the presentation. Phil’s presentation on “<a href=\"https://www.youtube.com/watch?v=mBKIMhGO8WA\" rel=\"noreferrer noopener\" target=\"_blank\">The Out of Office World</a>” was where it all clicked. He talks about the hierarchy of communication and the tools for modulating it. (IMO this is a must-watch piece for anyone thinking about the future of internet apps. I’m surprised how few people seem to have watched it.)<br /></li></ol>\\n\\n\\n\\n<figure class=\"wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\\n\\n</div></figure>\\n\\n\\n\\n<ol start=\"5\"><li>Trying <a href=\"https://www.getsupernatural.com/\">Supernatural</a> using the Meta Quest 2 headset completed the connection between my experience using Zoom and Peloton for fitness with friends and the VR-dominant framing of the metaverse. Here I was, standing on the edge of one of the lava lakes at <a href=\"https://www.atlasobscura.com/places/erta-ale\">Erta Ale</a> in Ethiopia, an astonishing volcano right out of central casting for Mount Doom in <em>The Lord of the Rings</em>, working through warm-up exercises with a video of a fitness instructor green-screened into the scene, before launching into a boxing training game. Coach Susie was present in stored time, just like Robin and Rad. All that was missing was Jen and Sabrina. I’m sure that such shared experiences in remarkable places are very much part of the VR future.</li></ol>\\n\\n\\n\\n<p></p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><a href=\"https://www.youtube.com/watch?v=jufCUdibP4c\" rel=\"noreferrer noopener\" target=\"_blank\"><img alt=\"\" class=\"wp-image-14643\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_02.png\" /></a></figure>\\n\\n\\n\\n<p>That kind of shared experience is central to Mark Zuckerberg’s vision of <a href=\"https://www.youtube.com/watch?v=b9vWShsmE20\" rel=\"noreferrer noopener\" target=\"_blank\">socializing in the metaverse</a>.</p>\\n\\n\\n\\n<figure class=\"wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\\n\\n</div></figure>\\n\\n\\n\\n<p>In that video, Zuck shows off lavishly decorated personal spaces, photorealistic and cartoon avatars, and an online meeting interrupted by a live video call. He says:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>It&#8217;s a ways off but you can start to see some of the fundamental building blocks take shape. First the feeling of presence. This is the defining quality of the metaverse. You&#8217;re going to really feel like you&#8217;re there with other people. You&#8217;ll see their facial expressions, you&#8217;ll see their body language, maybe figure out if they&#8217;re actually holding a winning hand—all the subtle ways that we communicate that today&#8217;s technology can&#8217;t quite deliver.</em></p></blockquote>\\n\\n\\n\\n<p>I totally buy the idea that presence is central. But Meta’s vision seems to miss the mark in its focus on avatars. Embedded video delivers more of that feeling of presence with far less effort on the part of the user than learning to create avatars that mimic our gestures and expressions.</p>\\n\\n\\n\\n<p>Chris Milk, the CEO of Within, the company that created Supernatural, both agreed and disagreed about avatars when explaining the company’s origin story to me in a phone conversation a few months ago:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>What we learned early on was that photorealism matters a lot in terms of establishing presence and human connection. Humans, captured using photorealistic methods like immersive video, allow for a deeper connection between the audience and the people recorded in the immersive VR experience. The audience feels present in the story with them. But it&#8217;s super hard to do from a technical standpoint and you give up a bunch of other things. The trade-off is that you can have photorealism but sacrifice interactivity, as the photorealistic humans need to be prerecorded. Alternatively, you can have lots of interactivity and human-to-human communication, but you give up on anyone looking real. In the latter, the humans need to be real-time-rendered avatars, and those, for the moment, don’t look remotely like real humans.</em></p></blockquote>\\n\\n\\n\\n<p>At the same time, Milk pointed out that humans are able to read a lot into even crude avatars, especially when they’re accompanied by real-time communication using voice.</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>Especially if it’s someone you already know, then the human connection can overcome a lot of missing visual realism. We did an experiment back in 2014 or 2015, probably. Aaron [Koblin, the cofounder of Within] was living in San Francisco, and I was in Los Angeles. We had built a VR prototype where we each had a block for the head and two blocks for our hands. I got into my headset in LA, and Aaron&#8217;s blocks were sitting over on the floor across from me as his headset and hand controllers were sitting on his floor in San Francisco. All of a sudden the three blocks jumped up off the ground into the air as he picked up his headset and put it on. The levitating cubes “walked” up to me, waved, and said, “Hey.” Immediately, before I even heard the voice, I recognized the person in those blocks as Aaron. I recognized through the posture and gait the spirit of Aaron in these three cubes moving through space. The resolution, or any shred of photorealism, was completely absent, but the humanity still showed through. And when his voice came out of them, my brain just totally accepted that the soul of Aaron now resides in these three floating cubes. Nothing was awkward about communicating back and forth. My brain just accepted it instantly. </em></p></blockquote>\\n\\n\\n\\n<p>And that’s where we get back to vectors. Understanding the future of photorealism in the metaverse depends on the speed and direction of progress in AI. In many ways, a photorealistic avatar is a kind of <a href=\"https://en.wikipedia.org/wiki/Deepfake\" rel=\"noreferrer noopener\" target=\"_blank\">deepfake</a>, and we know how computationally expensive their creation is today. How long will it be before the creation of deepfakes is cheap enough and fast enough that hundreds of millions of people can be creating and using them in real time? I suspect it will be a while.</p>\\n\\n\\n\\n<p>Mmhmm’s blending of video and virtual works really well, using today’s technology. It’s ironic that in Meta’s video about the future, video is only shown on a screen in the virtual space rather than as an integral part of it. Meta could learn a lot from mmhmm.</p>\\n\\n\\n\\n<p>On the other hand, creating a vast library of immersive 3D still images of amazing places into which either avatars or green-screened video images can be inserted seems much closer to realization. It’s still hard, but the problem is orders of magnitude smaller. The virtual spaces offered by Supernatural and other VR developers give an amazing taste of what’s possible here.</p>\\n\\n\\n\\n<p>In this regard, an interesting sidenote came from a virtual session that we held earlier this year at the Social Science Foo Camp (an event put together annually by O’Reilly, Meta, and Sage) using the <a href=\"https://engagevr.io/\" rel=\"noreferrer noopener\" target=\"_blank\">ENGAGE</a> virtual media conferencing app. The group began their discussion in one of the default meeting spaces, but one of the attendees, Adam Flaherty, proposed that they have it in a more appropriate place. They moved to a beautifully rendered version of <a href=\"https://en.wikipedia.org/wiki/Bodleian_Library\" rel=\"noreferrer noopener\" target=\"_blank\">Oxford’s Bodleian Library</a>, and attendees reported that the entire tenor of the conversation changed.</p>\\n\\n\\n\\n<p>Two other areas worth thinking about:</p>\\n\\n\\n\\n<ol><li>Social media evolved from a platform for real-time interaction (real-time status updates, forums, conversations, and groups) to one that’s often dominated by stored-time interaction (posts, stories, reels, et al). Innovation in formats for stored-time communications is at the heart of future social media competition, as TikTok has so forcefully reminded Facebook. There’s a real opportunity for developers and influencers to pioneer new formats as the metaverse unfolds.</li><li>Bots are likely to play a big role in the metaverse, just as they do in today’s gaming environments. Will we be able to distinguish bots from humans? Chris Hecker’s indie game <a href=\"http://www.spyparty.com/\" rel=\"noreferrer noopener\" target=\"_blank\"><em>SpyParty</em></a>, prototyped in 2009, made this a central feature of <a href=\"https://en.wikipedia.org/wiki/SpyParty\" rel=\"noreferrer noopener\" target=\"_blank\">its game play</a>, requiring two human players (one spy and one sniper) to find or evade each other among a party crowded with bots (what game developers call non-player characters or NPCs). Bots and deepfakes are already transforming our social experiences on the internet; expect this to happen on steroids in the metaverse. Some bots will be helpful, but others will be malevolent and disruptive. We will need to tell the difference.</li></ol>\\n\\n\\n\\n<h3>The need for interoperability</h3>\\n\\n\\n\\n<p>There’s one thing that a focus on communications as the heart of the metaverse story reminds us: communication, above all, depends on interoperability. A balkanized metaverse in which a few big providers engage in a winner-takes-all competition to create the Meta- or Apple- or whatever-owned metaverse will take far longer to develop than one that allows developers to create great environments and experiences and connect them bit by bit with the innovations of others. It would be far better if the metaverse were an extension of the internet (“the network of networks”) rather than an attempt to replace it with a walled garden.</p>\\n\\n\\n\\n<p>Some things that it would be great to have be interoperable:</p>\\n\\n\\n\\n<ul><li><strong>Identity.</strong> We should be able to use the digital assets that represent who we are across platforms, apps, and places offered by different companies.</li><li><strong>Sensors.</strong> Smartwatches, rings, and so forth are increasingly being used to collect physiological signals. This technology can be built into VR-specific headsets, but we would do better if it were easily shared between devices from different providers.</li><li><strong>Places.</strong> (Yes, places are part of this after all.) Rather than having a single provider (say Meta) become the ur-repository of photorealistic 360-degree immersive spaces, it would be great to have an interoperability layer that allows their reuse.</li><li><strong>Bot identification.</strong> Might NFTs end up becoming the basis for a nonrepudiable form of identity that must be produced by both humans and bots? (I suspect we can only force bots to identify themselves as such if we also require humans to do so.)</li></ul>\\n\\n\\n\\n<h3>Foundations of the metaverse</h3>\\n\\n\\n\\n<p>You can continue this exercise by thinking about the metaverse as the combination of multiple technology trend vectors progressing at different speeds and coming from different directions, and pushing the overall vector forward (or backward) accordingly. No new technology is the product of a single vector.</p>\\n\\n\\n\\n<p>So rather than settling on just “the metaverse is a communications medium,” think about the various technology vectors besides real-time communications that are coming together in the current moment. What news from the future might we be looking for?</p>\\n\\n\\n\\n<ul><li><strong>Virtual Reality/Augmented Reality. </strong>Lighter and less obtrusive headsets. Advances in 3D video recording. Advances in sensors, including eye-tracking, expression recognition, physiological monitoring, even <a href=\"https://www.cnbc.com/2019/09/23/facebook-announces-acquisition-of-brain-computing-start-up-ctrl-labs.html\" rel=\"noreferrer noopener\" target=\"_blank\">brain-control interfaces</a>. Entrepreneurial innovations in the balance between AR and VR. (Why do we think of them as mutually exclusive rather than on a continuum?)</li><li><strong>Social media. </strong>Innovations in connections between influencers and fans. How does stored time become more real time?</li><li><strong>Gaming. </strong>Richer integration between games and communications. What’s the next Twitch + Discord?</li><li><strong>AI. </strong>Not just deepfakes but the proliferation of AIs and bots as participants in social media and other communications. NPCs becoming a routine part of our online experience outside of gaming. Standards for identification of bots versus humans in online communities.</li><li><strong>Cryptocurrencies and “Web3.”</strong>&nbsp;Does crypto/Web3 provide new business models for the metaverse? (BTW, I enjoyed the way that Neal Stephenson, in <a href=\"https://en.wikipedia.org/wiki/Reamde\" rel=\"noreferrer noopener\" target=\"_blank\"><em>Reamde</em></a>, had his character design the business model and money flows for his online game before he designed anything else. Many startups just try to get users and assume the business model will follow, but that has led us down the dead end of advertising and <a href=\"https://en.wikipedia.org/wiki/Surveillance_capitalism\" rel=\"noreferrer noopener\" target=\"_blank\">surveillance capitalism</a>.) </li><li><strong>Identity. </strong>Most of today’s identity systems are centralized in one way or another, with identity supplied by a trusted provider or verifier. Web3 proponents, however, are exploring a variety of systems for decentralized “<a href=\"https://en.wikipedia.org/wiki/Self-sovereign_identity\" rel=\"noreferrer noopener\" target=\"_blank\">self-sovereign identity</a>,” including Vitalik Buterin’s “<a href=\"https://vitalik.eth.limo/general/2022/01/26/soulbound.html\" rel=\"noreferrer noopener\" target=\"_blank\">soulbound tokens</a>.” The vulnerability of crypto systems to <a href=\"https://en.wikipedia.org/wiki/Sybil_attack\">Sybil attacks</a> in the absence of verifiable identity is driving a lot of innovation in the identity space. <a href=\"https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/\" rel=\"noreferrer noopener\" target=\"_blank\">Molly White’s skeptical survey of these various initiatives</a> is a great overview of the problem and the difficulties in overcoming it. Gordon Brander’s “<a href=\"https://subconscious.substack.com/p/soulbinding-like-a-state\" rel=\"noreferrer noopener\" target=\"_blank\">Soulbinding Like A State</a>,” a riff on Molly White’s post and James C. Scott’s <a href=\"https://en.wikipedia.org/wiki/Seeing_Like_a_State\" rel=\"noreferrer noopener\" target=\"_blank\"><em>Seeing Like A State</em></a>, provides a further warning: “Scott’s framework reveals…that the dangers of legibility are not related to the sovereignty of an ID. There are many reasons self-sovereignty is valuable, but the function of a self-sovereign identity is still to make the bearer legible. What’s measured gets managed. What’s legible gets controlled.” As is often the case, no perfect solution will be found, but society will adopt an imperfect solution by making trade-offs that are odious to some, very profitable to others, and that the great mass of users will passively accept.</li></ul>\\n\\n\\n\\n<p>There’s a lot more we ought to be watching. I’d love your thoughts in the comments.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/the-metaverse-is-not-a-place/feed/', 'slash_comments': '0'}, {'title': 'Radar Trends to Watch: August 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: August 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/#respond', 'published': 'Tue, 02 Aug 2022 11:18:24 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=8, tm_mday=2, tm_hour=11, tm_min=18, tm_sec=24, tm_wday=1, tm_yday=214, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14631', 'guidislink': False, 'summary': 'The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to explain JavaScript code.</p>\\n\\n\\n\\n<p>On other fronts, NIST has released the first proposed standard for post-quantum cryptography (i.e., cryptography that can’t be broken by quantum computers). CRISPR has been used in human trials to re-engineer a patient’s DNA to reduce cholesterol. And a surprising number of cities are paying high tech remote workers to move there.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li>Regardless of where a company is based, to avoid legal problems later, it’s a good idea to build AI and other data-based systems that <a href=\"https://thenextweb.com/news/european-or-not-make-sure-your-ai-business-sticks-to-eu-data-laws\" rel=\"noreferrer noopener\" target=\"_blank\">observe the EU’s data laws</a>.</li><li><a href=\"https://openai.com/blog/dall-e-now-available-in-beta/\" rel=\"noreferrer noopener\" target=\"_blank\">Public (beta) access to DALL-E is beginning</a>! It might take a while to get in because there are over a million on the waitlist. Accepted users get 50 free credits the first month, 15/month thereafter; a credit allows you to give one prompt, which returns 4 images. Users can buy additional credits.</li><li>Researchers have used reinforcement learning to build a <a href=\"https://www.technologyreview.com/2022/07/18/1056059/robot-dog-ai-reinforcement/\" rel=\"noreferrer noopener\" target=\"_blank\">robotic dog that learns to walk on its own</a> in the real world (i.e., without prior training and use of a simulator).</li><li>Princeton held a <a href=\"https://sites.google.com/princeton.edu/rep-workshop/\" rel=\"noreferrer noopener\" target=\"_blank\">workshop</a> on the <a href=\"https://twitter.com/random_walker/status/1542879397245423616\" rel=\"noreferrer noopener\" target=\"_blank\">reproducibility crisis</a> that the use of machine learning is causing in science. Evaluating the accuracy of results from machine learning is a problem that most scientific disciplines aren’t yet equipped to deal with.</li><li>Microsoft has revised its <a href=\"https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">Responsible AI standard</a>, making recommendations more concrete, particularly in the areas of accountability, transparency, fairness, safety, privacy, and inclusiveness. Microsoft also provides <a href=\"https://www.microsoft.com/en-us/ai/responsible-ai-resources\" rel=\"noreferrer noopener\" target=\"_blank\">tools and resources</a> to help developers build responsible AI systems.</li><li>The Dallery Gallery has published a <a href=\"https://dallery.gallery/the-dalle-2-prompt-book/\" rel=\"noreferrer noopener\" target=\"_blank\">Prompt Engineering Guide to DALL-E</a>. (DALL-E is maintaining a <a href=\"https://help.openai.com/en/articles/4936794-is-dall-e-available-yet\" rel=\"noreferrer noopener\" target=\"_blank\">waitlist</a> for free trial accounts.)</li><li>Simon Willison has successfully used GPT-3 to <a href=\"https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/\" rel=\"noreferrer noopener\" target=\"_blank\">explain how code works</a>. It is amazingly good and, as Simon pointed out, works both on code that he understands, and code that he doesn’t.</li><li><a href=\"https://huggingface.co/bigscience/bloom\" rel=\"noreferrer noopener\" target=\"_blank\">Bloom</a>, the open and transparent large language model developed by the BigScience group, is <a href=\"https://bigscience.huggingface.co/blog/bloom\" rel=\"noreferrer noopener\" target=\"_blank\">finished</a>!&nbsp; You can try it out, download it, and read its specifications. Unlike all other large language models, Bloom was developed in public, and is open to the public.</li><li>Radiologists outperform AI systems operating by themselves at detecting breast cancer from mammograms. However, a <a href=\"https://www.technologyreview.com/2022/07/11/1055677/ai-diagnose-breast-cancer-mammograms/\" rel=\"noreferrer noopener\" target=\"_blank\">system designed to collaborate</a> with radiologists in making decisions is better than either radiologists or AI alone. (The big question is whether these results hold up when taken to other hospitals.)</li><li>You liked Copilot? Try <a href=\"https://www.autoregex.xyz/\" rel=\"noreferrer noopener\" target=\"_blank\">Autoregex</a>: GPT-3 to generate regular expressions from natural language descriptions.</li><li><a href=\"https://github.com/facebookresearch/fairseq/tree/nllb\" rel=\"noreferrer noopener\" target=\"_blank\">No Language Left Behind</a> (NLLB) is a Meta AI project that translates text directly between any pair of over 200 languages. Benchmarks, training code, and models are all open source.</li><li><a href=\"https://www.nature.com/articles/s41562-022-01383-x\" rel=\"noreferrer noopener\" target=\"_blank\">Democratic AI</a> is an experiment in human-in-the-loop design that enables an AI system to design a social mechanism with human collaboration. </li><li>The Allen Institute, Microsoft, and others have developed a tool to <a href=\"https://www.technologyreview.com/2022/07/06/1055458/ai-research-emissions-energy-efficient/\" rel=\"noreferrer noopener\" target=\"_blank\">measure the energy use and emissions generated by training AI models</a> on Azure. They have found that emissions can be reduced substantially by training during periods when renewable power is at its peak.</li><li><a href=\"https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html\" rel=\"noreferrer noopener\" target=\"_blank\">Minerva</a> is a large language model that Google has trained to solve quantitative reasoning (i.e., mathematics) problems, generating simple proofs in addition to answers. The problem domain extends through pre-calculus, including algebra and geometry, roughly at a high school level. Minerva has also been trained and tested in chemistry and physics.  </li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Perhaps the scariest exploit in security would be a <a href=\"https://arstechnica.com/information-technology/2022/07/researchers-unpack-unkillable-uefi-rootkit-that-survives-os-reinstalls/\" rel=\"noreferrer noopener\" target=\"_blank\">rootkit that cannot be detected or removed</a>, even by wiping the disk and reinstalling the operating system.&nbsp;Such rootkits were recently discovered (one is named CosmicStrand); they have apparently been in the wild since 2016.</li><li>AWS is offering some customers a free <a href=\"https://thenewstack.io/aws-customers-can-now-order-a-free-mfa-security-key/\" rel=\"noreferrer noopener\" target=\"_blank\">multi factor authentication</a> (MFA) security key.</li><li>Lost passwords are an important <a href=\"https://arstechnica.com/information-technology/2022/07/malware-circulating-online-wrangles-industrial-systems-into-a-botnet/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">attack vector for industrial systems</a>. A system is installed; the default password is changed; the person who changed the password leaves; the password is lost; the company installs password recovery software, which is often malware-infested, to recover the password.</li><li>A <a href=\"https://www.wired.com/story/web-deanonymization-side-channel-attack-njit/\" rel=\"noreferrer noopener\" target=\"_blank\">new technique for browser de-anonymization</a> is based on correlating users’ activities on different websites.</li><li><a href=\"https://www.bleepingcomputer.com/news/security/ransomware-gang-now-lets-you-search-their-stolen-data/\" rel=\"noreferrer noopener\" target=\"_blank\">Ransomware companies are now using search engines</a> to allow their users to search the data they have stolen.</li><li>Ransomware doesn’t get as much attention in the news as it did last year, but in the past week one ransomware operation has shut down and released its decryptors, and two new ones (RedAlert and omega) <a href=\"https://www.bleepingcomputer.com/news/security/the-week-in-ransomware-july-8th-2022-one-down-many-to-go/\" rel=\"noreferrer noopener\" target=\"_blank\">have started</a>.</li><li>Apple has added “<a href=\"https://www.apple.com/newsroom/2022/07/apple-expands-commitment-to-protect-users-from-mercenary-spyware/\" rel=\"noreferrer noopener\" target=\"_blank\">lockdown mode</a>” to iOS.&nbsp; Lockdown mode provides an extreme degree of privacy; it is intended for people who believe they are being targeted by state-sponsored mercenary spyware.</li><li>The <a href=\"https://openssf.org/oss-security-mobilization-plan/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Source Security Mobilization Plan</a> is an initiative that aims to address major areas of open source security, including education, risk assessment, digital signatures, memory safety, incident response, and software supply chain management.</li><li>Mitre has released their annual list of the <a href=\"https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html\" rel=\"noreferrer noopener\" target=\"_blank\">25 most dangerous software weaknesses</a> (bugs, flaws, vulnerabilities).</li><li>Patches for the Log4J vulnerability were released back in February, 2022, but <a href=\"https://thenewstack.io/log4shell-hacks-on-and-on/\" rel=\"noreferrer noopener\" target=\"_blank\">many organizations have not applied them</a>, and remain vulnerable to attack.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Microsoft and Oracle have announced <a href=\"https://www.oracle.com/news/announcement/oracle-database-service-for-microsoft-azure-2022-07-20/\" rel=\"noreferrer noopener\" target=\"_blank\">Oracle Data Service</a>, which allows applications running on Azure to manage and use data in Oracle’s cloud. It’s a multicloud strategy that’s enabled by the cloud providers.</li><li>Google has announced a new programming language, <a href=\"https://9to5google.com/2022/07/19/carbon-programming-language-google-cpp/\" rel=\"noreferrer noopener\" target=\"_blank\">Carbon</a>, that is intended to be the successor to C++. One goal is complete interoperability between Carbon and existing C++ code and libraries.</li><li><a href=\"https://theburningmonk.com/2022/07/the-best-ways-to-save-money-on-lambda/\" rel=\"noreferrer noopener\" target=\"_blank\">How to save money on AWS Lambda</a>: watch your memory!&nbsp; Don’t over-allocate memory. This probably only applies to a few of your functions, but those functions are what drive the cost up.</li><li><a href=\"https://www.technologyreview.com/2022/07/14/1055894/us-military-sofware-linux-kernel-open-source/\" rel=\"noreferrer noopener\" target=\"_blank\">SocialCyber</a> is a <a href=\"https://www.darpa.mil/program/hybrid-ai-to-protect-integrity-of-open-source-code\" rel=\"noreferrer noopener\" target=\"_blank\">DARPA program</a> to understand the internals of open source software, along with the communities that create the software. They plan to use machine learning heavily, both to understand the code and to map and analyze communications within the communities. They are concerned about potential vulnerabilities in the software that the US military depends on.</li><li><a href=\"https://thenewstack.io/whats-next-in-webassembly/\" rel=\"noreferrer noopener\" target=\"_blank\">WebAssembly in the cloud</a>? Maybe it isn’t just a client-side technology. As language support grows, so do the kinds of applications Wasm can support.</li><li>A <a href=\"https://tidelift.com/2022-open-source-software-supply-chain-survey\" rel=\"noreferrer noopener\" target=\"_blank\">surveyreports</a> that 62% of its respondents were only “somewhat confident” that open source software was “secure, up-to-date, and well-maintained.”&nbsp; Disappointing as this may be, it’s actually an improvement over prior results.</li><li>Is <a href=\"https://thenewstack.io/infrastructure-as-code-goes-low-code-no-code/\" rel=\"noreferrer noopener\" target=\"_blank\">low-code infrastructure as code</a> the future of cloud operations?</li><li><a href=\"https://lunduke.substack.com/p/tiny-core-linux-130-full-linux-desktop\" rel=\"noreferrer noopener\" target=\"_blank\">Tiny Core Linux</a> is amazingly small: a 22MB download, and runs in 48MB of RAM. As a consequence, it’s also amazingly fast. With a few exceptions, making things small has not been a trend over the past few years.&nbsp;We hope to see more of this.</li><li>Yet another JavaScript web framework? <a href=\"https://thenewstack.io/denos-fresh-uses-server-side-rendering-for-faster-apps/\" rel=\"noreferrer noopener\" target=\"_blank\">Fresh</a> does server-side rendering, and is based on Deno rather than NodeJS.</li></ul>\\n\\n\\n\\n<h2>Web</h2>\\n\\n\\n\\n<ul><li>Facebook is considering whether to <a href=\"https://arstechnica.com/tech-policy/2022/07/meta-thinks-facebook-may-need-more-harmful-health-misinformation/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">rescind its bans on health misinformation</a>. The pandemic is over, after all. Except that it isn’t. However, being a conduit for health misinformation is clearly profitable.</li><li><a href=\"https://www.etsy.com/codeascraft/priority-hints-what-your-browser-doesnt-know-yet\" rel=\"noreferrer noopener\" target=\"_blank\">Priority Hints</a> are a way for web developers to tell the browser <a href=\"https://web.dev/priority-hints/\" rel=\"noreferrer noopener\" target=\"_blank\">which parts of the page are most important</a>, so that they can be rendered quickly. They are currently supported by the Chrome and Edge browsers.</li><li><a href=\"https://hotwired.dev/\" rel=\"noreferrer noopener\" target=\"_blank\">Hotwire</a>, <a href=\"https://htmx.org/\" rel=\"noreferrer noopener\" target=\"_blank\">HTMX</a>, and <a href=\"https://unpoly.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Unpoly</a> are frameworks for building complex web applications while minimizing the need for complex Javascript. Are they an alternative to heavyweight JavaScript frameworks like React? Could a return to server-side web applications lead to a resurgence of platforms like <a href=\"https://thenewstack.io/turbocharging-ruby-on-rails-with-html-over-the-wire/\" rel=\"noreferrer noopener\" target=\"_blank\">Ruby on Rails</a>?</li><li>Facebook has started <a href=\"https://www.ghacks.net/2022/07/17/facebook-has-started-to-encrypt-links-to-counter-privacy-improving-url-stripping/\" rel=\"noreferrer noopener\" target=\"_blank\">encrypting the portions of URLs that are used to track users</a>, preventing the Firefox and Brave browsers from stripping the tracking portion of the URL.</li><li><a href=\"https://www.technologyreview.com/2022/07/15/1056042/chinese-novel-censored-before-shared/\" rel=\"noreferrer noopener\" target=\"_blank\">A priori censorship?</a>&nbsp; A popular cloud-based word processor in China has been observed censoring content upon the creation of a link for sharing the content. The document is locked; it cannot be edited or even opened by the author.</li><li>The <a href=\"http://pilimi.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Pirate Library Mirror</a> is exactly what it says: a mirror of libraries of pirated books. It is focused on the preservation of human knowledge. There is no search engine, and it is only accessible by using BitTorrent over TOR.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://arstechnica.com/gaming/2022/07/minecraft-blocks-the-blockchain-from-its-block-game/\" rel=\"noreferrer noopener\" target=\"_blank\">Minecraft has decided that they will not “support or allow” the integration of NFTs</a> into their virtual worlds. They object to “digital ownership based on scarcity and exclusion.”</li><li><a href=\"https://arstechnica.com/information-technology/2022/07/usage-of-crypto-mixers-for-stymying-blockchain-investigations-hits-all-time-high/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">Mixers</a> are cryptocurrency services that randomize the currency you use; rather than pay with your own coin, you deposit money in a mixer and pay with randomly selected coins from other users. It’s similar to a traditional bank in that you never withdraw the same money you deposited.</li><li>So much for privacy. Coinbase, one of the largest cryptocurrency exchanges, <a href=\"https://theintercept.com/2022/06/29/crypto-coinbase-tracer-ice/\" rel=\"noreferrer noopener\" target=\"_blank\">sells geolocation data to ICE</a> (the US Immigration and Customs Enforcement agency).</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://phys.org/news/2022-07-quantum.html\" rel=\"noreferrer noopener\" target=\"_blank\">Quantum computers aren’t limited to binary</a>: That limit is imposed by analogy to traditional computers, but some quantum computers have access to more state, and taking advantage of those states may make applications like simulating physical or biological systems easier.</li><li>Is quantum-aided computing for some industrial applications just around the corner? <a href=\"https://thenewstack.io/quantum-computing-use-cases-how-viable-is-it-really/\" rel=\"noreferrer noopener\" target=\"_blank\">IonQ and GE have announced a results from a hybrid system</a> for risk management. The quantum computer does random sampling from probability distributions, which are computationally expensive for classical computers; the rest of the computation is classical.</li><li><a href=\"https://phys.org/news/2022-07-entanglement-quantum-memories.html\" rel=\"noreferrer noopener\" target=\"_blank\">Quantum networking</a> is becoming real: researchers have created entangled qubits via a 33-mile fiber optic connection. In addition to their importance for secure communications, quantum networks may be a crucial step in building quantum computers at scale. </li><li>NIST has announced <a href=\"https://arstechnica.com/information-technology/2022/07/nist-selects-quantum-proof-algorithms-to-head-off-the-coming-cryptopocalypse/\" rel=\"noreferrer noopener\" target=\"_blank\">four candidate algorithms for post-quantum cryptography</a>. While it may be years before quantum computing can break current algorithms, many organizations are anxious to start the transition from current algorithms. </li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>Not long ago (2020), DeepMind released AlphaFold, which used AI to solve protein folding problems. In 2021, they announced a public database containing the structure of a million proteins. With their latest additions, that database now contains the structure of <a href=\"https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe\" rel=\"noreferrer noopener\" target=\"_blank\">over 200 million</a> proteins, almost every protein known to science.</li><li>A <a href=\"https://www.nature.com/articles/s41586-022-04910-y\" rel=\"noreferrer noopener\" target=\"_blank\">motor made of DNA</a>!&nbsp; This nanoscale motor uses ideas from origami to fold DNA in a way that causes it to rotate when an electrical field is applied. </li><li>An <a href=\"https://www.bloomberg.com/news/articles/2022-07-18/brain-computer-interface-company-implants-new-type-of-device?sref=htOHjx5Y\" rel=\"noreferrer noopener\" target=\"_blank\">electrode has been implanted into the brain of an ALS patient</a> that will allow them to communicate thoughts via computer. The patient has otherwise lost the ability to move or speak.</li><li>Genetic editing with <a href=\"https://www.technologyreview.com/2022/07/12/1055773/crispr-gene-editing-cholesterol/\" rel=\"noreferrer noopener\" target=\"_blank\">CRISPR was tested in a human</a> to permanently lower LDL (“bad cholesterol”) levels. If this works, it could make heart attacks much rarer, and could be the first widespread use of CRISPR in humans.</li></ul>\\n\\n\\n\\n<h2>Energy</h2>\\n\\n\\n\\n<ul><li>Researchers in India have developed a carbon-negative process for <a href=\"https://techxplore.com/news/2022-07-green-hydrogen-biomass-abundant-renewable.html\" rel=\"noreferrer noopener\" target=\"_blank\">generating Hydrogen from biomass</a>. </li></ul>\\n\\n\\n\\n<h2>Work</h2>\\n\\n\\n\\n<ul><li>Some cities (largely in the US South and Midwest) are giving <a href=\"https://thenewstack.io/us-cities-try-luring-remote-tech-workers-with-cash/\" rel=\"noreferrer noopener\" target=\"_blank\">cash bonuses to tech worker</a>s who are willing to move there and work remotely.</li><li>The <a href=\"https://www.zdnet.com/article/fbi-warning-crooks-are-are-using-deepfakes-to-apply-for-remote-tech-jobs/\" rel=\"noreferrer noopener\" target=\"_blank\">FBI is warning employers</a> that they are seeing an increasing number of fraudulent applications for remote work in which the application uses stolen personal information and deepfake imagery.</li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/feed/', 'slash_comments': '0'}, {'title': 'SQL: The Universal Solvent for REST APIs', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'SQL: The Universal Solvent for REST APIs'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/'}], 'link': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/', 'comments': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/#respond', 'published': 'Tue, 19 Jul 2022 11:16:39 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=7, tm_mday=19, tm_hour=11, tm_min=16, tm_sec=39, tm_wday=1, tm_yday=200, tm_isdst=0), 'authors': [{'name': 'Jon Udell'}], 'author': 'Jon Udell', 'author_detail': {'name': 'Jon Udell'}, 'tags': [{'term': 'Data', 'scheme': None, 'label': None}, {'term': 'Deep Dive', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14612', 'guidislink': False, 'summary': 'Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need to do it a page at a time, but pagination works differently from one API to the next. So does unpacking the resulting JSON structures. HTTP and JSON are low-level standards, and REST is a loosely-defined framework, but nothing guarantees absolute simplicity, never mind consistency across APIs.</p>\\n\\n\\n\\n<p>What if there were a way of reading from APIs that abstracted all the low-level grunt work and worked the same way everywhere? Good news! That is exactly what\\xa0<a href=\"https://steampipe.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Steampipe</a>\\xa0does. It&#8217;s a tool that translates REST API calls directly into SQL tables. Here are three examples of questions that you can ask and answer using Steampipe.</p>\\n\\n\\n\\n<h3>1. Twitter: What are recent tweets that mention PySpark?</h3>\\n\\n\\n\\n<p>Here&#8217;s a SQL query to ask that question:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>select\\n  id,\\n  text\\nfrom\\n  twitter_search_recent\\nwhere\\n  query = \\'pyspark\\'\\norder by\\n  created_at desc\\nlimit 5;</code></pre>\\n\\n\\n\\n<p>Here&#8217;s the answer:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>+---------------------+------------------------------------------------------------------------------------------------&gt;\\n| id                  | text                                                                                           &gt;\\n+---------------------+------------------------------------------------------------------------------------------------&gt;\\n| 1526351943249154050 | @dump Tenho trabalhando bastante com Spark, mas especificamente o PySpark. Vale a pena usar um &gt;\\n| 1526336147856687105 | RT @MitchellvRijkom: PySpark Tip &#x26a1;                                                            &gt;\\n|                     |                                                                                                &gt;\\n|                     | When to use what StorageLevel for Cache / Persist?                                             &gt;\\n|                     |                                                                                                &gt;\\n|                     | StorageLevel decides how and where data should be s…                                           &gt;\\n| 1526322757880848385 | Solve challenges and exceed expectations with a career as a AWS Pyspark Engineer. https://t.co/&gt;\\n| 1526318637485010944 | RT @JosMiguelMoya1: #pyspark #spark #BigData curso completo de Python y Spark con PySpark      &gt;\\n|                     |                                                                                                &gt;\\n|                     | https://t.co/qf0gIvNmyx                                                                        &gt;\\n| 1526318107228524545 | RT @money_personal: PySpark &amp;amp; AWS: Master Big Data With PySpark and AWS                    &gt;\\n|                     | #ApacheSpark #AWSDatabases #BigData #PySpark #100DaysofCode                                    &gt;\\n|                     | -&amp;gt; http…                                                                                    &gt;\\n+---------------------+------------------------------------------------------------------------------------------------&gt;</code></pre>\\n\\n\\n\\n<p>The table that&#8217;s being queried here,&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent\" rel=\"noreferrer noopener\" target=\"_blank\">twitter_search_recent</a>, receives the output from Twitter&#8217;s&nbsp;<a href=\"https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\" rel=\"noreferrer noopener\" target=\"_blank\">/2/tweets/search/recent</a>&nbsp;endpoint and formulates it as a table with&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent#inspect\" rel=\"noreferrer noopener\" target=\"_blank\">these columns</a>. You don&#8217;t have to make an HTTP call to that API endpoint or unpack the results, you just write a SQL query that refers to the documented columns. One of those columns,&nbsp;<code>query</code>, is special: it encapsulates Twitter&#8217;s&nbsp;<a href=\"https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\" rel=\"noreferrer noopener\" target=\"_blank\">query syntax</a>. Here, we are just looking for tweets that match&nbsp;<em>PySpark</em>&nbsp;but we could as easily refine the query by pinning it to specific users, URLs, types (<code>is:retweet</code>,&nbsp;<code>is:reply</code>), properties (<code>has:mentions</code>,&nbsp;<code>has_media</code>), etc. That query syntax is the same no matter how you&#8217;re accessing the API: from Python, from R, or from Steampipe. It&#8217;s plenty to think about, and all you should really need to know when crafting queries to mine Twitter data.</p>\\n\\n\\n\\n<h3>2. GitHub: What are repositories that mention PySpark?</h3>\\n\\n\\n\\n<p>Here&#8217;s a SQL query to ask that question:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>select \\n  name, \\n  owner_login, \\n  stargazers_count \\nfrom \\n  github_search_repository \\nwhere \\n  query = \\'pyspark\\' \\norder by stargazers_count desc \\nlimit 10;</code></pre>\\n\\n\\n\\n<p>Here&#8217;s the answer:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>+----------------------+-------------------+------------------+\\n| name                 | owner_login       | stargazers_count |\\n+----------------------+-------------------+------------------+\\n| SynapseML            | microsoft         | 3297             |\\n| spark-nlp            | JohnSnowLabs      | 2725             |\\n| incubator-linkis     | apache            | 2524             |\\n| ibis                 | ibis-project      | 1805             |\\n| spark-py-notebooks   | jadianes          | 1455             |\\n| petastorm            | uber              | 1423             |\\n| awesome-spark        | awesome-spark     | 1314             |\\n| sparkit-learn        | lensacom          | 1124             |\\n| sparkmagic           | jupyter-incubator | 1121             |\\n| data-algorithms-book | mahmoudparsian    | 1001             |\\n+----------------------+-------------------+------------------+</code></pre>\\n\\n\\n\\n<p>This looks very similar to the first example! In this case, the table that&#8217;s being queried,&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository\">github_search_repository</a>, receives the output from GitHub&#8217;s&nbsp;<a href=\"https://docs.github.com/en/rest/search#search-repositories\" rel=\"noreferrer noopener\" target=\"_blank\">/search/repositories</a>&nbsp;endpoint and formulates it as a table with&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository#inspect\" rel=\"noreferrer noopener\" target=\"_blank\">these columns</a>.</p>\\n\\n\\n\\n<p>In both cases the Steampipe documentation not only shows you the schemas that govern the mapped tables, it also gives examples (<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent#examples\" rel=\"noreferrer noopener\" target=\"_blank\">Twitter</a>,&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository#examples\" rel=\"noreferrer noopener\" target=\"_blank\">GitHub</a>) of SQL queries that use the tables in various ways.</p>\\n\\n\\n\\n<p>Note that these are just two of many available tables. The Twitter API is mapped to&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/twitter/tables\" rel=\"noreferrer noopener\" target=\"_blank\">7 tables</a>, and the GitHub API is mapped to&nbsp;<a href=\"https://hub.steampipe.io/plugins/turbot/github/tables\" rel=\"noreferrer noopener\" target=\"_blank\">41 tables</a>.</p>\\n\\n\\n\\n<h3>3. Twitter + GitHub: What have owners of PySpark-related repositories tweeted lately?</h3>\\n\\n\\n\\n<p>To answer this question we need to consult two different APIs, then join their results. That&#8217;s even harder to do, in a consistent way, when you&#8217;re reasoning over REST payloads in Python or R. But this is the kind of thing SQL was born to do. Here&#8217;s one way to ask the question in SQL.</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>-- find pyspark repos\\nwith github_repos as (\\n  select \\n    name, \\n    owner_login, \\n    stargazers_count \\n  from \\n    github_search_repository \\n  where \\n    query = \\'pyspark\\' and name ~ \\'pyspark\\'\\n  order by stargazers_count desc \\n  limit 50\\n),\\n\\n-- find twitter handles of repo owners\\ngithub_users as (\\n  select\\n    u.login,\\n    u.twitter_username\\n  from\\n    github_user u\\n  join\\n    github_repos r\\n  on\\n    r.owner_login = u.login\\n  where\\n    u.twitter_username is not null\\n),\\n\\n-- find corresponding twitter users\\n  select\\n    id\\n  from\\n    twitter_user t\\n  join\\n    github_users g\\n  on\\n    t.username = g.twitter_username\\n)\\n\\n-- find tweets from those users\\nselect\\n  t.author-&gt;&gt;\\'username\\' as twitter_user,\\n  \\'https://twitter.com/\\' || (t.author-&gt;&gt;\\'username\\') || \\'/status/\\' || t.id as url,\\n  t.text\\nfrom\\n  twitter_user_tweet t\\njoin\\n  twitter_userids u\\non\\n  t.user_id = u.id\\nwhere\\n  t.created_at &gt; now()::date - interval \\'1 week\\'\\norder by\\n  t.author\\nlimit 5</code></pre>\\n\\n\\n\\n<p>Here is the answer:</p>\\n\\n\\n\\n<pre class=\"wp-block-code\"><code>+----------------+---------------------------------------------------------------+-------------------------------------&gt;\\n| twitter_user   | url                                                           | text                                &gt;\\n+----------------+---------------------------------------------------------------+-------------------------------------&gt;\\n| idealoTech     | https://twitter.com/idealoTech/status/1524688985649516544     | Are you able to find creative soluti&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | Join our @codility Order #API Challe&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | #idealolife #codility #php          &gt;\\n| idealoTech     | https://twitter.com/idealoTech/status/1526127469706854403     | Our #ProductDiscovery team at idealo&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | Think you can solve it? &#x1f60e;          &gt;\\n|                |                                                               | &#x27a1;  https://t.co/ELfUfp94vB https://t&gt;/\\n| ioannides_alex | https://twitter.com/ioannides_alex/status/1525049398811574272 | RT @scikit_learn: scikit-learn 1.1 i&gt;\\n|                |                                                               | What\\'s new? You can check the releas&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | pip install -U…                     &gt;\\n| andfanilo      | https://twitter.com/andfanilo/status/1524999923665711104      | @edelynn_belle Thanks! Sometimes it &gt;\\n| andfanilo      | https://twitter.com/andfanilo/status/1523676489081712640      | @juliafmorgado Good luck on the reco&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | My advice: power through it + a dead&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | I hated my first few short videos bu&gt;\\n|                |                                                               |                                     &gt;\\n|                |                                                               | Looking forward to the video &#x1f642;</code></pre>\\n\\n\\n\\n<p>When APIs frictionlessly become tables, you can devote your full attention to reasoning over the abstractions represented by those APIs. Larry Wall, the creator of Perl, famously said: &#8220;Easy things should be easy, hard things should be possible.&#8221; The first two examples are things that should be, and are, easy: each is just 10 lines of simple, straight-ahead SQL that requires no wizardry at all.</p>\\n\\n\\n\\n<p>The third example is a harder thing. It would be hard in any programming language. But SQL makes it possible in several nice ways. The solution is made of concise stanzas (CTEs, Common Table Expressions) that form a pipeline. Each phase of the pipeline handles one clearly-defined piece of the problem. You can validate the output of each phase before proceeding to the next. And you can do all this with the most mature and widely-used grammar for selection, filtering, and recombination of data.</p>\\n\\n\\n\\n<h4>Do I have to use SQL?</h4>\\n\\n\\n\\n<p>No! If you like the idea of mapping APIs to tables, but you would rather reason over those tables in Python or R dataframes, then Steampipe can oblige. Under the covers it&#8217;s Postgres, enhanced with&nbsp;<a href=\"https://wiki.postgresql.org/wiki/Foreign_data_wrappers\" rel=\"noreferrer noopener\" target=\"_blank\">foreign data wrappers</a>&nbsp;that handle the API-to-table transformation. Anything that can connect to Postgres can connect to Steampipe, including SQL drivers like Python&#8217;s&nbsp;<code>psycopg2</code>&nbsp;and R&#8217;s&nbsp;<code>RPostgres</code>&nbsp;as well as business-intelligence tools like Metabase, Tableau, and PowerBI. So you can use Steampipe to frictionlessly consume APIs into dataframes, then reason over the data in Python or R.</p>\\n\\n\\n\\n<p>But if you haven&#8217;t used SQL in this way before, it&#8217;s worth a look. Consider this comparison of SQL to Pandas from&nbsp;<a href=\"https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e\" rel=\"noreferrer noopener\" target=\"_blank\">How to rewrite your SQL queries in Pandas</a>.</p>\\n\\n\\n\\n<figure class=\"wp-block-table\"><table class=\"\"><thead><tr><th class=\"has-text-align-center\">SQL</th><th class=\"has-text-align-center\">Pandas</th></tr></thead><tbody><tr><td class=\"has-text-align-center\">select * from airports</td><td class=\"has-text-align-center\">airports</td></tr><tr><td class=\"has-text-align-center\">select * from airports limit 3</td><td class=\"has-text-align-center\">airports.head(3)</td></tr><tr><td class=\"has-text-align-center\">select id from airports where ident = &#8216;KLAX&#8217;</td><td class=\"has-text-align-center\">airports[airports.ident == &#8216;KLAX&#8217;].id</td></tr><tr><td class=\"has-text-align-center\">select distinct type from airport</td><td class=\"has-text-align-center\">airports.type.unique()</td></tr><tr><td class=\"has-text-align-center\">select * from airports where iso_region = &#8216;US-CA&#8217; and type = &#8216;seaplane_base&#8217;</td><td class=\"has-text-align-center\">airports[(airports.iso_region == &#8216;US-CA&#8217;) &amp; (airports.type == &#8216;seaplane_base&#8217;)]</td></tr><tr><td class=\"has-text-align-center\">select ident, name, municipality from airports where iso_region = &#8216;US-CA&#8217; and type = &#8216;large_airport&#8217;</td><td class=\"has-text-align-center\">airports[(airports.iso_region == &#8216;US-CA&#8217;) &amp; (airports.type == &#8216;large_airport&#8217;)][[&#8216;ident&#8217;, &#8216;name&#8217;, &#8216;municipality&#8217;]]</td></tr></tbody></table></figure>\\n\\n\\n\\n<p>We can argue the merits of one style versus the other, but there&#8217;s no question that SQL is the most universal and widely-implemented way to express these operations on data. So no, you don&#8217;t have to use SQL to its fullest potential in order to benefit from Steampipe. But you might find that you want to.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/feed/', 'slash_comments': '0'}, {'title': 'Artificial Creativity?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Artificial Creativity?'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/artificial-creativity-2/'}], 'link': 'https://www.oreilly.com/radar/artificial-creativity-2/', 'comments': 'https://www.oreilly.com/radar/artificial-creativity-2/#respond', 'published': 'Tue, 12 Jul 2022 13:24:16 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=7, tm_mday=12, tm_hour=13, tm_min=24, tm_sec=16, tm_wday=1, tm_yday=193, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14604', 'guidislink': False, 'summary': 'There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&#160; As with the discussion of sentience, authors are [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&#160; As with the discussion of sentience, authors are [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&nbsp; As with the discussion of sentience, authors are being misled by a very human will to believe. And in being misled, they’re missing out on what’s important.</p>\\n\\n\\n\\n<p>It’s impressive to see AI-generated pictures of an <a href=\"https://twitter.com/OpenAI/status/1511714545529614338?ref_src=twsrc%5Etfw\" rel=\"noreferrer noopener\" target=\"_blank\">astronaut riding a horse</a>, or a <a href=\"https://www.thedailybeast.com/googles-new-text-to-image-generator-imagen-is-scary-accurate\" rel=\"noreferrer noopener\" target=\"_blank\">dog riding a bike in Times Square</a>. But where’s the creativity?&nbsp; Is it in the prompt or in the product?&nbsp; I couldn’t draw a picture of a dog riding a bike; I’m not that good an artist. Given a few pictures of dogs, Times Square, and whatnot, I could probably photoshop my way into something passable, but not very good. &nbsp;(To be clear: these AI systems are not automating photoshop.) So the AI is doing something that many, perhaps most humans, wouldn’t be able to do. That’s important. Very few humans (if any) can play Go at the level of AlphaGo. We’re getting used to being second-best.</p>\\n\\n\\n\\n<p>However, a computer replacing a human’s limited photoshop skills isn’t creativity. It took a human to say “create a picture of a dog riding a bike.” An AI couldn’t do that of its own volition. That’s creativity.&nbsp;But before writing off the creation of the picture, let’s think more about what that really means. Works of art really have two sources: the idea itself and the technique required to instantiate that idea. You can have all the ideas you want, but if you can’t paint like Rembrandt, you’ll never generate a Dutch master. Throughout history, painters have learned technique by copying the works of masters. What’s interesting about DALL-E, Imagen, and their relatives is that they supply the technique. Using DALL-E or Imagen, I could create a painting of a tarsier eating an anaconda without knowing how to paint.</p>\\n\\n\\n\\n<p>That distinction strikes me as very important. In the 20th and 21st centuries we’ve become very impatient with technique. We haven’t become impatient with creating good ideas. (Or at least strange ideas.) The “age of mechanical reproduction” seems to have made technique less relevant; after all, we’re heirs of the poet Ezra Pound, who famously said, “Make it new.”</p>\\n\\n\\n\\n<p>But does that quote mean what we think? Pound’s “Make it new” has been <a href=\"https://www.guernicamag.com/the-making-of-making-it-new/\" rel=\"noreferrer noopener\" target=\"_blank\">traced back</a> to 18th century China, and from there to the 12th century, something that’s not at all surprising if you’re familiar with Pound’s fascination with Chinese literature. What’s interesting, though, is that Chinese art has always focused on technique to a level that’s almost inconceivable to the European tradition. And “Make it new” has, within it, the acknowledgment that what’s new first has to be made. Creativity and technique don’t come apart that easily.</p>\\n\\n\\n\\n<p>We can see that in other art forms. Beethoven broke Classical music and put it back together again, but different-–he’s the most radical composer in the Western tradition (except for, perhaps, Thelonious Monk). And it’s worth asking how we get from what’s old to what’s new.&nbsp; AI has been used to <a href=\"https://www.classicfm.com/composers/beethoven/unfinished-tenth-symphony-completed-by-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">complete Beethoven’s 10th symphony</a>, for which Beethoven left a number of sketches and notes at the time of his death. The result is pretty good, better than the human attempts I’ve heard at completing the 10th.&nbsp;It sounds Beethoven-like; its flaw is that it goes on and on, repeating Beethoven-like riffs but without the tremendous forward-moving force that you get in Beethoven’s compositions. But completing the 10th isn’t the problem we should be looking at. How did we get Beethoven in the first place?&nbsp; If you trained an AI on the music Beethoven was trained on, would you eventually get the 9th symphony?&nbsp;Or would you get something that sounds a lot like Mozart and Haydn?</p>\\n\\n\\n\\n<p>I’m betting the latter. The progress of art isn’t unlike the structure of scientific revolutions, and Beethoven indeed took everything that was known, broke it apart, and put it back together differently. Listen to the <a href=\"https://www.youtube.com/watch?v=HljSXSm6v9M\" rel=\"noreferrer noopener\" target=\"_blank\">opening of Beethoven’s 9th symphony</a>: what is happening? Where’s the theme? It sounds like the orchestra is tuning up. When the first theme finally arrives, it’s not the traditional “melody” that pre-Beethoven listeners would have expected, but something that dissolves back into the sound of instruments tuning, then gets reformed and reshaped. Mozart would never do this. Or listen again to <a href=\"https://www.youtube.com/watch?v=a9UApyClFKA\" rel=\"noreferrer noopener\" target=\"_blank\">Beethoven’s 5th symphony</a>, probably the most familiar piece of orchestral music in the world. That opening duh-duh-duh-DAH–what kind of theme is that? Beethoven builds this movement by taking that four note fragment, moving it around, changing it, breaking it into even smaller bits and reassembling them. You can’t imagine a witty, urbane, polite composer like Haydn writing music like this. But I don’t want to worship some notion of Beethoven’s “genius” that privileges creativity over technique. Beethoven could never have gotten beyond Mozart and Haydn (with whom Beethoven studied) without extensive knowledge of the technique of composing; he would have had some good ideas, but he would never have known how to realize them. Conversely, the realization of radical ideas as actual works of art inevitably changes the technique. Beethoven did things that weren’t conceivable to Mozart or Haydn, and they changed the way music was written: those changes made the music of Schubert, Schumann, and Brahms possible, along with the rest of the 19th century. </p>\\n\\n\\n\\n<p>That brings us back to the question of computers, creativity, and craft. Systems like DALL-E and Imagen break apart the idea and the technique, or the execution of the idea. Does that help us be more creative, or less? I could tell Imagen to “paint a picture of a 15th century woman with an enigmatic smile,” and after a few thousand tries I might get something like the Mona Lisa. I don’t think that anyone would care, really.&nbsp; But this isn’t creating something new; it’s reproducing something old. If I magically appeared early in the 20th century, along with a computer capable of running Imagen (though only trained on art through 1900), would I be able to tell it to create a Picasso or a Dali? I have no idea how to do that. Nor do I have any idea what the next step for art is now, in the 21st century, or how I’d ask Imagen to create it. It sure isn’t Bored Apes. And if I could ask Imagen or DALL-E to create a painting from the 22nd century, how would that change the AI’s conception of technique?</p>\\n\\n\\n\\n<p>At least part of what I lack is the technique, for technique isn’t just mechanical ability; it’s also the ability to think the way great artists do. And that gets us to the big question:</p>\\n\\n\\n\\n<p>Now that we have abstracted technique away from the artistic process, can we build interfaces between the creators of ideas and the machines of technique in a way that allows the creators to “make it new”?&nbsp; That’s what we really want from creativity: something that didn’t exist, and couldn’t have existed, before.</p>\\n\\n\\n\\n<p>Can artificial intelligence help us to be creative? That’s the important question, and it’s a question about user interfaces, not about who has the biggest model.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/artificial-creativity-2/feed/', 'slash_comments': '0'}, {'title': 'Radar Trends to Watch: July 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: July 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/#respond', 'published': 'Tue, 05 Jul 2022 11:09:04 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=7, tm_mday=5, tm_hour=11, tm_min=9, tm_sec=4, tm_wday=1, tm_yday=186, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14591', 'guidislink': False, 'summary': 'This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask. The most important issue facing technology might now be [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask. The most important issue facing technology might now be [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask.</p>\\n\\n\\n\\n<p>The most important issue facing technology might now be the protection of privacy. While that’s not a new concern, it’s a concern that most computer users have been willing to ignore, and that most technology companies have been willing to let them ignore. New state laws that criminalize having abortions out of state and the stockpiling of location information by antiabortion groups have made privacy an issue that can’t be ignored.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.nature.com/articles/d41586-022-01705-z\" rel=\"noreferrer noopener\" target=\"_blank\">Big Science has almost finished training</a> its open source <a href=\"https://bigscience.huggingface.co/blog/model-training-launched\" rel=\"noreferrer noopener\" target=\"_blank\">BLOOM language model</a>, which was developed by volunteer researchers and trained using public funds. Bloom will provide an open, public platform for research into the capabilities of large language models and, specifically,&nbsp; issues like avoiding bias and toxic language. </li><li>AI tools like AlphaFold2 can <a href=\"https://colbyford.medium.com/am-i-hallucinating-or-can-ai-now-design-cancer-curing-antibodies-3ef1bef92106\" rel=\"noreferrer noopener\" target=\"_blank\">create new proteins</a>, not just analyze existing ones; the unexpected creation of new artifacts by an AI system is playfully called “hallucination.” The proteins designed so far probably aren’t useful; still, this is a major step forward in drug design.</li><li>Microsoft is <a href=\"https://www.theverge.com/2022/6/21/23177016/microsoft-retires-emotion-recognition-azure-ai-tool-api\" rel=\"noreferrer noopener\" target=\"_blank\">limiting or removing access</a> to some features in its face recognition service, Azure Face. Organizations will have to tell Microsoft how and why facial recognition will be used in their systems; and services like emotion recognition will be removed completely.</li><li>Amazon plans to <a href=\"https://www.reuters.com/technology/amazon-has-plan-make-alexa-mimic-anyones-voice-2022-06-22/\" rel=\"noreferrer noopener\" target=\"_blank\">give Alexa the ability to imitate anyone’s voice</a>, using under a minute of audio. They give the example of a (possibly dead) grandmother “reading” a book to a child. Other AI vendors (most notably <a href=\"https://thenextweb.com/news/openai-punished-dev-used-gpt-3-to-resurrect-dead-ethics\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAI/Microsoft</a>) have considered such mimicry unethical.</li><li><a href=\"https://github.com/dolthub/dolt\" rel=\"noreferrer noopener\" target=\"_blank\">Dolt</a> is a SQL database that lets you version data using git commands, You can clone, push, pull, fork, branch, and merge just as with git; you access data using standard SQL.</li><li>It’s sadly unsurprising that a robot incorporating a widely-used neural network (OpenAI CLIP) learns <a href=\"https://techxplore.com/news/2022-06-robots-racist-sexist-flawed-ai.html\" rel=\"noreferrer noopener\" target=\"_blank\">racist and sexist biases</a>, and that these biases affect its performance on tasks.</li><li>Building <a href=\"https://techxplore.com/news/2022-06-technology-self-driving-cars-memories.html\" rel=\"noreferrer noopener\" target=\"_blank\">autonomous vehicles with memory</a>, so that they can learn about objects on the routes they drive, may be an important step in making AV practical. In real life, most people drive over routes they are already familiar with. Autonomous vehicles should have the same advantage.</li><li>The argument about whether Google’s LaMDA is “sentient” continues, with a Google engineer placed on administrative leave for <a href=\"https://www.theguardian.com/technology/2022/jun/12/google-engineer-ai-bot-sentient-blake-lemoine\" rel=\"noreferrer noopener\" target=\"_blank\">publishing transcripts of conversations</a> that he claimed demonstrate sentience. Or are large language models just <a href=\"https://twitter.com/janellecshane/status/1535835610396692480\" rel=\"noreferrer noopener\" target=\"_blank\">squirrels</a>?</li><li>For <a href=\"https://techxplore.com/news/2022-06-ai-future-art.html\" rel=\"noreferrer noopener\" target=\"_blank\">artists working in collaboration with AI</a>, the possibilities and imperfections of AI are a means of extending their creativity.</li><li>Pete Warden’s proposal for <a href=\"https://petewarden.com/2022/06/09/what-are-ml-sensors/\" rel=\"noreferrer noopener\" target=\"_blank\">ML Sensors</a> could make developing embedded ML systems much simpler: push the machine learning into the sensors themselves.</li><li>Researchers using DALL-E 2 discovered that <a href=\"https://theconversation.com/do-ai-systems-really-have-their-own-secret-language-184335\" rel=\"noreferrer noopener\" target=\"_blank\">the model has a “secret vocabulary”</a> that’s not human language, but that can be used somewhat reliably to create consistent pictures. It may be an artifact of the model’s inability to say “I didn’t understand that”; given nonsense input, it is pulled towards similar words in the training corpus.</li><li>HuggingFace has made an <a href=\"https://huggingface.co/blog/hugging-face-endpoints-on-azure\" rel=\"noreferrer noopener\" target=\"_blank\">agreement</a> with Microsoft that will allow Azure customers to <a href=\"https://thenextweb.com/news/what-hugging-face-and-microsofts-collaboration-means-for-applied-ai\" rel=\"noreferrer noopener\" target=\"_blank\">run HuggingFace language models on the Azure platform</a>.</li><li>The startup <a href=\"https://predibase.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Predibase</a> has built a <a href=\"https://thenewstack.io/predibase-takes-declarative-approach-to-automl/\" rel=\"noreferrer noopener\" target=\"_blank\">declarative low-code platform</a> for building AI systems. In a declarative system, you describe the outcome you want, rather than the process for creating the outcome. The system figures out the process.</li><li>Researchers are developing AI models that implement <a href=\"https://techxplore.com/news/2022-06-artificial-intelligence-human.html\" rel=\"noreferrer noopener\" target=\"_blank\">metamemory</a>: the ability to remember whether or not you know something.</li><li>As the population ages, it will be more important to diagnose diseases like Alzheimer’s early, when treatment is still meaningful. AI is <a href=\"https://www.technologyreview.com/2022/06/02/1052942/evaluating-brain-mri-scans-with-the-help-of-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">providing tools</a> to help doctors analyze MRI images more accurately than humans. These tools don’t attempt diagnosis; they provide data about brain features.</li><li>Google has <a href=\"https://www.bleepingcomputer.com/news/technology/google-quietly-bans-deepfake-training-projects-on-colab/\" rel=\"noreferrer noopener\" target=\"_blank\">banned the training of Deepfakes</a> on Colab, its free Jupyter-based cloud programming platform.</li></ul>\\n\\n\\n\\n<h2>Metaverse</h2>\\n\\n\\n\\n<ul><li>Samsung and RedHat are working on <a href=\"https://thenewstack.io/samsung-red-hat-to-work-on-linux-drivers-for-future-tech/\" rel=\"noreferrer noopener\" target=\"_blank\">new memory architectures and device drivers</a> that will be adequate to the demands of a 3D-enabled, cloud-based metaverse.</li><li>The <a href=\"https://metaverse-standards.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Metaverse Standards Forum</a> is a new industry group with the goal of solving interoperability problems for the Metaverse. It views the Metaverse as the outgrowth of the Web, and plans to coordinate work between existing standards groups (like the W3C) relevant to the Metaverse.</li><li>Can the “<a href=\"https://thenewstack.io/how-the-open-metaverse-will-transform-our-online-identities/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Metaverse</a>” be the future of the Internet?&nbsp; The <a href=\"https://github.com/omigroup/omigroup/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Metaverse Interoperability Group</a> is building vendor-independent standards for social graphs, identities, and other elements of a Metaverse.</li><li><a href=\"https://techxplore.com/news/2022-06-augmented-reality-head-up-next-gen.html\" rel=\"noreferrer noopener\" target=\"_blank\">Holographic heads-up displays</a> allow for 3D augmented reality: the ability to project 3D images onto the real world (for example, onto a car’s windshield).</li><li>Google’s <a href=\"https://medium.com/@bilawal/new-google-api-turns-the-world-into-a-3d-canvas-for-augmented-reality-developers-on-ios-android-5c541a705800\" rel=\"noreferrer noopener\" target=\"_blank\">Visual Position Service</a> uses the data they’ve collected through Street View to provide high-accuracy positioning data for augmented reality applications. (This may be related to Niantic’s VPS, or they may just be using the same acronym.)</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>With the end of Roe v. Wade, <a href=\"https://www.siliconvalley.com/2022/06/27/search-histories-location-data-text-messages-how-personal-data-could-be-used-to-enforce-anti-abortion-laws/\" rel=\"noreferrer noopener\" target=\"_blank\">personal data, including search histories and location data, could be used to prosecute women who have abortions</a>. Data brokers already collect and sell this data. It is unclear how large Internet companies that also collect this data will respond. (Google has announced that they will <a href=\"https://blog.google/technology/safety-security/protecting-peoples-privacy-on-health-topics/\" rel=\"noreferrer noopener\" target=\"_blank\">delete location histories</a> that include visits to sensitive locations.)</li><li>Security researchers have identified over <a href=\"https://www.bleepingcomputer.com/news/security/over-900-000-kubernetes-instances-found-exposed-online/\" rel=\"noreferrer noopener\" target=\"_blank\">900,000 Kubernetes clusters that are exposed (and possibly vulnerable) to malicious scans</a>. 65% of them are in the US.</li><li>Sonatype has discovered a number of <a href=\"https://blog.sonatype.com/python-packages-upload-your-aws-keys-env-vars-secrets-to-web\" rel=\"noreferrer noopener\" target=\"_blank\">modules in the Python’s PyPI repository that steal AWS credentials</a> and other important data. Supply chain security will continue to be a problem for developers, regardless of the programming language or problem domain.</li><li><a href=\"https://blogs.microsoft.com/on-the-issues/2022/06/22/defending-ukraine-early-lessons-from-the-cyber-war/\" rel=\"noreferrer noopener\" target=\"_blank\">Microsoft’s analysis of Russia’s cyberwar efforts</a> show that they have increasingly attacked resources in countries allied with Ukraine (most notably the US), and that government computers that are on-premises are especially vulnerable.</li><li>Working with Fastly and Cloudflare, Apple has developed a service called <a href=\"https://thenextweb.com/news/apple-ios-16-banish-captchas\" rel=\"noreferrer noopener\" target=\"_blank\">Automatic Verification</a> that eliminates the need for Captchas. According to rumors, it will be enabled by default in the beta of iOS16.</li><li>A surprisingly small botnet (only 5,000 hosts) generated a <a href=\"https://arstechnica.com/information-technology/2022/06/tsunami-of-junk-traffic-that-broke-ddos-records-delivered-by-tiniest-of-botnets/\" rel=\"noreferrer noopener\" target=\"_blank\">record-setting DDOS attack</a> that peaked at 26M HTTPS requests per second. The botnet was so powerful because most of its devices belonged to cloud providers. Cloudflare’s free service was able to mitigate the attack.</li><li>A different kind of attack against neural networks: present them with <a href=\"https://ieeexplore.ieee.org/document/9581273\" rel=\"noreferrer noopener\" target=\"_blank\">inputs that drive worst-case energy consumption</a>, forcing processors to reduce their clock speed or even overheat. </li><li>A new attack called Hertzbleed uses <a href=\"https://arstechnica.com/tech-policy/2022/06/cryptocurrency-plunges-as-crypto-bank-celsius-suspends-withdrawals/\" rel=\"noreferrer noopener\" target=\"_blank\">small variations in a processor’s clock speed</a> while it is processing encryption keys to guess those keys. Intel and AMD CPUs are vulnerable. While this attack may never be seen in the wild, it shows how the complexity of modern processors creates vulnerabilities.</li><li><a href=\"https://www.bleepingcomputer.com/news/security/new-symbiote-malware-infects-all-running-processes-on-linux-systems/\" rel=\"noreferrer noopener\" target=\"_blank\">Symbiote is a new kind of malware that attacks Linux</a>, injects software into all running processes, and uses Berkeley packet filters (eBPF) to steal data and create covert communications channels. Symbiote uses <a href=\"https://thenewstack.io/the-symbiote-malware-what-we-know-so-far/\" rel=\"noreferrer noopener\" target=\"_blank\">dynamic linker hijacking</a> to link executables to modified system libraries at run time.</li><li>In the first quarter of 2022, the <a href=\"https://www.bleepingcomputer.com/news/security/ransomware-gangs-now-give-victims-time-to-save-their-reputation/\" rel=\"noreferrer noopener\" target=\"_blank\">number of known ransomware attacks was down 40%</a>, largely due to the disappearance of the Conti ransomware group. This drop is probably only temporary. Tactics also changed; attackers aren’t announcing the names of their victims publicly, preferring to negotiate a ransom privately. </li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Amazon has launched <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\" rel=\"noreferrer noopener\" target=\"_blank\">CodeWhisperer</a>, a direct competitor to GitHub Copilot.</li><li>Linus Torvalds predicts that <a href=\"https://thenewstack.io/rust-in-the-linux-kernel-by-2023-linus-torvalds-predicts/\" rel=\"noreferrer noopener\" target=\"_blank\">Rust will be used in the Linux kernel by 2023</a>.</li><li>GitHub Copilot is now <a href=\"https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/\" rel=\"noreferrer noopener\" target=\"_blank\">generally available</a> (for a price); it’s free to students and open source maintainers. Corporate licenses will be available later this year.</li><li>WebAssembly is making inroads. The universal WebAssembly runtime, <a href=\"https://wasmer.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Wasmer</a>, runs any code, on any platform. Impressive, if it delivers.</li><li><a href=\"https://thenewstack.io/when-webassembly-replaces-docker/\" rel=\"noreferrer noopener\" target=\"_blank\">Can WebAssembly replace Docker?</a> Maybe, in some applications. WASM provides portability and eliminates some security issues (possibly introducing its own); Docker sets up environments.</li><li>Mozilla’s <a href=\"https://blog.mozilla.org/en/mozilla/local-translation-add-on-project-bergamot/\" rel=\"noreferrer noopener\" target=\"_blank\">Project Bergamot</a> is an automated translation tool designed for use on the Web. It can be used to build multilingual forms and other web pages. Unlike most other AI technologies, Bergamot runs in the browser using WASM. No data is sent to the cloud.</li><li>Microsoft has <a href=\"https://thenewstack.io/microsoft-talks-collaborative-apps-at-build-conference/\" rel=\"noreferrer noopener\" target=\"_blank\">released</a> a framework called <a href=\"https://fluidframework.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Fluid</a> for building collaborative apps, such as Slack, Discord, and Teams. Microsoft will also be releasing <a href=\"https://docs.microsoft.com/en-us/azure/azure-fluid-relay/\" rel=\"noreferrer noopener\" target=\"_blank\">Azure Fluid Relay</a> to support Fluid-based applications.</li><li><a href=\"https://github.com/dragonflydb/dragonfly\" rel=\"noreferrer noopener\" target=\"_blank\">Dragonfly</a> is a new in-memory database that claims significantly faster performance than memcached and Redis.</li><li>The Chinese government has <a href=\"https://www.technologyreview.com/2022/05/30/1052879/censoring-china-open-source-backfire/\" rel=\"noreferrer noopener\" target=\"_blank\">blocked access to open source code</a> on Gitee, the Chinese equivalent to GitHub, saying that all code must be reviewed by the government before it can be released to the public.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://blog.trailofbits.com/2022/06/21/are-blockchains-decentralized/\" rel=\"noreferrer noopener\" target=\"_blank\">Is Blockchain Decentralized?</a> <a href=\"https://assets-global.website-files.com/5fd11235b3950c2c1a3b6df4/62af6c641a672b3329b9a480_Unintended_Centralities_in_Distributed_Ledgers.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">A study commissioned by DARPA</a> investigates whether a blockchain is truly immutable, or whether it can be modified without exploiting cryptographic vulnerabilities, but by attacking the blockchain’s implementation, networking, and consensus protocols. This is the most comprehensive examination of blockchain security that we’ve seen. </li><li>Jack Dorsey has announced that he’s working on <a href=\"https://cryptobriefing.com/jack-dorsey-tbd-build-web5-on-bitcoin/\" rel=\"noreferrer noopener\" target=\"_blank\">Web5</a>, which will be focused on identity management and be based on Bitcoin.</li><li>Molly White’s post questioning the possibility of <a href=\"https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/\" rel=\"noreferrer noopener\" target=\"_blank\">acceptably non-dystopian self-sovereign identity</a> is a must-read; she has an excellent summary and critique of just about all the work going on in the field.</li><li>Cryptographer Matthew Green makes an important <a href=\"https://blog.cryptographyengineering.com/2022/06/09/in-defense-of-cryptocurrency/\" rel=\"noreferrer noopener\" target=\"_blank\">argument for the technologies behind cryptocurrency</a> (though not for the current implementations).</li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>The Innovative Genomics Institute is trying to <a href=\"https://www.technologyreview.com/2022/06/14/1053843/carbon-capture-crispr-crops/\" rel=\"noreferrer noopener\" target=\"_blank\">use CRISPR gene editing to optimize plants for carbon storage</a>.</li><li>A printed artificial skin with embedded transistors may <a href=\"https://techxplore.com/news/2022-06-artificial-skin-capable-pain-touch-sensitive.html\" rel=\"noreferrer noopener\" target=\"_blank\">allow robots to feel pain</a>. That’s one step closer to dreaming of electric sheep.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://techxplore.com/news/2022-06-potential-p-computers.html\" rel=\"noreferrer noopener\" target=\"_blank\">Probabilistic computers</a>, built from probabilistic bits (p-bits), may provide a significant step forward for probabilistic decision making. This sounds esoteric, but it’s essentially what we’re asking AI systems to do. P-bits may also be able to simulate q-bits and quantum computing.</li><li>A system that <a href=\"https://thenextweb.com/news/eureka-scientists-just-linked-two-time-crystals-together-first-time\" rel=\"noreferrer noopener\" target=\"_blank\">links two time crystals</a> could be the basis for a new form of quantum computing. Time crystals can exist at room temperature, and remain coherent for much longer than existing qubit technologies.</li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/feed/', 'slash_comments': '0'}, {'title': '2022 Cloud Salary Survey', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '2022 Cloud Salary Survey'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/'}], 'link': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/', 'comments': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/#respond', 'published': 'Wed, 22 Jun 2022 11:21:41 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=22, tm_hour=11, tm_min=21, tm_sec=41, tm_wday=2, tm_yday=173, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Cloud', 'scheme': None, 'label': None}, {'term': 'Radar Column', 'scheme': None, 'label': None}, {'term': 'Research', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14547', 'guidislink': False, 'summary': 'Last year, our&#160;report on cloud adoption&#160;concluded that adoption was proceeding rapidly; almost all organizations are using cloud services. Those findings confirmed the results we got in&#160;2020: everything was “up and to the right.” That’s probably still true—but saying “everything is still up and to the right” would be neither interesting nor informative. So rather than [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Last year, our&#160;report on cloud adoption&#160;concluded that adoption was proceeding rapidly; almost all organizations are using cloud services. Those findings confirmed the results we got in&#160;2020: everything was “up and to the right.” That’s probably still true—but saying “everything is still up and to the right” would be neither interesting nor informative. So rather than [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Last year, our&nbsp;<a href=\"https://learning.oreilly.com/library/view/the-cloud-in/9781492096733\" rel=\"noreferrer noopener\" target=\"_blank\">report on cloud adoption</a>&nbsp;concluded that adoption was proceeding rapidly; almost all organizations are using cloud services. Those findings confirmed the results we got in&nbsp;<a href=\"https://learning.oreilly.com/library/view/cloud-adoption-in/9781492088042\">2020</a>: everything was “up and to the right.” That’s probably still true—but saying “everything is still up and to the right” would be neither interesting nor informative. So rather than confirming the same results for a third year, we decided to do something different.</p>\\n\\n\\n\\n<p>This year’s survey asked questions about compensation for “cloud professionals”: the software developers, operations staff, and others who build cloud-based applications, manage a cloud platform, and use cloud services. We limited the survey to residents of the United States because salaries from different countries aren’t directly comparable; in addition to fluctuating exchange rates, there are different norms for appropriate compensation. This survey ran from April 4 through April 15, 2022, and was publicized via email to recipients of our&nbsp;<a href=\"https://www.oreilly.com/emails/newsletters\" rel=\"noreferrer noopener\" target=\"_blank\"><em>Infrastructure &amp; Ops Newsletter</em></a>&nbsp;whom we could identify as residing in the United States or whose location was unknown.</p>\\n\\n\\n\\n<div class=\"wp-block-group has-very-light-gray-background-color has-background\"><div class=\"wp-block-group__inner-container\">\\n<h4>Executive Summary</h4>\\n\\n\\n\\n<ul><li>Survey respondents earn an average salary of $182,000.</li><li>The average salary increase over the past year was 4.3%.</li><li>20% of respondents reported changing employers in the past year.</li><li>25% of respondents are planning to change employers because of compensation.</li><li>The average salary for women is 7% lower than the average salary for men.</li><li>63% of respondents work remotely all the time; 94% work remotely at least one day a week.</li><li>Respondents who participated in 40 or more hours of training in the past year received higher salary increases.</li></ul>\\n</div></div>\\n\\n\\n\\n<p>Of the 1,408 responses we initially received, 468 were disqualified. Respondents were disqualified (and the survey terminated) if the respondent said they weren’t a US resident or if they were under 18 years old; respondents were also disqualified if they said they weren’t involved with their organization’s use of cloud services. Another 162 respondents filled out part of the survey but didn’t complete it; we chose to include only complete responses. That left us with 778 responses. Participants came from 43 states plus Washington, DC. As with our other surveys, the respondents were a relatively senior group: the average age was 47 years old, and while the largest number identified themselves as programmers (43%), 14% identified as executives and 33% as architects.</p>\\n\\n\\n\\n<h2>The Big Picture</h2>\\n\\n\\n\\n<p>Cloud professionals are well paid. That’s not a surprise in itself. We expected salaries (including bonuses) to be high, and they were. The cloud professionals who responded to our survey earn an average salary of $182,000; the most common salary range among respondents was $150,000 to $175,000 per year (16% of the total), as shown in&nbsp;Figure 1. The peak was fairly broad: 68% of the respondents earn between $100,000 and $225,000 per year. And there was a significant “long tail” in the compensation stratosphere: 7% of the respondents earn over $300,000 per year, and 2.4% over $400,000 per year.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14550\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0101-2-1048x762.png\" /><figcaption>Figure 1. <em>Annual salary by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>We believe that job changes are part of what’s driving high salaries. After all, we’ve heard about talent shortages in almost every field, with many employers offering very high salaries to attract the staff they need. By staying with their current employer, an employee may get an annual salary increase of 4%. But if they change jobs, they might get a significantly higher offer—20% or more—plus a signing bonus.</p>\\n\\n\\n\\n<p>20% of the respondents reported that they changed employers in the past year. That number isn’t high in and of itself, but it looks a lot higher when you add it to the 25% who are planning to leave jobs over compensation. (Another 20% of the respondents declined to answer this question.) It’s also indicative that 19% of the respondents received promotions. There was some overlap between those who received promotions and those who changed jobs (5% of the total said “yes” to both questions, or roughly one quarter of those who changed jobs). When you look at the number of respondents who left their employer, are planning to leave their employer, or got a promotion and a salary increase, it’s easy to see why salary budgets are under pressure. Right now, qualified candidates have the power in the job market, though with the stock market correction that began in March 2022 and significant layoffs from some large technology-sector companies, that may be changing.</p>\\n\\n\\n\\n<p>These conclusions are borne out when you look at the salaries of those who were promoted, changed jobs, or intend to change jobs. A promotion roughly doubled respondents’ year-over-year salary increase. On the average, those who were promoted received a 7% raise; those who weren’t promoted received a 3.7% increase. The result was almost exactly the same for those who changed jobs: those who changed averaged a 6.8% salary increase, while those who remained averaged 3.7%. We also see a difference in the salaries of those who intend to leave because of compensation: their average salary is $171,000, as opposed to $188,000 for those who didn’t plan to leave. That’s a $17,000 difference, or roughly 10%.</p>\\n\\n\\n\\n<h2>Salaries by Gender</h2>\\n\\n\\n\\n<p>One goal of this survey was to determine whether women are being paid fairly. Last year’s&nbsp;<a href=\"https://learning.oreilly.com/library/view/2021-data-ai-salary/9781098118662\" rel=\"noreferrer noopener\" target=\"_blank\">salary survey for data and AI</a>&nbsp;found a substantial difference between men’s and women’s salaries: women were paid 16% less than men. Would we see the same here?</p>\\n\\n\\n\\n<p>The quick answer is “yes,” but the difference was smaller. Average salaries for women are 7% lower than for men ($172,000 as opposed to $185,000). But let’s take a step back before looking at salaries in more detail. We asked our respondents what pronouns they use. Only 8.5% said “she,” while 79% chose “he.” That’s still only 87% of the total. Where are the rest? 12% preferred not to say; this is a larger group than those who used “she.” 0.5% chose &#8220;other,&#8221; and 0.7% chose &#8220;they.&#8221; (That&#8217;s only four and six respondents, respectively.) Compared to results from our survey on the data/AI industry, the percentage of cloud professionals who self-identified as women appears to be much smaller (8.5%, as opposed to 14%). But there’s an important difference between the surveys: “I prefer not to answer” wasn’t an option for the Data/AI Salary Survey. We can’t do much with those responses. When we eyeballed the data for the “prefer not to say” group, we saw somewhat higher salaries than for women, but still significantly less (5% lower) than for men.</p>\\n\\n\\n\\n<p>The difference between men’s and women’s salaries is smaller than we expected, given the results of last year’s Data/AI Salary Survey. But it’s still a real difference, and it begs the question: Is compensation improving for women? Talent shortages are driving compensation up in many segments of the software industry. Furthermore, the average reported salaries for both men and women in our survey are high. Again, is that a consequence of the talent shortage? Or is it an artifact of our sample, which appears to be somewhat older, and rich in executives? We can’t tell from a single year’s data, and the year-over-year comparison we made above is based on a different industry segment. But the evidence suggests that the salary gap is closing, and progress is being made. And that is indeed a good thing.</p>\\n\\n\\n\\n<p>Salaries for respondents who answered “other” to the question about the pronouns they use are 31% lower than salaries for respondents who chose “he.” Likewise, salaries for respondents who chose “they” are 28% lower than men’s average salaries. However, both of these groups are extremely small, and in both groups, one or two individuals pulled the averages down. We could make the average salaries higher by calling these individuals “outliers” and removing their data; after all, outliers can have outsized effects on small groups. That’s a step we won’t take. Whatever the reason, the outliers are there; they’re part of the data. Professionals all across the spectrum have low-paying jobs—sometimes by choice, sometimes out of necessity. Why does there appear to be a concentration of them among people who don’t use “he” or “she” as their pronouns? The effect probably isn’t quite as strong as our data indicates, but we won’t try to explain our data away. It’s certainly indicative that the groups that use “they” or another pronoun than &#8220;he&#8221; or &#8220;she&#8221; showed a salary penalty. We have to conclude that respondents who use nonbinary pronouns earn lower salaries, but without more data, we don’t know why, nor do we know how much lower their salaries are or whether this difference would disappear with a larger sample.</p>\\n\\n\\n\\n<p>To see more about the differences between men&#8217;s and women&#8217;s salaries, we looked at the men and women in each salary range. The overall shapes of the salary distributions are clear: a larger percentage of women earn salaries between $0 and $175,000, and (with two exceptions) a larger percentage of men earn salaries over $175,000. However, a slightly larger percentage of women earn supersize salaries ($400,000 or more), and a significantly larger percentage earn salaries between $225,000 and $250,000 (Figure 2).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14551\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0102-1-807x1048.png\" /><figcaption>Figure 2. <em>Men’s and women’s salaries by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>We can get some additional information by looking at salary increases (Figure 3). On average, women’s salary increases were higher than men’s: $9,100 versus $8,100. That doesn’t look like a big difference, but it’s over 10%. We can read that as a sign that women’s salaries are certainly catching up. But the signals are mixed. Men’s salaries increased more than women’s in almost every segment, with two big exceptions: 12% of women received salary increases over $30,000, while only 8% of men did the same. Likewise, 17% of women received increases between $10,000 and $15,000, but only 9% of men did. These differences might well disappear with more data.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14553\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0103-1-1048x874.png\" /><figcaption>Figure 3. <em>Salary increases for women and men by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>When we look at salary increases as a percentage of salary, we again see mixed results (Figure 4). Women’s salary increases were much larger than men’s in three bands: over $325,000 (with the exception of $375,000–$400,000, where there were no women respondents), $275,000–$300,000, and $150,000–$175,000. For those with very large salaries, women’s salary increases were much higher than men’s. Furthermore, the $150,000–$175,000 band had the largest number of women. While there was a lot of variability, salary increases are clearly an important factor driving women&#8217;s salaries toward parity with men’s.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14554\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0104-1-754x1048.png\" /><figcaption>Figure 4. <em>Salary increases as a percentage of salary</em></figcaption></figure>\\n\\n\\n\\n<h3>The Effect of Education</h3>\\n\\n\\n\\n<p>The difference between men’s and women’s salaries is significant at almost every educational level (Figure 5). The difference is particularly high for respondents who are self-taught, where women earned 39% less ($112,000 versus $184,000), and for students (45% less, $87,000 versus $158,000). However, those were relatively small groups, with only two women in each group. It’s more important that for respondents with bachelor’s degrees, women’s salaries were 4% higher than men’s ($184,000 versus $176,000)—and this was the largest group in our survey. For respondents with advanced degrees, women with doctorates averaged a 15% lower salary than men with equivalent education; women with master’s degrees averaged 10% lower. The difference between women’s and men’s salaries appears to be greatest at the extremes of the educational spectrum.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14555\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0105-1-1048x756.png\" /><figcaption>Figure 5. <em>Men’s and women’s salaries by degree</em></figcaption></figure>\\n\\n\\n\\n<h2>Salaries by State</h2>\\n\\n\\n\\n<p>Participants in the survey come from 43 states plus Washington, DC. Looking at salaries by state creates some interesting puzzles. The highest salaries are found in Oklahoma; South Dakota is third, following California. And the top of the list is an interesting mix of states where we expected high salaries (like New York) and states where we expected salaries to be lower. So what’s happening?</p>\\n\\n\\n\\n<p>The average salary from Oklahoma is $225,000—but that only reflects two respondents, both of whom work remotely 100% of the time. (We’ll discuss remote work later in this report.) Do they work for a Silicon Valley company and get a Silicon Valley salary? We don’t know, but that’s certainly a possibility. The average salary for South Dakota is $212,000, but we shouldn’t call it an “average,” because we only had one response, and this respondent reported working remotely 1–4 days per week. Likewise, Vermont had a single respondent, who works remotely and who also had an above-average salary. Many other states have high average salaries but a very small number of respondents.</p>\\n\\n\\n\\n<p>So the first conclusion that we can draw is that remote work might be making it possible for people in states without big technology industries to get high salaries. Or it could be the opposite: there’s no state without some businesses using the cloud, and the possibility of remote work puts employers in those states in direct competition with Silicon Valley salaries: they need to pay much higher salaries to get the expertise they need. And those job offers may include the opportunity to work remotely full or part time—even if the employer is local. Both of those possibilities no doubt hold true for individuals, if not for geographical regions as a whole.</p>\\n\\n\\n\\n<p>Outliers aside, salaries are highest in California ($214,000), New York ($212,000), Washington ($203,000), Virginia ($195,000), and Illinois ($191,000). Massachusetts comes next at $189,000. At $183,000, average salaries in Texas are lower than we’d expect, but they’re still slightly above the national average ($182,000). States with high average salaries tended to have the largest numbers of respondents—with the important exceptions that we’ve already noted. The lowest salaries are found in West Virginia ($87,000) and New Mexico ($84,000), but these reflected a small number of respondents (one and four, respectively). These two states aside, the average salary in every state was over $120,000 (Figure 6).</p>\\n\\n\\n\\n<p>So, is remote work equalizing salaries between different geographical regions? It’s still too early to say. We don’t think there will be a mass exodus from high-salary states to more rural states, but it’s clear that professionals who want to make that transition can, and that companies that aren’t in high-salary regions will need to offer salaries that compete in the nationwide market. Future surveys will tell us whether this pattern holds true.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14556\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0106-1-558x1048.png\" /><figcaption>Figure 6. <em>Average salary by state</em></figcaption></figure>\\n\\n\\n\\n<h2>Salaries by Age</h2>\\n\\n\\n\\n<p>The largest group of respondents to our survey were between 45 and 54 years old (Figure 7). This group also had the highest average salary ($196,000). Salaries for respondents between 55 and 65 years old were lower (averaging $173,000), and salaries dropped even more for respondents over 65 ($139,000). Salaries for the 18- to 24-year-old age range were low, averaging $87,000. These lower salaries are no surprise because this group includes both students and those starting their first jobs after college.</p>\\n\\n\\n\\n<p>It’s worth noting that our respondents were older than we expected; 29% were between 35 and 44 years old, 36% were between 45 and 54, and 22% were between 55 and 64. Data from our learning platform shows that this distribution isn’t indicative of the field as a whole, or of our audience. It may be an artifact of the survey itself. Are our newsletter readers older, or are older people more likely to respond to surveys? We don’t know.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14557\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0107-1-1048x420.png\" /><figcaption>Figure 7. <em>Average salary by age</em></figcaption></figure>\\n\\n\\n\\n<p>The drop in salaries after age 55 is surprising. Does seniority count for little? It’s easy to make hypotheses: Senior employees are less likely to change jobs, and we’ve seen that changing jobs drives higher salaries. But it’s also worth noting that AWS launched in 2002, roughly 20 years ago. People who are now 45 to 54 years old started their careers in the first years of Amazon’s rollout. They “grew up” with the cloud; they’re the real cloud natives, and that appears to be worth something in today’s market.</p>\\n\\n\\n\\n<h2>Job Titles and Roles</h2>\\n\\n\\n\\n<p>Job titles are problematic. There’s no standardized naming system, so a programming lead at one company might be an architect or even a CTO at another. So we ask about job titles at a fairly high level of abstraction. We offered respondents a choice of four “general” roles: executive, director, manager, or associate. We also allowed respondents to write in their own job titles; roughly half chose this option. The write-in titles were more descriptive and, as expected, inconsistent. We were able to group them into some significant clusters by looking for people whose write-in title used the words “engineer,” “programmer,” “developer,” “architect,” “consultant,” or “DevOps.” We also looked at two modifiers: “senior” and “lead.” There’s certainly room for overlap: someone could be a “senior DevOps engineer.” But in practice, overlap was small. (For example, no respondents used both “developer” and “architect” in a write-in job title.) There was no overlap between the titles submitted by respondents and the general titles we offered on the survey: our respondents had to choose one or the other.</p>\\n\\n\\n\\n<p>So what did we see? As shown in&nbsp;Figure 8, the highest salaries go to those who classified themselves as directors ($235,000) or executives ($231,000). Salaries for architects, “leads,” and managers are on the next tier ($196,000, $190,000, and $188,000, respectively). People who identified as engineers earn slightly lower salaries ($175,000). Associates, a relatively junior category, earn an average of $140,000 per year. Those who used “programmer” in their job title are a puzzle. There were only three of them, which is a surprise in itself, and all have salaries in the $50,000 to $100,000 range (average $86,000). Consultants also did somewhat poorly, with an average salary of $129,000.</p>\\n\\n\\n\\n<p>Those who identified as engineers (19%) made up the largest group of respondents, followed by associates (18%). Directors and managers each comprised 15% of the respondents. That might be a bias in our survey, since it’s difficult to believe that 30% of cloud professionals have directorial or managerial roles. (That fits the observation that our survey results may skew toward older participants.) Architects were less common (7%). And relatively few respondents identified themselves with the terms “DevOps” (2%), “consultant” (2%), or “developer” (2%). The small number of people who identify with DevOps is another puzzle. It’s often been claimed that the cloud makes operations teams unnecessary; “NoOps” shows up in discussions from time to time. But we’ve never believed that. Cloud deployments still have a significant operational component. While the cloud may allow a smaller group to oversee a huge number of virtual machines, managing those machines has become more complex—particularly with cloud orchestration tools like Kubernetes.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14558\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0108-1-1048x807.png\" /><figcaption>Figure 8. <em>Average salary by job title</em></figcaption></figure>\\n\\n\\n\\n<p>We also tried to understand what respondents are doing at work by asking about job roles, decoupling responsibilities from titles (Figure 9). So in another question, we asked respondents to choose between marketing, sales, product, executive, programmer, and architect roles, with no write-in option. Executives earn the highest salaries ($237,000) but were a relatively small group (14%). Architects are paid $188,000 per year on average; they were 33% of respondents. And for this question, respondents didn’t hesitate to identify as programmers: this group was the largest (43%), with salaries somewhat lower than architects ($163,000). This is roughly in agreement with the data we got from job titles. (And we should have asked about operations staff. Next year, perhaps.)</p>\\n\\n\\n\\n<p>The remaining three groups—marketing, sales, and product—are relatively small. Only five respondents identified their role as marketing (0.6%), but they were paid well ($187,000). 1.5% of the respondents identified as sales, with an average salary of $186,000. And 8% of the respondents identified themselves with product, with a somewhat lower average salary of $162,000.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14559\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0109-1-1048x387.png\" /><figcaption>Figure 9. <em>Average salary by role</em></figcaption></figure>\\n\\n\\n\\n<h2>Working from Home</h2>\\n\\n\\n\\n<p>When we were planning this survey, we were very curious about&nbsp;<em>where</em>&nbsp;people worked. Many companies have moved to a fully remote work model (as O’Reilly has), and many more are taking a hybrid approach. But just how common is remote work? And what consequences does it have for the employees who work from home rather than in an office?</p>\\n\\n\\n\\n<p>It turns out that remote work is surprisingly widespread (Figure 10). We found that only 6% of respondents answered no to the question “Do you work remotely?” More than half (63%) said that they work remotely all the time, and the remainder (31%) work remotely 1–4 days per week.</p>\\n\\n\\n\\n<p>Working remotely is also associated with higher salaries: the average salary for people who work remotely 1–4 days a week is $188,000. It’s only slightly less ($184,000) for people who work remotely all the time. Salaries are sharply lower for people who never work remotely (average $131,000).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14560\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0110-1-1048x223.png\" /><figcaption>Figure 10. <em>Salaries and remote work</em></figcaption></figure>\\n\\n\\n\\n<p>Salary increases show roughly the same pattern (Figure 11). While salaries are slightly higher for respondents who occasionally work in the office, salary increases were higher for those who are completely remote: the average increase was $8,400 for those who are remote 100% of the time, while those who work from home 1–4 days per week only averaged a $7,800 salary increase. We suspect that given time, these two groups would balance out. Salary changes for those who never work remotely were sharply lower ($4,500).</p>\\n\\n\\n\\n<p>Of all jobs in the computing industry, cloud computing is probably the most amenable to remote work. After all, you’re working with systems that are remote by definition. You’re not reliant on your own company’s data center. If the application crashes in the middle of the night, nobody will be rushing to the machine room to reboot the server. A laptop and a network connection are all you need.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14561\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0111-1-1048x228.png\" /><figcaption>Figure 11. <em>Salary increases and remote work</em></figcaption></figure>\\n\\n\\n\\n<p>We’re puzzled by the relatively low salaries and salary increases for those who never work remotely. While there were minor differences, as you’d expect, there were no “smoking guns”: no substantial differences in education or job titles or roles. Does this difference reflect old-school companies that don’t trust their staff to be productive at home? And do they pay correspondingly lower salaries? If so, they’d better be forewarned: it’s very easy for employees to change jobs in the current labor market.</p>\\n\\n\\n\\n<p>As the pandemic wanes (if indeed it wanes—despite what people think,&nbsp;<a href=\"https://covid.cdc.gov/covid-data-tracker/#datatracker-home\" rel=\"noreferrer noopener\" target=\"_blank\">that’s not what the data shows</a>), will companies stick with remote work or will they require employees to come back to the office? Some companies have already asked their employees to return. But we believe that the trend toward remote work will be hard, if not impossible, to reverse, especially in a job market where employers are competing for talent. Remote work certainly raises issues about onboarding new hires, training, group dynamics, and more. And it’s not without problems for the employees themselves: childcare, creating appropriate work spaces, etc. These challenges notwithstanding, it’s difficult to imagine people who have eliminated a lengthy commute from their lives going back to the office on a permanent basis.</p>\\n\\n\\n\\n<h2>Certifications and Training</h2>\\n\\n\\n\\n<p>Nearly half (48%) of our respondents participated in technical training or certification programs in the last year. 18% of them obtained one or more certifications, suggesting that 30% participated in training or some other form of professional development that wasn’t tied to a certification program.</p>\\n\\n\\n\\n<p>The most common reasons for participating in training were learning new technologies (42%) and improving existing skills (40%). (Percentages are relative to the total number of respondents, which was 778.) 21% wanted to work on more interesting projects. The other possible responses were chosen less frequently: 9% of respondents wanted to move into a leadership role, and 12% were required to take training. Job security was an issue for 4% of the respondents, a very small minority. That’s consistent with our observation that employees have the upper hand in the labor market and are more concerned with advancement than with protecting their status quo.</p>\\n\\n\\n\\n<p>Survey participants obtained a very broad range of certifications. We asked specifically about 11 cloud certifications that we identified as being particularly important. Most were specific to one of the three major cloud vendors: Microsoft Azure, Amazon Web Services, and Google Cloud. However, the number of people who obtained any specific certification was relatively small. The most popular certifications were AWS Certified Cloud Practitioner and Solutions Architect (both 4% of the total number of respondents). However, 8% of respondents answered “other” and provided a write-in answer. That’s 60 respondents—and we got 55 different write-ins. Obviously, there was very little duplication. The only submissions with multiple responses were CKA (Certified Kubernetes Administrator) and CKAD (Certified Kubernetes Application Developer). The range of training in this “other” group was extremely broad, spanning various forms of Agile training, security, machine learning, and beyond. Respondents were pursuing many vendor-specific certifications, and even academic degrees. (It’s worth noting that our&nbsp;<em>2021 Data/AI Salary Survey</em>report also concluded that earning a certification for one of the major cloud providers was a useful tool for career advancement.)</p>\\n\\n\\n\\n<p>Given the number of certifications that are available, this isn’t surprising. It’s somewhat more surprising that there isn’t any consensus on which certifications are most important. When we look at salaries, though, we see some signals&#8230;at least among the leading certifications. The largest salaries are associated with Google Cloud Certified Professional Cloud Architect ($231,000). People who earned this certification also received a substantial salary increase (7.1%). Those who obtained an AWS Certified Solutions Architect &#8211; Professional, AWS Certified Solutions Architect &#8211; Associate, or Microsoft Certified: Azure Solutions Architect Expert certification also earn very high salaries ($212,000, $201,000, and $202,000, respectively), although these three received smaller salary increases (4.6%, 4.4%, and 4.0%, respectively). Those who earned the CompTIA Cloud+ certification receive the lowest salary ($132,000) and got a relatively small salary increase (3.5%). The highest salary increase went to those who obtained the Google Cloud Certified Professional Cloud DevOps Engineer certification (9.7%), with salaries in the middle of the range ($175,000).</p>\\n\\n\\n\\n<p>We can’t draw any conclusions about the salaries or salary increases corresponding to the many certifications listed among the “other” responses; most of those certifications only appeared once. But it seems clear that the largest salaries and salary increases go to those who are certified for one of the big three platforms: Google Cloud, AWS, and Microsoft Azure (Figures&nbsp;12&nbsp;and&nbsp;13).</p>\\n\\n\\n\\n<p>The salaries and salary increases for the two Google certifications are particularly impressive. Given that Google Cloud is the least widely used of the major platforms, and that the number of respondents for these certifications was relatively small, we suspect that talent proficient with Google’s tools and services is harder to find and drives the salaries up.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14562\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0112-1-1048x708.png\" /><figcaption>Figure 12. <em>Average salary by certification</em></figcaption></figure>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14563\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0113-1-1048x770.png\" /><figcaption>Figure 13. <em>Average salary increase by certification</em></figcaption></figure>\\n\\n\\n\\n<p>Our survey respondents engaged in many different types of training. The most popular were watching videos and webinars (41%), reading books (39%), and reading blogs and industry articles (34%). 30% of the respondents took classes online. Given the pandemic, it isn’t at all surprising that only 1.7% took classes in person. 23% attended conferences, either online or in person. (We suspect that the majority attended online.) And 24% participated in company-offered training.</p>\\n\\n\\n\\n<p>There’s surprisingly little difference between the average salaries associated with each type of learning. That’s partly because respondents were allowed to choose more than one response. But it’s also notable that the average salaries for most types of learning are lower than the average salary for the respondents as a whole. The average salary by type of learning ranges from $167,000 (in-person classes) to $184,000 (company-provided educational programs). These salaries are on the low side compared to the overall average of $182,000. Lower salaries may indicate that training is most attractive to people who want to get ahead in their field. This fits the observation that most of the people who participated in training did so to obtain new skills or to improve current ones. After all, to many companies “the cloud” is still relatively new, and they need to retrain their current workforces.</p>\\n\\n\\n\\n<p>When we look at the time that respondents spent in training (Figure 14), we see that the largest group spent 20–39 hours in the past year (13% of all the respondents). 12% spent 40–59 hours; and 10% spent over 100 hours. No respondents reported spending 10–19 hours in training. (There were also relatively few in the 80–99 hour group, but we suspect that’s an artifact of “bucketing”: if you’ve taken 83 hours of training, you’re likely to think, “I don’t know how much time I spent in training, but it was a lot,” and choose 100+.) The largest salary increases went to those who spent 40–59 hours in training, followed by those who spent over 100 hours; the smallest salary increases, and the lowest salaries, went to those who only spent 1–9 hours in training. Managers take training into account when planning compensation, and those who skimp on training shortchange themselves.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14564\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0114-1-1048x514.png\" /><figcaption>Figure 14. <em>Percentage salary increase by time spent in training</em></figcaption></figure>\\n\\n\\n\\n<h2>The Cloud Providers</h2>\\n\\n\\n\\n<p>A survey of this type wouldn’t be complete without talking about the major cloud providers. There’s no really big news here (Figure 15). Amazon Web Services has the most users, at 72%, followed by Microsoft Azure (42%) and Google Cloud (31%). Compared to the cloud survey we did last year, it looks like Google Cloud and Azure have dropped slightly compared to AWS. But the changes aren’t large. Oracle’s cloud offering was surprisingly strong at 6%, and 4% of the respondents use IBM Cloud.</p>\\n\\n\\n\\n<p>When we look at the biggest cloud providers that aren’t based in the US, we find that they’re still a relatively small component of cloud usage: 0.6% of respondents use Alibaba, while 0.3% use Tencent. Because there are so few users among our respondents, the percentages don’t mean much: a few more users, and we might see something completely different. That said, we expected to see more users working with Alibaba; it’s possible that tensions between the United States and China have made it a less attractive option.</p>\\n\\n\\n\\n<p>20% of the respondents reported using a private cloud. While it’s not entirely clear what the term “private cloud” means—for some, it just means a traditional data center—almost all the private cloud users also reported using one of the major cloud providers. This isn’t surprising; private clouds make the most sense as part of a hybrid or multicloud strategy, where the private cloud holds data that must be kept on premises for security or compliance reasons.</p>\\n\\n\\n\\n<p>6% of the respondents reported using a cloud provider that we didn’t list. These answers were almost entirely from minor cloud providers, which had only one or two users among the survey&nbsp;participants. And surprisingly, 4% of the respondents reported that they weren’t using any cloud provider.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14565\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0115-1-1048x595.png\" /><figcaption>Figure 15. <em>Cloud provider usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>There’s little difference between the salaries reported by people using the major providers (Figure 16). Tencent stands out; the average salary for its users is $275,000. But there were so few Tencent users among the survey respondents that we don’t believe this average is meaningful. There appears to be a slight salary premium for users of Oracle ($206,000) and Google ($199,000); since these cloud providers aren’t as widely used, it’s easy to assume that organizations committed to them are willing to pay slightly more for specialized talent, a phenomenon we’ve observed elsewhere. Almost as a footnote, we see that the respondents who don’t use a cloud have significantly lower salaries ($142,000).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14566\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0116-1-1048x598.png\" /><figcaption>Figure 16. <em>Average salary by cloud provider</em></figcaption></figure>\\n\\n\\n\\n<p>Cloud providers offer many services, but their basic services fall into a few well-defined classes (Figure 17). 75% of the survey respondents reported using virtual instances (for example, AWS EC2), and 74% use bucket storage (for example, AWS S3). These are services that are offered by every cloud provider. Most respondents use an SQL database (59%). Somewhat smaller numbers reported using a NoSQL database (41%), often in conjunction with an SQL database. 49% use container orchestration services; 45% use “serverless,” which suggests that serverless is more popular than we’ve seen in our other recent surveys.</p>\\n\\n\\n\\n<p>Only 11% reported using some kind of AutoML—again, a service that’s provided by all the major cloud providers, though under differing names. And again, we saw no significant differences in salary based on what services were in use. That makes perfect sense; you wouldn’t pay a carpenter more for using a hammer than for using a saw.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14567\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0117-1-1048x456.png\" /><figcaption>Figure 17. <em>Basic cloud services usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<h2>The Work Environment</h2>\\n\\n\\n\\n<p>Salaries aside, what are cloud developers working with? What programming languages and tools are they using?</p>\\n\\n\\n\\n<h3>Languages</h3>\\n\\n\\n\\n<p>Python is the most widely used language (59% of respondents), followed by SQL (49%), JavaScript (45%), and Java (32%). It’s somewhat surprising that only a third of the respondents use Java, given that programming language surveys done by TIOBE and RedMonk almost always have Java, Python, and JavaScript in a near tie for first place. Java appears not to have adapted well to the cloud (Figure 18).</p>\\n\\n\\n\\n<p>Salaries also follow a pattern that we’ve seen before. Although the top four languages are in high demand, they don’t command particularly high salaries: $187,000 for Python, $179,000 for SQL, $181,000 for JavaScript, and $188,000 for Java (Figure 19). These are all “table stakes” languages: they’re necessary and they’re what most programmers use on the job, but the programmers who use them don’t stand out. And despite the necessity, there’s a lot of talent available to fill these roles. As we saw in last year’s&nbsp;<em>Data/AI Salary Survey</em>&nbsp;report, expertise in Scala, Rust, or Go commands a higher salary ($211,000, $202,000, and $210,000, respectively). While the demand for these languages isn’t as high, there’s a lot less available expertise. Furthermore, fluency in any of these languages shows that a programmer has gone considerably beyond basic competence. They’ve done the work necessary to pick up additional skills.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14568\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0118-1-1048x887.png\" /><figcaption>Figure 18. <em>Programming language usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<p>The lowest salaries were reported by respondents using PHP ($155,000). Salaries for C, C++, and C# are also surprisingly low ($170,000, $172,000, and $170,000, respectively); given the importance of C and C++ for software development in general and the importance of C# for the Microsoft world, we find it hard to understand why.</p>\\n\\n\\n\\n<p>Almost all of the respondents use multiple languages. If we had to make a recommendation for someone who wanted to move into cloud development or operations, or for someone planning a cloud strategy from scratch, it would be simple: focus on SQL plus one of the other table stakes languages (Java, JavaScript, or Python). If you want to go further, pick one of the languages associated with the highest salaries. We think Scala is past its peak, but because of its strong connection to the Java ecosystem, Scala makes sense for Java programmers. For Pythonistas, we’d recommend choosing Go or Rust.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14569\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0119-1-1048x879.png\" /><figcaption>Figure 19. <em>Average salary by programming language</em></figcaption></figure>\\n\\n\\n\\n<h3>Operating Systems</h3>\\n\\n\\n\\n<p>We asked our survey participants which operating systems they used so we could test something we’ve heard from several people who hire software developers: Linux is a must. That appears to be the case: 80% of respondents use Linux (Figure 20). Even though Linux really hasn’t succeeded in the desktop market (sorry), it’s clearly the operating system for most software that runs in the cloud. If Linux isn’t a requirement, it’s awfully close.</p>\\n\\n\\n\\n<p>67% of the respondents reported using macOS, but we suspect that’s mostly as a desktop or laptop operating system. Of the major providers, only AWS offers macOS virtual instances, and they’re not widely used. (Apple’s license only allows macOS to run on Apple hardware, and only AWS provides Apple servers.) 57% of the respondents reported using some version of Windows. While we suspect that Windows is also used primarily as a desktop or laptop operating system, Windows virtual instances are available from all the major providers, including Oracle and IBM.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14570\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0120-1-1048x227.png\" /><figcaption>Figure 20. <em>Operating system usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<h3>Tools</h3>\\n\\n\\n\\n<p>We saw little variation in salary from tool to tool. This lack of variation makes sense. As we said above, we don’t expect a carpenter who uses a hammer to be paid more than a carpenter who uses a saw. To be a competent carpenter, you need to use both, along with levels, squares, and a host of other tools.</p>\\n\\n\\n\\n<p>However, it is interesting to know what tools are commonly in use (Figure 21). There aren’t any real surprises. Docker is almost universal, used by 76% of the respondents. Kubernetes use is very widespread, by 61% of the respondents. Other components of the Kubernetes ecosystem didn’t fare as well: 27% of respondents reported using Helm, and 12% reported using Istio, which has been widely criticized for being too complex.</p>\\n\\n\\n\\n<p>Alternatives to this core cluster of tools don’t appear to have much traction. 10% of the respondents reported using OpenShift, the IBM/Red Hat package that includes Kubernetes and other core components. Our respondents seem to prefer building their tooling environment themselves. Podman, an alternative to Docker and a component of OpenShift, is only used by 8% of the respondents. Unfortunately, we didn’t ask about Linkerd, which appears to be establishing itself as a service mesh that’s simpler to configure than Istio. However, it didn’t show up among the write-in responses, and the number of respondents who said “other” was relatively small (9%).</p>\\n\\n\\n\\n<p>The HashiCorp tool set (Terraform, Consul, and Vault) appears to be more widely used: 41% of the respondents reported using Terraform, 17% use Vault, and 8% use Consul. However, don’t view these as alternatives to Kubernetes. Terraform is a tool for building and configuring cloud infrastructure, and Vault is a secure repository for secrets. Only Consul competes directly.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14571\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/06/csr_0121-1-1048x657.png\" /><figcaption>Figure 21. <em>Tool usage by percentage of respondents</em></figcaption></figure>\\n\\n\\n\\n<h2>The Biggest Impact</h2>\\n\\n\\n\\n<p>Finally, we asked the respondents what would have the biggest impact on compensation and promotion. The least common answer was “data tools” (6%). This segment of our audience clearly isn’t working directly with data science or AI—though we’d argue that might change as more machine learning applications reach production. “Programming languages” was second from the bottom. The lack of concern about programming languages reflects reality. While we observed higher salaries for respondents who used Scala, Rust, or Go, if you’re solidly grounded in the basics (like Python and SQL), you’re in good shape. There’s limited value in pursuing additional languages once you have the table stakes.</p>\\n\\n\\n\\n<p>The largest number of respondents said that knowledge of “cloud and containers” would have the largest effect on compensation. Again, containers are table stakes, as we saw in the previous section. Automation, security, and machine learning were also highly rated (18%, 15%, and 16%, respectively). It’s not clear why machine learning was ranked highly but data tools wasn’t. Perhaps our respondents interpreted “data tools” as software like Excel, R, and pandas.</p>\\n\\n\\n\\n<p>11% of the respondents wrote in an answer. As usual with write-ins, the submissions were scattered, and mostly singletons. However, many of the write-in answers pointed toward leadership and management skills. Taken all together, these varied responses add up to about 2% of the total respondents. Not a large number, but still a signal that some part of our audience is thinking seriously about IT leadership.</p>\\n\\n\\n\\n<h2>Confidence in the Future</h2>\\n\\n\\n\\n<p>“Cloud adoption is up and to the right”? No, we already told you we weren’t going to conclude that. Though it’s no doubt true; we don’t see cloud adoption slowing in the near future.</p>\\n\\n\\n\\n<p>Salaries are high. That’s good for employees and difficult for employers. It’s common for staff to jump to another employer offering a higher salary and a generous signing bonus. The current stock market correction may put a damper on that trend. There are signs that Silicon Valley’s money supply is starting to dry up, in part because of higher interest rates but also because investors are nervous about how the online economy will respond to regulation, and impatient with startups whose business plan is to lose billions “buying” a market before they figure out how to make money. Higher interest rates and nervous investors could mean an end to skyrocketing salaries.</p>\\n\\n\\n\\n<p>The gap between women’s and men’s salaries has narrowed, but it hasn’t closed. While we don’t have a direct comparison for the previous year, last year’s&nbsp;<em>Data/AI Salary Survey</em>report showed a 16% gap. In this survey, the gap has been cut to 7%, and women are receiving salary increases that are likely to close that gap even further. It’s anyone’s guess how this will play out in the future. Talent is in short supply, and that puts upward pressure on salaries. Next year, will we see women’s salaries on par with men’s? Or will the gap widen again when the talent shortage isn’t so acute?</p>\\n\\n\\n\\n<p>While we aren’t surprised by the trend toward remote work, we are surprised at how widespread remote work has become: as we saw, only 10% of our survey respondents never work remotely, and almost two-thirds work remotely full time. Remote work may be easier for cloud professionals, because part of their job is inherently remote. However, after seeing these results, we&#8217;d predict similar numbers for other industry sectors. Remote work is here to stay.</p>\\n\\n\\n\\n<p>Almost half of our survey respondents participated in some form of training in the past year. Training on the major cloud platforms (AWS, Azure, and Google Cloud) was associated with higher salaries. However, our participants also wrote in 55 “other” kinds of training and certifications, of which the most popular was CKA (Certified Kubernetes Administrator).</p>\\n\\n\\n\\n<p>Let’s end by thinking a bit more about the most common answer to the question “What area do you feel will have the biggest impact on compensation and promotion in the next year?”: cloud and containers. Our first reaction is that this is a poorly phrased option; we should have just asked about containers. Perhaps that’s true, but there’s something deeper hidden in this answer. If you want to get ahead in cloud computing, learn more about the cloud. It’s tautological, but it also shows some real confidence in where the industry is heading. Cloud professionals may be looking for their next employer, but they aren’t looking to jump ship to the “next big thing.” Businesses aren’t jumping away from the cloud to “the next big thing” either; whether it’s AI, the “metaverse,” or something else, their next big thing will be built in the cloud. And containers are the building blocks of the cloud; they’re the foundation on which the future of cloud computing rests. Salaries are certainly “up and to the right,” and we don’t see demand for cloud-capable talent dropping any time in the near future.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/2022-cloud-salary-survey/feed/', 'slash_comments': '0'}, {'title': '“Sentience” is the Wrong Question', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '“Sentience” is the Wrong Question'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/'}], 'link': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/', 'comments': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/#respond', 'published': 'Tue, 21 Jun 2022 13:30:35 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=21, tm_hour=13, tm_min=30, tm_sec=35, tm_wday=1, tm_yday=172, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14576', 'guidislink': False, 'summary': 'On June 6, Blake Lemoine, a Google engineer, was suspended by Google for disclosing a series of conversations he had with LaMDA, Google’s impressive large model, in violation of his NDA. Lemoine’s claim that LaMDA has achieved “sentience” was widely publicized–and criticized–by almost every AI expert. And it’s only two weeks after Nando deFreitas, tweeting [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'On June 6, Blake Lemoine, a Google engineer, was suspended by Google for disclosing a series of conversations he had with LaMDA, Google’s impressive large model, in violation of his NDA. Lemoine’s claim that LaMDA has achieved “sentience” was widely publicized–and criticized–by almost every AI expert. And it’s only two weeks after Nando deFreitas, tweeting [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>On June 6, Blake Lemoine, a Google engineer, was suspended by Google for disclosing a <a href=\"https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917\">series of conversations he had with LaMDA</a>, Google’s impressive large model, in violation of his NDA. Lemoine’s claim that LaMDA has achieved “sentience” was widely publicized–and criticized–by almost every AI expert. And it’s only two weeks after Nando deFreitas, <a href=\"https://twitter.com/NandoDF/status/1525397036325019649\">tweeting</a> about DeepMind’s new Gato model, claimed that artificial general intelligence is only a matter of scale. I’m with the experts; I think Lemoine was taken in by his own willingness to believe, and I believe DeFreitas is <a href=\"https://www.oreilly.com/radar/closer-to-agi/\">wrong about general intelligence</a>. But I also think that “sentience” and “general intelligence” aren’t the questions we ought to be discussing.</p>\\n\\n\\n\\n<p>The latest generation of models is good enough to convince some people that they are intelligent, and whether or not those people are deluding themselves is beside the point. What we should be talking about is what responsibility the researchers building those models have to the general public. I recognize Google’s right to require employees to sign an NDA; but when a technology has implications as potentially far-reaching as general intelligence, are they right to keep it under wraps?&nbsp; Or, looking at the question from the other direction, will developing that technology in public breed misconceptions and panic where none is warranted?</p>\\n\\n\\n\\n<p>Google is one of the three major actors driving AI forward, in addition to OpenAI and Facebook. These three have demonstrated different attitudes towards openness. Google communicates largely through academic papers and press releases; we see gaudy announcements of its accomplishments, but the number of people who can actually experiment with its models is extremely small. OpenAI is much the same, though it has also made it possible to test-drive models like GPT-2 and GPT-3, in addition to building new products on top of its APIs–GitHub Copilot is just one example. Facebook has <a href=\"https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/\">open sourced its largest model, OPT-175B</a>, along with several smaller pre-built models and a voluminous set of notes describing how OPT-175B was trained.</p>\\n\\n\\n\\n<p>I want to look at these different versions of “openness” through the lens of the scientific method. (And I’m aware that this research really is a matter of engineering, not science.)&nbsp; Very generally speaking, we ask three things of any new scientific advance:</p>\\n\\n\\n\\n<ul><li>It can reproduce past results. It’s not clear what this criterion means in this context; we don’t want an AI to reproduce the poems of Keats, for example. We would want a newer model to perform at least as well as an older model.</li><li>It can predict future phenomena. I interpret this as being able to produce new texts that are (as a minimum) convincing and readable. It’s clear that many AI models can accomplish this.</li><li>It is reproducible. Someone else can do the same experiment and get the same result. Cold fusion fails this test badly. What about large language models?</li></ul>\\n\\n\\n\\n<p>Because of their scale, large language models have a significant problem with reproducibility. You can download the source code for Facebook’s OPT-175B, but you won’t be able to train it yourself on any hardware you have access to. It’s too large even for universities and other research institutions. You still have to take Facebook’s word that it does what it says it does.&nbsp;</p>\\n\\n\\n\\n<p>This isn’t just a problem for AI. One of our authors from the 90s went from grad school to a professorship at Harvard, where he researched large-scale distributed computing. A few years after getting tenure, he left Harvard to join Google Research. Shortly after arriving at Google, he blogged that he was “<a href=\"http://matt-welsh.blogspot.com/2010/11/why-im-leaving-harvard.html\">working on problems that are orders of magnitude larger and more interesting than I can work on at any university</a>.” That raises an important question: what can academic research mean when it can’t scale to the size of industrial processes? Who will have the ability to replicate research results on that scale? This isn’t just a problem for computer science; many recent experiments in high-energy physics require energies that can only be reached at the Large Hadron Collider (LHC).&nbsp;Do we trust results if there’s only one laboratory in the world where they can be reproduced?</p>\\n\\n\\n\\n<p>That’s exactly the problem we have with large language models. OPT-175B can’t be reproduced at Harvard or MIT. It probably can’t even be reproduced by Google and OpenAI, even though they have sufficient computing resources. I would bet that OPT-175B is too closely tied to Facebook’s infrastructure (including custom hardware) to be reproduced on Google’s infrastructure. I would bet the same is true of LaMDA, GPT-3, and other very large models, if you take them out of the environment in which they were built.&nbsp; If Google released the source code to LaMDA, Facebook would have trouble running it on its infrastructure. The same is true for GPT-3.&nbsp;</p>\\n\\n\\n\\n<p>So: what can “reproducibility” mean in a world where the infrastructure needed to reproduce important experiments can’t be reproduced?&nbsp; The answer is to provide free access to outside researchers and early adopters, so they can ask their own questions and see the wide range of results. Because these models can only run on the infrastructure where they’re built, this access will have to be via public APIs.</p>\\n\\n\\n\\n<p>There are lots of impressive examples of text produced by large language models. LaMDA’s are the best I’ve seen. But we also know that, for the most part, these examples are heavily cherry-picked. And there are many examples of failures, which are certainly also cherry-picked.&nbsp; I’d argue that, if we want to build safe, usable systems, paying attention to the failures (cherry-picked or not) is more important than applauding the successes. Whether it’s sentient or not, we care more about a self-driving car crashing than about it navigating the streets of San Francisco safely at rush hour. That’s not just our (sentient) propensity for drama;&nbsp; if you’re involved in the accident, one crash can ruin your day. If a natural language model has been trained not to produce racist output (and that’s still very much a research topic), its failures are more important than its successes.&nbsp;</p>\\n\\n\\n\\n<p>With that in mind, OpenAI has done well by allowing others to use GPT-3–initially, through a limited free trial program, and now, as a commercial product that customers access through APIs. While we may be legitimately concerned by GPT-3’s ability to generate pitches for conspiracy theories (or just plain marketing), at least we know those risks.&nbsp; For all the useful output that GPT-3 creates (whether deceptive or not), we’ve also seen its errors. Nobody’s claiming that GPT-3 is sentient; we understand that its output is a function of its input, and that if you steer it in a certain direction, <a href=\"https://www.oreilly.com/radar/ai-powered-misinformation-and-manipulation-at-scale-gpt-3/\">that’s the direction it takes</a>. When GitHub Copilot (built from OpenAI Codex, which itself is built from GPT-3) was first released, I saw lots of speculation that it will cause programmers to lose their jobs. Now that we’ve seen Copilot, we understand that it’s a useful tool within its limitations, and discussions of job loss have dried up.&nbsp;</p>\\n\\n\\n\\n<p>Google hasn’t offered that kind of visibility for LaMDA. It’s irrelevant whether they’re concerned about intellectual property, liability for misuse, or inflaming public fear of AI. Without public experimentation with LaMDA, our attitudes towards its output–whether fearful or ecstatic–are based at least as much on fantasy as on reality. Whether or not we put appropriate safeguards in place, research done in the open, and the ability to play with (and even build products from) systems like GPT-3, have made us aware of the consequences of “deep fakes.” Those are realistic fears and concerns. With LaMDA, we can’t have realistic fears and concerns. We can only have imaginary ones–which are inevitably worse. In an area where reproducibility and experimentation are limited, allowing outsiders to experiment may be the best we can do.&nbsp;</p>\\n\\n\\n\\n<p></p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/sentience-is-the-wrong-question/feed/', 'slash_comments': '0'}, {'title': 'Closer to AGI?', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Closer to AGI?'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/closer-to-agi/'}], 'link': 'https://www.oreilly.com/radar/closer-to-agi/', 'comments': 'https://www.oreilly.com/radar/closer-to-agi/#respond', 'published': 'Tue, 07 Jun 2022 11:09:16 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=7, tm_hour=11, tm_min=9, tm_sec=16, tm_wday=1, tm_yday=158, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14516', 'guidislink': False, 'summary': 'DeepMind’s new model, Gato, has sparked a debate on whether artificial general intelligence (AGI) is nearer–almost at hand–just a matter of scale.&#160; Gato is a model that can solve multiple unrelated problems: it can play a large number of different games, label images, chat, operate a robot, and more.&#160; Not so many years ago, one [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'DeepMind’s new model, Gato, has sparked a debate on whether artificial general intelligence (AGI) is nearer–almost at hand–just a matter of scale.&#160; Gato is a model that can solve multiple unrelated problems: it can play a large number of different games, label images, chat, operate a robot, and more.&#160; Not so many years ago, one [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>DeepMind’s new model, Gato, has sparked a debate on whether artificial general intelligence (AGI) is nearer–almost at hand–just a matter of scale.&nbsp; Gato is a model that can solve multiple unrelated problems: it can <a href=\"https://www.deepmind.com/publications/a-generalist-agent\" rel=\"noreferrer noopener\" target=\"_blank\">play a large number of different games, label images, chat, operate a robot, and more</a>.&nbsp; Not so many years ago, one problem with AI <a href=\"https://www.oreilly.com/radar/what-is-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">was that AI systems were only good at one thing</a>. After IBM’s Deep Blue defeated Garry Kasparov in chess,&nbsp; it was easy to say “But the ability to play chess isn’t really what we mean by intelligence.” A model that plays chess can’t also play space wars. That’s obviously no longer true; we can now have models capable of doing many different things. 600 things, in fact, and future models will no doubt do more.</p>\\n\\n\\n\\n<p>So, are we on the verge of artificial general intelligence, as <a href=\"https://twitter.com/NandoDF/status/1525397036325019649\" rel=\"noreferrer noopener\" target=\"_blank\">Nando de Frietas (research director at DeepMind) claims? That the only problem left is scale?</a> I don’t think so.&nbsp; It seems inappropriate to be talking about AGI when <a href=\"https://www.oreilly.com/radar/artificial-intelligence-human-inhuman/\" rel=\"noreferrer noopener\" target=\"_blank\">we don’t really have a good definition of “intelligence.”</a> If we had AGI, how would we know it? We have a lot of vague notions about the Turing test, but in the final analysis, Turing wasn’t offering a definition of machine intelligence; he was probing the question <a href=\"https://aeon.co/essays/why-we-should-remember-alan-turing-as-a-philosopher\" rel=\"noreferrer noopener\" target=\"_blank\">of what human intelligence means</a>.</p>\\n\\n\\n\\n<p>Consciousness and intelligence seem to require <a href=\"https://www.oreilly.com/radar/intelligence-and-comprehension/\" rel=\"noreferrer noopener\" target=\"_blank\">some sort of agency</a>.&nbsp; An AI can’t choose what it wants to learn, neither can it say “I don’t want to play Go, I’d rather play Chess.” Now that we have computers that can do both, can they “want” to play one game or the other? One reason we know our children (and, for that matter, our pets) are intelligent and not just automatons is that they’re capable of disobeying. A child can refuse to do homework; a dog can refuse to sit. And that refusal is as important to intelligence as the ability to solve differential equations, or to play chess. Indeed, the path towards artificial intelligence is as much about teaching us what intelligence isn’t (as Turing knew) as it is about building an AGI.</p>\\n\\n\\n\\n<p>Even if we accept that Gato is a huge step on the path towards AGI, and that scaling is the only problem that’s left, it is more than a bit problematic to think that scaling is a problem that’s easily solved. We don’t know how much power it took to train Gato, but GPT-3 required about <a href=\"https://info.deeplearning.ai/the-batch-recognizing-distracted-drivers-training-fighter-pilots-dominating-the-bridge-table-training-trillions-of-parameters\" rel=\"noreferrer noopener\" target=\"_blank\">1.3 Gigawatt-hours</a>: roughly 1/1000th the energy it takes to <a href=\"https://home.cern/resources/faqs/facts-and-figures-about-lhc#:~:text=What%20is%20the%20LHC%20power,is%20750%20GWh%20per%20year.\" rel=\"noreferrer noopener\" target=\"_blank\">run the Large Hadron Collider</a> for a year. Granted, Gato is much smaller than GPT-3, though <a href=\"https://www.zdnet.com/article/deepminds-gato-is-mediocre-so-why-did-they-build-it/\" rel=\"noreferrer noopener\" target=\"_blank\">it doesn’t work as well</a>; Gato’s performance is generally inferior to that of single-function models. And granted, a lot can be done to optimize training (and <a href=\"https://arxiv.org/pdf/2203.15556.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">DeepMind has done a lot of work</a> on models that require less energy). But Gato has just over 600 capabilities, focusing on natural language processing, image classification, and game playing. These are only a few of many tasks an AGI will need to perform. How many tasks would a machine be able to perform to qualify as a “general intelligence”? Thousands?&nbsp; Millions? Can those tasks even be enumerated? At some point, the project of training an artificial general intelligence sounds like something from Douglas Adams’ novel <a href=\"https://en.wikipedia.org/wiki/The_Hitchhiker\\'s_Guide_to_the_Galaxy\" rel=\"noreferrer noopener\" target=\"_blank\"><em>The Hitchhiker’s Guide to the Galaxy</em></a>, in which the Earth is a computer designed by an AI called Deep Thought to answer the question “What is the question to which 42 is the answer?”</p>\\n\\n\\n\\n<p>Building bigger and bigger models in hope of somehow achieving general intelligence may be an interesting research project, but AI may already have achieved a level of performance that suggests specialized training on top of existing <a href=\"https://arxiv.org/abs/2108.07258\" rel=\"noreferrer noopener\" target=\"_blank\">foundation models</a> will reap far more short term benefits. A foundation model trained to recognize images can be trained further to be part of a self-driving car, or <a href=\"https://www.resetera.com/threads/midjourney-is-lighting-up-the-ai-generated-art-community.586463/\" rel=\"noreferrer noopener\" target=\"_blank\">to create generative art</a>. A foundation model like GPT-3 trained to understand and speak human language can be <a href=\"https://copilot.github.com/\" rel=\"noreferrer noopener\" target=\"_blank\">trained more deeply to write computer code</a>.</p>\\n\\n\\n\\n<p>Yann LeCun posted a <a href=\"https://m.alpha.facebook.com/story.php?story_fbid=10158256523332143&amp;id=722677142\" rel=\"noreferrer noopener\" target=\"_blank\">Twitter thread about general intelligence (consolidated on Facebook)</a> stating some “simple facts.” First, LeCun says that there is no such thing as “general intelligence.” LeCun also says that “human level AI” is a useful goal–acknowledging that human intelligence itself is something less than the type of general intelligence sought for AI. All humans are specialized to some extent. I’m human; I’m arguably intelligent; I can play Chess and Go, but not <a href=\"https://en.wikipedia.org/wiki/Xiangqi\" rel=\"noreferrer noopener\" target=\"_blank\">Xiangqi</a> (often called Chinese Chess) or Golf. I could presumably learn to play other games, but I don’t have to learn them all. I can also play the piano, but not the violin. I can speak a few languages. Some humans can speak dozens, but none of them speak every language.</p>\\n\\n\\n\\n<p>There’s an important point about expertise hidden in here: we expect our AGIs to be “experts” (to beat top-level Chess and Go players), but as a human, I’m only fair at chess and poor at Go. Does human intelligence require expertise? (Hint: re-read <a href=\"https://academic.oup.com/mind/article/LIX/236/433/986238\" rel=\"noreferrer noopener\" target=\"_blank\">Turing’s original paper</a> about the Imitation Game, and check the computer’s answers.) And if so, what kind of expertise? Humans are capable of broad but limited expertise in many areas, combined with deep expertise in a small number of areas. So this argument is really about terminology: could Gato be a step towards human-level intelligence (limited expertise for a large number of tasks), but not general intelligence?</p>\\n\\n\\n\\n<p>LeCun agrees that we are missing some “fundamental concepts,” and we don’t yet know what those fundamental concepts are. In short, we can’t adequately define intelligence. More specifically, though, he mentions that “a few others believe that symbol-based manipulation is necessary.” That’s an allusion to the debate (<a href=\"https://twitter.com/garymarcus/status/1411401507610796032\" rel=\"noreferrer noopener\" target=\"_blank\">sometimes on Twitter</a>) between LeCun and Gary Marcus, who has argued many times that <a href=\"https://nautil.us/deep-learning-is-hitting-a-wall-14467/\" rel=\"noreferrer noopener\" target=\"_blank\">combining deep learning with symbolic reasoning</a> is the only way for AI to progress. (In his response to the Gato announcement, Marcus labels this school of thought “<a href=\"https://garymarcus.substack.com/p/the-new-science-of-alt-intelligence\" rel=\"noreferrer noopener\" target=\"_blank\">Alt-intelligence</a>.”) That’s an important point: impressive as models like GPT-3 and <a href=\"https://arxiv.org/abs/2112.06905\" rel=\"noreferrer noopener\" target=\"_blank\">GLaM</a> are, they make a lot of mistakes. Sometimes those are <a href=\"https://www.linkedin.com/pulse/gpt-3-does-understand-what-saying-steve-shwartz/\" rel=\"noreferrer noopener\" target=\"_blank\">simple mistakes of fact</a>, such as when GPT-3 wrote an article about the United Methodist Church that got a number of basic facts wrong. Sometimes, the mistakes reveal a horrifying (or hilarious, they’re often the same) <a href=\"https://www.tidio.com/blog/how-smart-are-gpt-3-chatbots/\" rel=\"noreferrer noopener\" target=\"_blank\">lack of what we call “common sense.”</a> Would you sell your children for refusing to do their homework? (To give GPT-3 credit, it points out that selling your children is illegal in most countries, and that there are better forms of discipline.)</p>\\n\\n\\n\\n<p>It’s not clear, at least to me, that these problems can be solved by “scale.” How much more text would you need to know that humans don’t, normally, sell their children? I can imagine “selling children” showing up in sarcastic or frustrated remarks by parents, along with texts discussing slavery. I suspect there are few texts out there that actually state that selling your children is a bad idea.&nbsp;Likewise, how much more text would you need to know that Methodist general conferences take place every four years, not annually? The general conference in question generated some press coverage, but not a lot; it’s reasonable to assume that GPT-3 had most of the facts that were available. What additional data would a large language model need to avoid making these mistakes? Minutes from prior conferences, documents about Methodist rules and procedures, and a few other things.&nbsp;As modern datasets go, it’s probably not very large; a few gigabytes, at most. But then the question becomes “How many specialized datasets would we need to train a general intelligence so that it’s accurate on any conceivable topic?”&nbsp; Is that answer a million?&nbsp; A billion?&nbsp; What are all the things we might want to know about? Even if any single dataset is relatively small, we’ll soon find ourselves building the successor to Douglas Adams’ Deep Thought.</p>\\n\\n\\n\\n<p>Scale isn’t going to help. But in that problem is, I think, a solution. If I were to build an artificial therapist bot, would I want a general language model?&nbsp; Or would I want a language model that had some broad knowledge, but has received some special training to give it deep expertise in psychotherapy? Similarly, if I want a system that writes news articles about religious institutions, do I want a fully general intelligence? Or would it be preferable to train a general model with data specific to religious institutions? The latter seems preferable–and it’s certainly more similar to real-world human intelligence, which is broad, but with areas of deep specialization.&nbsp;Building such an intelligence is a problem we’re already on the road to solving, by using large “foundation models” with additional training to customize them for special purposes. GitHub’s <a href=\"https://copilot.github.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Copilot</a> is one such model; <a href=\"https://www.oreilly.com/online-learning/article-answers.html\" rel=\"noreferrer noopener\" target=\"_blank\">O’Reilly Answers</a> is another.</p>\\n\\n\\n\\n<p>If a “general AI” is no more than “a model that can do lots of different things,” do we really need it, or is it just an academic curiosity?&nbsp; What’s clear is that we need better models for specific tasks. If the way forward is to build specialized models on top of foundation models, and if this process generalizes from language models like GPT-3 and O’Reilly Answers to other models for different kinds of tasks, then we have a different set of questions to answer. First, rather than trying to build a general intelligence by making an even bigger model, we should ask whether we can build a good foundation model that’s smaller, cheaper, and more easily distributed, perhaps as open source. Google has done <a href=\"https://info.deeplearning.ai/the-batch-recognizing-distracted-drivers-training-fighter-pilots-dominating-the-bridge-table-training-trillions-of-parameters\" rel=\"noreferrer noopener\" target=\"_blank\">some excellent work at reducing power consumption, though it remains huge</a>, and Facebook has released their <a href=\"https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/\" rel=\"noreferrer noopener\" target=\"_blank\">OPT model with an open source license</a>. Does a foundation model actually require anything more than the ability to parse and create sentences that are grammatically correct and stylistically reasonable?&nbsp; Second, we need to know how to specialize these models effectively.&nbsp; We can obviously do that now, but I suspect that training these subsidiary models can be optimized. These specialized models might also incorporate symbolic manipulation, as Marcus suggests; for two of our examples, psychotherapy and religious institutions, symbolic manipulation would probably be essential. If we’re going to build an AI-driven therapy bot, I’d rather have a bot that can do that one thing well than a bot that makes mistakes that are much subtler than <a href=\"https://www.artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/\" rel=\"noreferrer noopener\" target=\"_blank\">telling patients to commit suicide</a>. I’d rather have a bot that can collaborate intelligently with humans than one that needs to be watched constantly to ensure that it doesn’t make any egregious mistakes.</p>\\n\\n\\n\\n<p>We need the ability to combine models that perform different tasks, and we need the ability to interrogate those models about the results. For example, I can see the value of a chess model that included (or was integrated with) a language model that would enable it to answer questions like “What is the significance of Black’s 13th move in the 4th game of FischerFisher vs. Spassky?” Or “You’ve suggested Qc5, but what are the alternatives, and why didn’t you choose them?” Answering those questions doesn’t require a model with 600 different abilities. It requires two abilities: chess and language. Moreover, it requires the ability to explain why the AI&nbsp;rejected certain alternatives in its decision-making process. As far as I know, little has been done on this latter question, though the ability to expose other alternatives <a href=\"http://radar.oreilly.com/2011/02/watson-machine-learning.html\" rel=\"noreferrer noopener\" target=\"_blank\">could be important in applications like medical diagnosis</a>. “What solutions did you reject, and why did you reject them?” seems like important information we should be able to get from an AI, whether or not it’s “general.”</p>\\n\\n\\n\\n<p>An AI that can answer those questions seems more relevant than an AI that can simply do a lot of different things.</p>\\n\\n\\n\\n<p>Optimizing the specialization process is crucial because we’ve turned a technology question into an economic question. How many specialized models, like Copilot or O’Reilly Answers, can the world support? We’re no longer talking about a massive AGI that takes terawatt-hours to train, but about specialized training for a huge number of smaller models. A psychotherapy bot might be able to pay for itself–even though it would need the ability to retrain itself on current events, for example, to deal with patients who are anxious about, say, the invasion of Ukraine. (There is <a href=\"https://arxiv.org/pdf/2106.06297.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">ongoing research</a> on models that can incorporate new information as needed.) It’s not clear that a specialized bot for producing news articles about religious institutions would be economically viable. That’s the third question we need to answer about the future of AI: what kinds of economic models will work? Since AI models are essentially cobbling together answers from other sources that have their own licenses and business models, how will our future agents compensate the sources from which their content is derived? How should these models deal with issues like attribution and license compliance?</p>\\n\\n\\n\\n<p>Finally, projects like Gato don’t help us understand how AI systems should collaborate with humans. Rather than just building bigger models, researchers and entrepreneurs need to be exploring different kinds of interaction between humans and AI. That question is out of scope for Gato, but it is something we need to address regardless of whether the future of artificial intelligence is general or narrow but deep. Most of our current AI systems are oracles: you give them a prompt, they produce an output.&nbsp; Correct or incorrect, you get what you get, take it or leave it. Oracle interactions don’t take advantage of human expertise, and risk wasting human time on “obvious” answers, where the human says “I already know that; I don’t need an AI to tell me.”</p>\\n\\n\\n\\n<p>There are some exceptions to the oracle model. Copilot places its suggestion in your code editor, and changes you make can be fed back into the engine to improve future suggestions. <a href=\"https://boingboing.net/2022/03/24/midjourney-sharpens-style-of-ai-art.html\" rel=\"noreferrer noopener\" target=\"_blank\">Midjourney</a>, a platform for AI-generated art that is currently in closed beta, also incorporates a feedback loop.</p>\\n\\n\\n\\n<p>In the next few years, we will inevitably rely more and more on machine learning and artificial intelligence. If that interaction is going to be productive, we will need a lot from AI. We will need interactions between humans and machines, a better understanding of how to train specialized models, the ability to distinguish between correlations and facts–and that’s only a start. Products like Copilot and O’Reilly Answers give a glimpse of what’s possible, but they’re only the first steps. AI has made dramatic progress in the last decade, but we won’t get the products we want and need merely by scaling.&nbsp;We need to learn to think differently.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/closer-to-agi/feed/', 'slash_comments': '0'}, {'title': 'Radar Trends to Watch: June 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: June 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/#respond', 'published': 'Wed, 01 Jun 2022 11:54:59 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=6, tm_mday=1, tm_hour=11, tm_min=54, tm_sec=59, tm_wday=2, tm_yday=152, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14510', 'guidislink': False, 'summary': 'The explosion of large models continues.&#160;Several developments are especially noteworthy. DeepMind’s Gato model is unique in that it’s a single model that’s trained for over 600 different tasks; whether or not it’s a step towards general intelligence (the ensuing debate may be more important than the model itself), it’s an impressive achievement. Google Brain’s Imagen [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The explosion of large models continues.&#160;Several developments are especially noteworthy. DeepMind’s Gato model is unique in that it’s a single model that’s trained for over 600 different tasks; whether or not it’s a step towards general intelligence (the ensuing debate may be more important than the model itself), it’s an impressive achievement. Google Brain’s Imagen [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>The explosion of large models continues.&nbsp;Several developments are especially noteworthy. DeepMind’s Gato model is unique in that it’s a single model that’s trained for over 600 different tasks; whether or not it’s a step towards general intelligence (the ensuing debate may be more important than the model itself), it’s an impressive achievement. Google Brain’s Imagen creates photorealistic images that are impressive, even after you’ve seen what DALL-E 2 can do. And Allen AI’s Macaw (surely an allusion to Emily Bender and Timnit Gebru’s <a href=\"https://dl.acm.org/doi/10.1145/3442188.3445922\">Stochastic Parrots</a> paper) is open source, one tenth the size of GPT-3, and claims to be more accurate. Facebook/Meta is also releasing an open source large language model, including the model’s training log, which records in detail the work required to train it.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li>Is thinking of autonomous vehicles as AI systems rather than as robots the next step forward? <a href=\"https://www.technologyreview.com/2022/05/27/1052826/ai-reinforcement-learning-self-driving-cars-autonomous-vehicles-wayve-waabi-cruise/\" rel=\"noreferrer noopener\" target=\"_blank\">A new wave of startups is trying techniques such as reinforcement learning</a> to train AVs to drive safely.</li><li><a href=\"https://yoshuabengio.org/2022/03/05/generative-flow-networks/\" rel=\"noreferrer noopener\" target=\"_blank\">Generative Flow Networks</a> may be the next major step in building better AI systems.</li><li>The <a href=\"https://thenextweb.com/news/openai-punished-dev-used-gpt-3-to-resurrect-dead-ethics\" rel=\"noreferrer noopener\" target=\"_blank\">ethics of building AI bots that mimic real dead people</a> seems like an academic question, until someone does it: using GPT-3, a developer created a bot based on his deceased fiancée. OpenAI objected, stating that building such a bot was a violation of its terms of service.</li><li>Cortical Labs and other startups are building computers that <a href=\"https://theconversation.com/tech-firms-are-making-computer-chips-with-human-cells-is-it-ethical-183394\" rel=\"noreferrer noopener\" target=\"_blank\">incorporate human neurons</a>.&nbsp;It’s claimed that these systems can be trained to perform game-playing tasks significantly faster than traditional AI.</li><li>Google Brain has built a new text-to-image generator called <a href=\"https://imagen.research.google/\" rel=\"noreferrer noopener\" target=\"_blank\">Imagen</a> that <a href=\"https://www.theverge.com/2022/5/24/23139297/google-imagen-text-to-image-ai-system-examples-paper\" rel=\"noreferrer noopener\" target=\"_blank\">creates photorealistic images</a>. Although images generated by projects like this are always cherry-picked, the image quality is impressive; the developers claim that it is better than DALL-E 2.</li><li>DeepMind has created a new “generalist” model called <a href=\"https://www.deepmind.com/publications/a-generalist-agent\" rel=\"noreferrer noopener\" target=\"_blank\">Gato</a>. It is a single model that can solve many different kinds of tasks: playing multiple games, labeling images, and so on. It has prompted a <a href=\"https://twitter.com/NandoDF/status/1525397036325019649?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1525397036325019649%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fthenextweb.com%2Fnews%2Fdeepmind-researcher-claims-new-gato-ai-could-lead-to-agi-says-game-is-over\">debate</a><a href=\"https://twitter.com/ylecun/status/1526672565233758213?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1526672787187941376%7Ctwgr%5E%7Ctwcon%5Es2_&amp;ref_url=http%3A%2F%2Fnew-savanna.blogspot.com%2F2022%2F05%2Fwhere-we-are-now-no-such-thing-as-agi.html\"> </a><a href=\"https://twitter.com/ylecun/status/1526672565233758213?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1526672787187941376%7Ctwgr%5E%7Ctwcon%5Es2_&amp;ref_url=http%3A%2F%2Fnew-savanna.blogspot.com%2F2022%2F05%2Fwhere-we-are-now-no-such-thing-as-agi.html\" rel=\"noreferrer noopener\" target=\"_blank\">on whether</a> Artificial General Intelligence is simply a matter of scale.</li><li>AI in autonomous vehicles can be used to <a href=\"https://techxplore.com/news/2022-05-artificial-intelligence-autonomous-vehicles-idling.html\" rel=\"noreferrer noopener\" target=\"_blank\">eliminate waiting at traffic lights</a>, increase travel speed, and reduce fuel consumption and carbon emissions. Surprisingly, if only 25% of the vehicles are autonomous, you get 50% of the benefit.</li><li><a href=\"https://github.com/allenai/macaw\" rel=\"noreferrer noopener\" target=\"_blank\">Macaw</a> is a language model developed by Allen AI (<a href=\"https://allenai.org/\" rel=\"noreferrer noopener\" target=\"_blank\">AI2</a>). It is freely available and open-source. <a href=\"https://blog.allenai.org/general-purpose-question-answering-with-macaw-84cd7e3af0f7\" rel=\"noreferrer noopener\" target=\"_blank\">Macaw is 1/10th the size of GPT-3</a> and roughly 10% more accurate at answering questions, though (like GPT-3) it tends to fail at questions that require common sense or involve logical tricks.</li><li><a href=\"https://theconversation.com/is-ai-generated-art-really-creative-it-depends-on-the-presentation-181663\" rel=\"noreferrer noopener\" target=\"_blank\">Ai-da is an AI-driven robot that can paint portraits</a>–but is it art? Art is as much about human perception as it is about creation. What social cues prompt us to think that a robot is being creative?</li><li>Facebook/Meta has created a large language model called <a href=\"https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/\" rel=\"noreferrer noopener\" target=\"_blank\">OPT</a> that is similar in size and performance to GPT-3. Using the model is free for non-commercial work; the code is being released open source, along with documents describing how the model was trained.</li><li><a href=\"https://github.com/project-alice-assistant/ProjectAlice\" rel=\"noreferrer noopener\" target=\"_blank\">Alice</a> is a modular and extensible open source virtual assistant (think Alexa) that can run completely offline. It is private by default, though it can be configured to use Amazon or Google as backups. Alice can identify different users (for whom it can develop “likes” or “dislikes,” based on interactions).</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li><a href=\"https://thenewstack.io/nosql-nomq-palo-alto-networks-new-event-streaming-paradigm/\" rel=\"noreferrer noopener\" target=\"_blank\">High volume event streaming without a message queue</a>: Palo Alto Networks has built a system for processing terabytes of security events per day without using a message queue, just a NoSQL database.</li><li>New tools allow <a href=\"https://medium.com/short-bits/layer-a-new-tool-for-spreadsheet-management-6f45278c1cf7\" rel=\"noreferrer noopener\" target=\"_blank\">workflow management across groups of spreadsheets</a>. Spreadsheets are the original “low code”; these tools seem to offer spreadsheet users many of the features that software developers get from tools like git.</li><li><a href=\"https://www.portainer.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Portainer</a> is a container management tool that lets you <a href=\"https://thenewstack.io/how-to-create-and-use-container-volumes-within-portainer/\" rel=\"noreferrer noopener\" target=\"_blank\">mount Docker containers as persistent filesystems</a>.</li><li><a href=\"https://www.bleepingcomputer.com/news/linux/nvidia-has-open-sourced-its-linux-gpu-kernel-drivers/\" rel=\"noreferrer noopener\" target=\"_blank\">NVIDIA has open-sourced its Linux device drivers</a>. The code is <a href=\"https://github.com/NVIDIA/open-gpu-kernel-modules\" rel=\"noreferrer noopener\" target=\"_blank\">available</a> on GitHub. This is a significant change for a company that historically has avoided open source.</li><li>A startup named Buoyant is building tools to <a href=\"https://thenewstack.io/buoyant-wants-to-make-linkerd-easier-to-use-and-manage/\" rel=\"noreferrer noopener\" target=\"_blank\">automate management of Linkerd</a>. <a href=\"https://linkerd.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Linkerd</a>, in turn, is a service mesh that is easier to manage and more appropriate for small to medium businesses, than Istio.</li><li>Are we entering the “third age of JavaScript”? An intriguing <a href=\"https://thenewstack.io/the-third-age-of-javascript-an-update-from-reactathon/\" rel=\"noreferrer noopener\" target=\"_blank\">article</a> suggests that we are. In this view of the future, static site generation disappears, incremental rendering and edge routing become more important, and Next.js becomes a dominant platform.</li><li><a href=\"https://github.com/rowyio/rowy\" rel=\"noreferrer noopener\" target=\"_blank\">Rowy</a> is a low-code programming environment that intends to <a href=\"https://thenewstack.io/rowy-takes-on-the-limits-of-airtable-with-low-code-cloud-collaboration/\" rel=\"noreferrer noopener\" target=\"_blank\">escape the limitations of Airtable</a> and other low-code collaboration services. The interface is like a spreadsheet, but it’s built on top of the Google Cloud Firestore document database.</li><li><a href=\"https://www.anaconda.com/blog/pyscript-python-in-the-browser\" rel=\"noreferrer noopener\" target=\"_blank\">PyScript</a> is framework for running Python in the browser, mixed with HTML (in some ways, not unlike PHP). It is based on Pyodide (a WASM implementation of Python), integrates well with JavaScript, and might support other languages in the future.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Machine learning raises the possibility of <a href=\"https://thenextweb.com/news/machine-learning-has-an-alarming-threat-undetectable-backdoors\" rel=\"noreferrer noopener\" target=\"_blank\">undetectable backdoor attacks</a>, malicious attacks that can affect the output of a model but don’t measurably detect its performance. Security issues for machine learning aren’t well understood, and aren’t getting a lot of attention.</li><li>In a <a href=\"https://www.bleepingcomputer.com/news/security/popular-python-and-php-libraries-hijacked-to-steal-aws-keys/\" rel=\"noreferrer noopener\" target=\"_blank\">new supply chain attack</a>, two widely used libraries (Python’s ctx and PHP’s PHPass) have been compromised to steal AWS credentials. The attacker now claims that these exploits were “<a href=\"https://www.bleepingcomputer.com/news/security/hacker-says-hijacking-libraries-stealing-aws-keys-was-ethical-research/\" rel=\"noreferrer noopener\" target=\"_blank\">ethical research</a>,” possibly with the goal of winning bounties for reporting exploits.</li><li>While it is not yet accurate enough to work in practice, a <a href=\"https://techxplore.com/news/2022-05-method-cyberattacks.html\" rel=\"noreferrer noopener\" target=\"_blank\">new method for detecting cyber attacks</a> can detect and stop attacks in under one second.</li><li>The <a href=\"https://www.bleepingcomputer.com/news/security/eternity-malware-kit-offers-stealer-miner-worm-ransomware-tools/\" rel=\"noreferrer noopener\" target=\"_blank\">Eternity Project</a> is a new malware-as-a-service organization that offers many different kinds of tools for data theft, ransomware, and many other exploits. It’s possible that the project is itself a scam, but it appears to be genuine.</li><li>Palo Alto Networks has published a <a href=\"https://unit42.paloaltonetworks.com/iam-cloud-threat-research/\" rel=\"noreferrer noopener\" target=\"_blank\">study</a> showing that <a href=\"https://thenewstack.io/unused-credentials-key-culprits-in-cloud-attacks-study-says/\" rel=\"noreferrer noopener\" target=\"_blank\">most cloud identity and access management policies are too permissive</a>, and that 90% of the permissions granted are never used. Overly-permissive policies are a major vulnerability for cloud users.</li><li>NIST has just published a massive guide to <a href=\"https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-161r1.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">supply chain security</a>. For organizations that can’t digest this 326-page document, they plan to publish a quick-start guide.</li><li>The <a href=\"https://arstechnica.com/gadgets/2022/05/apple-google-and-microsoft-want-bluetooth-proximity-to-replace-the-password/\" rel=\"noreferrer noopener\" target=\"_blank\">Passkey</a> standard, supported by Google, Apple, and Microsoft, replaces passwords with other forms of authentication. An application makes an authentication request to the device, which can then respond using any authentication method it supports. Passkey is operating system-independent, and supports both Bluetooth in addition to Internet protocols.</li><li>Google and Mandiant both report significant year-over-year increases in the <a href=\"https://www.schneier.com/blog/archives/2022/04/zero-day-vulnerabilities-are-on-the-rise.html\" rel=\"noreferrer noopener\" target=\"_blank\">number of 0-day vulnerabilities</a> discovered in 2021.</li><li>Interesting <a href=\"https://www.bleepingcomputer.com/news/security/ransom-payment-is-roughly-15-percent-of-the-total-cost-of-ransomware-attacks/\" rel=\"noreferrer noopener\" target=\"_blank\">statistics about ransomware</a> attacks: The ransom is usually only 15% of the total cost of the attack; and on average, the ransom is 2.8% of net revenue (with discounts of up to 25% for prompt payment).</li><li><a href=\"https://www.bleepingcomputer.com/news/security/conti-revil-lockbit-ransomware-bugs-exploited-to-block-encryption/\" rel=\"noreferrer noopener\" target=\"_blank\">Bugs in the most widely used ransomware software</a>, including REvil and Conti, can be used to prevent the attacker from encrypting your data.</li></ul>\\n\\n\\n\\n<h2>Web and Web3</h2>\\n\\n\\n\\n<ul><li>DeviantArt is allowing anyone to use its tool to <a href=\"https://www.deviantartprotect.com/\" rel=\"noreferrer noopener\" target=\"_blank\">detect NFTs that are created without the artist’s permission</a>.</li><li>A <a href=\"https://www.vice.com/en/article/akvmke/facebook-doesnt-know-what-it-does-with-your-data-or-where-it-goes\" rel=\"noreferrer noopener\" target=\"_blank\">leaked Facebook document obtained by Motherboard</a> reveals that they do not have an “adequate level of control” over data use, and thus “can’t confidently make controlled policy changes … such as ‘we will not use X data for Y purpose.’” A lack of data governance and lineage makes it impossible to comply with regulation, both current and forthcoming.</li></ul>\\n\\n\\n\\n<h2>VR/AR/Metaverse</h2>\\n\\n\\n\\n<ul><li>Niantic is building VPS (Visual Positioning System), an <a href=\"https://www.theverge.com/2022/5/24/23138313/niantic-lightship-augmented-reality-ar-platform-social-network-gaming\" rel=\"noreferrer noopener\" target=\"_blank\">augmented reality map of the world</a>, as part of its Lightship platform. VPS allows games and other AR products to be grounded to the physical world.</li><li><a href=\"https://livingcities.xyz/\" rel=\"noreferrer noopener\" target=\"_blank\">LivingCities</a> is building a <a href=\"https://medium.com/@mattmiesnieks/reality-is-scarce-68be119dace2\" rel=\"noreferrer noopener\" target=\"_blank\">digital twin of the real world</a> as a platform for experiencing the world in extended reality. That experience includes history, a place’s textures and feelings, and, of course, a new kind of social media.</li><li><a href=\"https://techxplore.com/news/2022-05-haptics-device-realistic-virtual-textures.html\" rel=\"noreferrer noopener\" target=\"_blank\">New research in haptics</a> allows the creation of realistic virtual textures by measuring how people feel things.&nbsp;Humans are extremely sensitive to the textures of materials, so creating good textures is important for everything from video games to telesurgery.</li><li><a href=\"https://techxplore.com/news/2022-05-google-remaking-tiktok.html\" rel=\"noreferrer noopener\" target=\"_blank\">Google is upgrading its search engine for augmented reality</a>: they are integrating images more fully into searches, creating multi-modal searches that incorporate images, text, and audio, and generating search results that can be explored through AR.</li><li><a href=\"https://thenewstack.io/babylon-js-hints-that-microsoft-metaverse-will-be-web-based/\" rel=\"noreferrer noopener\" target=\"_blank\">BabylonJS</a> is an open source 3D engine, based on WebGL and WebGPU, that Microsoft developed. It is a strong hint that Microsoft’s version of the Metaverse will be web-based. It will support WebXR.</li><li>The <a href=\"https://thenewstack.io/the-fediverse-points-to-our-social-media-future-post-musk/\" rel=\"noreferrer noopener\" target=\"_blank\">fediverse</a> is an ensemble of microblogging social media sites (such as Mastodon) that communicate with each other.&nbsp;Will they become a viable alternative to Elon Musk’s Twitter?</li><li><a href=\"https://varjo.com/blog/varjo-teleportation/\" rel=\"noreferrer noopener\" target=\"_blank\">Varjo</a> is building a “reality cloud”: a 3D mixed reality streaming service that allows photorealistic “virtual teleportation.” It’s not about weird avatars in a fake 3D world; they record your actions in your actual environment.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li><a href=\"https://techxplore.com/news/2022-05-smart-human-machine-interaction.html\" rel=\"noreferrer noopener\" target=\"_blank\">“Smart films</a>” could allow developers to build interactive touch interfaces into screens, objects, and even clothing.</li><li>Fairphone is a <a href=\"https://thenextweb.com/news/fairphone-sustainable-phone-repair-modules-interview\" rel=\"noreferrer noopener\" target=\"_blank\">cell phone that is designed to last for years</a> and be easily repairable. Three quarters of the CO2 emissions associated with the lifecycle of a device come from manufacturing; increasing device longevity is a key to sustainability.</li><li>An extremely lightweight drone that is <a href=\"https://techxplore.com/news/2022-05-tiny-drone-based-maple-seed.html\" rel=\"noreferrer noopener\" target=\"_blank\">based on the maple tree’s seeds</a> weighs under 100 grams and can hover for 40 minutes. The drone is capable of carrying small payloads.</li><li><a href=\"https://thenextweb.com/news/drones-can-help-reforest-reseed-fight-dengue-fever\" rel=\"noreferrer noopener\" target=\"_blank\">Seed-firing drones can help fight deforestation</a>. They drop seed pods that are complete packages including the water and minerals the seeds need to survive. The drones can monitor the success of the areas that they’ve replanted.</li><li>Researchers have developed an optoelectronic system for <a href=\"https://theconversation.com/weve-created-a-device-that-could-allow-instant-disease-diagnosis-while-fitting-inside-your-phone-lens-181342\" rel=\"noreferrer noopener\" target=\"_blank\">diagnosing disease that could be integrated into a cell phone lens</a>.</li><li><a href=\"https://techcrunch.com/2022/04/28/snap-announces-a-mini-drone-called-pixy/\" rel=\"noreferrer noopener\" target=\"_blank\">Pixy</a> is a small drone that follows you around, taking video for posting to Snapchat.</li></ul>\\n\\n\\n\\n<h2>Design</h2>\\n\\n\\n\\n<ul><li>Ethical design starts with a <a href=\"https://alistapart.com/article/redefine-success-first/\" rel=\"noreferrer noopener\" target=\"_blank\">redefinition of success</a>: well-being, equity, and sustainability, with good metrics for measuring your progress.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li>QICK is a new <a href=\"https://arxiv.org/abs/2110.00557\" rel=\"noreferrer noopener\" target=\"_blank\">standardized control plane</a> for quantum devices. The design of the control plane, including software, is all open source. A large part of the cost of building a quantum device is building the electronics to control it. QICK will greatly reduce the cost of quantum experimentation.</li><li>Researchers have built <a href=\"https://phys.org/news/2022-05-error-free-quantum-real.html\" rel=\"noreferrer noopener\" target=\"_blank\">logical gates using error-corrected quantum bits</a>. This is a significant step towards building a useful quantum computer. </li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/feed/', 'slash_comments': '0'}, {'title': 'Building a Better Middleman', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Building a Better Middleman'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/building-a-better-middleman-2/'}], 'link': 'https://www.oreilly.com/radar/building-a-better-middleman-2/', 'comments': 'https://www.oreilly.com/radar/building-a-better-middleman-2/#respond', 'published': 'Tue, 17 May 2022 10:58:32 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=5, tm_mday=17, tm_hour=10, tm_min=58, tm_sec=32, tm_wday=1, tm_yday=137, tm_isdst=0), 'authors': [{'name': 'Q McCallum'}], 'author': 'Q McCallum', 'author_detail': {'name': 'Q McCallum'}, 'tags': [{'term': 'Operations', 'scheme': None, 'label': None}, {'term': 'Deep Dive', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14497', 'guidislink': False, 'summary': 'In the previous article, I explored the role of the middleman in a two-sided marketplace.&#160; The term &#8220;middleman&#8221; has a stigma to it. Mostly because, when you sit between two parties that want to interact, it&#8217;s easy to get greedy. Greed will bring you profits in the short term. Probably in the long term, as [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'In the previous article, I explored the role of the middleman in a two-sided marketplace.&#160; The term &#8220;middleman&#8221; has a stigma to it. Mostly because, when you sit between two parties that want to interact, it&#8217;s easy to get greedy. Greed will bring you profits in the short term. Probably in the long term, as [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>In <a href=\"https://www.oreilly.com/radar/building-a-better-middleman/\" rel=\"noreferrer noopener\" target=\"_blank\">the previous article</a>, I explored the role of the middleman in a two-sided marketplace.&nbsp; The term &#8220;middleman&#8221; has a stigma to it. Mostly because, when you sit between two parties that want to interact, it&#8217;s easy to get greedy.</p>\\n\\n\\n\\n<p>Greed will bring you profits in the short term. Probably in the long term, as well.&nbsp; As a middleman, though, your greed is an existential threat.&nbsp; When you abuse your position and mistreat the parties you connect–when your cost outweighs your value–they&#8217;ll find a way to replace you. Maybe not today, maybe not tomorrow, but it will happen.</p>\\n\\n\\n\\n<p>Luckily, you can make money as a middleman and still keep everyone happy.&nbsp; Here&#8217;s how to create that win-win-win triangle:</p>\\n\\n\\n\\n<h3>Keep refining your platform</h3>\\n\\n\\n\\n<p>Running a marketplace is a game of continuous improvement. You need to keep asking yourself: <em>how can I make this better for the people who interact through the marketplace?</em></p>\\n\\n\\n\\n<p>To start, you can look for ways to make your platform more attractive to existing customers. I emphasize <em>both</em> customers, not just one side of the marketplace. Mistreating one side to favor the other may work for a time, but it will eventually fall through. Frustration has a way of helping people overcome switching costs.</p>\\n\\n\\n\\n<p>Some stock exchanges designate <em>market makers</em> (&#8220;specialists,&#8221; if you&#8217;re old-school)<em>,</em> firms that are always ready to both buy and sell shares of a given stock. If I want to offload a thousand shares and there&#8217;s no one who wants to buy them from me, the market maker steps in to play the role of the buyer. By guaranteeing that there will always be <em>someone</em> on the other side of the bid or ask, exchanges keep everyone happy.</p>\\n\\n\\n\\n<p>If you constantly review how the two parties interact, you can look for opportunities to mitigate their risk, create new services, or otherwise reduce friction. Most platforms connect strangers, right?&nbsp; So if you look at your business through the lens of safety, you&#8217;ll find a lot of work to do. Note how eBay&#8217;s review system provides extra assurance for buyers and sellers to trade with people they&#8217;ve never met.&nbsp; Similarly, in the early days of online commerce, credit card issuers limited shoppers&#8217; fraud risk to just $50 per purchase.&nbsp; This improved consumers&#8217; trust in online shopping, which helped make e-commerce the everyday norm that it is today.</p>\\n\\n\\n\\n<p>Safety improvements also extend to communications. Do the parties really <em>need</em> to swap e-mail addresses or phone numbers?&nbsp; If they&#8217;re just confirming a rideshare pickup or flirting through a dating app, probably not.&nbsp; As a middleman, you are perfectly positioned to serve as the conduit;&nbsp; one that provides an appropriate level of masking or pseudonymity.&nbsp; And the money you invest in deploying a custom messaging system or temporary phone numbers (Twilio, anyone?) will pay off in terms of improved adoption and retention.</p>\\n\\n\\n\\n<h3>Design new products and services</h3>\\n\\n\\n\\n<p>If you understand how your parties interact and what they want to achieve, you&#8217;re in a position to spot new product opportunities that will make your customers happy.</p>\\n\\n\\n\\n<p>From a conversation with Cyril Nigg, Director of Analytics at Reverb, the music-gear marketplace was &#8220;founded by music makers, for music makers.&#8221;&nbsp; Musicians like to try new gear, but they want to offload it if it doesn&#8217;t pan out. Reverb has therefore built tools around pricing assistance to help musicians with their product listings: <em>You want to sell this distortion pedal within 7 days? List it as $X.</em> This extra assurance that they&#8217;ll be able to resell a piece of equipment, in short order, reduces apprehensions about buying. (Going back to the point about keeping both sides of the marketplace happy: Cyril also pointed out that a Reverb customer may act as both buyer and seller across different transactions.&nbsp; That means the company can&#8217;t skimp on one side of the experience.)</p>\\n\\n\\n\\n<p>People on a dating site want to communicate, so an easy win there is to keep an eye on new communications tools. Maybe your platform started out with an asynchronous, text-based tool that resembled e-mail.&nbsp; Can you add an option for real-time chat?&nbsp; What would it take to move up to voice? And ultimately, video? Each step in the progression requires advances in technology, so you may have to wait before you can actually deploy something. But if you can envision the system you want, you can keep an eye on the tech and be poised to pounce when it is generally available.</p>\\n\\n\\n\\n<p>Unlike dating sites, financial exchanges are marketplaces for opposing views. One person thinks that some event will happen, they seek a counterpart who thinks that it will not, and fate determines the winner.&nbsp; This can be as vanilla as people buying or selling shares of stock, where the counterparties believe the share price will rise or fall, respectively.&nbsp; You also see situations that call for more exotic tools.&nbsp; In the lead-up to what would become the 2008 financial crisis, investors wanted to stake claims around mortgage-backed securities but there wasn&#8217;t a way to express the belief that those prices would fall. In response to this desire, a group of banks dusted off the credit default swap (CDS) concept and devised a standard, easily-tradable contract.&nbsp; Now there was a way for people to take either side of the trade, and for the banks to collect fees in the middle.&nbsp; A win-win-win situation.</p>\\n\\n\\n\\n<p>(Well, the actual <em>trade</em> was a win-win-win. The long-term <em>outcome</em> was more of a lose-lose-win. Mortgage defaults rose, sending prices for the associated mortgage-backed securities into decline, leading to big payouts for the &#8220;I told you this was going to happen&#8221; side of each CDS contract. The banks that served double-duty as both market participant <em>and</em> middleman took on sizable losses as a result. Let this be a lesson to you: part of why a middleman makes money is precisely because they have no stake in the long-term outcome of putting the parties together. Stay in the middle if you want to play it safe.)</p>\\n\\n\\n\\n<p>Granted, you don&#8217;t have to roll out every possible product or feature on your first day. You have to let the marketplace grow and mature somewhat, to see what will actually be useful. Still, you want to plan ahead. As you watch the marketplace, you will spot opportunities well in advance, so you can position yourself to implement them before the need is urgent.</p>\\n\\n\\n\\n<h3>Focus on your business</h3>\\n\\n\\n\\n<p>Besides making things easier for customers, being a better middleman means improving how your business runs.</p>\\n\\n\\n\\n<p>To start, identify and eliminate inefficiencies in your operations.&nbsp;I don&#8217;t mean that you should cut corners, as that will come back to bite you later.&nbsp; I mean that you can check for genuine money leaks. The easy candidates will be right there on your balance sheet: have you actually used Service ABC in the last year?&nbsp; If not, maybe it&#8217;s time to cut it. Is there an equivalent to Service XYZ at a lower price? Once you&#8217;ve confirmed that the cheaper service is indeed a suitable replacement, it&#8217;s time to make the switch.</p>\\n\\n\\n\\n<p>A more subtle candidate is your codebase.&nbsp;Custom code is a weird form of debt. It requires steady, ongoing maintenance just like payments in a loan. It may also require disruptive changes if you encounter a bug. (Imagine that your mortgage lender occasionally demanded a surprise lump sum in mid-month.) Can you replace that home-grown system with an off-the-shelf tool or a third-party service, for a cheaper and more predictable payment schedule?</p>\\n\\n\\n\\n<p>You also want to check on the size of your total addressable market (TAM).&nbsp; What happens when you&#8217;ve reached everyone who will ever join? It&#8217;s emotionally reassuring to tell yourself that the entire planet will use your service, sure.&nbsp;But do you really want to base revenue projections on customers you can&#8217;t realistically acquire or retain? At some point, your customer numbers will plateau (and, after that, sink). You need to have a difficult conversation with yourself, your leadership team, and your investors around how you&#8217;ll handle that. And you need to have that conversation well in advance. Once you hit that limit on your TAM, you&#8217;ll need to be ready to deliver improvements that reduce churn.&nbsp;Perhaps you can offer new services, which may extend your addressable market into new territory, but even that has its limits.</p>\\n\\n\\n\\n<p>What are you doing for risk management?&nbsp;A risk represents a possible future entry on your balance sheet, one of indeterminate size. Maybe it&#8217;s a code bug that spirals out of control under an edge case.&nbsp;Or a lingering complaint that blossoms into a full-scale PR issue. To be blunt: good risk management will save you money. Possibly lots of money.&nbsp;While it&#8217;s tempting to let some potential problems linger, understand that it&#8217;s easier and cheaper to address them early and on your own schedule.&nbsp;That&#8217;s much nicer than being under pressure to fix a surprise in real-time.</p>\\n\\n\\n\\n<p>Sharp-eyed readers will catch that subtle tradeoff between &#8220;addressing inefficiencies&#8221; and &#8220;proactively mitigating risks.&#8221;&nbsp;Risk management often requires that you leave extra slack in the system, such as higher staff headcount, or extra machines that mostly sit idle.&nbsp;This slack serves as a cushion in the event of a surge in customer activity but it also costs money.&nbsp; There&#8217;s no easy answer here. It&#8217;s a blend of art and science to spot the difference between slack and waste.</p>\\n\\n\\n\\n<p>Most of all, as a marketplace, you want to mature with your customers and the field overall. The term &#8220;innovate&#8221; gets some much-deserved flack, but it&#8217;s not complete hogwash. Be prepared to invest in research so you can see what changes are on the horizon, and then adapt accordingly. Also, keep an eye on the new features your customers are asking for, or the complaints they raise about your service.&nbsp;You&#8217;ll&nbsp; otherwise fall into the very trap described in <em>The Innovator&#8217;s Dilemma</em>. Don&#8217;t become the slow-moving, inattentive behemoth that some nimble upstart will work to unseat.</p>\\n\\n\\n\\n<h3>Use technology as a force multiplier</h3>\\n\\n\\n\\n<p>Bad middlemen squeeze the parties they connect; good middlemen squeeze technology.</p>\\n\\n\\n\\n<p>Done well, technology is a source of asymmetric advantage. Putting code in the right places allows you to accomplish more work, more consistently, with fewer people, and in less time. All of the efficiencies you get through code will leave more money to split between yourself and your customers.&nbsp; That is a solid retention strategy.</p>\\n\\n\\n\\n<p>To start, you can apply software to real and artificial scarcity that exists in other middlemen.&nbsp;A greenfield operation can start with lower headcount, less (or zero!) office space, and so on.</p>\\n\\n\\n\\n<p>Tech staffing, for example, is a matching problem at its core.&nbsp;A smart staffing firm would start with self-service search tools so a company could easily find people to match their open roles. No need to interact with a human recruiter. It could also standardize contract language to reduce legal overhead (no one wants a thousand slightly-different contracts laying around, anyway) and use electronic signatures to make it easier to store paperwork for future reference.</p>\\n\\n\\n\\n<p>You don&#8217;t even have to do anything fancy. Sometimes, the very act of putting something online is a huge step up from the incumbent solution. Craigslist, simply by running classified ads on a website, gave people a much-improved experience over the print-newspaper version. People had more space to write (goodbye, obscure acronyms), had search functionality (why skim all the listings to find what you&#8217;re after?), and could pull their ad when it had been resolved (no more getting phone calls for an extra week just because the print ad is still visible).</p>\\n\\n\\n\\n<p>Technology also makes it easier to manage resources. Love or loathe them, rideshare companies like Lyft and Uber can scale to a greater number of drivers and riders than the old-school taxi companies that rely on radio dispatch and flag-pulls. And they can do it with less friction. Why call a company and tell them your pickup location, when an app can use your phone&#8217;s GPS? And why should that dispatcher have to radio around in search of a driver? To arrange a ride, you need to match three elements–pickup location, dropoff location, and number of passengers–to an available driver. This is a trivial effort for a computer. Throw in mobile apps for drivers and passengers, and you have a system that can scale very well.</p>\\n\\n\\n\\n<p>(Some may argue that the rideshare companies get extra scale because their drivers are classified as independent contractors, and because they don&#8217;t require expensive taxi medallions. I don&#8217;t disagree. I just want to point out that the companies&#8217; technology is also a strong enabler.)</p>\\n\\n\\n\\n<p>Being at the center of the marketplace means you get to see the entire system at once. You can analyze the data around customer activity, and pass on insights to market participants to make their lives easier. Airbnb, for example, has deep insight into how different properties perform. Their research team determined that listings with high-quality photos tend to earn more revenue. They publicized this information to help hosts and, to sweeten the deal, the company then built a <a href=\"https://www.airbnb.com/d/pro-photography\" rel=\"noreferrer noopener\" target=\"_blank\">service to connect hosts with professional photographers</a>.</p>\\n\\n\\n\\n<p>What about ML/AI? While I hardly believe that it&#8217;s ready to eat <em>every</em> job, I do see <a href=\"https://qethanm.cc/2021/10/18/human-ai-interaction-exoskeletons-sidekicks-and-blinking-lights/\" rel=\"noreferrer noopener\" target=\"_blank\">opportunities for AI to make a smaller team of people more effective</a>.&nbsp;ML models are well-suited for decisions that are too fuzzy or cumbersome to be expressed as hard rules in software, but not so nuanced that they require human judgment.&nbsp;Putting AI in the seat for those decisions frees up your team for things that genuinely merit a human&#8217;s eyes and expertise.</p>\\n\\n\\n\\n<p>I&#8217;ve argued before that a lot of machine learning is high-powered matching. What is &#8220;classification,&#8221; if not rating one item&#8217;s similarity to an archetype?&nbsp; A marketplace that deals in the long tail of goods can use ML to help with that matching.</p>\\n\\n\\n\\n<p>Take Reverb, where most pieces of gear are unique but still similar to other items. They&#8217;re neither completely fungible, nor completely non-fungible.&nbsp; They&#8217;re sort of <em>semi-</em>fungible. To simplify search, then, Director of Analytics Cyril Nigg says that the company groups related items into ML-based <em>canonical products</em> (where some specific Product X is really part of a wider Canonical Product Y).&nbsp;&#8220;[We use] ML to match listings to a product–say, matching on title, price point, or some other attribute. This tells us, with a high degree of confidence, that a seller&#8217;s used Fender guitar is actually an American Standard Stratocaster. Now that we know the make and model, a buyer can easily compare all the different listings within that product to help them find the best option. This ML system learns over time, so that a seller can upload a listing and the system can file it under the proper canonical product.&#8221;</p>\\n\\n\\n\\n<p>Machine-based matching works for food as well as guitars. Resham Sarkar heads up data science at Slice, which gives local pizzerias the tools, technology and guidance they need to thrive. In a 2021 interview, she told me how her team applies ML to answer the age-old question: <em>will Person X enjoy Pizza Y at Restaurant Z?</em> Slice&#8217;s recommendations give eaters the confidence to try a new flavor in a new location, which helps them (maybe they&#8217;ll develop a new favorite) and also helps pizzerias (they get new customers).\\xa0This is especially useful when a pizza lover lands in a new city and doesn&#8217;t know where to get their fix.</p>\\n\\n\\n\\n<p>Any discussion of technology wouldn&#8217;t be complete without a nod to emerging tech. Yes, keeping up with the Shiny New Thing of the Moment means having to wade through plenty of hype. But if you look closely, you may also find some real game-changers for your business. This was certainly true of the 1990s internet boom. We&#8217;ve seen it in the past decade of what we now call AI, <a href=\"https://www.oreilly.com/radar/rebranding-data/\" rel=\"noreferrer noopener\" target=\"_blank\">across all of its rebrandings</a>. And yes, I expect that blockchain technologies will prove more useful than the curmudgeons want to let on.&nbsp; (Even NFTs. Or, <em>especially</em> NFTs.)</p>\\n\\n\\n\\n<p>Skip past the success stories and vendor pitches, though. Do your own homework on what the new technology really is and what it can do. Then, engage an expert to help you fill in the gaps and sort out what is possible with <em>your</em> business. The way a new technology addresses your challenges may not align with whatever is being hyped in the news, but who cares? All that matters is that it drives improvements for your use cases.</p>\\n\\n\\n\\n<h3>Watch your tech</h3>\\n\\n\\n\\n<p>Technology is a double-edged sword. It&#8217;s like using leverage in the stock market: employing software or AI exposes you to higher highs when things go right, but also lower lows when things unravel.</p>\\n\\n\\n\\n<p>One benefit to employing people to perform a task is that they can notice when something is wrong and then stop working. A piece of code, by comparison, has no idea that it is operating out of its depth. The same tools that let you do so much more, with far fewer people, also expose you to a sizable risk: one bug or environmental disconnect can trigger a series of errors, at machine speeds, cascading into a massive failure.</p>\\n\\n\\n\\n<p>All it takes is for a few smaller problems to collide. Consider the case of Knight Capital. This experienced, heavyweight market-maker once managed $21BN in daily transaction volume on the NYSE. One day in 2012, an inconsistent software deployment met a branch of old code, which in turn collided with a new order type on the exchange. This led to a <a href=\"https://www.henricodolfing.com/2019/06/project-failure-case-study-knight-capital.html\" rel=\"noreferrer noopener\" target=\"_blank\">meltdown</a> in which <a href=\"https://www.sec.gov/litigation/admin/2013/34-70694.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">Knight Capital lost $440M in under an hour</a>.</p>\\n\\n\\n\\n<p>The lesson here is that some of the money you save from reduced headcount should be reinvested in the company in the form of people and tools to keep an eye on the larger system. You&#8217;ll want to separate responsibilities in order to provide checks and balances, such as assigning someone who is not a developer to manage and review code deployments. Install monitors that provide fine-grained information about the state of your systems. Borrowing a line from a colleague: you can almost never have too many dimensions of data when troubleshooting.</p>\\n\\n\\n\\n<p>You&#8217;ll also need people to step in when someone gets caught in your web of automation. Have you ever called a company&#8217;s customer service line, only to wind up in a phone-tree dead-end? That can be very frustrating. You don&#8217;t want that for <em>your</em> customers, so you need to build escape hatches that route them to a person. That holds for your AI-driven chatbot as much as your self-help customer service workflows. And especially for any place where people can report a bug or an emergency situation.</p>\\n\\n\\n\\n<p>Most of all, this level of automation requires a high-caliber team. Don&#8217;t skimp on hiring. Pay a premium for very experienced people to build and manage your technology. If you can, hire someone who has built trading systems on Wall St.&nbsp;That culture is wired to identify and handle risk in complex, automated systems where there is a lot of real money at stake.&nbsp; And they have seen technology fail in ways that you cannot imagine.</p>\\n\\n\\n\\n<h3>Markets, everywhere</h3>\\n\\n\\n\\n<p>I&#8217;ve often said that problems in technology are rarely tech-related; they&#8217;re people-related.&nbsp;The same holds for building a marketplace, where the big problem is really human greed.</p>\\n\\n\\n\\n<p>Don&#8217;t fall for the greed trap. You can certainly run the business in a way that brings you revenue, keeps customers happy, and attracts new prospects. Identify inefficiencies in your business operations, and keep thinking of ways to make the platform better for your customers. That&#8217;s it.&nbsp; A proper application of software and AI, risk management, and research into emerging technologies should help you with both. And the money you save, you can split with your user base.</p>\\n\\n\\n\\n<p>If you&#8217;re willing to blur the lines a little, you will probably find markets in not-so-obvious places. An airline sits between passengers and destinations. Grocery stores sit between shoppers and suppliers. Employers sit between employees and clients. And so on. Once you find the right angle, you can borrow ideas from the established, well-run middlemen to improve your business.</p>\\n\\n\\n\\n<p>(Many thanks to <a href=\"https://www.oreilly.com/people/chris-butler/\" rel=\"noreferrer noopener\" target=\"_blank\">Chris Butler</a> for his thoughtful and insightful feedback on early drafts of this article.)</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/building-a-better-middleman-2/feed/', 'slash_comments': '0'}, {'title': 'Quantum Computing without the Hype', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Quantum Computing without the Hype'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/'}], 'link': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/', 'comments': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/#respond', 'published': 'Tue, 10 May 2022 11:45:05 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=5, tm_mday=10, tm_hour=11, tm_min=45, tm_sec=5, tm_wday=1, tm_yday=130, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Big Data Tools and Pipelines', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14492', 'guidislink': False, 'summary': 'Several weeks ago, I had a great conversation with Sebastian Hassinger about the state of quantum computing. It’s exciting–but also, not what a lot of people are expecting. I’ve seen articles in the trade press telling people to invest in quantum computing now or they’ll be hopelessly behind. That’s silly. There are too many people [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Several weeks ago, I had a great conversation with Sebastian Hassinger about the state of quantum computing. It’s exciting–but also, not what a lot of people are expecting. I’ve seen articles in the trade press telling people to invest in quantum computing now or they’ll be hopelessly behind. That’s silly. There are too many people [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>Several weeks ago, I had a great conversation with Sebastian Hassinger about the state of quantum computing. It’s exciting–but also, not what a lot of people are expecting.</p>\\n\\n\\n\\n<p>I’ve seen articles in the trade press telling people to invest in quantum computing now or they’ll be hopelessly behind. That’s silly. There are too many people in the world who think that a quantum computer is just a fast mainframe. It isn’t; quantum programming is completely different, and right now, the number of algorithms we know that will work on quantum computers is very small. You can count them on your fingers and toes. While it’s probably important to prepare for quantum computers that can decrypt current cryptographic codes, those computers won’t be around for 10-20 years. While there is still debate on how many physical qubits will be needed for error correction, and even on the meaning of a “logical” (error-corrected) qubit, the most common&nbsp; estimates are that it will require on the order of 1,000 error corrected qubits to break current encryption systems, and that it will take 1,000 physical qubits to make one error corrected qubit. So we’ll need an order of 1 million qubits, and current quantum computers are all in the area of 100 qubits. Figuring out how to scale our current quantum computers by 5 orders of magnitude may well be the biggest problem facing researchers, and there’s no solution in sight.</p>\\n\\n\\n\\n<p>So what can quantum computers do now that’s interesting? First, they are excellent tools for simulating quantum behavior: the behavior of subatomic particles and atoms that make up everything from semiconductors to bridges to proteins. Most, if not all, modeling in these areas is based on numerical methods–and modern digital computers are great at that. But it’s time to think again about non-numerical methods: can a quantum computer simulate directly what happens when two atoms interact? Can it figure out what kind of molecules will be formed, and what their shapes will be? This is the next step forward in quantum computing, and while it’s still research, It’s a significant way forward. We live in a quantum world. We can’t observe quantum behavior directly, but it’s what makes your laptop work and your bridges stay up. If we can model that behavior directly with quantum computers, rather than through numeric analysis, we’ll make a huge step forward towards finding new kinds of materials, new treatments for disease, and more. In a way, it’s like the difference between analog and digital computers. Any engineer knows that digital computers spend a lot of time finding approximate numeric solutions to complicated differential equations. But until digital computers got sufficiently large and fast, the behavior of those systems could be modeled directly on analog computers. Perhaps the earliest known examples of analog computers are <a href=\"https://en.wikipedia.org/wiki/Stonehenge\" rel=\"noreferrer noopener\" target=\"_blank\">Stonehenge</a> and the <a href=\"https://en.wikipedia.org/wiki/Antikythera_mechanism\" rel=\"noreferrer noopener\" target=\"_blank\">Antikythera mechanism</a>, both of which were used to predict astronomical positions. Thousands of years before digital computers existed, these analog computers modeled the behavior of the cosmos, solving equations that their makers couldn’t have understood–and that we now solve numerically on digital computers.</p>\\n\\n\\n\\n<p>Recently, researchers have developed a <a href=\"https://arxiv.org/abs/2110.00557\" rel=\"noreferrer noopener\" target=\"_blank\">standardized control plane</a> that should be able to work with all kinds of quantum devices. The design of the control plane, including software, is all open source. This should greatly decrease the cost of experimentation, allowing researchers to focus on the quantum devices themselves, instead of designing the circuitry needed to manage the qubits.&nbsp; It’s not unlike the dashboard of a car: relatively early in automotive history, we developed a fairly standard set of tools for displaying data and controlling the machinery.&nbsp; If we hadn’t, the development of automobiles would have been set back by decades: every automaker would need to design its own controls, and you’d need fairly extensive training on your specific car before you could drive it. <a href=\"https://en.wikipedia.org/wiki/Quantum_programming\" rel=\"noreferrer noopener\" target=\"_blank\">Programming languages for quantum devices</a> also need to standardize; fortunately, there has already been a lot of work in that direction.&nbsp; Open source development kits that provide libraries that can be called from Python to perform quantum operations (<a href=\"https://github.com/Qiskit\" rel=\"noreferrer noopener\" target=\"_blank\">Qiskit</a>, <a href=\"https://searchaws.techtarget.com/definition/Amazon-Braket\" rel=\"noreferrer noopener\" target=\"_blank\">Braket</a>, and <a href=\"https://quantumai.google/cirq\" rel=\"noreferrer noopener\" target=\"_blank\">Cirq</a> are some examples), and <a href=\"https://github.com/Qiskit/openqasm\" rel=\"noreferrer noopener\" target=\"_blank\">OpenQASM</a> is an open source “quantum assembly language” that lets programmers write (virtual) machine-level code that can be mapped to instructions on a physical machine.</p>\\n\\n\\n\\n<p>Another approach to simulating quantum behavior won’t help probe quantum behavior, but might help researchers to develop algorithms for numerical computing. <a href=\"https://arxiv.org/abs/1809.04028\" rel=\"noreferrer noopener\" target=\"_blank\">P-bits</a>, or probabilistic bits, behave probabilistically but don’t depend on quantum physics: they’re traditional electronics that work at room temperature. P-bits have some of the behavior of qubits, but they’re much easier to build; the developers call them “poor man’s qubits.” Will p-bits make it easier to develop a quantum future?&nbsp; Possibly.</p>\\n\\n\\n\\n<p>It’s important not to get over-excited about quantum computing. The best way to avoid a “trough of disillusionment” is to be realistic about your expectations in the first place. Most of what computers currently do will remain unchanged. There will be some breakthroughs in areas like cryptography, search, and a few other areas where we’ve developed algorithms. Right now, “preparing for quantum computing” means evaluating your cryptographic infrastructure. Given that infrastructure changes are difficult, expensive, and slow, it makes sense to prepare for quantum-safe cryptography now. (Quantum-safe cryptography is cryptography that can’t be broken by quantum computers–it does not require quantum computers.)&nbsp; Quantum computers may still be 20 years in the future, but infrastructure upgrades could easily take that long.</p>\\n\\n\\n\\n<p>Practical (numeric) quantum computing at significant scale could be 10 to 20 years away, but a few breakthroughs could shorten that time drastically.&nbsp; In the meantime, a lot of work still needs to be done on discovering quantum algorithms. And a lot of important work can already be done by using quantum computers as tools for investigating quantum behavior. It is an exciting time; it’s just important to be excited by the right things, and not misled by the hype.</p>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/quantum-computing-without-the-hype/feed/', 'slash_comments': '0'}, {'title': 'Radar trends to watch: May 2022', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar trends to watch: May 2022'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/'}], 'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/', 'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/#respond', 'published': 'Tue, 03 May 2022 11:19:02 +0000', 'published_parsed': time.struct_time(tm_year=2022, tm_mon=5, tm_mday=3, tm_hour=11, tm_min=19, tm_sec=2, tm_wday=1, tm_yday=123, tm_isdst=0), 'authors': [{'name': 'Mike Loukides'}], 'author': 'Mike Loukides', 'author_detail': {'name': 'Mike Loukides'}, 'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'id': 'https://www.oreilly.com/radar/?p=14482', 'guidislink': False, 'summary': 'April was the month for large language models. There was one announcement after another; most new models were larger than the previous ones, several claimed to be significantly more energy efficient. The largest (as far as we know) is Google’s GLAM, with 1.2 trillion parameters–but requiring significantly less energy to train than GPT-3. Chinchilla has [&#8230;]', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'April was the month for large language models. There was one announcement after another; most new models were larger than the previous ones, several claimed to be significantly more energy efficient. The largest (as far as we know) is Google’s GLAM, with 1.2 trillion parameters–but requiring significantly less energy to train than GPT-3. Chinchilla has [&#8230;]'}, 'content': [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>April was the month for large language models. There was one announcement after another; most new models were larger than the previous ones, several claimed to be significantly more energy efficient. The largest (as far as we know) is Google’s GLAM, with 1.2 trillion parameters–but requiring significantly less energy to train than GPT-3. Chinchilla has ¼ as many parameters as GPT-3, but claims to outperform it. It’s not clear where the race to bigger and bigger models will end, or where it will lead us. The PaLM model claims to be able to reason about cause and effect (in addition to being more efficient than other large models); we don’t yet have thinking machines (and we may never), but we’re getting closer. It’s also good to see that energy efficiency has become part of the conversation.</p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li>Google has created <a href=\"https://arxiv.org/abs/2112.06905\" rel=\"noreferrer noopener\" target=\"_blank\">GLAM</a> a 1.2 trillion parameter model (7 times the size of GPT-3).\\xa0 Training GLAM required <a href=\"https://info.deeplearning.ai/the-batch-recognizing-distracted-drivers-training-fighter-pilots-dominating-the-bridge-table-training-trillions-of-parameters\" rel=\"noreferrer noopener\" target=\"_blank\">456 megawatt-hours</a>,\\xa0 ⅓ the energy of GPT-3. GLAM uses a <a href=\"https://arxiv.org/abs/1701.06538\" rel=\"noreferrer noopener\" target=\"_blank\">Mixture-of-Experts</a> (MoE) model, in which different subsets of the neural network are used, depending on the input.</li><li>Google has released a <a href=\"https://arxiv.org/abs/2204.11918\" rel=\"noreferrer noopener\" target=\"_blank\">dataset of 3D-scanned household items</a>.\\xa0 This will be invaluable for anyone working on AI for virtual reality.</li><li>FOMO (Faster Objects, More Objects) is a <a href=\"https://thenextweb.com/news/fomo-tinyml-neural-network-object-detection\" rel=\"noreferrer noopener\" target=\"_blank\">machine learning model for object detection</a> in real time that requires less than 200KB of memory. It’s part of the TinyML movement: machine learning for small embedded systems.</li><li><a href=\"https://laion.ai/#about\" rel=\"noreferrer noopener\" target=\"_blank\">LAION</a> (Large Scale Artificial Intelligence Open Network) is a non-profit, free, and open organization that is creating large models and making them available to the public. It’s what OpenAI was supposed to be. The first model is a set of image-text pairs for training models similar to DALL-E.</li><li>NVidia is <a href=\"https://www.hpcwire.com/2022/04/18/nvidia-rd-chief-on-how-ai-is-improving-chip-design/\" rel=\"noreferrer noopener\" target=\"_blank\">using AI to automate the design of their latest GPU chips</a>.\\xa0 </li><li>Using <a href=\"https://techxplore.com/news/2022-04-ai-tool-efficiency-uk-sewer.html\" rel=\"noreferrer noopener\" target=\"_blank\">AI to inspect sewer pipes</a> is one example of an “unseen” AI application. It’s infrastructural, it doesn’t risk incorporating biases or significant ethical problems, and (if it works) it improves the quality of human life.</li><li>Large language models are generally based on text. Facebook is working on <a href=\"https://medium.com/product-ai/textless-nlp-the-future-of-speech-generation-31a6c713cb2d\" rel=\"noreferrer noopener\" target=\"_blank\">building a language model from spoken language</a>, which is a much more difficult problem.</li><li><a href=\"https://marhamilresearch4.blob.core.windows.net/stego-public/stego_paper.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">STEGO</a> is a new <a href=\"https://techxplore.com/news/2022-04-scientists-algorithm-assign-pixel-world.html\" rel=\"noreferrer noopener\" target=\"_blank\">algorithm for automatically labeling image data</a>. It uses transformers to understand relationships between objects, allowing it to segment and label objects without human input.</li><li>A researcher has developed a model for <a href=\"https://techxplore.com/news/2022-04-algorithm-opinions.html\" rel=\"noreferrer noopener\" target=\"_blank\">predicting first impressions and stereotypes</a>, based on a photograph.\\xa0 They’re careful to say that this model could easily be used to fine-tune fakes for maximum impact, and that “first impressions” don’t actually say anything about a person.</li><li>A group building <a href=\"https://www.technologyreview.com/2022/04/22/1050394/artificial-intelligence-for-the-people/\" rel=\"noreferrer noopener\" target=\"_blank\">language models for the Maori people</a> shows that AI for indigenous languages require different ways of thinking about artificial intelligence, data, and data rights.</li><li>A21 is a new company offering a <a href=\"https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1\" rel=\"noreferrer noopener\" target=\"_blank\">large language model “as a service.”</a> They allow customers to train custom versions of their model, and they claim to make humans and machines “thought partners.”</li><li>Researchers have found a method for <a href=\"https://techxplore.com/news/2022-04-method-bots-toxic-language.html\" rel=\"noreferrer noopener\" target=\"_blank\">reducing toxic text</a> generated by language models. It sounds like a GAN (generative adversarial network), in which a model trained to produce toxic text “plays against” a model being trained to detect and reject toxicity.</li><li>More bad applications of AI: companies are using AI to <a href=\"https://www.protocol.com/enterprise/emotion-ai-sales-virtual-zoom\" rel=\"noreferrer noopener\" target=\"_blank\">monitor your mood</a> during sales calls.\\xa0 This questionable feature will soon be coming to Zoom.</li><li><a href=\"http://primer.ai/\" rel=\"noreferrer noopener\" target=\"_blank\">Primer</a> has developed a tool that uses AI to <a href=\"https://www.wired.com/story/russia-ukraine-war-ai-surveillance/\" rel=\"noreferrer noopener\" target=\"_blank\">transcribe, translate, and analyze</a> intercepted communications in the war between Russia and Ukraine.</li><li>Deep Mind claims that another new large language model, <a href=\"https://www.marktechpost.com/2022/04/09/check-out-this-deepminds-new-language-model-chinchilla-70b-parameters-which-significantly-outperforms-gopher-280b-and-gpt-3-175b-on-a-large-range-of-downstream-evaluation-tasks/\" rel=\"noreferrer noopener\" target=\"_blank\">Chinchilla, outperforms GPT-3</a> and Gopher with roughly ¼th the number of parameters. It was trained on roughly 4 times as much data, but with fewer parameters, it requires less energy to train and fine-tune.</li><li><a href=\"https://thenewstack.io/its-time-for-data-reliability-engineering/\" rel=\"noreferrer noopener\" target=\"_blank\">Data Reliability Engineering</a> (DRE) borrows ideas from SRE and DevOps as a framework to provide higher-quality data for machine learning applications while reducing the manual labor required. It’s closely related to <a href=\"https://datacentricai.org/\" rel=\"noreferrer noopener\" target=\"_blank\">data-centric AI</a>.</li><li><a href=\"https://openai.com/dall-e-2/\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAI’s DALL-E 2</a> is a new take on their system (DALL-E) for generating images from natural language descriptions. It is also capable of modifying existing artworks based on natural language descriptions of the modifications.\\xa0OpenAI plans to open DALL-E 2 to the public, on terms similar to GPT-3.</li><li>Google’s new <a href=\"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\" rel=\"noreferrer noopener\" target=\"_blank\">Pathways Language Model</a> (PaLM) is more efficient, can understand concepts, and reason about cause and effect, in addition to being relatively energy-efficient. It’s another step forward towards AI that actually appears to think.</li><li><a href=\"https://www.sandboxaq.com/post/sandbox-aq-test-post-two\" rel=\"noreferrer noopener\" target=\"_blank\">SandboxAQ</a> is an Alphabet startup that is using AI to build technologies needed for a post-quantum world.\\xa0 They’re not doing quantum computing as such, but solving problems such as protocols for post-quantum cryptography.</li><li>IBM has open sourced the <a href=\"https://thenewstack.io/ibms-open-source-gt4sd-generates-ideas-for-scientists/\" rel=\"noreferrer noopener\" target=\"_blank\">Generative Toolkit for Scientific Discovery (GT4SD)</a>, which is a generative model designed to produce new ideas for scientific research, both in machine learning and in areas like biology and materials science.</li><li>Waymo (Alphabet’s self-driving car company) now offers <a href=\"https://blog.waymo.com/2022/03/taking-our-next-step-in-city-by-bay.html\" rel=\"noreferrer noopener\" target=\"_blank\">driverless service in San Francisco</a>.\\xa0 San Francisco is a more challenging environment than Phoenix, where Waymo has offered driverless service since 2020. Participation is limited to members of their Trusted Tester program.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.pcmag.com/news/more-users-flock-to-mastodon-after-musks-twitter-acquisition-bid\" rel=\"noreferrer noopener\" target=\"_blank\">Mastodon</a>, a decentralized social network, appears to be benefitting from Elon Musk’s takeover of Twitter.</li><li><a href=\"https://thenewstack.io/ontologys-web3-reputation-and-identity-management-solutions/\" rel=\"noreferrer noopener\" target=\"_blank\">Reputation and identity management</a> for web3 is a significant problem: how do you verify identity and reputation without giving applications more information than they should have?&nbsp; A startup called <a href=\"https://ont.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Ontology</a> claims to have solved it.</li><li>A virtual <a href=\"https://oncyber.io/6529om\" rel=\"noreferrer noopener\" target=\"_blank\">art museum for NFTs</a> is still under construction, but it exists, and you can visit it. It’s probably a better experience in VR.</li><li>2022 promises to be an even bigger year for cryptocrime than 2021. Attacks are <a href=\"https://blog.chainalysis.com/reports/2022-defi-hacks/\" rel=\"noreferrer noopener\" target=\"_blank\">increasingly focused on decentralized finance (DeFi) platforms</a>.</li><li>Could a <a href=\"https://thenextweb.com/news/web3-developers-building-decentralized-wikipedia-evade-russian-censorship\" rel=\"noreferrer noopener\" target=\"_blank\">web3 version of Wikipedia</a> evade Russia’s demands that they remove “prohibited information”?&nbsp; Or will it lead to a Wikipedia that’s <a href=\"https://theoutline.com/post/2369/everipedia-is-the-wikipedia-for-being-wrong\" rel=\"noreferrer noopener\" target=\"_blank\">distorted by economic incentives</a> (like past attempts to build a blockchain-based encyclopedia)?</li><li>The <a href=\"https://blog.helium.com/elevating-the-helium-network-with-new-helium-inc-name-series-d-46d8266fb7\" rel=\"noreferrer noopener\" target=\"_blank\">Helium Network</a> is a decentralized public wide area network using LoRaWAN that pays access point operators in cryptocurrency. The network has over 700,000 hotspots, and coverage in most of the world’s major metropolitan areas.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Do we really need another shell scripting language?\\xa0 The developers of <a href=\"https://hush-shell.github.io/foreword.html\" rel=\"noreferrer noopener\" target=\"_blank\">hush</a> think we do.\\xa0 Hush is based on <a href=\"https://www.lua.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Lua</a>, and claims to make shell scripting more robust and maintainable.</li><li>Web Assembly is making inroads; here’s a <a href=\"https://reneeshah.medium.com/how-webassembly-gets-used-the-18-most-exciting-startups-building-with-wasm-939474e951db\" rel=\"noreferrer noopener\" target=\"_blank\">list of startups using wasm</a> for everything from client-side media editing to building serverless platforms, smart data pipelines, and other server-side infrastructure.</li><li>QR codes are awful. Are they less awful when they’re <a href=\"https://www.bleepingcomputer.com/news/technology/animated-qr-codes-how-do-they-work-and-how-to-create-your-own/\" rel=\"noreferrer noopener\" target=\"_blank\">animated</a>? It doesn’t sound like it should work, but playing games with the error correction built into the standard allows the construction of animated QR codes.</li><li>Build your own quantum computer (in simulation)?\\xa0 <a href=\"https://quantumai.google/education/thequbitgame\" rel=\"noreferrer noopener\" target=\"_blank\">The Qubit Game</a> lets players “build” a quantum computer, starting with a single qubit.</li><li>One of Docker’s founders is developing a new product, <a href=\"https://medium.com/@Aaron-007/docker-founder-launches-new-devops-platform-dagger-which-has-secured-hundreds-of-millions-in-19bfde266191\" rel=\"noreferrer noopener\" target=\"_blank\">Dagger</a>, that will help developers manage DevOps pipelines.</li><li>Can applications use “<a href=\"https://www.theverge.com/2022/4/15/23026074/google-little-signals-concept-diy-build-ambient-notifications\" rel=\"noreferrer noopener\" target=\"_blank\">ambient notifications</a>” (like a breeze, a gentle tap, or a shift in shadows) rather than intrusive beeps and gongs?\\xa0 Google has published <a href=\"https://experiments.withgoogle.com/little-signals\" rel=\"noreferrer noopener\" target=\"_blank\">Little Signals</a>, six experiments with ambient notifications that includes code, electronics, and 3D models for hardware.</li><li><a href=\"https://aws.amazon.com/blogs/aws/announcing-aws-lambda-function-urls-built-in-https-endpoints-for-single-function-microservices/?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform\" rel=\"noreferrer noopener\" target=\"_blank\">Lambda Function URLs</a> automate the configuration of an API endpoint for single-function microservices on AWS. They make the process of mapping a URL to a serverless function simple.</li><li>GitHub has added a <a href=\"https://www.bleepingcomputer.com/news/security/github-can-now-alert-of-supply-chain-bugs-in-new-dependencies/\" rel=\"noreferrer noopener\" target=\"_blank\">dependency review</a> feature that inspects the consequences of a pull request and warns of vulnerabilities that were introduced by new dependencies.</li><li>Google has proposed <a href=\"https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform\" rel=\"noreferrer noopener\" target=\"_blank\">Supply Chain Levels for Software Artifacts</a> (SLSA) as a framework for\\xa0 ensuring the integrity of the software supply chain.\\xa0 It is a set of security guidelines that can be used to generate metadata; the metadata can be audited and tracked to ensure that software components have not been tampered with and have traceable provenance.</li><li>Harvard and the Linux Foundation have produced <a href=\"https://linuxfoundation.org/tools/census-ii-of-free-and-open-source-software-application-libraries/\" rel=\"noreferrer noopener\" target=\"_blank\">Census II</a>, which <a href=\"https://thenewstack.io/secure-your-code-with-census-ii-open-source-libraries/\" rel=\"noreferrer noopener\" target=\"_blank\">lists thousands of the most popular open source libraries</a> and attempts to rank their usage.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>The <a href=\"https://www.bleepingcomputer.com/news/security/revils-tor-sites-come-alive-to-redirect-to-new-ransomware-operation/\" rel=\"noreferrer noopener\" target=\"_blank\">REvil ransomware has returned</a> (maybe). Although there’s a lot of speculation, it isn’t yet clear what this means or who is behind it. Nevertheless, they appear to be looking for business partners.</li><li>Attackers used stolen OAuth tokens to <a href=\"https://github.blog/2022-04-15-security-alert-stolen-oauth-user-tokens/\" rel=\"noreferrer noopener\" target=\"_blank\">compromise GitHub</a> and download data from a number of organizations, most notably npm.</li><li>The NSA, Department of Energy, and other federal agencies have <a href=\"https://arstechnica.com/information-technology/2022/04/us-uncovers-swiss-army-knife-for-hacking-industrial-control-systems/\" rel=\"noreferrer noopener\" target=\"_blank\">discovered a new malware toolkit</a> named “pipedream” that is designed to disable power infrastructure. It&#8217;s adaptable to other critical infrastructure systems.\\xa0It doesn’t appear to have been used yet.</li><li>A <a href=\"https://www.bleepingcomputer.com/news/security/sandworm-hackers-fail-to-take-down-ukrainian-energy-provider/\" rel=\"noreferrer noopener\" target=\"_blank\">Russian state-sponsored group known as Sandworm</a> failed in an attempt to bring down the Ukraine&#8217;s power grid. They used new versions of Industroyer (for attacking industrial control systems) and Caddywiper (for cleaning up after the attack).</li><li>Re-use of IP addresses by a cloud provider can lead to “<a href=\"https://techxplore.com/news/2022-04-cloud-server-leasing-sensitive.html\" rel=\"noreferrer noopener\" target=\"_blank\">cloud squatting</a>,” where an organization that is assigned a previously used IP address receives data intended for the previous addressee. Address assignment has become highly dynamic; DNS wasn’t designed for that.</li><li>Pete Warden wants to build a coalition of researchers that will discuss ways of <a href=\"https://petewarden.com/2022/04/11/is-google-spying-on-your-conversations/\" rel=\"noreferrer noopener\" target=\"_blank\">verifying the privacy of devices</a> that have cameras and microphones (not limited to phones).</li><li>Cyber warfare on the home front: The FBI remotely accessed devices at some US companies to <a href=\"https://arstechnica.com/information-technology/2022/04/fbi-accesses-us-servers-to-dismantle-botnet-malware-installed-by-russian-spies/\" rel=\"noreferrer noopener\" target=\"_blank\">remove Russian botnet malware</a>. The malware targets WatchGuard firewalls and Asus routers. The Cyclops Blink botnet was developed by the Russia-sponsored Sandworm group.</li><li>Ransomware attacks have been seen that <a href=\"https://blog.aquasec.com/python-ransomware-jupyter-notebook\" rel=\"noreferrer noopener\" target=\"_blank\">target Jupyter Notebooks</a> on notebook servers where <a href=\"https://blog.jupyter.org/please-dont-disable-authentication-in-jupyter-servers-dd197206e7f6\" rel=\"noreferrer noopener\" target=\"_blank\">authentication has been disabled</a>. There doesn’t appear to be a significant vulnerability in Jupyter itself; just don&#8217;t disable authentication!</li><li>By using a version of <a href=\"https://techxplore.com/news/2022-03-tool-privacy-surveillance-footage.html\" rel=\"noreferrer noopener\" target=\"_blank\">differential privacy on video feeds</a>, surveillance cameras can provide a limited kind of privacy. Users can ask questions about the image, but can’t identify individuals. (Whether anyone wants a surveillance camera with privacy features is another question.)</li></ul>\\n\\n\\n\\n<h2>Biology and Neuroscience</h2>\\n\\n\\n\\n<ul><li>A <a href=\"https://arstechnica.com/science/2022/04/bci-lets-completely-locked-in-man-communicate-with-his-son-ask-for-a-beer/\" rel=\"noreferrer noopener\" target=\"_blank\">brain-computer interface</a> has allowed an ALS patient who was completely “locked in” to communicate with the outside world.&nbsp; Communication is slow, but it goes well beyond simple yes/no requests.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li>CAT scans aren’t just for radiology. <a href=\"https://www.lumafield.com/products\" rel=\"noreferrer noopener\" target=\"_blank\">Lumafield</a> has produced a table-sized CT-scan machine that can be used in small shops and offices, with the image analysis done in their cloud.</li><li>Boston Dynamics has a second robot on the market: <a href=\"https://arstechnica.com/gadgets/2022/04/boston-dynamics-stretch-robot-hits-production-and-its-already-sold-out/\" rel=\"noreferrer noopener\" target=\"_blank\">Stretch</a>, a box-handling robot designed to perform tasks like unloading trucks and shipping containers.</li><li>A startup claims it has the ability to put <a href=\"https://www.technologyreview.com/2022/03/31/1048672/roswell-molecular-electronics-revival/\" rel=\"noreferrer noopener\" target=\"_blank\">thousands of single-molecule biosensors on a silicon chip</a> that can be mass-produced. They intend to have a commercial product by the end of 2022. </li></ul>\\n\\n\\n\\n<h2>Metaverse</h2>\\n\\n\\n\\n<ul><li>Meta is releasing tools that will <a href=\"https://www.theverge.com/2022/4/11/23020684/meta-horizon-worlds-test-creators-sell-virtual-items-monetization\" rel=\"noreferrer noopener\" target=\"_blank\">allow creators to sell virtual merchandise</a> in Horizon Worlds, Meta’s virtual world platform. Meta will take a significant cut of the payment.</li><li>Meta is planning a <a href=\"https://thenextweb.com/news/meta-f8-cancel-zuck-bucks-analysis\" rel=\"noreferrer noopener\" target=\"_blank\">digital currency for its Metaverse</a>. It won’t be a cryptocurrency, and won’t be backed by a blockchain. It will probably be similar to an in-game currency. It might be used as compensation for posts in Facebook groups or Instagram. And it probably has little relationship to Facebook’s failed <a href=\"https://en.wikipedia.org/wiki/Diem_(digital_currency)\" rel=\"noreferrer noopener\" target=\"_blank\">Diem</a> cryptocurrency.</li><li>Pixar’s <a href=\"https://github.com/PixarAnimationStudios/USD\" rel=\"noreferrer noopener\" target=\"_blank\">Universal Scene Description</a> (USD) provides a way to <a href=\"https://medium.com/@nvidiaomniverse/plumbing-for-the-metaverse-with-universal-scene-description-usd-856a863d9b12\" rel=\"noreferrer noopener\" target=\"_blank\">share and collaborate in virtual worlds</a>.</li></ul>'}], 'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2022/feed/', 'slash_comments': '0'}]\n"
     ]
    }
   ],
   "source": [
    "print(len(oreilly.entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Obtain a list of components (keys) available for an entry.\n",
    "\n",
    "*Hint: Remember to index first before requesting the keys*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'title_detail', 'links', 'link', 'comments', 'published', 'published_parsed', 'authors', 'author', 'author_detail', 'tags', 'id', 'guidislink', 'summary', 'summary_detail', 'content', 'wfw_commentrss', 'slash_comments']\n"
     ]
    }
   ],
   "source": [
    "entry_components = list(oreilly.entries[0].keys())\n",
    "print(entry_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Extract a list of entry titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ad Networks and Content Marketing', 'On Technique', 'Scaling False Peaks', 'The Metaverse Is Not a Place', 'Radar Trends to Watch: August 2022', 'SQL: The Universal Solvent for REST APIs', 'Artificial Creativity?', 'Radar Trends to Watch: July 2022', '2022 Cloud Salary Survey', '“Sentience” is the Wrong Question', 'Closer to AGI?', 'Radar Trends to Watch: June 2022', 'Building a Better Middleman', 'Quantum Computing without the Hype', 'Radar trends to watch: May 2022']\n"
     ]
    }
   ],
   "source": [
    "entry_titles = [entry.title for entry in oreilly.entries]\n",
    "print(entry_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate the percentage of \"Four short links\" entry titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Radar Trends to Watch: August 2022', 'Radar Trends to Watch: July 2022', 'Radar Trends to Watch: June 2022', 'Radar trends to watch: May 2022']\n",
      "26.666666666666668\n"
     ]
    }
   ],
   "source": [
    "# WARNING, THERE ARE NO \"FOUR SHORT LINKS\" TITLES. CALCULATING PERCENTAGE OF \"TRENDS TO WATCH\" TITLES INSTEAD\n",
    "\n",
    "counted_titles = [entry_title for entry_title in entry_titles if \"Radar trends\".lower() in entry_title.lower()]\n",
    "percentage_titles = (len(counted_titles)/len(entry_titles))*100\n",
    "print(percentage_titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Create a Pandas data frame from the feed's entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>comments</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>tags</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>content</th>\n",
       "      <th>wfw_commentrss</th>\n",
       "      <th>slash_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ad Networks and Content Marketing</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/ad-networks-and-...</td>\n",
       "      <td>https://www.oreilly.com/radar/ad-networks-and-...</td>\n",
       "      <td>Tue, 16 Aug 2022 11:21:21 +0000</td>\n",
       "      <td>(2022, 8, 16, 11, 21, 21, 1, 228, 0)</td>\n",
       "      <td>[{'name': 'Q McCallum'}]</td>\n",
       "      <td>Q McCallum</td>\n",
       "      <td>{'name': 'Q McCallum'}</td>\n",
       "      <td>[{'term': 'Operations', 'scheme': None, 'label...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14688</td>\n",
       "      <td>False</td>\n",
       "      <td>In a recent Radar piece, I explored N-sided ma...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/ad-networks-and-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>On Technique</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/on-technique/</td>\n",
       "      <td>https://www.oreilly.com/radar/on-technique/#re...</td>\n",
       "      <td>Tue, 09 Aug 2022 11:12:22 +0000</td>\n",
       "      <td>(2022, 8, 9, 11, 12, 22, 1, 221, 0)</td>\n",
       "      <td>[{'name': 'Mike Loukides'}]</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>{'name': 'Mike Loukides'}</td>\n",
       "      <td>[{'term': 'AI &amp; ML', 'scheme': None, 'label': ...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14669</td>\n",
       "      <td>False</td>\n",
       "      <td>In a previous article, I wrote about how model...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/on-technique/feed/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Scaling False Peaks</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/scaling-false-pe...</td>\n",
       "      <td>https://www.oreilly.com/radar/scaling-false-pe...</td>\n",
       "      <td>Thu, 04 Aug 2022 11:12:44 +0000</td>\n",
       "      <td>(2022, 8, 4, 11, 12, 44, 3, 216, 0)</td>\n",
       "      <td>[{'name': 'Kevlin Henney'}]</td>\n",
       "      <td>Kevlin Henney</td>\n",
       "      <td>{'name': 'Kevlin Henney'}</td>\n",
       "      <td>[{'term': 'AI &amp; ML', 'scheme': None, 'label': ...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14661</td>\n",
       "      <td>False</td>\n",
       "      <td>Humans are notoriously poor at judging distanc...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/scaling-false-pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Metaverse Is Not a Place</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/the-metaverse-is...</td>\n",
       "      <td>https://www.oreilly.com/radar/the-metaverse-is...</td>\n",
       "      <td>Tue, 02 Aug 2022 18:38:46 +0000</td>\n",
       "      <td>(2022, 8, 2, 18, 38, 46, 1, 214, 0)</td>\n",
       "      <td>[{'name': 'Tim O’Reilly'}]</td>\n",
       "      <td>Tim O’Reilly</td>\n",
       "      <td>{'name': 'Tim O’Reilly'}</td>\n",
       "      <td>[{'term': 'Metaverse', 'scheme': None, 'label'...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14641</td>\n",
       "      <td>False</td>\n",
       "      <td>The metaphors we use to describe new technolog...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/the-metaverse-is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Radar Trends to Watch: August 2022</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>Tue, 02 Aug 2022 11:18:24 +0000</td>\n",
       "      <td>(2022, 8, 2, 11, 18, 24, 1, 214, 0)</td>\n",
       "      <td>[{'name': 'Mike Loukides'}]</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>{'name': 'Mike Loukides'}</td>\n",
       "      <td>[{'term': 'Radar Trends', 'scheme': None, 'lab...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14631</td>\n",
       "      <td>False</td>\n",
       "      <td>The large model train keeps rolling on. This m...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0   Ad Networks and Content Marketing   \n",
       "1                        On Technique   \n",
       "2                 Scaling False Peaks   \n",
       "3        The Metaverse Is Not a Place   \n",
       "4  Radar Trends to Watch: August 2022   \n",
       "\n",
       "                                        title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base...   \n",
       "2  {'type': 'text/plain', 'language': None, 'base...   \n",
       "3  {'type': 'text/plain', 'language': None, 'base...   \n",
       "4  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                                               links  \\\n",
       "0  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "1  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "2  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "3  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "4  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.oreilly.com/radar/ad-networks-and-...   \n",
       "1        https://www.oreilly.com/radar/on-technique/   \n",
       "2  https://www.oreilly.com/radar/scaling-false-pe...   \n",
       "3  https://www.oreilly.com/radar/the-metaverse-is...   \n",
       "4  https://www.oreilly.com/radar/radar-trends-to-...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  https://www.oreilly.com/radar/ad-networks-and-...   \n",
       "1  https://www.oreilly.com/radar/on-technique/#re...   \n",
       "2  https://www.oreilly.com/radar/scaling-false-pe...   \n",
       "3  https://www.oreilly.com/radar/the-metaverse-is...   \n",
       "4  https://www.oreilly.com/radar/radar-trends-to-...   \n",
       "\n",
       "                         published                      published_parsed  \\\n",
       "0  Tue, 16 Aug 2022 11:21:21 +0000  (2022, 8, 16, 11, 21, 21, 1, 228, 0)   \n",
       "1  Tue, 09 Aug 2022 11:12:22 +0000   (2022, 8, 9, 11, 12, 22, 1, 221, 0)   \n",
       "2  Thu, 04 Aug 2022 11:12:44 +0000   (2022, 8, 4, 11, 12, 44, 3, 216, 0)   \n",
       "3  Tue, 02 Aug 2022 18:38:46 +0000   (2022, 8, 2, 18, 38, 46, 1, 214, 0)   \n",
       "4  Tue, 02 Aug 2022 11:18:24 +0000   (2022, 8, 2, 11, 18, 24, 1, 214, 0)   \n",
       "\n",
       "                       authors         author              author_detail  \\\n",
       "0     [{'name': 'Q McCallum'}]     Q McCallum     {'name': 'Q McCallum'}   \n",
       "1  [{'name': 'Mike Loukides'}]  Mike Loukides  {'name': 'Mike Loukides'}   \n",
       "2  [{'name': 'Kevlin Henney'}]  Kevlin Henney  {'name': 'Kevlin Henney'}   \n",
       "3   [{'name': 'Tim O’Reilly'}]   Tim O’Reilly   {'name': 'Tim O’Reilly'}   \n",
       "4  [{'name': 'Mike Loukides'}]  Mike Loukides  {'name': 'Mike Loukides'}   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [{'term': 'Operations', 'scheme': None, 'label...   \n",
       "1  [{'term': 'AI & ML', 'scheme': None, 'label': ...   \n",
       "2  [{'term': 'AI & ML', 'scheme': None, 'label': ...   \n",
       "3  [{'term': 'Metaverse', 'scheme': None, 'label'...   \n",
       "4  [{'term': 'Radar Trends', 'scheme': None, 'lab...   \n",
       "\n",
       "                                       id  guidislink  \\\n",
       "0  https://www.oreilly.com/radar/?p=14688       False   \n",
       "1  https://www.oreilly.com/radar/?p=14669       False   \n",
       "2  https://www.oreilly.com/radar/?p=14661       False   \n",
       "3  https://www.oreilly.com/radar/?p=14641       False   \n",
       "4  https://www.oreilly.com/radar/?p=14631       False   \n",
       "\n",
       "                                             summary  \\\n",
       "0  In a recent Radar piece, I explored N-sided ma...   \n",
       "1  In a previous article, I wrote about how model...   \n",
       "2  Humans are notoriously poor at judging distanc...   \n",
       "3  The metaphors we use to describe new technolog...   \n",
       "4  The large model train keeps rolling on. This m...   \n",
       "\n",
       "                                      summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base'...   \n",
       "1  {'type': 'text/html', 'language': None, 'base'...   \n",
       "2  {'type': 'text/html', 'language': None, 'base'...   \n",
       "3  {'type': 'text/html', 'language': None, 'base'...   \n",
       "4  {'type': 'text/html', 'language': None, 'base'...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [{'type': 'text/html', 'language': None, 'base...   \n",
       "1  [{'type': 'text/html', 'language': None, 'base...   \n",
       "2  [{'type': 'text/html', 'language': None, 'base...   \n",
       "3  [{'type': 'text/html', 'language': None, 'base...   \n",
       "4  [{'type': 'text/html', 'language': None, 'base...   \n",
       "\n",
       "                                      wfw_commentrss slash_comments  \n",
       "0  https://www.oreilly.com/radar/ad-networks-and-...              0  \n",
       "1   https://www.oreilly.com/radar/on-technique/feed/              0  \n",
       "2  https://www.oreilly.com/radar/scaling-false-pe...              0  \n",
       "3  https://www.oreilly.com/radar/the-metaverse-is...              0  \n",
       "4  https://www.oreilly.com/radar/radar-trends-to-...              0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_df = pd.DataFrame(oreilly.entries)\n",
    "\n",
    "entries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Count the number of entries per author and sort them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike Loukides    10\n",
      "Q McCallum        2\n",
      "Kevlin Henney     1\n",
      "Tim O’Reilly      1\n",
      "Jon Udell         1\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(entries_df[\"author\"].value_counts(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Add a new column to the data frame that contains the length (number of characters) of each entry title. Return a data frame that contains the title, author, and title length of each entry in descending order (longest title length at the top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>SQL: The Universal Solvent for REST APIs</td>\n",
       "      <td>Jon Udell</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Radar Trends to Watch: August 2022</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Quantum Computing without the Hype</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ad Networks and Content Marketing</td>\n",
       "      <td>Q McCallum</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>“Sentience” is the Wrong Question</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title         author  length\n",
       "5   SQL: The Universal Solvent for REST APIs      Jon Udell      40\n",
       "4         Radar Trends to Watch: August 2022  Mike Loukides      34\n",
       "13        Quantum Computing without the Hype  Mike Loukides      34\n",
       "0          Ad Networks and Content Marketing     Q McCallum      33\n",
       "9          “Sentience” is the Wrong Question  Mike Loukides      33"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_df[\"length\"] = entries_df[\"title\"].apply(len)\n",
    "\n",
    "entries_df[['title', 'author', 'length']].sort_values('length', ascending=False).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Create a list of entry titles whose summary includes the phrase \"machine learning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['On Technique', {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'On Technique'}, [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/on-technique/'}], 'https://www.oreilly.com/radar/on-technique/', 'https://www.oreilly.com/radar/on-technique/#respond', 'Tue, 09 Aug 2022 11:12:22 +0000', time.struct_time(tm_year=2022, tm_mon=8, tm_mday=9, tm_hour=11, tm_min=12, tm_sec=22, tm_wday=1, tm_yday=221, tm_isdst=0), [{'name': 'Mike Loukides'}], 'Mike Loukides', {'name': 'Mike Loukides'}, [{'term': 'AI & ML', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'https://www.oreilly.com/radar/?p=14669', False, 'In a previous article, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, [&#8230;]', {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'In a previous article, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, [&#8230;]'}, [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>In a <a href=\"https://www.oreilly.com/radar/artificial-creativity-2/\" rel=\"noreferrer noopener\" target=\"_blank\">previous article</a>, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, “Make me a picture of a lion attacking a horse,” and it will happily generate one. Maybe not as good as the one that <a href=\"https://collections.britishart.yale.edu/catalog/tms:32\" rel=\"noreferrer noopener\" target=\"_blank\">hangs in an art museum</a>, but you don’t need to know anything about canvas, paints, and brushes, nor do you need to get your clothes covered with paint. </p>\\n\\n\\n\\n<p>This raises some important questions, though. What is the connection between expertise and ideation? Does technique help you form ideas? (The Victorian artist William Morris is often <a href=\"https://books.google.com/books?id=Til0DwAAQBAJ&amp;pg=PT292&amp;lpg=PT292&amp;dq=%E2%80%9CYou+can%E2%80%99t+have+art,%E2%80%9D+said+William+Morris,+the+designer,+poet,+and+master+craftsman+of+the+Victorians,+%E2%80%9Cwithout+resistance+in+the+material.%E2%80%9D&amp;source=bl&amp;ots=WYX6uA9wTq&amp;sig=ACfU3U3M2qyEIEsf1rrjKJ3poWb8CWIj9g&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj0-JHhlo35AhUVjIkEHYP-AT0Q6AF6BAgCEAM#v=onepage&amp;q=%E2%80%9CYou%20can%E2%80%99t%20have%20art%2C%E2%80%9D%20said%20William%20Morris%2C%20the%20designer%2C%20poet%2C%20and%20master%20craftsman%20of%20the%20Victorians%2C%20%E2%80%9Cwithout%20resistance%20in%20the%20material.%E2%80%9D&amp;f=false\" rel=\"noreferrer noopener\" target=\"_blank\">quoted</a> as saying “You can’t have art without resistance in the materials,” though he may only have been talking about his hatred of typewriters.) And what kinds of user interfaces will be effective for collaborations between humans and computers, where the computers supply the technique and we supply the ideas? Designing the prompts to get DALL-E to do something extraordinary requires a new kind of technique that’s very different from understanding pigments and brushes. What kinds of creativity does that new technique enable? How are these works different from what came before?</p>\\n\\n\\n\\n<p>As interesting as it is to talk about art, there’s an area where these questions are more immediate. GitHub Copilot (based on a model named <a href=\"https://openai.com/blog/openai-codex/\" rel=\"noreferrer noopener\" target=\"_blank\">Codex</a>, which is derived from GPT-3) generates code in a number of programming languages, based on comments that the user writes. Going in the other direction, GPT-3 has proven to be surprisingly good at <a href=\"https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/\" rel=\"noreferrer noopener\" target=\"_blank\">explaining code</a>. Copilot users still need to be programmers; they need to know whether the code that Copilot supplies is correct, and they need to know how to test it. The prompts themselves are really a sort of pseudo-code; even if the programmers don’t need to remember details of the language’s syntax or the names of library functions, they still need to think like programmers. But it’s obvious where this is trending. We need to ask ourselves how much “technique” we will ask of future programmers: in the 2030s or 2040s, will people just be able to tell some future Copilot what they want a program to be? More to the point, what sort of higher-order knowledge will future programmers need? Will they be able to focus more on the nature of what they want to accomplish, and less on the syntactic details of writing code?</p>\\n\\n\\n\\n<p>It’s easy to imagine a lot of software professionals saying, “Of course you’ll have to know C. Or Java. Or Python. Or Scala.” But I don’t know if that’s true. We’ve been here before. In the 1950s, computers were programmed in machine language. (And before that, with cables and plugs.) It’s hard to imagine now, but the introduction of the first programming languages–Fortran, COBOL, and the like–was met with resistance from programmers who thought you needed to understand the machine. Now almost no one works in machine language or assembler. Machine language is reserved for a few people who need to work on some specialized areas of operating system internals, or who need to write some kinds of embedded systems code.</p>\\n\\n\\n\\n<p>What would be necessary for another transformation? Tools like Copilot, useful as they may be, are nowhere near ready to take over. What capabilities will they need? At this point, programmers still have to decide whether or not code generated by Copilot is correct.&nbsp;We don’t (generally) have to decide whether the output of a C or Java compiler is correct, nor do we have to worry about whether, given the same source code, the compiler will generate identical output. Copilot doesn’t make that guarantee–and, even if it did, any change to the model (for example, to incorporate new StackOverflow questions or GitHub repositories) would be very likely to change its output.&nbsp;While we can certainly imagine compiling a program from a series of Copilot prompts, I can’t imagine a program that would be likely to stop working if it was recompiled without changes to the source code. Perhaps the only exception would be a library that could be developed once, then tested, verified, and used without modification–but the development process would have to re-start from ground zero whenever a bug or a security vulnerability was found. That wouldn’t be acceptable; we’ve never written programs that don’t have bugs, or that never need new features. A key principle behind much modern software development is minimizing the amount of code that has to change to fix bugs or add features.</p>\\n\\n\\n\\n<p>It’s easy to think that programming is all about creating new code. It isn’t; one thing that every professional learns quickly is that most of the work goes into maintaining old code. A new generation of programming tools must take that into account, or we’ll be left in a weird situation where a tool like Copilot can be used to write new code, but programmers will still have to understand that code in detail because it can only be maintained by hand. (It is possible–even likely–that we will have AI-based tools that help programmers research software supply chains, discover vulnerabilities, and possibly even suggest fixes.) Writing about AI-generated art, Raphaël Millière <a href=\"https://www.wired.com/story/dalle-art-curation-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">says</a>, “No prompt will produce the exact same result twice”; that may be desirable for artwork, but is destructive for programming. Stability and consistency is a requirement for next-generation programming tools; we can’t take a step backwards.</p>\\n\\n\\n\\n<p>The need for greater stability might drive tools like Copilot from free-form English language prompts to some kind of more formal language. A book about <a href=\"https://dallery.gallery/the-dalle-2-prompt-book/\" rel=\"noreferrer noopener\" target=\"_blank\">prompt engineering for DALL-E</a> already exists; in a way, that’s trying to reverse-engineer a formal language for generating images. A formal language for prompts is a move back in the direction of traditional programming, though possibly with a difference. Current programming languages are all about describing, step by step, what you want the computer to do in great detail. Over the years, we’ve gradually progressed to higher levels of abstraction. Could building a language model into a compiler facilitate the creation of a simpler language, one in which programmers just described what they wanted to do, and let the machine worry about the implementation, while providing guarantees of stability? Remember that it was possible to build applications with graphical interfaces, and for those applications to communicate about the Internet, before the Web. The Web (and, specifically, HTML) added a new formal language that encapsulated tasks that used to require programming.</p>\\n\\n\\n\\n<p>Now let’s move up a level or two: from lines of code to functions, modules, libraries, and systems. Everyone I know who has worked with Copilot has said that, while you don’t need to remember the details of the programming libraries you’re using, you have to be even more aware of what you’re trying to accomplish. You have to know what you want to do; you have to have a design in mind. Copilot is good at low-level coding; does a programmer need to be in touch with the craft of low-level coding to think about the high-level design? Up until now that’s certainly been true, but largely out of necessity: you wouldn’t let someone design a large system who hasn’t built smaller systems. It is true (as Dave Thomas and Andy Hunt argued in <a href=\"https://learning.oreilly.com/library/view/the-pragmatic-programmer/9780135956977/\" rel=\"noreferrer noopener\" target=\"_blank\">The Pragmatic Programmer</a>) that knowing different programming languages gives you different tools and approaches for solving problems.&nbsp; Is the craft of software architecture different from the craft of programming?</p>\\n\\n\\n\\n<p>We don’t really have a good language for describing software design. Attempts like UML have been partially successful at best. UML was both over- and under-specified, too precise and not precise enough; tools that generated source code scaffolding from UML diagrams exist, but aren’t commonly used these days. The scaffolding defined interfaces, classes, and methods that could then be implemented by programmers. While automatically generating the structure of a system sounds like a good idea, in practice it may have made things more difficult: if the high-level specification changed, so did the scaffolding, obsoleting any work that had been put into implementing with the scaffold. This is similar to the compiler’s stability problem, modulated into a different key. Is this an area where AI could help?</p>\\n\\n\\n\\n<p>I suspect we still don’t want source code scaffolding, at least as UML envisioned it; that’s bound to change with any significant change in the system’s description. Stability will continue to be a problem. But it might be valuable to have a AI-based design tool that can take a verbal description of a system’s requirements, then generate some kind of design based on a large library of software systems–like Copilot, but at a higher level. Then the problem would be integrating that design with implementations of the design, some of which could be created (or at least suggested) by a system like Copilot. The problem we’re facing is that software development takes place on two levels: high level design and mid-level programming. Integrating the two is a hard problem that hasn’t been solved convincingly.&nbsp; Can we imagine taking a high-level design, adding our descriptions to it, and going directly from the high-level design with mid-level details to an executable program? That programming environment would need the ability to partition a large project into smaller pieces, so teams of programmers could collaborate. It would need to allow changes to the high-level descriptions, without disrupting work on the objects and methods that implement those descriptions. It would need to be integrated with a version control system that is effective for the English-language descriptions as it is for lines of code. This wouldn’t be thinkable without guarantees of stability.</p>\\n\\n\\n\\n<p>It was fashionable for a while to talk about programming as “craft.”&nbsp; I think that fashion has waned, probably for the better; “code as craft” has always seemed a bit precious to me. But the idea of “craft” is still useful: it is important for us to think about how the craft may change, and how fundamental those changes can’t be.&nbsp;It’s clear that we are a long way from a world where only a few specialists need to know languages like C or Java or Python. But it’s also possible that developments like Copilot give us a glimpse of what the next step might be. Lamenting the state of programing tools, which haven’t changed much since the 1960s, Alan Kay <a href=\"https://www.quora.com/What-was-the-last-breakthrough-in-computer-programming\" rel=\"noreferrer noopener\" target=\"_blank\">wrote on Quora</a> that “the next significant threshold that programming must achieve is for programs and programming systems to have a much deeper understanding of both what they are trying to do, and what they are actually doing.” A new craft of programming that is focused less on syntactic details, and more on understanding what the systems we are building are trying to accomplish, is the goal we should be aiming for.</p>'}], 'https://www.oreilly.com/radar/on-technique/feed/', '0', 12], ['Radar Trends to Watch: August 2022', {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: August 2022'}, [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/'}], 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/', 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/#respond', 'Tue, 02 Aug 2022 11:18:24 +0000', time.struct_time(tm_year=2022, tm_mon=8, tm_mday=2, tm_hour=11, tm_min=18, tm_sec=24, tm_wday=1, tm_yday=214, tm_isdst=0), [{'name': 'Mike Loukides'}], 'Mike Loukides', {'name': 'Mike Loukides'}, [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'https://www.oreilly.com/radar/?p=14631', False, 'The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to [&#8230;]', {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to [&#8230;]'}, [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to explain JavaScript code.</p>\\n\\n\\n\\n<p>On other fronts, NIST has released the first proposed standard for post-quantum cryptography (i.e., cryptography that can’t be broken by quantum computers). CRISPR has been used in human trials to re-engineer a patient’s DNA to reduce cholesterol. And a surprising number of cities are paying high tech remote workers to move there.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li>Regardless of where a company is based, to avoid legal problems later, it’s a good idea to build AI and other data-based systems that <a href=\"https://thenextweb.com/news/european-or-not-make-sure-your-ai-business-sticks-to-eu-data-laws\" rel=\"noreferrer noopener\" target=\"_blank\">observe the EU’s data laws</a>.</li><li><a href=\"https://openai.com/blog/dall-e-now-available-in-beta/\" rel=\"noreferrer noopener\" target=\"_blank\">Public (beta) access to DALL-E is beginning</a>! It might take a while to get in because there are over a million on the waitlist. Accepted users get 50 free credits the first month, 15/month thereafter; a credit allows you to give one prompt, which returns 4 images. Users can buy additional credits.</li><li>Researchers have used reinforcement learning to build a <a href=\"https://www.technologyreview.com/2022/07/18/1056059/robot-dog-ai-reinforcement/\" rel=\"noreferrer noopener\" target=\"_blank\">robotic dog that learns to walk on its own</a> in the real world (i.e., without prior training and use of a simulator).</li><li>Princeton held a <a href=\"https://sites.google.com/princeton.edu/rep-workshop/\" rel=\"noreferrer noopener\" target=\"_blank\">workshop</a> on the <a href=\"https://twitter.com/random_walker/status/1542879397245423616\" rel=\"noreferrer noopener\" target=\"_blank\">reproducibility crisis</a> that the use of machine learning is causing in science. Evaluating the accuracy of results from machine learning is a problem that most scientific disciplines aren’t yet equipped to deal with.</li><li>Microsoft has revised its <a href=\"https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">Responsible AI standard</a>, making recommendations more concrete, particularly in the areas of accountability, transparency, fairness, safety, privacy, and inclusiveness. Microsoft also provides <a href=\"https://www.microsoft.com/en-us/ai/responsible-ai-resources\" rel=\"noreferrer noopener\" target=\"_blank\">tools and resources</a> to help developers build responsible AI systems.</li><li>The Dallery Gallery has published a <a href=\"https://dallery.gallery/the-dalle-2-prompt-book/\" rel=\"noreferrer noopener\" target=\"_blank\">Prompt Engineering Guide to DALL-E</a>. (DALL-E is maintaining a <a href=\"https://help.openai.com/en/articles/4936794-is-dall-e-available-yet\" rel=\"noreferrer noopener\" target=\"_blank\">waitlist</a> for free trial accounts.)</li><li>Simon Willison has successfully used GPT-3 to <a href=\"https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/\" rel=\"noreferrer noopener\" target=\"_blank\">explain how code works</a>. It is amazingly good and, as Simon pointed out, works both on code that he understands, and code that he doesn’t.</li><li><a href=\"https://huggingface.co/bigscience/bloom\" rel=\"noreferrer noopener\" target=\"_blank\">Bloom</a>, the open and transparent large language model developed by the BigScience group, is <a href=\"https://bigscience.huggingface.co/blog/bloom\" rel=\"noreferrer noopener\" target=\"_blank\">finished</a>!&nbsp; You can try it out, download it, and read its specifications. Unlike all other large language models, Bloom was developed in public, and is open to the public.</li><li>Radiologists outperform AI systems operating by themselves at detecting breast cancer from mammograms. However, a <a href=\"https://www.technologyreview.com/2022/07/11/1055677/ai-diagnose-breast-cancer-mammograms/\" rel=\"noreferrer noopener\" target=\"_blank\">system designed to collaborate</a> with radiologists in making decisions is better than either radiologists or AI alone. (The big question is whether these results hold up when taken to other hospitals.)</li><li>You liked Copilot? Try <a href=\"https://www.autoregex.xyz/\" rel=\"noreferrer noopener\" target=\"_blank\">Autoregex</a>: GPT-3 to generate regular expressions from natural language descriptions.</li><li><a href=\"https://github.com/facebookresearch/fairseq/tree/nllb\" rel=\"noreferrer noopener\" target=\"_blank\">No Language Left Behind</a> (NLLB) is a Meta AI project that translates text directly between any pair of over 200 languages. Benchmarks, training code, and models are all open source.</li><li><a href=\"https://www.nature.com/articles/s41562-022-01383-x\" rel=\"noreferrer noopener\" target=\"_blank\">Democratic AI</a> is an experiment in human-in-the-loop design that enables an AI system to design a social mechanism with human collaboration. </li><li>The Allen Institute, Microsoft, and others have developed a tool to <a href=\"https://www.technologyreview.com/2022/07/06/1055458/ai-research-emissions-energy-efficient/\" rel=\"noreferrer noopener\" target=\"_blank\">measure the energy use and emissions generated by training AI models</a> on Azure. They have found that emissions can be reduced substantially by training during periods when renewable power is at its peak.</li><li><a href=\"https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html\" rel=\"noreferrer noopener\" target=\"_blank\">Minerva</a> is a large language model that Google has trained to solve quantitative reasoning (i.e., mathematics) problems, generating simple proofs in addition to answers. The problem domain extends through pre-calculus, including algebra and geometry, roughly at a high school level. Minerva has also been trained and tested in chemistry and physics.  </li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Perhaps the scariest exploit in security would be a <a href=\"https://arstechnica.com/information-technology/2022/07/researchers-unpack-unkillable-uefi-rootkit-that-survives-os-reinstalls/\" rel=\"noreferrer noopener\" target=\"_blank\">rootkit that cannot be detected or removed</a>, even by wiping the disk and reinstalling the operating system.&nbsp;Such rootkits were recently discovered (one is named CosmicStrand); they have apparently been in the wild since 2016.</li><li>AWS is offering some customers a free <a href=\"https://thenewstack.io/aws-customers-can-now-order-a-free-mfa-security-key/\" rel=\"noreferrer noopener\" target=\"_blank\">multi factor authentication</a> (MFA) security key.</li><li>Lost passwords are an important <a href=\"https://arstechnica.com/information-technology/2022/07/malware-circulating-online-wrangles-industrial-systems-into-a-botnet/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">attack vector for industrial systems</a>. A system is installed; the default password is changed; the person who changed the password leaves; the password is lost; the company installs password recovery software, which is often malware-infested, to recover the password.</li><li>A <a href=\"https://www.wired.com/story/web-deanonymization-side-channel-attack-njit/\" rel=\"noreferrer noopener\" target=\"_blank\">new technique for browser de-anonymization</a> is based on correlating users’ activities on different websites.</li><li><a href=\"https://www.bleepingcomputer.com/news/security/ransomware-gang-now-lets-you-search-their-stolen-data/\" rel=\"noreferrer noopener\" target=\"_blank\">Ransomware companies are now using search engines</a> to allow their users to search the data they have stolen.</li><li>Ransomware doesn’t get as much attention in the news as it did last year, but in the past week one ransomware operation has shut down and released its decryptors, and two new ones (RedAlert and omega) <a href=\"https://www.bleepingcomputer.com/news/security/the-week-in-ransomware-july-8th-2022-one-down-many-to-go/\" rel=\"noreferrer noopener\" target=\"_blank\">have started</a>.</li><li>Apple has added “<a href=\"https://www.apple.com/newsroom/2022/07/apple-expands-commitment-to-protect-users-from-mercenary-spyware/\" rel=\"noreferrer noopener\" target=\"_blank\">lockdown mode</a>” to iOS.&nbsp; Lockdown mode provides an extreme degree of privacy; it is intended for people who believe they are being targeted by state-sponsored mercenary spyware.</li><li>The <a href=\"https://openssf.org/oss-security-mobilization-plan/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Source Security Mobilization Plan</a> is an initiative that aims to address major areas of open source security, including education, risk assessment, digital signatures, memory safety, incident response, and software supply chain management.</li><li>Mitre has released their annual list of the <a href=\"https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html\" rel=\"noreferrer noopener\" target=\"_blank\">25 most dangerous software weaknesses</a> (bugs, flaws, vulnerabilities).</li><li>Patches for the Log4J vulnerability were released back in February, 2022, but <a href=\"https://thenewstack.io/log4shell-hacks-on-and-on/\" rel=\"noreferrer noopener\" target=\"_blank\">many organizations have not applied them</a>, and remain vulnerable to attack.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Microsoft and Oracle have announced <a href=\"https://www.oracle.com/news/announcement/oracle-database-service-for-microsoft-azure-2022-07-20/\" rel=\"noreferrer noopener\" target=\"_blank\">Oracle Data Service</a>, which allows applications running on Azure to manage and use data in Oracle’s cloud. It’s a multicloud strategy that’s enabled by the cloud providers.</li><li>Google has announced a new programming language, <a href=\"https://9to5google.com/2022/07/19/carbon-programming-language-google-cpp/\" rel=\"noreferrer noopener\" target=\"_blank\">Carbon</a>, that is intended to be the successor to C++. One goal is complete interoperability between Carbon and existing C++ code and libraries.</li><li><a href=\"https://theburningmonk.com/2022/07/the-best-ways-to-save-money-on-lambda/\" rel=\"noreferrer noopener\" target=\"_blank\">How to save money on AWS Lambda</a>: watch your memory!&nbsp; Don’t over-allocate memory. This probably only applies to a few of your functions, but those functions are what drive the cost up.</li><li><a href=\"https://www.technologyreview.com/2022/07/14/1055894/us-military-sofware-linux-kernel-open-source/\" rel=\"noreferrer noopener\" target=\"_blank\">SocialCyber</a> is a <a href=\"https://www.darpa.mil/program/hybrid-ai-to-protect-integrity-of-open-source-code\" rel=\"noreferrer noopener\" target=\"_blank\">DARPA program</a> to understand the internals of open source software, along with the communities that create the software. They plan to use machine learning heavily, both to understand the code and to map and analyze communications within the communities. They are concerned about potential vulnerabilities in the software that the US military depends on.</li><li><a href=\"https://thenewstack.io/whats-next-in-webassembly/\" rel=\"noreferrer noopener\" target=\"_blank\">WebAssembly in the cloud</a>? Maybe it isn’t just a client-side technology. As language support grows, so do the kinds of applications Wasm can support.</li><li>A <a href=\"https://tidelift.com/2022-open-source-software-supply-chain-survey\" rel=\"noreferrer noopener\" target=\"_blank\">surveyreports</a> that 62% of its respondents were only “somewhat confident” that open source software was “secure, up-to-date, and well-maintained.”&nbsp; Disappointing as this may be, it’s actually an improvement over prior results.</li><li>Is <a href=\"https://thenewstack.io/infrastructure-as-code-goes-low-code-no-code/\" rel=\"noreferrer noopener\" target=\"_blank\">low-code infrastructure as code</a> the future of cloud operations?</li><li><a href=\"https://lunduke.substack.com/p/tiny-core-linux-130-full-linux-desktop\" rel=\"noreferrer noopener\" target=\"_blank\">Tiny Core Linux</a> is amazingly small: a 22MB download, and runs in 48MB of RAM. As a consequence, it’s also amazingly fast. With a few exceptions, making things small has not been a trend over the past few years.&nbsp;We hope to see more of this.</li><li>Yet another JavaScript web framework? <a href=\"https://thenewstack.io/denos-fresh-uses-server-side-rendering-for-faster-apps/\" rel=\"noreferrer noopener\" target=\"_blank\">Fresh</a> does server-side rendering, and is based on Deno rather than NodeJS.</li></ul>\\n\\n\\n\\n<h2>Web</h2>\\n\\n\\n\\n<ul><li>Facebook is considering whether to <a href=\"https://arstechnica.com/tech-policy/2022/07/meta-thinks-facebook-may-need-more-harmful-health-misinformation/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">rescind its bans on health misinformation</a>. The pandemic is over, after all. Except that it isn’t. However, being a conduit for health misinformation is clearly profitable.</li><li><a href=\"https://www.etsy.com/codeascraft/priority-hints-what-your-browser-doesnt-know-yet\" rel=\"noreferrer noopener\" target=\"_blank\">Priority Hints</a> are a way for web developers to tell the browser <a href=\"https://web.dev/priority-hints/\" rel=\"noreferrer noopener\" target=\"_blank\">which parts of the page are most important</a>, so that they can be rendered quickly. They are currently supported by the Chrome and Edge browsers.</li><li><a href=\"https://hotwired.dev/\" rel=\"noreferrer noopener\" target=\"_blank\">Hotwire</a>, <a href=\"https://htmx.org/\" rel=\"noreferrer noopener\" target=\"_blank\">HTMX</a>, and <a href=\"https://unpoly.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Unpoly</a> are frameworks for building complex web applications while minimizing the need for complex Javascript. Are they an alternative to heavyweight JavaScript frameworks like React? Could a return to server-side web applications lead to a resurgence of platforms like <a href=\"https://thenewstack.io/turbocharging-ruby-on-rails-with-html-over-the-wire/\" rel=\"noreferrer noopener\" target=\"_blank\">Ruby on Rails</a>?</li><li>Facebook has started <a href=\"https://www.ghacks.net/2022/07/17/facebook-has-started-to-encrypt-links-to-counter-privacy-improving-url-stripping/\" rel=\"noreferrer noopener\" target=\"_blank\">encrypting the portions of URLs that are used to track users</a>, preventing the Firefox and Brave browsers from stripping the tracking portion of the URL.</li><li><a href=\"https://www.technologyreview.com/2022/07/15/1056042/chinese-novel-censored-before-shared/\" rel=\"noreferrer noopener\" target=\"_blank\">A priori censorship?</a>&nbsp; A popular cloud-based word processor in China has been observed censoring content upon the creation of a link for sharing the content. The document is locked; it cannot be edited or even opened by the author.</li><li>The <a href=\"http://pilimi.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Pirate Library Mirror</a> is exactly what it says: a mirror of libraries of pirated books. It is focused on the preservation of human knowledge. There is no search engine, and it is only accessible by using BitTorrent over TOR.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://arstechnica.com/gaming/2022/07/minecraft-blocks-the-blockchain-from-its-block-game/\" rel=\"noreferrer noopener\" target=\"_blank\">Minecraft has decided that they will not “support or allow” the integration of NFTs</a> into their virtual worlds. They object to “digital ownership based on scarcity and exclusion.”</li><li><a href=\"https://arstechnica.com/information-technology/2022/07/usage-of-crypto-mixers-for-stymying-blockchain-investigations-hits-all-time-high/#p3\" rel=\"noreferrer noopener\" target=\"_blank\">Mixers</a> are cryptocurrency services that randomize the currency you use; rather than pay with your own coin, you deposit money in a mixer and pay with randomly selected coins from other users. It’s similar to a traditional bank in that you never withdraw the same money you deposited.</li><li>So much for privacy. Coinbase, one of the largest cryptocurrency exchanges, <a href=\"https://theintercept.com/2022/06/29/crypto-coinbase-tracer-ice/\" rel=\"noreferrer noopener\" target=\"_blank\">sells geolocation data to ICE</a> (the US Immigration and Customs Enforcement agency).</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://phys.org/news/2022-07-quantum.html\" rel=\"noreferrer noopener\" target=\"_blank\">Quantum computers aren’t limited to binary</a>: That limit is imposed by analogy to traditional computers, but some quantum computers have access to more state, and taking advantage of those states may make applications like simulating physical or biological systems easier.</li><li>Is quantum-aided computing for some industrial applications just around the corner? <a href=\"https://thenewstack.io/quantum-computing-use-cases-how-viable-is-it-really/\" rel=\"noreferrer noopener\" target=\"_blank\">IonQ and GE have announced a results from a hybrid system</a> for risk management. The quantum computer does random sampling from probability distributions, which are computationally expensive for classical computers; the rest of the computation is classical.</li><li><a href=\"https://phys.org/news/2022-07-entanglement-quantum-memories.html\" rel=\"noreferrer noopener\" target=\"_blank\">Quantum networking</a> is becoming real: researchers have created entangled qubits via a 33-mile fiber optic connection. In addition to their importance for secure communications, quantum networks may be a crucial step in building quantum computers at scale. </li><li>NIST has announced <a href=\"https://arstechnica.com/information-technology/2022/07/nist-selects-quantum-proof-algorithms-to-head-off-the-coming-cryptopocalypse/\" rel=\"noreferrer noopener\" target=\"_blank\">four candidate algorithms for post-quantum cryptography</a>. While it may be years before quantum computing can break current algorithms, many organizations are anxious to start the transition from current algorithms. </li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>Not long ago (2020), DeepMind released AlphaFold, which used AI to solve protein folding problems. In 2021, they announced a public database containing the structure of a million proteins. With their latest additions, that database now contains the structure of <a href=\"https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe\" rel=\"noreferrer noopener\" target=\"_blank\">over 200 million</a> proteins, almost every protein known to science.</li><li>A <a href=\"https://www.nature.com/articles/s41586-022-04910-y\" rel=\"noreferrer noopener\" target=\"_blank\">motor made of DNA</a>!&nbsp; This nanoscale motor uses ideas from origami to fold DNA in a way that causes it to rotate when an electrical field is applied. </li><li>An <a href=\"https://www.bloomberg.com/news/articles/2022-07-18/brain-computer-interface-company-implants-new-type-of-device?sref=htOHjx5Y\" rel=\"noreferrer noopener\" target=\"_blank\">electrode has been implanted into the brain of an ALS patient</a> that will allow them to communicate thoughts via computer. The patient has otherwise lost the ability to move or speak.</li><li>Genetic editing with <a href=\"https://www.technologyreview.com/2022/07/12/1055773/crispr-gene-editing-cholesterol/\" rel=\"noreferrer noopener\" target=\"_blank\">CRISPR was tested in a human</a> to permanently lower LDL (“bad cholesterol”) levels. If this works, it could make heart attacks much rarer, and could be the first widespread use of CRISPR in humans.</li></ul>\\n\\n\\n\\n<h2>Energy</h2>\\n\\n\\n\\n<ul><li>Researchers in India have developed a carbon-negative process for <a href=\"https://techxplore.com/news/2022-07-green-hydrogen-biomass-abundant-renewable.html\" rel=\"noreferrer noopener\" target=\"_blank\">generating Hydrogen from biomass</a>. </li></ul>\\n\\n\\n\\n<h2>Work</h2>\\n\\n\\n\\n<ul><li>Some cities (largely in the US South and Midwest) are giving <a href=\"https://thenewstack.io/us-cities-try-luring-remote-tech-workers-with-cash/\" rel=\"noreferrer noopener\" target=\"_blank\">cash bonuses to tech worker</a>s who are willing to move there and work remotely.</li><li>The <a href=\"https://www.zdnet.com/article/fbi-warning-crooks-are-are-using-deepfakes-to-apply-for-remote-tech-jobs/\" rel=\"noreferrer noopener\" target=\"_blank\">FBI is warning employers</a> that they are seeing an increasing number of fraudulent applications for remote work in which the application uses stolen personal information and deepfake imagery.</li></ul>'}], 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/feed/', '0', 34], ['Artificial Creativity?', {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Artificial Creativity?'}, [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/artificial-creativity-2/'}], 'https://www.oreilly.com/radar/artificial-creativity-2/', 'https://www.oreilly.com/radar/artificial-creativity-2/#respond', 'Tue, 12 Jul 2022 13:24:16 +0000', time.struct_time(tm_year=2022, tm_mon=7, tm_mday=12, tm_hour=13, tm_min=24, tm_sec=16, tm_wday=1, tm_yday=193, tm_isdst=0), [{'name': 'Mike Loukides'}], 'Mike Loukides', {'name': 'Mike Loukides'}, [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None}, {'term': 'Commentary', 'scheme': None, 'label': None}], 'https://www.oreilly.com/radar/?p=14604', False, 'There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&#160; As with the discussion of sentience, authors are [&#8230;]', {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&#160; As with the discussion of sentience, authors are [&#8230;]'}, [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&nbsp; As with the discussion of sentience, authors are being misled by a very human will to believe. And in being misled, they’re missing out on what’s important.</p>\\n\\n\\n\\n<p>It’s impressive to see AI-generated pictures of an <a href=\"https://twitter.com/OpenAI/status/1511714545529614338?ref_src=twsrc%5Etfw\" rel=\"noreferrer noopener\" target=\"_blank\">astronaut riding a horse</a>, or a <a href=\"https://www.thedailybeast.com/googles-new-text-to-image-generator-imagen-is-scary-accurate\" rel=\"noreferrer noopener\" target=\"_blank\">dog riding a bike in Times Square</a>. But where’s the creativity?&nbsp; Is it in the prompt or in the product?&nbsp; I couldn’t draw a picture of a dog riding a bike; I’m not that good an artist. Given a few pictures of dogs, Times Square, and whatnot, I could probably photoshop my way into something passable, but not very good. &nbsp;(To be clear: these AI systems are not automating photoshop.) So the AI is doing something that many, perhaps most humans, wouldn’t be able to do. That’s important. Very few humans (if any) can play Go at the level of AlphaGo. We’re getting used to being second-best.</p>\\n\\n\\n\\n<p>However, a computer replacing a human’s limited photoshop skills isn’t creativity. It took a human to say “create a picture of a dog riding a bike.” An AI couldn’t do that of its own volition. That’s creativity.&nbsp;But before writing off the creation of the picture, let’s think more about what that really means. Works of art really have two sources: the idea itself and the technique required to instantiate that idea. You can have all the ideas you want, but if you can’t paint like Rembrandt, you’ll never generate a Dutch master. Throughout history, painters have learned technique by copying the works of masters. What’s interesting about DALL-E, Imagen, and their relatives is that they supply the technique. Using DALL-E or Imagen, I could create a painting of a tarsier eating an anaconda without knowing how to paint.</p>\\n\\n\\n\\n<p>That distinction strikes me as very important. In the 20th and 21st centuries we’ve become very impatient with technique. We haven’t become impatient with creating good ideas. (Or at least strange ideas.) The “age of mechanical reproduction” seems to have made technique less relevant; after all, we’re heirs of the poet Ezra Pound, who famously said, “Make it new.”</p>\\n\\n\\n\\n<p>But does that quote mean what we think? Pound’s “Make it new” has been <a href=\"https://www.guernicamag.com/the-making-of-making-it-new/\" rel=\"noreferrer noopener\" target=\"_blank\">traced back</a> to 18th century China, and from there to the 12th century, something that’s not at all surprising if you’re familiar with Pound’s fascination with Chinese literature. What’s interesting, though, is that Chinese art has always focused on technique to a level that’s almost inconceivable to the European tradition. And “Make it new” has, within it, the acknowledgment that what’s new first has to be made. Creativity and technique don’t come apart that easily.</p>\\n\\n\\n\\n<p>We can see that in other art forms. Beethoven broke Classical music and put it back together again, but different-–he’s the most radical composer in the Western tradition (except for, perhaps, Thelonious Monk). And it’s worth asking how we get from what’s old to what’s new.&nbsp; AI has been used to <a href=\"https://www.classicfm.com/composers/beethoven/unfinished-tenth-symphony-completed-by-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">complete Beethoven’s 10th symphony</a>, for which Beethoven left a number of sketches and notes at the time of his death. The result is pretty good, better than the human attempts I’ve heard at completing the 10th.&nbsp;It sounds Beethoven-like; its flaw is that it goes on and on, repeating Beethoven-like riffs but without the tremendous forward-moving force that you get in Beethoven’s compositions. But completing the 10th isn’t the problem we should be looking at. How did we get Beethoven in the first place?&nbsp; If you trained an AI on the music Beethoven was trained on, would you eventually get the 9th symphony?&nbsp;Or would you get something that sounds a lot like Mozart and Haydn?</p>\\n\\n\\n\\n<p>I’m betting the latter. The progress of art isn’t unlike the structure of scientific revolutions, and Beethoven indeed took everything that was known, broke it apart, and put it back together differently. Listen to the <a href=\"https://www.youtube.com/watch?v=HljSXSm6v9M\" rel=\"noreferrer noopener\" target=\"_blank\">opening of Beethoven’s 9th symphony</a>: what is happening? Where’s the theme? It sounds like the orchestra is tuning up. When the first theme finally arrives, it’s not the traditional “melody” that pre-Beethoven listeners would have expected, but something that dissolves back into the sound of instruments tuning, then gets reformed and reshaped. Mozart would never do this. Or listen again to <a href=\"https://www.youtube.com/watch?v=a9UApyClFKA\" rel=\"noreferrer noopener\" target=\"_blank\">Beethoven’s 5th symphony</a>, probably the most familiar piece of orchestral music in the world. That opening duh-duh-duh-DAH–what kind of theme is that? Beethoven builds this movement by taking that four note fragment, moving it around, changing it, breaking it into even smaller bits and reassembling them. You can’t imagine a witty, urbane, polite composer like Haydn writing music like this. But I don’t want to worship some notion of Beethoven’s “genius” that privileges creativity over technique. Beethoven could never have gotten beyond Mozart and Haydn (with whom Beethoven studied) without extensive knowledge of the technique of composing; he would have had some good ideas, but he would never have known how to realize them. Conversely, the realization of radical ideas as actual works of art inevitably changes the technique. Beethoven did things that weren’t conceivable to Mozart or Haydn, and they changed the way music was written: those changes made the music of Schubert, Schumann, and Brahms possible, along with the rest of the 19th century. </p>\\n\\n\\n\\n<p>That brings us back to the question of computers, creativity, and craft. Systems like DALL-E and Imagen break apart the idea and the technique, or the execution of the idea. Does that help us be more creative, or less? I could tell Imagen to “paint a picture of a 15th century woman with an enigmatic smile,” and after a few thousand tries I might get something like the Mona Lisa. I don’t think that anyone would care, really.&nbsp; But this isn’t creating something new; it’s reproducing something old. If I magically appeared early in the 20th century, along with a computer capable of running Imagen (though only trained on art through 1900), would I be able to tell it to create a Picasso or a Dali? I have no idea how to do that. Nor do I have any idea what the next step for art is now, in the 21st century, or how I’d ask Imagen to create it. It sure isn’t Bored Apes. And if I could ask Imagen or DALL-E to create a painting from the 22nd century, how would that change the AI’s conception of technique?</p>\\n\\n\\n\\n<p>At least part of what I lack is the technique, for technique isn’t just mechanical ability; it’s also the ability to think the way great artists do. And that gets us to the big question:</p>\\n\\n\\n\\n<p>Now that we have abstracted technique away from the artistic process, can we build interfaces between the creators of ideas and the machines of technique in a way that allows the creators to “make it new”?&nbsp; That’s what we really want from creativity: something that didn’t exist, and couldn’t have existed, before.</p>\\n\\n\\n\\n<p>Can artificial intelligence help us to be creative? That’s the important question, and it’s a question about user interfaces, not about who has the biggest model.</p>'}], 'https://www.oreilly.com/radar/artificial-creativity-2/feed/', '0', 22], ['Radar Trends to Watch: July 2022', {'type': 'text/plain', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'Radar Trends to Watch: July 2022'}, [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/'}], 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/', 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/#respond', 'Tue, 05 Jul 2022 11:09:04 +0000', time.struct_time(tm_year=2022, tm_mon=7, tm_mday=5, tm_hour=11, tm_min=9, tm_sec=4, tm_wday=1, tm_yday=186, tm_isdst=0), [{'name': 'Mike Loukides'}], 'Mike Loukides', {'name': 'Mike Loukides'}, [{'term': 'Radar Trends', 'scheme': None, 'label': None}, {'term': 'Signals', 'scheme': None, 'label': None}], 'https://www.oreilly.com/radar/?p=14591', False, 'This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask. The most important issue facing technology might now be [&#8230;]', {'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': 'This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask. The most important issue facing technology might now be [&#8230;]'}, [{'type': 'text/html', 'language': None, 'base': 'http://feeds.feedburner.com/oreilly/radar/atom', 'value': '<p>This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask.</p>\\n\\n\\n\\n<p>The most important issue facing technology might now be the protection of privacy. While that’s not a new concern, it’s a concern that most computer users have been willing to ignore, and that most technology companies have been willing to let them ignore. New state laws that criminalize having abortions out of state and the stockpiling of location information by antiabortion groups have made privacy an issue that can’t be ignored.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.nature.com/articles/d41586-022-01705-z\" rel=\"noreferrer noopener\" target=\"_blank\">Big Science has almost finished training</a> its open source <a href=\"https://bigscience.huggingface.co/blog/model-training-launched\" rel=\"noreferrer noopener\" target=\"_blank\">BLOOM language model</a>, which was developed by volunteer researchers and trained using public funds. Bloom will provide an open, public platform for research into the capabilities of large language models and, specifically,&nbsp; issues like avoiding bias and toxic language. </li><li>AI tools like AlphaFold2 can <a href=\"https://colbyford.medium.com/am-i-hallucinating-or-can-ai-now-design-cancer-curing-antibodies-3ef1bef92106\" rel=\"noreferrer noopener\" target=\"_blank\">create new proteins</a>, not just analyze existing ones; the unexpected creation of new artifacts by an AI system is playfully called “hallucination.” The proteins designed so far probably aren’t useful; still, this is a major step forward in drug design.</li><li>Microsoft is <a href=\"https://www.theverge.com/2022/6/21/23177016/microsoft-retires-emotion-recognition-azure-ai-tool-api\" rel=\"noreferrer noopener\" target=\"_blank\">limiting or removing access</a> to some features in its face recognition service, Azure Face. Organizations will have to tell Microsoft how and why facial recognition will be used in their systems; and services like emotion recognition will be removed completely.</li><li>Amazon plans to <a href=\"https://www.reuters.com/technology/amazon-has-plan-make-alexa-mimic-anyones-voice-2022-06-22/\" rel=\"noreferrer noopener\" target=\"_blank\">give Alexa the ability to imitate anyone’s voice</a>, using under a minute of audio. They give the example of a (possibly dead) grandmother “reading” a book to a child. Other AI vendors (most notably <a href=\"https://thenextweb.com/news/openai-punished-dev-used-gpt-3-to-resurrect-dead-ethics\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAI/Microsoft</a>) have considered such mimicry unethical.</li><li><a href=\"https://github.com/dolthub/dolt\" rel=\"noreferrer noopener\" target=\"_blank\">Dolt</a> is a SQL database that lets you version data using git commands, You can clone, push, pull, fork, branch, and merge just as with git; you access data using standard SQL.</li><li>It’s sadly unsurprising that a robot incorporating a widely-used neural network (OpenAI CLIP) learns <a href=\"https://techxplore.com/news/2022-06-robots-racist-sexist-flawed-ai.html\" rel=\"noreferrer noopener\" target=\"_blank\">racist and sexist biases</a>, and that these biases affect its performance on tasks.</li><li>Building <a href=\"https://techxplore.com/news/2022-06-technology-self-driving-cars-memories.html\" rel=\"noreferrer noopener\" target=\"_blank\">autonomous vehicles with memory</a>, so that they can learn about objects on the routes they drive, may be an important step in making AV practical. In real life, most people drive over routes they are already familiar with. Autonomous vehicles should have the same advantage.</li><li>The argument about whether Google’s LaMDA is “sentient” continues, with a Google engineer placed on administrative leave for <a href=\"https://www.theguardian.com/technology/2022/jun/12/google-engineer-ai-bot-sentient-blake-lemoine\" rel=\"noreferrer noopener\" target=\"_blank\">publishing transcripts of conversations</a> that he claimed demonstrate sentience. Or are large language models just <a href=\"https://twitter.com/janellecshane/status/1535835610396692480\" rel=\"noreferrer noopener\" target=\"_blank\">squirrels</a>?</li><li>For <a href=\"https://techxplore.com/news/2022-06-ai-future-art.html\" rel=\"noreferrer noopener\" target=\"_blank\">artists working in collaboration with AI</a>, the possibilities and imperfections of AI are a means of extending their creativity.</li><li>Pete Warden’s proposal for <a href=\"https://petewarden.com/2022/06/09/what-are-ml-sensors/\" rel=\"noreferrer noopener\" target=\"_blank\">ML Sensors</a> could make developing embedded ML systems much simpler: push the machine learning into the sensors themselves.</li><li>Researchers using DALL-E 2 discovered that <a href=\"https://theconversation.com/do-ai-systems-really-have-their-own-secret-language-184335\" rel=\"noreferrer noopener\" target=\"_blank\">the model has a “secret vocabulary”</a> that’s not human language, but that can be used somewhat reliably to create consistent pictures. It may be an artifact of the model’s inability to say “I didn’t understand that”; given nonsense input, it is pulled towards similar words in the training corpus.</li><li>HuggingFace has made an <a href=\"https://huggingface.co/blog/hugging-face-endpoints-on-azure\" rel=\"noreferrer noopener\" target=\"_blank\">agreement</a> with Microsoft that will allow Azure customers to <a href=\"https://thenextweb.com/news/what-hugging-face-and-microsofts-collaboration-means-for-applied-ai\" rel=\"noreferrer noopener\" target=\"_blank\">run HuggingFace language models on the Azure platform</a>.</li><li>The startup <a href=\"https://predibase.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Predibase</a> has built a <a href=\"https://thenewstack.io/predibase-takes-declarative-approach-to-automl/\" rel=\"noreferrer noopener\" target=\"_blank\">declarative low-code platform</a> for building AI systems. In a declarative system, you describe the outcome you want, rather than the process for creating the outcome. The system figures out the process.</li><li>Researchers are developing AI models that implement <a href=\"https://techxplore.com/news/2022-06-artificial-intelligence-human.html\" rel=\"noreferrer noopener\" target=\"_blank\">metamemory</a>: the ability to remember whether or not you know something.</li><li>As the population ages, it will be more important to diagnose diseases like Alzheimer’s early, when treatment is still meaningful. AI is <a href=\"https://www.technologyreview.com/2022/06/02/1052942/evaluating-brain-mri-scans-with-the-help-of-artificial-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">providing tools</a> to help doctors analyze MRI images more accurately than humans. These tools don’t attempt diagnosis; they provide data about brain features.</li><li>Google has <a href=\"https://www.bleepingcomputer.com/news/technology/google-quietly-bans-deepfake-training-projects-on-colab/\" rel=\"noreferrer noopener\" target=\"_blank\">banned the training of Deepfakes</a> on Colab, its free Jupyter-based cloud programming platform.</li></ul>\\n\\n\\n\\n<h2>Metaverse</h2>\\n\\n\\n\\n<ul><li>Samsung and RedHat are working on <a href=\"https://thenewstack.io/samsung-red-hat-to-work-on-linux-drivers-for-future-tech/\" rel=\"noreferrer noopener\" target=\"_blank\">new memory architectures and device drivers</a> that will be adequate to the demands of a 3D-enabled, cloud-based metaverse.</li><li>The <a href=\"https://metaverse-standards.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Metaverse Standards Forum</a> is a new industry group with the goal of solving interoperability problems for the Metaverse. It views the Metaverse as the outgrowth of the Web, and plans to coordinate work between existing standards groups (like the W3C) relevant to the Metaverse.</li><li>Can the “<a href=\"https://thenewstack.io/how-the-open-metaverse-will-transform-our-online-identities/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Metaverse</a>” be the future of the Internet?&nbsp; The <a href=\"https://github.com/omigroup/omigroup/\" rel=\"noreferrer noopener\" target=\"_blank\">Open Metaverse Interoperability Group</a> is building vendor-independent standards for social graphs, identities, and other elements of a Metaverse.</li><li><a href=\"https://techxplore.com/news/2022-06-augmented-reality-head-up-next-gen.html\" rel=\"noreferrer noopener\" target=\"_blank\">Holographic heads-up displays</a> allow for 3D augmented reality: the ability to project 3D images onto the real world (for example, onto a car’s windshield).</li><li>Google’s <a href=\"https://medium.com/@bilawal/new-google-api-turns-the-world-into-a-3d-canvas-for-augmented-reality-developers-on-ios-android-5c541a705800\" rel=\"noreferrer noopener\" target=\"_blank\">Visual Position Service</a> uses the data they’ve collected through Street View to provide high-accuracy positioning data for augmented reality applications. (This may be related to Niantic’s VPS, or they may just be using the same acronym.)</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>With the end of Roe v. Wade, <a href=\"https://www.siliconvalley.com/2022/06/27/search-histories-location-data-text-messages-how-personal-data-could-be-used-to-enforce-anti-abortion-laws/\" rel=\"noreferrer noopener\" target=\"_blank\">personal data, including search histories and location data, could be used to prosecute women who have abortions</a>. Data brokers already collect and sell this data. It is unclear how large Internet companies that also collect this data will respond. (Google has announced that they will <a href=\"https://blog.google/technology/safety-security/protecting-peoples-privacy-on-health-topics/\" rel=\"noreferrer noopener\" target=\"_blank\">delete location histories</a> that include visits to sensitive locations.)</li><li>Security researchers have identified over <a href=\"https://www.bleepingcomputer.com/news/security/over-900-000-kubernetes-instances-found-exposed-online/\" rel=\"noreferrer noopener\" target=\"_blank\">900,000 Kubernetes clusters that are exposed (and possibly vulnerable) to malicious scans</a>. 65% of them are in the US.</li><li>Sonatype has discovered a number of <a href=\"https://blog.sonatype.com/python-packages-upload-your-aws-keys-env-vars-secrets-to-web\" rel=\"noreferrer noopener\" target=\"_blank\">modules in the Python’s PyPI repository that steal AWS credentials</a> and other important data. Supply chain security will continue to be a problem for developers, regardless of the programming language or problem domain.</li><li><a href=\"https://blogs.microsoft.com/on-the-issues/2022/06/22/defending-ukraine-early-lessons-from-the-cyber-war/\" rel=\"noreferrer noopener\" target=\"_blank\">Microsoft’s analysis of Russia’s cyberwar efforts</a> show that they have increasingly attacked resources in countries allied with Ukraine (most notably the US), and that government computers that are on-premises are especially vulnerable.</li><li>Working with Fastly and Cloudflare, Apple has developed a service called <a href=\"https://thenextweb.com/news/apple-ios-16-banish-captchas\" rel=\"noreferrer noopener\" target=\"_blank\">Automatic Verification</a> that eliminates the need for Captchas. According to rumors, it will be enabled by default in the beta of iOS16.</li><li>A surprisingly small botnet (only 5,000 hosts) generated a <a href=\"https://arstechnica.com/information-technology/2022/06/tsunami-of-junk-traffic-that-broke-ddos-records-delivered-by-tiniest-of-botnets/\" rel=\"noreferrer noopener\" target=\"_blank\">record-setting DDOS attack</a> that peaked at 26M HTTPS requests per second. The botnet was so powerful because most of its devices belonged to cloud providers. Cloudflare’s free service was able to mitigate the attack.</li><li>A different kind of attack against neural networks: present them with <a href=\"https://ieeexplore.ieee.org/document/9581273\" rel=\"noreferrer noopener\" target=\"_blank\">inputs that drive worst-case energy consumption</a>, forcing processors to reduce their clock speed or even overheat. </li><li>A new attack called Hertzbleed uses <a href=\"https://arstechnica.com/tech-policy/2022/06/cryptocurrency-plunges-as-crypto-bank-celsius-suspends-withdrawals/\" rel=\"noreferrer noopener\" target=\"_blank\">small variations in a processor’s clock speed</a> while it is processing encryption keys to guess those keys. Intel and AMD CPUs are vulnerable. While this attack may never be seen in the wild, it shows how the complexity of modern processors creates vulnerabilities.</li><li><a href=\"https://www.bleepingcomputer.com/news/security/new-symbiote-malware-infects-all-running-processes-on-linux-systems/\" rel=\"noreferrer noopener\" target=\"_blank\">Symbiote is a new kind of malware that attacks Linux</a>, injects software into all running processes, and uses Berkeley packet filters (eBPF) to steal data and create covert communications channels. Symbiote uses <a href=\"https://thenewstack.io/the-symbiote-malware-what-we-know-so-far/\" rel=\"noreferrer noopener\" target=\"_blank\">dynamic linker hijacking</a> to link executables to modified system libraries at run time.</li><li>In the first quarter of 2022, the <a href=\"https://www.bleepingcomputer.com/news/security/ransomware-gangs-now-give-victims-time-to-save-their-reputation/\" rel=\"noreferrer noopener\" target=\"_blank\">number of known ransomware attacks was down 40%</a>, largely due to the disappearance of the Conti ransomware group. This drop is probably only temporary. Tactics also changed; attackers aren’t announcing the names of their victims publicly, preferring to negotiate a ransom privately. </li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Amazon has launched <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\" rel=\"noreferrer noopener\" target=\"_blank\">CodeWhisperer</a>, a direct competitor to GitHub Copilot.</li><li>Linus Torvalds predicts that <a href=\"https://thenewstack.io/rust-in-the-linux-kernel-by-2023-linus-torvalds-predicts/\" rel=\"noreferrer noopener\" target=\"_blank\">Rust will be used in the Linux kernel by 2023</a>.</li><li>GitHub Copilot is now <a href=\"https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/\" rel=\"noreferrer noopener\" target=\"_blank\">generally available</a> (for a price); it’s free to students and open source maintainers. Corporate licenses will be available later this year.</li><li>WebAssembly is making inroads. The universal WebAssembly runtime, <a href=\"https://wasmer.io/\" rel=\"noreferrer noopener\" target=\"_blank\">Wasmer</a>, runs any code, on any platform. Impressive, if it delivers.</li><li><a href=\"https://thenewstack.io/when-webassembly-replaces-docker/\" rel=\"noreferrer noopener\" target=\"_blank\">Can WebAssembly replace Docker?</a> Maybe, in some applications. WASM provides portability and eliminates some security issues (possibly introducing its own); Docker sets up environments.</li><li>Mozilla’s <a href=\"https://blog.mozilla.org/en/mozilla/local-translation-add-on-project-bergamot/\" rel=\"noreferrer noopener\" target=\"_blank\">Project Bergamot</a> is an automated translation tool designed for use on the Web. It can be used to build multilingual forms and other web pages. Unlike most other AI technologies, Bergamot runs in the browser using WASM. No data is sent to the cloud.</li><li>Microsoft has <a href=\"https://thenewstack.io/microsoft-talks-collaborative-apps-at-build-conference/\" rel=\"noreferrer noopener\" target=\"_blank\">released</a> a framework called <a href=\"https://fluidframework.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Fluid</a> for building collaborative apps, such as Slack, Discord, and Teams. Microsoft will also be releasing <a href=\"https://docs.microsoft.com/en-us/azure/azure-fluid-relay/\" rel=\"noreferrer noopener\" target=\"_blank\">Azure Fluid Relay</a> to support Fluid-based applications.</li><li><a href=\"https://github.com/dragonflydb/dragonfly\" rel=\"noreferrer noopener\" target=\"_blank\">Dragonfly</a> is a new in-memory database that claims significantly faster performance than memcached and Redis.</li><li>The Chinese government has <a href=\"https://www.technologyreview.com/2022/05/30/1052879/censoring-china-open-source-backfire/\" rel=\"noreferrer noopener\" target=\"_blank\">blocked access to open source code</a> on Gitee, the Chinese equivalent to GitHub, saying that all code must be reviewed by the government before it can be released to the public.</li></ul>\\n\\n\\n\\n<h2>Web3</h2>\\n\\n\\n\\n<ul><li><a href=\"https://blog.trailofbits.com/2022/06/21/are-blockchains-decentralized/\" rel=\"noreferrer noopener\" target=\"_blank\">Is Blockchain Decentralized?</a> <a href=\"https://assets-global.website-files.com/5fd11235b3950c2c1a3b6df4/62af6c641a672b3329b9a480_Unintended_Centralities_in_Distributed_Ledgers.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">A study commissioned by DARPA</a> investigates whether a blockchain is truly immutable, or whether it can be modified without exploiting cryptographic vulnerabilities, but by attacking the blockchain’s implementation, networking, and consensus protocols. This is the most comprehensive examination of blockchain security that we’ve seen. </li><li>Jack Dorsey has announced that he’s working on <a href=\"https://cryptobriefing.com/jack-dorsey-tbd-build-web5-on-bitcoin/\" rel=\"noreferrer noopener\" target=\"_blank\">Web5</a>, which will be focused on identity management and be based on Bitcoin.</li><li>Molly White’s post questioning the possibility of <a href=\"https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/\" rel=\"noreferrer noopener\" target=\"_blank\">acceptably non-dystopian self-sovereign identity</a> is a must-read; she has an excellent summary and critique of just about all the work going on in the field.</li><li>Cryptographer Matthew Green makes an important <a href=\"https://blog.cryptographyengineering.com/2022/06/09/in-defense-of-cryptocurrency/\" rel=\"noreferrer noopener\" target=\"_blank\">argument for the technologies behind cryptocurrency</a> (though not for the current implementations).</li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>The Innovative Genomics Institute is trying to <a href=\"https://www.technologyreview.com/2022/06/14/1053843/carbon-capture-crispr-crops/\" rel=\"noreferrer noopener\" target=\"_blank\">use CRISPR gene editing to optimize plants for carbon storage</a>.</li><li>A printed artificial skin with embedded transistors may <a href=\"https://techxplore.com/news/2022-06-artificial-skin-capable-pain-touch-sensitive.html\" rel=\"noreferrer noopener\" target=\"_blank\">allow robots to feel pain</a>. That’s one step closer to dreaming of electric sheep.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://techxplore.com/news/2022-06-potential-p-computers.html\" rel=\"noreferrer noopener\" target=\"_blank\">Probabilistic computers</a>, built from probabilistic bits (p-bits), may provide a significant step forward for probabilistic decision making. This sounds esoteric, but it’s essentially what we’re asking AI systems to do. P-bits may also be able to simulate q-bits and quantum computing.</li><li>A system that <a href=\"https://thenextweb.com/news/eureka-scientists-just-linked-two-time-crystals-together-first-time\" rel=\"noreferrer noopener\" target=\"_blank\">links two time crystals</a> could be the basis for a new form of quantum computing. Time crystals can exist at room temperature, and remain coherent for much longer than existing qubit technologies.</li></ul>'}], 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/feed/', '0', 32]]\n"
     ]
    }
   ],
   "source": [
    "machine_learning_entries = entries_df[entries_df[\"summary\"].str.contains(\"DALL-E\")]\n",
    "\n",
    "machine_learning_entries_list = machine_learning_entries.values.tolist()\n",
    "\n",
    "print(machine_learning_entries_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
