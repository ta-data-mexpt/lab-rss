{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with RSS Feeds Lab\n",
    "\n",
    "Complete the following set of exercises to solidify your knowledge of parsing RSS feeds and extracting information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use feedparser to parse the following RSS feed URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://feeds.feedburner.com/oreilly/radar/atom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bozo': False,\n",
       " 'entries': [{'title': 'Low-Code and the Democratization of Programming',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Low-Code and the Democratization of Programming'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/low-code-and-the-democratization-of-programming/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/low-code-and-the-democratization-of-programming/',\n",
       "   'comments': 'https://www.oreilly.com/radar/low-code-and-the-democratization-of-programming/#respond',\n",
       "   'published': 'Tue, 16 Nov 2021 12:36:18 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=11, tm_mday=16, tm_hour=12, tm_min=36, tm_sec=18, tm_wday=1, tm_yday=320, tm_isdst=0),\n",
       "   'authors': [{}],\n",
       "   'author': '',\n",
       "   'tags': [{'term': 'Programming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=14083',\n",
       "   'guidislink': False,\n",
       "   'summary': 'In the past decade, the growth in low-code and no-code solutions—promising that anyone can create simple computer programs using templates—has become a multi-billion dollar industry that touches everything from data and business analytics to application building and automation. As more companies look to integrate low-code and no-code solutions into their digital transformation plan, the question [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'In the past decade, the growth in low-code and no-code solutions—promising that anyone can create simple computer programs using templates—has become a multi-billion dollar industry that touches everything from data and business analytics to application building and automation. As more companies look to integrate low-code and no-code solutions into their digital transformation plan, the question [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>In the past decade, the growth in low-code and no-code solutions—promising that anyone can create simple computer programs using templates—has become a multi-billion dollar industry that touches everything from data and business analytics to application building and automation. As more companies look to integrate low-code and no-code solutions into their digital transformation plan, the question emerges again and again: what will happen to programming?</p>\\n\\n\\n\\n<p>Programmers know their jobs won’t disappear with a broadscale low-code takeover (even low-code is built on code), but undeniably their roles as programmers will shift as more companies adopt low-code solutions. This report is for programmers and software development teams looking to navigate that shift and understand how low-code and no-code solutions will shape their approach to code and coding. It will be fundamental for anyone working in software development—and, indeed, anyone working in any business that is poised to become a digital business—to understand what low-code means, how it will transform their roles, what kinds of issues it creates, why it won’t work for everything, and what new kinds of programmers and programming will emerge as a result.</p>\\n\\n\\n\\n<h2>Everything Is Low-Code</h2>\\n\\n\\n\\n<p>Low-code: what does it even mean? “Low-code” sounds simple: less is more, right? But we’re not talking about modern architecture; we’re talking about telling a computer how to achieve some result. In that context, low-code quickly becomes a complex topic.</p>\\n\\n\\n\\n<p>One way of looking at low-code starts with the spreadsheet, which has a&nbsp;<a href=\"https://oreil.ly/qG48P\" rel=\"noreferrer noopener\" target=\"_blank\">pre-history</a>&nbsp;that goes back to the&nbsp;1960s—and,&nbsp;if we consider paper, even earlier. It’s a different, non-procedural, non-algorithmic approach to doing computation that has been wildly successful: is there anyone in finance who can’t use Excel? Excel has become table stakes. And spreadsheets have enabled a whole generation of businesspeople to use computers effectively—most of whom have never used any other programming language, and wouldn’t have wanted to learn a more “formal” programming language. So we could think about low-code as tools similar to Excel, tools that enable people to use computers effectively without learning a formal programming language.</p>\\n\\n\\n\\n<p>Another way of looking at low-code is to take an even bigger step back, and look at the history of programming from the start. Python is low-code relative to C++; C and FORTRAN are low-code relative to assembler; assembler is low-code relative to machine language and toggling switches to insert binary instructions directly into the computer’s memory. In this sense, the history of programming is the history of low-code. It’s a history of democratization and reducing barriers to entry. (Although, in an ironic and unfortunate twist, many of the people who spent their careers plugging in patch cords, toggling in binary, and doing math on mechanical calculators&nbsp;<a href=\"https://oreil.ly/r6QOK\">were</a>&nbsp;<a href=\"https://oreil.ly/jEImN\" rel=\"noreferrer noopener\" target=\"_blank\">women</a>, who were later forced out of the industry as those jobs became “professional.” Democratization is relative.) It may be surprising to say that Python is a low-code language, but it takes less work to accomplish something in Python than in C; rather than building everything from scratch, you’re relying on millions of lines of code in the Python runtime environment and its libraries.</p>\\n\\n\\n\\n<p>In taking this bigger-picture, language-based approach to understanding low-code, we also have to take into account what the low-code language is being used for. Languages like Java and C++ are intended for large projects involving collaboration between teams of programmers. These are projects that can take years to develop, and run to millions of lines of code. A language like bash or Perl is designed for short programs that connect other utilities; bash and Perl scripts typically have a single author, and are frequently only a few lines long. (Perl is legendary for inscrutable one-liners.) Python is in the middle. It’s not great for large programs (though it has certainly been used for them); its sweet spot is programs that are a few hundred lines long. That position between big code and minimal code probably has a lot to do with its success. A successor to Python might require less code (and be a “lower code” language, if that’s meaningful); it would almost certainly have to do something better. For example, R (a domain-specific language for stats) may be a better language for doing heavy duty statistics, and we’ve been told many times that it’s easier to learn if you think like a statistician. But that’s where the trade-off becomes apparent. Although R has a web framework that allows you to build data-driven dashboards, you wouldn’t use R to build an e-commerce or an automated customer service agent; those are tasks for which Python is well suited.</p>\\n\\n\\n\\n<p>Is it completely out of bounds to say that Python is a low-code language? Perhaps; but it certainly requires much less coding than the languages of the 1960s and &#8217;70s. Like Excel, though not as successfully, Python has made it possible for people to work with computers who would never have learned C or C++. (The same claim could probably be made for BASIC, and certainly for Visual Basic.)</p>\\n\\n\\n\\n<p>But this makes it possible for us to talk about an even more outlandish meaning of low-code. Configuration files for large computational systems, such as Kubernetes, can be extremely complex. But configuring a tool is almost always simpler than writing the tool yourself. Kelsey Hightower&nbsp;<a href=\"https://oreil.ly/vesCZ\" rel=\"noreferrer noopener\" target=\"_blank\">said</a>&nbsp;that Kubernetes is the “sum of all the bash scripts and best practices that most system administrators would cobble together over time”; it’s just that many years of experience have taught us the limitations of endless scripting. Replacing a huge and tangled web of scripts with a few configuration files certainly sounds like low-code. (You could object that Kubernetes’ configuration language isn’t Turing complete, so it’s not a programming language. Be that way.) It enables operations staff who couldn’t write Kubernetes from scratch, regardless of the language, to create configurations that manage very complicated distributed systems in production. What’s the ratio—a few hundred lines of Kubernetes configuration, compared to a million lines of Go, the language Kubernetes was written in? Is that low-code? Configuration languages are rarely simple, but they’re always simpler than writing the program you’re configuring.</p>\\n\\n\\n\\n<p>As examples go, Kubernetes isn’t all that unusual. It’s an example of a “domain-specific language” (DSL) constructed to solve a specific kind of problem. DSLs enable someone to get a task done without having to describe the whole process from scratch, in immense detail. If you look around, there’s no shortage of domain-specific languages.&nbsp;<a href=\"https://rubyonrails.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Ruby on Rails</a>&nbsp;was originally described as a DSL. COBOL was a DSL before anyone really knew what a DSL was. And so are many mainstays of Unix history:&nbsp;<em>awk</em>,&nbsp;<em>sed</em>, and even the Unix shell (which is much simpler than using old&nbsp;<a href=\"https://oreil.ly/crAGp\" rel=\"noreferrer noopener\" target=\"_blank\">IBM JCL</a>s to run a program). They all make certain programming tasks simpler by relying on a lot of code that’s hidden in libraries, runtime environments, and even other programming languages. And they all sacrifice generality for ease of use in solving a specific kind of problem.</p>\\n\\n\\n\\n<p>So, now that we’ve broadened the meaning of low-code to include just about everything, do we give up? For the purposes of this report, we’re probably best off looking at the narrowest and most likely implementation of low-code technology and limiting ourselves to the first, Excel-like meaning of “low-code”—but remembering that the history of programming is the history of enabling people to do more with less, enabling people to work with computers without requiring as much formal education, adding layer upon layer of abstraction so that humans don’t need to understand the 0s and the 1s. So Python is low-code. Kubernetes is low-code. And their successors will inevitably be even lower-code; a lower-code version of Kubernetes might well be built&nbsp;<a href=\"https://oreil.ly/UnbbF\" rel=\"noreferrer noopener\" target=\"_blank\">on top of the Kubernetes API</a>. Mirantis has taken a step in that direction by building an&nbsp;<a href=\"https://oreil.ly/W4CVm\" rel=\"noreferrer noopener\" target=\"_blank\">Integrated Development Environment (IDE) for Kubernete</a><a href=\"https://oreil.ly/W4CVm\">s</a>. Can we imagine a spreadsheet-like (or even graphical) interface to Kubernetes configuration? We certainly can, and we’re fine with putting Python to the side. We’re also fine with putting Kubernetes aside, as long as we remember that DSLs are an important part of the low-code picture: in&nbsp;<a href=\"https://oreil.ly/haiKH\" rel=\"noreferrer noopener\" target=\"_blank\">Paul Ford’s</a><a href=\"https://oreil.ly/haiKH\"> words</a>, tools to help users do whatever “makes the computer go.”</p>\\n\\n\\n\\n<h3>Excel (And Why It Works)</h3>\\n\\n\\n\\n<p>Excel deservedly comes up in any discussion of low-code programming. So it’s worth looking at what it does (and let’s willfully ignore Excel’s immediate ancestors,&nbsp;<a href=\"https://oreil.ly/bchdN\" rel=\"noreferrer noopener\" target=\"_blank\">VisiCalc</a>&nbsp;and&nbsp;<a href=\"https://oreil.ly/kWIhe\" rel=\"noreferrer noopener\" target=\"_blank\">Lotus</a>). Why has Excel succeeded?</p>\\n\\n\\n\\n<p>One important difference between spreadsheets and traditional programming languages is so obvious that it’s easily overlooked. Spreadsheets are “written” on a two-dimensional grid (Figure 1). Every other programming language in common use is a list of\\xa0statements: a list of instructions that are executed more or less\\xa0sequentially.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14095\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/11/lcdp_0101-1048x348.png\" /><figcaption><em>Figure 1.\\xa0A Microsoft Excel grid (source:\\xa0</em><a href=\"https://oreil.ly/30QKZ\" rel=\"noreferrer noopener\" target=\"_blank\">Python for Excel</a><em>)</em></figcaption></figure>\\n\\n\\n\\n<p>What’s a 2D grid useful for? Formatting, for one thing. It’s great for making tables. Many Excel files do that—and no more. There are no formulas, no equations, just text (including numbers) arranged into a grid and aligned properly. By itself, that is tremendously enabling.</p>\\n\\n\\n\\n<p>Add the simplest of equations, and built-in understanding of numeric datatypes (including the all-important financial datatypes), and you have a powerful tool for building very simple applications: for example, a spreadsheet that sums a bunch of items and computes sales tax to do simple invoices. A spreadsheet that computes loan payments. A spreadsheet that estimates the profit or loss (P&amp;L) on a project.</p>\\n\\n\\n\\n<p>All of these could be written in Python, and we could argue that most of them could be written in Python with less code. However, in the real world, that’s not how they’re written. Formatting is a huge value, in and of itself. (Have you ever tried to make output columns line up in a “real” programming language? In most programming languages, numbers and texts are formatted using an arcane and non-intuitive syntax. It’s not pretty.) The ability to think without loops and a minimal amount of programming logic (Excel has a primitive IF statement) is important. Being able to structure the problem in two or three dimensions (you get a third dimension if you use multiple sheets) is useful, but most often, all you need to do is SUM a column.</p>\\n\\n\\n\\n<p>If you do need a complete programming language, there’s always been Visual Basic—not part of Excel strictly speaking, but that&nbsp;distinction&nbsp;really isn’t meaningful. With the recent addition of&nbsp;<a href=\"https://oreil.ly/lF30q\" rel=\"noreferrer noopener\" target=\"_blank\">LAMBDA</a>&nbsp;functions, Excel is now a complete programming language in its own right. And Microsoft recently released&nbsp;<a href=\"https://oreil.ly/in8eA\" rel=\"noreferrer noopener\" target=\"_blank\">Power Fx</a>&nbsp;as an Excel-based low-code programming language; essentially, it’s Excel equations with something that looks like a web application replacing the 2D spreadsheet.</p>\\n\\n\\n\\n<p>Making Excel a 2D language accomplished two things: it gave users the ability to format simple tables, which they really cared about; and it enabled them to think in columns and rows. That’s not sophisticated, but it’s very, very useful. Excel gave a new group of people the ability to use computers effectively. It’s been too long since we’ve used the phrase “become creative,” but that’s exactly what Excel did: it helped more people to become creative. It created a new generation of “citizen programmers” who never saw themselves as programmers—just more effective users.</p>\\n\\n\\n\\n<p>That’s what we should expect of a low-code language. It isn’t about the amount of code. It’s about extending the ability to create to more people by changing paradigms (1D to 2D), eliminating hard parts (like formatting), and limiting what can be done to what most users need to do. This is democratizing.</p>\\n\\n\\n\\n<h3>UML</h3>\\n\\n\\n\\n<p>UML (Unified Modeling Language) was a visual language for describing the design of object oriented systems. UML was often misused by programmers who thought that UML diagrams somehow validated a design, but it gave us something that we didn’t have, and arguably needed: a common language for scribbling software architectures on blackboards and whiteboards. The architects who design buildings have a very detailed visual language for blueprints: one kind of line means a concrete wall, another wood, another wallboard, and so on. Programmers wanted to design software with a visual vocabulary that was equally rich.</p>\\n\\n\\n\\n<p>It’s not surprising that vendors built products to compile UML diagrams into scaffolds of code in various programming languages. Some went further to add an “action language” that turned UML into a complete programming language in its own right. As a visual language, UML required different kinds of tools: diagram editors, rather than text editors like Emacs or vi (or Visual Studio). In modern software development processes, you’d also need the ability to check the UML diagrams themselves (not the generated code) into some kind of source management system; i.e., the important artifact is the diagram, not something generated from the diagram. But UML proved to be too complex and heavyweight. It tried to be everything to everybody: both a standard notation for high-level design and visual tool for building software. It’s still used, though it has fallen out of favor.</p>\\n\\n\\n\\n<p>Did UML give anyone a new way of thinking about programming? We’re not convinced that it did, since programmers were already good at making diagrams on whiteboards. UML was of, by, and for engineers, from the start. It didn’t have any role in democratization. It reflected a desire to standardize notations for high-level design, rather than rethink it. Excel and other spreadsheets enabled more people to be creative with computers; UML didn’t.</p>\\n\\n\\n\\n<h3>LabVIEW</h3>\\n\\n\\n\\n<p><a href=\"https://oreil.ly/Dka0f\" rel=\"noreferrer noopener\" target=\"_blank\">LabVIEW</a>&nbsp;is a commercial system that’s widely used in industry—primarily in research &amp; development—for data collection and automation. The high-school&nbsp;<a href=\"https://www.firstinspires.org/\" rel=\"noreferrer noopener\" target=\"_blank\">FIRST Robotics</a>&nbsp;program depends heavily on it. The visual language that LabVIEW is built on is called G, and doesn’t have a textual representation. The dominant metaphor for G is a control panel or dashboard (or possibly an entire laboratory). Inputs are called “controls”; outputs are called “indicators.” Functions are “virtual instruments,” and are connected to each other by “wires.” G is a&nbsp;<a href=\"https://oreil.ly/tivSy\" rel=\"noreferrer noopener\" target=\"_blank\">dataflow</a>&nbsp;language, which means that functions run as soon as all their inputs are available; it is inherently&nbsp;parallel.</p>\\n\\n\\n\\n<p>It’s easy to see how a non-programmer could create software with LabVIEW doing nothing more than connecting together virtual instruments, all of which come from a library. In that sense, it’s democratizing: it lets non-programmers create software visually, thinking only about where the data comes from and where it needs to go. And it lets hardware developers build abstraction layers on top of FPGAs and other low-level hardware that would otherwise have to be programmed in languages like&nbsp;<a href=\"https://oreil.ly/ZwKeB\" rel=\"noreferrer noopener\" target=\"_blank\">Verilog</a>&nbsp;or&nbsp;<a href=\"https://oreil.ly/HpVpY\" rel=\"noreferrer noopener\" target=\"_blank\">VHDL</a>. At the same time, it is easy to underestimate the technical sophistication required to get a complex system working with LabVIEW. It is visual, but it isn’t necessarily simple. Just as in Fortran or Python, it’s possible to build complex libraries of functions (“virtual instruments”) to encapsulate standard tasks. And the fact that LabVIEW is visual doesn’t eliminate the need to understand, in depth, the task you’re trying to automate, and the hardware on which you’re automating it.</p>\\n\\n\\n\\n<p>As a purely visual language, LabVIEW doesn’t play well with modern tools for source control, automated testing, and deployment. Still, it’s an important (and commercially successful) step away from the traditional programming paradigm. You won’t see lines of code anywhere, just wiring diagrams (Figure 2). Like Excel, LabVIEW provides a different way of thinking about programming. It’s still code, but it’s a different kind of code, code that looks more like circuit diagrams than punch cards.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14096\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/11/lcdp_0102-1048x409.png\" /><figcaption><em>Figure 2.\\xa0An example of a LabVIEW schematic diagram\\xa0(source:\\xa0</em><a href=\"https://oreil.ly/v8Ued\" rel=\"noreferrer noopener\" target=\"_blank\">JKI</a><em>)</em></figcaption></figure>\\n\\n\\n\\n<h3>Copilot</h3>\\n\\n\\n\\n<p>There has been a lot of research on using AI to generate code from human descriptions. GPT-3 has made that work more widely visible, but it’s been around for a while, and it’s ongoing. We’ve written about using&nbsp;<a href=\"https://oreil.ly/rt64V\" rel=\"noreferrer noopener\" target=\"_blank\">AI as a partner in pair programming</a>. While we were writing this report, Microsoft, OpenAI, and GitHub announced the first fruit of this research:&nbsp;<a href=\"https://copilot.github.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Copilot</a>, an AI tool that was trained on all the public code in GitHub’s codebase. Copilot makes suggestions while you write code, generating function bodies based on descriptive comments (Figure 3). Copilot turns programming on its head: rather than writing the code first, and adding comments as an afterthought, start by thinking carefully about the problem you want to solve and describing what the components need to do. (This inversion has some&nbsp;similarities&nbsp;to&nbsp;<a href=\"https://oreil.ly/6GbYb\" rel=\"noreferrer noopener\" target=\"_blank\">test-driven</a>&nbsp;and&nbsp;<a href=\"https://oreil.ly/22d9U\" rel=\"noreferrer noopener\" target=\"_blank\">behavior-driven&nbsp;development</a>.)</p>\\n\\n\\n\\n<p>Still, this approach begs the question: how much work is required to find a description that generates the right code? Could technology like this be used to build a real-world project, and if so, would that help to democratize programming? It’s a fair question. Programming languages are precise and unambiguous, while human\\xa0languages\\xa0are by nature imprecise and ambiguous. Will compiling human language into code require a significant body of rules to make it, essentially, a programming language in its own right? Possibly. But on the other hand, Copilot takes on the burden of remembering syntax details, getting function names right, and many other tasks that are fundamentally just memory exercises.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14097\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/11/lcdp_0103-1048x523.png\" /><figcaption><em>Figure 3.\\xa0GitHub’s Copilot in action (source:\\xa0</em><a href=\"https://copilot.github.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Copilot</a><em>)</em></figcaption></figure>\\n\\n\\n\\n<p>Salvatore Sanfilippo (@antirez) touched on this in&nbsp;<a href=\"https://oreil.ly/RrjpQ\" rel=\"noreferrer noopener\" target=\"_blank\">a Twitter thread</a>, saying “Every task Copilot can do for you is a task that should NOT be part of modern programming.” Copilot doesn’t just free you from remembering syntax details, what functions are stashed in a library you rarely use, or how to implement some algorithm that you barely remember. It eliminates the boring drudgery of much of programming—and, let’s admit it, there’s a lot of that. It frees you to be more creative, letting you think more carefully about that task you’re doing, and how best to perform it. That’s liberating—and it extends programming to those who aren’t good at rote memory, but who are experts (“subject matter experts”) in solving particular problems.</p>\\n\\n\\n\\n<p>Copilot is in its very early days; it’s called a “Technical Preview,” not even a beta. It’s certainly not problem-free. The code it generates is often incorrect (though you can ask it to create any number of alternatives, and one is likely to be correct). But it will almost certainly get better, and it will probably get better fast. When the code works, it’s often low-quality; as Jeremy Howard&nbsp;<a href=\"https://oreil.ly/h6CAz\" rel=\"noreferrer noopener\" target=\"_blank\">writes</a>, language models reflect an average of how people use language, not great literature. Copilot is the same. But more importantly, as Howard says, most of a programmer’s work isn’t writing new code: it’s designing,&nbsp;debugging, and maintaining code. To use Copilot well, programmers will have to realize the trade-off: most of the work of programming won’t go away. You will need to understand, at a higher level, what you’re trying to do. For Sanfilippo, and for most good or great programmers, the interesting, challenging part of programming comes in that higher-level work, not in slinging curly braces.</p>\\n\\n\\n\\n<p>By reducing the labor of writing code, allowing people to focus their effort on higher-level thought about what they want to do rather than on syntactic correctness, Copilot will certainly make creative computing possible for more people. And that’s democratization.</p>\\n\\n\\n\\n<h3>Glitch</h3>\\n\\n\\n\\n<p>Glitch, which has become a compelling platform for developing web applications, is another alternative. Glitch claims to return to the copy/paste model from the early days of web development, when you could “view source” for any web page, copy it, and make any changes you want. That model doesn’t eliminate code, but offers a different approach to understanding coding. It reduces the amount of code you write; this in itself is democratizing because it enables more people to accomplish things more quickly. Learning to program isn’t fun if you have to work for six months before you can build something you actually want. It gets you interacting with code that’s already written and working from the start (Figure 4); you don’t have to stare at a blank screen and invent all the technology you need for the features you want. And it’s completely portable: Glitch code is just HTML, CSS, and JavaScript stored in a GitHub archive. You can take that code, modify it, and deploy it anywhere; you’re not stuck with Glitch’s proprietary app. Anil Dash, Glitch’s CEO, calls this\\xa0<a href=\"https://oreil.ly/kthcZ\" rel=\"noreferrer noopener\" target=\"_blank\">“Yes code”</a>, affirming the importance of code. Great artists steal from each other, and so do the great coders; Glitch is a platform that facilitates stealing, in all the best ways.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14098\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/11/lcdp_0104-1048x637.png\" /><figcaption><em>Figure 4.\\xa0Glitch’s prepopulated, comment-heavy React web application, which guides the user to using its code (source: Glitch)</em></figcaption></figure>\\n\\n\\n\\n<h3>Forms and Templates</h3>\\n\\n\\n\\n<p>Finally, many low-code platforms make heavy use of forms. This is particularly common among business intelligence (BI) platforms. You could certainly argue that filling in a form isn’t low-code at all, it’s just using a canned app; but think about what’s happening. The fields in the form are typically a template for filling in a complex SQL statement. A relational database executes that statement, and the results are formatted and displayed for the users. This is certainly democratizing: SQL expertise isn’t expected of most managers—or, for that matter, of most programmers. BI applications unquestionably allow people to do what they couldn’t do otherwise. (Anyone at O’Reilly can look up detailed sales data in O’Reilly’s BI system, even those of us who have never learned SQL or written programs in any language.) Painlessly formatting the results,&nbsp;including&nbsp;visualizations, is one of the qualities that made Excel&nbsp;revolutionary.</p>\\n\\n\\n\\n<p>Similarly, low-code platforms for building mobile and web apps—such as Salesforce, Webflow, Honeycode, and Airtable—provide non-programmers with drag-and-drop solutions for creating everything from consumer-facing apps to internal workflows via&nbsp;templated&nbsp;approaches and purport to be customizable, but are ultimately finite based on the offerings and capabilities of each particular&nbsp;platform.</p>\\n\\n\\n\\n<p>But do these templating approaches really allow a user to become creative? That may be the more important question. Templates arguably don’t. They allow the user to create one of a number (possibly a large number) of previously defined reports. But they rarely allow a user to create a new report without significant programming skills. In practice, regardless of how simple it may be to create a report, most users don’t go out of their way to create new reports. The problem isn’t that templating approaches are “ultimately finite”—that trade-off of limitations against ease comes with almost any low-code approach, and some template builders are extremely flexible. It’s that, unlike Excel, and unlike LabVIEW, and unlike Glitch, these tools don’t really offer new ways to think about problems.</p>\\n\\n\\n\\n<p>It’s worth noting—in fact, it’s absolutely essential to note—that these low-code approaches rely on huge amounts of traditional code. Even LabVIEW—it may be completely visual, but LabVIEW and G were implemented in a traditional programming language. What they’re really doing is allowing people with minimal coding skills to make connections between libraries. They enable people to work by connecting things together, rather than building the things that are being connected. That will turn out to be very important, as we’ll start to examine next.</p>\\n\\n\\n\\n<h2>Rethinking the Programmer</h2>\\n\\n\\n\\n<p>Programmers have cast themselves as gurus and rockstars, or as artisans, and to a large extent resisted democratization. In the web space, that has been very explicit: people who use HTML and CSS, but not sophisticated JavaScript, are “not real programmers.” It’s almost as if the evolution of the web from a Glitch-like world of copy and paste towards complex web apps took place with the intention of forcing out the great unwashed, and creating an underclass of coding-disabled.</p>\\n\\n\\n\\n<p>Low-code and no-code are about democratization, about extending the ability to be creative with computers and creating new citizen programmers. We’ve seen that it works in two ways: on the low end (as with Excel), it allows people with no formal programming background to perform computational tasks. Perhaps more significantly, Excel (and similar tools) allow a user to gradually work up the ladder to more complex tasks: from simple formatting to spreadsheets that do computation, to full-fledged programming.</p>\\n\\n\\n\\n<p>Can we go further? Can we enable subject matter experts to build sophisticated applications without needing to communicate their understanding to a group of coders? At the Strata Data Conference in 2019, Jeremy Howard discussed an AI application for&nbsp;<a href=\"https://oreil.ly/XlERc\" rel=\"noreferrer noopener\" target=\"_blank\">classifying burns</a>. This deep-learning application was trained by a dermatologist—a subject matter expert—who had no knowledge of programming. All the major cloud providers have services for automating machine learning, and there’s an ever-increasing number of&nbsp;<a href=\"https://oreil.ly/2BWTi\" rel=\"noreferrer noopener\" target=\"_blank\">AutoML</a>&nbsp;tools that aren’t tied to a specific provider. Eliminating the knowledge transfer between the SME and the programmer by letting SMEs build the application themselves is the shortest route to building better&nbsp;software.</p>\\n\\n\\n\\n<p>On the high end, the intersection between AI and programming promises to&nbsp;<a href=\"https://oreil.ly/aXYJI\" rel=\"noreferrer noopener\" target=\"_blank\">make skilled programmers more productive</a>&nbsp;by making suggestions, detecting bugs and vulnerabilities, and writing some of the boilerplate code itself.&nbsp;<a href=\"https://oreil.ly/ykmOt\" rel=\"noreferrer noopener\" target=\"_blank\">IBM</a>&nbsp;is trying to use AI to automate translations between different programming languages; we’ve already mentioned&nbsp;<a href=\"https://oreil.ly/wKLJs\" rel=\"noreferrer noopener\" target=\"_blank\">Microsoft’s work</a>&nbsp;on generating code from human-language descriptions of programming tasks, culminating with their Copilot project. This technology is still in the very early days, but it has the potential to change the nature of programming radically.</p>\\n\\n\\n\\n<p>These changes suggest that there’s another way of thinking about programmers. Let’s borrow the distinction between “blue-” and “white”-collar workers. Blue-collar programmers connect things; white-collar programmers build the things to be connected. This is similar to the distinction between the person who installs or connects household appliances and the person who designs them. You wouldn’t want your plumber designing your toilet; but likewise, you wouldn’t want a toilet designer (who wears a black turtleneck and works in a fancy office building) to install the toilet they designed.</p>\\n\\n\\n\\n<p>This model is hardly a threat to the industry as it’s currently institutionalized. We will always need people to connect things; that’s the bulk of what web developers do now, even those working with frameworks like React.js. In practice, there has been—and will&nbsp;continue&nbsp;to be—a lot of overlap between the “tool designer” and “tool user” roles. That won’t change. The essence of low-code is that it allows more people to connect things and become creative. We must never undervalue that creativity, but likewise, we have to understand that more people connecting things—managers, office workers, executives—doesn’t reduce the need for professional tools, any more than the 3D printers reduced the need for manufacturing engineers.</p>\\n\\n\\n\\n<p>The more people who are capable of connecting things, the more things need to be connected. Programmers will be needed to build everything from web widgets to the high-level tools that let citizen programmers do their work. And many citizen programmers will see ways for tools to be improved or have ideas about new tools that will help them become more productive, and will start to design and build their own tools.</p>\\n\\n\\n\\n<h2>Rethinking Programmer Education</h2>\\n\\n\\n\\n<p>Once we make the distinction between blue- and white-collar programmers, we can talk about what kinds of education are appropriate for the two groups. A plumber goes to a trade school and serves an apprenticeship; a designer goes to college, and may serve an internship. How does this compare to the ways programmers are educated?</p>\\n\\n\\n\\n<p>As complex as modern web frameworks like React.js may be (and we suspect they’re a very programmerly reaction against democratization), you don’t need a degree to become a competent web developer. The educational system is beginning to shift to take this into account. Boot camps (a format probably originating with Gregory Brown’s&nbsp;<a href=\"https://oreil.ly/pqoJJ\" rel=\"noreferrer noopener\" target=\"_blank\">Ruby Mendicant University</a>) are the programmer’s equivalent of trade schools. Many boot camps facilitate internships and initial jobs. Many students at boot camps already have degrees in a non-technical field, or in a technical field that’s not related to&nbsp;programming.</p>\\n\\n\\n\\n<p>Computer science majors in colleges and universities provide the “designer” education, with a focus on theory and algorithms. Artificial intelligence is a subdiscipline that originated in academia, and is still driven by academic research. So are disciplines like bioinformatics, which straddles the boundaries between biology, medicine, and computer science. Programs like&nbsp;<a href=\"https://datacarpentry.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Data Carpentry</a>&nbsp;and&nbsp;<a href=\"https://software-carpentry.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Software Carpentry</a>&nbsp;(two of the three organizations that make up&nbsp;<a href=\"https://carpentries.org/\" rel=\"noreferrer noopener\" target=\"_blank\">“The Carpentries”</a>) cater specifically to graduate students who want to improve their data or programming skills.</p>\\n\\n\\n\\n<p>This split matches a reality that we’ve always known. You’ve never needed a four-year computer science degree to get a programming job; you still don’t. There are many, many programmers who are self-taught, and some startup executives who never entered college (let alone finished it); as one programmer who left a senior position to found a successful startup once said in conversation, “I was making too much money building websites when I was in high school.” No doubt some of those who never entered college have made significant contributions in algorithms and theory.</p>\\n\\n\\n\\n<p>Boot camps and four-year institutions both have weaknesses. Traditional colleges and universities pay little attention to the parts of the job that aren’t software development: teamwork, testing, agile processes, as well as areas of software development that are central to the industry now, such as cloud computing. Students need to learn how to use databases and operating systems effectively, not design them. Boot camps, on the other hand,&nbsp;<a href=\"https://oreil.ly/SAF7L\" rel=\"noreferrer noopener\" target=\"_blank\">range</a>&nbsp;from the excellent to the mediocre. Many go deep on a particular framework, like Rails or React.js, but don’t give students a broader introduction to programming. Many engage in ethically questionable practices around payment (boot camps aren’t cheap) and job placement. Picking a good boot camp may be as difficult as choosing an undergraduate college.</p>\\n\\n\\n\\n<p>To some extent, the weaknesses of boot camps and traditional colleges can be helped through apprenticeships and internships. However, even that requires care: many companies use the language of the “agile” and CI/CD, but have only renamed their old, ineffective processes. How can interns be placed in positions where they can learn modern programming practices, when the companies in which they’re placed don’t understand those practices? That’s a critical problem, because we expect that trained programmers will, in effect, be responsible for bringing these practices to the low-code programmers.</p>\\n\\n\\n\\n<p>Why? The promise is that low-code allows people to become productive and creative with little or no formal education. We aren’t doing anyone a service by sneaking educational requirements in through the back door. “You don’t have to know how to program, but you do have to understand deployment and testing”—that misses the point. But that’s also essential, if we want software built by low-code developers to be reliable and deployable—and if software created by citizen programmers can’t be deployed, “democratization” is a fraud. That’s another place where professional software developers fit in. We will need people who can create and maintain the pipelines by which software is built, tested, archived, and deployed. Those tools already exist for traditional code-heavy languages; but new tools will be needed for low-code frameworks. And the programmers who create and maintain those tools will need to have experience with current software development practices. They will become the new teachers, teaching everything about computing that isn’t coding.</p>\\n\\n\\n\\n<p>Education doesn’t stop there; good professionals are always learning. Acquiring new skills will be a part of both the blue-collar and white-collar programmer experience well beyond the pervasiveness of low-code.</p>\\n\\n\\n\\n<h2>Rethinking the Industry</h2>\\n\\n\\n\\n<p>If programmers change, so will the software industry. We see three changes. In the last 20 years, we’ve learned a lot about managing the software development process. That’s an intentionally vague phrase that includes everything from source management (which has a history that goes back to the 1970s) to continuous deployment pipelines. And we have to ask: if useful work is coming from low-code developers, how do we maintain that? What does GitHub for Excel, LabVIEW, or GPT-3 look like? When something inevitably breaks, what will debugging and testing look like when dealing with low-code programs? What does continuous delivery mean for applications written with SAP or PageMaker? Glitch, Copilot, and Microsoft’s Power Fx are the only low-code systems we’ve discussed that can answer this question right now. Glitch fits into CI/CD practice because it’s a system for writing less code, and copying more, so it’s compatible with our current tooling. Likewise, Copilot helps you write code in a traditional programming language that works well with CI/CD tools. Power Fx fits because it’s a traditional text-based language: Excel formulas without the spreadsheet. (It’s worth noting that Excel’s&nbsp;<em>.xlsx</em>&nbsp;files aren’t amenable to source control, nor do they have great tools for debugging and testing, which are a standard part of software development.) Extending fundamental software development practices like version control, automated testing, and continuous deployment to other low-code and no-code tools sounds like a job for programmers, and one that’s still on the to-do list.</p>\\n\\n\\n\\n<p>Making tool designers and builders more effective will undoubtedly lead to new and better tools. That almost goes without saying. But we hope that if coders become more effective, they will spend more time thinking about the code they write: how it will be used, what problems are they trying to solve, what are the ethical questions these problems raise, and so on. This industry has no shortage of badly designed and ethically questionable products. Rather than rushing a product into release without considering its implications for security and safety, perhaps making software developers more effective will let them spend more time thinking about these issues up front, and during the process of software development.</p>\\n\\n\\n\\n<p>Finally, an inevitable shift in team structure will occur across the industry, allowing programmers to focus on solving with code what low-code solutions can’t solve, and ensuring that what is solved through low-code solutions is carefully monitored and corrected. Just as spreadsheets can be buggy and an errant decimal or bad data point can sink businesses and economies, buggy low-code programs built by citizen programmers could just as easily cause significant headaches. Collaboration—not further division—between programmers and citizen programmers within a company will ensure that low-code solutions are productive, not disruptive as programming becomes further democratized. Rebuilding teams with this kind of collaboration and governance in mind could increase productivity for companies large and small—affording smaller companies who can’t afford specialization the ability to diversify their applications, and allowing larger companies to build more impactful and ethical software.</p>\\n\\n\\n\\n<h2>Rethinking Code Itself</h2>\\n\\n\\n\\n<p>Still, when we look at the world of low-code and no-code programming, we feel a nagging disappointment. We’ve made great strides in producing libraries that reduce the amount of code programmers need to write; but it’s still programming, and that’s a barrier in itself. We’ve seen limitations in other low-code or no-code approaches; they’re typically “no code until you need to write code.” That’s&nbsp;progress, but only progress of a sort. Many of us would rather program in Python than in PL/I or Fortran, but that’s a difference of quality, not of kind. Are there any ways to rethink programming at a fundamental level? Can we ever get beyond 80-character lines that, no matter how good our IDEs and refactoring tools might be, are really just virtual punch cards?</p>\\n\\n\\n\\n<p>Here are a few ideas.</p>\\n\\n\\n\\n<p>Brett Victor’s&nbsp;<a href=\"https://dynamicland.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Dynamicland</a>&nbsp;represents a complete rethinking of programming. It rejects the notion of programming with virtual objects on laptop screens; it’s built upon the idea of working with real-world objects, in groups, without the visible intermediation of computers. People “play” with objects on a tabletop; sensors detect and record what they’re doing with the objects. The way objects are arranged become the programs. It’s more like playing with Lego blocks (in real life, not some virtual world), or with paper and scissors, than the programming that we’ve become accustomed to. And the word “play” is important. Dynamicland is all about reenvisioning computing as play rather than work. It’s the most radical attempt at no-code programming that we’ve seen.</p>\\n\\n\\n\\n<p>Dynamicland is a “50-year project.” At this point, we’re 6 years in: only at the beginning. Is it the future? We’ll see.</p>\\n\\n\\n\\n<p>If you’ve followed quantum computing, you may have seen quantum circuit notation (shown in\\xa0Figure 5), a way of writing quantum programs that looks sort of like music: a staff composed of lines representing qubits, with operations connecting those lines. We’re not going to discuss quantum programming; we find this notation suggestive for other reasons. Could it represent a different way to look at the programming enterprise? Kevlin Henney has\\xa0<a href=\"https://oreil.ly/5geqD\" rel=\"noreferrer noopener\" target=\"_blank\">talked about programming as managing space and time</a>. Traditional programming languages are (somewhat) good about space; languages like C, C++, and Java require you to define datatypes and data structures. But we have few tools for managing time, and (unsurprisingly) it’s hard to write concurrent code. Music is all about time management. Think of a symphony and the 100 or so musicians as independent “threads” that have to stay synchronized—or think of a jazz band, where improvisation is central, but synchronization remains a must. Could a music-aware notation (such as\\xa0<a href=\"https://sonic-pi.net/\" rel=\"noreferrer noopener\" target=\"_blank\">Sonic Pi</a>) lead to new ways for thinking about concurrency? And would such a notation be more approachable than virtual punch cards? This rethinking will\\xa0inevitably\\xa0fail if it tries too literally to replicate staves, note values, clefs and such; but it may be a way to free ourselves from thinking about business as usual.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14099\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/11/lcdp_0105-1048x222.png\" /><figcaption><em>Figure 5.\\xa0Quantum circuit notation (source:\\xa0</em><a href=\"https://oreil.ly/WGQl6\">Programmi</a><a href=\"https://oreil.ly/WGQl6\" rel=\"noreferrer noopener\" target=\"_blank\">ng Quantum Computers</a><em>)</em></figcaption></figure>\\n\\n\\n\\n<p>Here’s an even more radical thought. At an early Biofabricate conference, a speaker from Microsoft was talking about tools for programming DNA. He said something mind-blowing: we often say that DNA is a “programming language,” but it has control structures that are unlike anything in our current programming languages. It’s not clear that those programming structures are representable in a text. Our present notion of computation—and, for that matter, of what’s “computable”—derives partly from the Turing machine (a thought experiment) and Von Neumann’s notion of how to build such a machine. But are there other kinds of machines? Quantum computing says so; DNA says so. What are the limits of our current understanding of computing, and what kinds of notation will it take to push beyond those limits?</p>\\n\\n\\n\\n<p>Finally, programming has been dominated by English speakers, and programming languages are, with few exceptions, mangled variants of English. What would programming look like in other languages? There are programming languages in a number of&nbsp;<a href=\"https://oreil.ly/f3LYk\" rel=\"noreferrer noopener\" target=\"_blank\">non-English languages</a>, including Arabic, Chinese, and Amharic. But the most interesting is the&nbsp;<a href=\"https://oreil.ly/2U70Y\" rel=\"noreferrer noopener\" target=\"_blank\">Cree#</a>&nbsp;language, because it isn’t just an adaptation of a traditional programming language. Cree# tries to reenvision programming in terms of the indigenous American Cree culture, which revolves around storytelling. It’s a programming language for stories, built around the logic of stories. And as such, it’s a different way of looking at the world. That way of looking at the world might seem like an arcane curiosity (and currently Cree# is considered an “esoteric programming language”); but one of the biggest problems facing the artificial intelligence community is developing systems that can explain the reason for a decision. And explanation is ultimately about storytelling. Could Cree# provide better ways of thinking about algorithmic explainability?</p>\\n\\n\\n\\n<h2>Where We’ve Been and Where We’re Headed</h2>\\n\\n\\n\\n<p>Does a new way of programming increase the number of people who are able to be creative with computers? It has to; in&nbsp;<a href=\"https://oreil.ly/tyGvx\" rel=\"noreferrer noopener\" target=\"_blank\">&#8220;The Rise of the No Code Economy&#8221;</a>, the authors write that relying on IT departments and professional programmers is unsustainable. We need to enable people who aren’t programmers to develop the software they need. We need to enable people to solve their own computational problems. That’s the only way “digital transformation” will happen.</p>\\n\\n\\n\\n<p>We’ve talked about digital transformation for years, but relatively few companies have done it. One lesson to take from the COVID pandemic is that every business has to become an online business. When people can’t go into stores and restaurants, everything from the local pizza shop to the largest retailers needs to be online. When everyone is working at home, they are going to want tools to optimize their work time. Who is going to build all that software? There may not be enough programming talent to go around. There may not be enough of a budget to go around (think about small businesses that need to transact online). And there certainly won’t be the patience to wait for a project to work its way through an overworked IT department. Forget about yesterday’s arguments over whether everyone should learn to code. We are entering a business world in which almost everyone will need to code—and low-, no-, and yes-code frameworks are necessary to enable that. To enable businesses and their citizen programmers to be productive, we may see a proliferation of DSLs: domain-specific languages designed to solve specific problems. And those DSLs will inevitably evolve towards general purpose programming languages: they’ll need web frameworks, cloud capabilities, and more.</p>\\n\\n\\n\\n<p>“Enterprise low-code” isn’t all there is to the story. We also have to consider what low-code means for professional programmers. Doing more with less? We can all get behind that. But for professional programmers, “doing more with less” won’t mean using a templating engine and a drag-and-drop interface builder to create simple database applications. These tools inevitably limit what’s&nbsp;possible—that’s precisely why they’re valuable. Professional programmers will be needed to do what the low-code users can’t. They build new tools, and make the connections between these tools and the old tools. Remember that the amount of “glue code” that connects things rises as the&nbsp;<a href=\"https://oreil.ly/xnkka\" rel=\"noreferrer noopener\" target=\"_blank\">square</a>&nbsp;of the number of things being&nbsp;connected, and that most of the work involved in gluing components together is&nbsp;<a href=\"https://oreil.ly/39TxO\" rel=\"noreferrer noopener\" target=\"_blank\">data integration</a>, not just managing formats. Anyone concerned about computing jobs drying up should stop worrying; low-code will inevitably create more work, rather than less.</p>\\n\\n\\n\\n<p>There’s another side to this story, though: what will the future of programming look like? We’re still working with paradigms that haven’t changed much since the 1950s. As Kevlin Henney pointed out in conversation, most of the trendy new features in programming languages were actually invented in the 1970s: iterators, foreach loops, multiple assignment, coroutines, and many more. A surprising number of these go back to the&nbsp;<a href=\"https://oreil.ly/9Weex\" rel=\"noreferrer noopener\" target=\"_blank\">CLU</a>&nbsp;language from 1975. Will we continue to reinvent the past, and is that a bad thing? Are there fundamentally different ways to describe what we want a computer to do, and if so, where will those come from? We started with the idea that the history of programming was the history of “less code”: finding better abstractions, and building libraries to implement those abstractions—and that progress will certainly continue. It will certainly be aided by tools like Copilot, which will enable subject matter experts to develop software with less help from professional programmers. AI-based coding tools might not generate “less” code–but humans won’t be writing it. Instead, they’ll be thinking and analyzing the problems that they need to solve.</p>\\n\\n\\n\\n<p>But what happens next? A tool like Copilot can handle a lot of the “grunt work” that’s part of programming, but it’s (so far) built on the same set of paradigms and abstractions. Python is still Python. Linked lists and trees are still linked lists and trees, and getting concurrency right is still difficult. Are the abstractions we inherited from the past 70 years adequate to a world dominated by artificial intelligence and massively distributed systems?</p>\\n\\n\\n\\n<p>Probably not. Just as the two-dimensional grid of a spreadsheet allows people to think outside the box defined by lines of computer code, and just as the circuit diagrams of LabVIEW allow engineers to envision code as wiring diagrams, what will give us new ways to be creative? We’ve touched on a few: musical notation, genetics, and indigenous languages. Music is important because musical scores are all about synchronization at scale; genetics is important because of control structures that can’t be represented by our ancient IF and FOR statements; and indigenous languages help us to realize that human activity is fundamentally about stories. There are, no doubt, more. Is low-code the future—a “better abstraction”? We don’t know, but it will almost certainly enable different code.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<p><em>We would like to thank the following people whose insight helped inform various aspects of this report: Daniel Bryant, Anil Dash, Paul Ford, Kevlin Henney, Danielle Jobe, and Adam Olshansky.</em></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/low-code-and-the-democratization-of-programming/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Remote Teams in ML/AI',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Remote Teams in ML/AI'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/remote-teams-in-ml-ai/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/remote-teams-in-ml-ai/',\n",
       "   'comments': 'https://www.oreilly.com/radar/remote-teams-in-ml-ai/#respond',\n",
       "   'published': 'Tue, 09 Nov 2021 14:05:48 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=11, tm_mday=9, tm_hour=14, tm_min=5, tm_sec=48, tm_wday=1, tm_yday=313, tm_isdst=0),\n",
       "   'authors': [{'name': 'Q McCallum'}],\n",
       "   'author': 'Q McCallum',\n",
       "   'author_detail': {'name': 'Q McCallum'},\n",
       "   'tags': [{'term': 'Building a data culture', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=14075',\n",
       "   'guidislink': False,\n",
       "   'summary': 'I&#8217;m well-versed in the ups and downs of remote work. I&#8217;ve been doing some form thereof for most of my career, and I&#8217;ve met plenty of people who have a similar story. When companies ask for my help in building their ML/AI teams, I often recommend that they consider remote hires. Sometimes I&#8217;ll even suggest [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'I&#8217;m well-versed in the ups and downs of remote work. I&#8217;ve been doing some form thereof for most of my career, and I&#8217;ve met plenty of people who have a similar story. When companies ask for my help in building their ML/AI teams, I often recommend that they consider remote hires. Sometimes I&#8217;ll even suggest [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>I&#8217;m well-versed in the ups and downs of remote work. I&#8217;ve been doing some form thereof for most of my career, and I&#8217;ve met plenty of people who have a similar story. When companies ask for my help in building their ML/AI teams, I often recommend that they consider remote hires. Sometimes I&#8217;ll even suggest that they build their data function as a fully-remote, distributed group. (I&#8217;ll oversimplify for brevity, using &#8220;remote team&#8221; and &#8220;distributed team&#8221; interchangeably. And I&#8217;ll treat both as umbrella terms that cover &#8220;remote-friendly&#8221; and &#8220;fully-distributed.&#8221;)</p>\\n\\n\\n\\n<p>Remote hiring has plenty of benefits. As an employer, your talent pool spans the globe and you save a ton of money on office rent and insurance. For the people you hire, they get a near-zero commute and a Covid-free workplace.</p>\\n\\n\\n\\n<p>Then again, even though you really <em>should</em> build a remote team, <em>you also shouldn&#8217;t.</em> Not just yet. You first want to think through one very important question:</p>\\n\\n\\n\\n<p><em>Do I, as a leader, really want a remote team?</em></p>\\n\\n\\n\\n<h3><strong>The Litmus Test</strong></h3>\\n\\n\\n\\n<p>The key ingredient to successful remote work is, quite simply, whether company leadership wants it to work. Yes, it also requires policies, tooling, and re-thinking a lot of interactions. Not to mention, your HR team will need to double-check local laws wherever team members choose to live.&nbsp; But before any of that, the people in charge have to actually <em>want</em> a remote team.</p>\\n\\n\\n\\n<p>Here&#8217;s a quick test for the executives and hiring managers among you:</p>\\n\\n\\n\\n<ul><li>As the Covid-19 pandemic forced your team to work from home, did you insist on hiring only local candidates (so they could eventually work in the office)?</li><li>With wider vaccine rollouts and lower case counts, do you now require your team to spend some time in the office every week?</li><li>Do you see someone as &#8220;not really part of the team&#8221; or &#8220;less suitable for promotion&#8221; because they don&#8217;t come into the office?</li></ul>\\n\\n\\n\\n<p>If you&#8217;ve said yes to any of these, then you simply do not want a distributed team. You want an in-office team that you begrudgingly permit to work from home now and then. And as long as you don&#8217;t truly want one, any attempts to build and support one will not succeed.</p>\\n\\n\\n\\n<p>If you&#8217;ve said yes to any of these, then you simply do not want a distributed team. You want an in-office team that you begrudgingly permit to work from home now and then. And as long as you don&#8217;t truly want one, any attempts to build and support one will not succeed.</p>\\n\\n\\n\\n<p>And if you <em>don&#8217;t</em> want that, that&#8217;s fine. I&#8217;m not here to change your mind.</p>\\n\\n\\n\\n<p>But if you <em>do</em> want to build a successful remote team, and you want some ideas on how to make it work, read on.</p>\\n\\n\\n\\n<h3><strong>How You Say What You Have to Say</strong></h3>\\n\\n\\n\\n<p>As a leader, most of your job involves communicating with people. This will require some adjustment in a distributed team environment.</p>\\n\\n\\n\\n<p>A lot of you have developed a leadership style that&#8217;s optimized for everyone being in the same office space during working hours. That has cultivated poor, interruption-driven communication habits. It&#8217;s too easy to stop by someone&#8217;s office, pop over a cubicle wall, or bump into someone in the hallway and share some information with them.</p>\\n\\n\\n\\n<p>With a remote team you&#8217;ll need to write these thoughts down instead. That also means deciding what you want to do <em>before you even start writing,</em> and then sticking with it after you&#8217;ve filed the request.</p>\\n\\n\\n\\n<p>By communicating your thoughts in clear, unambiguous language, you&#8217;ve demonstrated your commitment to what you&#8217;re asking someone to do. You&#8217;re also leaving them a document they can refer to as they perform the task you&#8217;ve requested. This is key because, depending on work schedules, a person can&#8217;t just tap you on the shoulder to ask you to clarify a point.</p>\\n\\n\\n\\n<p>(Side note: I&#8217;ve spent my career working with extremely busy people, and being one myself. That&#8217;s taught me a lot about how to communicate in written form. Short sentences, bullet points, and starting the message with the call-to-action—sometimes referred to as <em>BLUF:</em> Bottom Line Up-Front—will go a long way in making your e-mails clearer.)</p>\\n\\n\\n\\n<p>The same holds true for meetings: the person who called the meeting should send an agenda ahead of time and follow up with recap notes. Attendees will be able to confirm their shared understanding of what is to be done and who is doing what.</p>\\n\\n\\n\\n<p>Does this feel like a lot of documentation? That&#8217;s great. In my experience, what feels like over-communication for an in-office scenario is usually the right amount for a distributed team.</p>\\n\\n\\n\\n<h3><strong>Embracing Remote for What It Is</strong></h3>\\n\\n\\n\\n<p>Grammar rules differ by language. You won&#8217;t get very far speaking the words of a new language while using grammatical constructs from your native tongue. It takes time, practice, and patience to learn the new language so that you can truly <em>express</em> yourself.&nbsp; The path takes you from &#8220;this is an unnatural and uncomfortable word order&#8221; to &#8220;German requires that I put the verb&#8217;s infinitive at the end of the clause.&nbsp; That&#8217;s just how it works.&#8221;</p>\\n\\n\\n\\n<p>There are parallels here to leading a distributed team. It&#8217;s too easy to assume that &#8220;remote work&#8221; is just &#8220;people re-creating the in-office experience, from their kitchen tables.&#8221; It will most certainly feel unnatural and uncomfortable if you hold that perspective.&nbsp; And it <em>should</em> feel weird, since optimizing for remote work will require re-thinking a lot of the whats and hows of team interactions and success metrics.&nbsp; You start winning when you determine where a distributed team works out <em>better</em> than the in-office alternative.</p>\\n\\n\\n\\n<p>Remote work is people getting things done from a space that is not your central office, on time schedules that aren&#8217;t strict 9-to-5, and maybe even communicating in text-based chat systems.&nbsp; Remote work is checking your messages in the morning, and seeing a stream of updates from your night-owl teammates.&nbsp; Remote work is its own thing, and trying to shoe-horn it into the shape of an in-office setup means losing out on all of the benefits.</p>\\n\\n\\n\\n<p>Embracing remote teams will require letting go of outdated in-office tropes to accept some uncomfortable truths. People will keep working when you&#8217;re not looking over their shoulder.&nbsp; Some of them will work even better when they can do so in the peace and quiet of an environment they control.&nbsp; They can be fully present in a meeting, even if they&#8217;ve turned off their video. They can most certainly be productive on a work schedule that doesn&#8217;t match yours, while wearing casual attire.</p>\\n\\n\\n\\n<p>The old tropes were hardly valid to begin with. And now, 18 months after diving head-first into remote work, those tropes are officially dead. It&#8217;s up to you to learn new ways to evaluate team (and team member) productivity. More importantly, in true remote work fashion, you&#8217;ll have to step back and trust the team you&#8217;ve hired.</p>\\n\\n\\n\\n<h3><strong>Exploring New Terrain</strong></h3>\\n\\n\\n\\n<p>If distributed teamwork is new territory for your company, expect to stumble now and then. You&#8217;re walking through a new area and instead of following your trusty old map, you&#8217;re now <em>creating</em> the map. One step at a time, one stubbed toe at a time.</p>\\n\\n\\n\\n<p>You&#8217;ll spend time defining new best practices that are specific to this environment. This will mean thinking through a lot more decisions than before—decisions that you used to be able to handle on autopilot—and as such you will find yourself saying &#8220;I don&#8217;t know&#8221; a lot more than you used to.</p>\\n\\n\\n\\n<p>You&#8217;ll feel some of this friction when sorting out workplace norms.&nbsp; What are &#8220;working hours,&#8221; if your team even has any?&nbsp; Maybe all you need is a weekly group check-in, after which everyone heads in separate directions to focus on their work?&nbsp; In that case, how will individuals specify <em>their</em> working hours and their off-time?&nbsp; With so much asynchronous communication, there&#8217;s bound to be confusion around when a person is expected to pick up on an ongoing conversation in a chat channel, versus their name being @-mentioned, or contacting them by DM.&nbsp; Setting those expectations will help the team shift into (the right kind of) autopilot, because they&#8217;ll know to not get frustrated when a person takes a few hours to catch up on a chat thread.&nbsp; As a bonus, going through this exercise will sort out when you really <em>need</em> to hold a group meeting versus when you have to just make an announcement (e-mail) or pose a quick question (chat).</p>\\n\\n\\n\\n<p>Security will be another source of friction.&nbsp; When everyone is in the same physical office space, there&#8217;s little question of the &#8220;inside&#8221; versus the &#8220;outside&#8221; network.&nbsp; But when your teammates are connecting to shared resources from home or a random cafe, how do you properly wall off the office from everything else? Mandating VPN usage is a start, but it&#8217;s hardly the entire picture.&nbsp; There are also questions around company-issued devices having visibility into home-network traffic, and what they&#8217;re allowed to do with that information.&nbsp; Or even a company laptop, hacked through the company network, infecting personal devices on the home LAN. Is your company&#8217;s work so sensitive that employees will require a separate, work-only internet service for their home office?&nbsp; That would be fairly extreme—in my experience, I haven&#8217;t even seen banks go that far—but it&#8217;s not out of the realm of possibility.&nbsp; At some point a CISO may rightfully determine that this is the best path.</p>\\n\\n\\n\\n<p>Saying &#8220;I don&#8217;t know&#8221; is OK in all of these cases, so long as you follow that with &#8220;so let&#8217;s figure it out.&#8221; Be honest with your team to explain that you, as a group, may have to try a few rounds of something before it all settles. The only two sins here are to refuse to change course when it&#8217;s not working, and to revert to the old, familiar, in-office ways just to ease your cognitive burden. So long as you are thoughtful and intentional in your approach, you&#8217;ll succeed over the long run.</p>\\n\\n\\n\\n<h3><strong>It&#8217;s Here to Stay</strong></h3>\\n\\n\\n\\n<p>Your data scientists (and developers, and IT ops team) have long known that remote work is possible. They communicate through Slack and collaborate using shared documents. They see that their &#8220;datacenter&#8221; is a cloud infrastructure. They already know that a lot of their day-to-day interactions don&#8217;t require everyone being in the same office. Company leadership is usually the last to pick up on this, which is why they tend to show the most resistance.</p>\\n\\n\\n\\n<p>If adaptive leadership is the key to success with distributed teams, then <em>discipline</em> is the key to that adaptation. You&#8217;ll need the discipline to plan your communication, to disable your office autopilot, and to trust your team more.</p>\\n\\n\\n\\n<p>You must focus on what matters—defining what needs to get done, and letting people do it—and learn to let go of what doesn&#8217;t. That will be uncomfortable, yes. But your job as a leader is to clear the path for people who are doing the implementation work. What makes <em>them</em> comfortable trumps what makes <em>you</em> comfortable.</p>\\n\\n\\n\\n<p>Not every company will accept this. Some are willing to trade the benefits of a distributed team for what they perceive to be a superior in-office experience. And that&#8217;s fine. But for those who want it, remote is here to stay.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/remote-teams-in-ml-ai/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: November 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: November 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2021/#respond',\n",
       "   'published': 'Tue, 02 Nov 2021 11:40:17 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=11, tm_mday=2, tm_hour=11, tm_min=40, tm_sec=17, tm_wday=1, tm_yday=306, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=14066',\n",
       "   'guidislink': False,\n",
       "   'summary': 'While October’s news was dominated by Facebook’s (excuse me, Meta’s) continued problems (you’d think they’d get tired of the apology tour), the most interesting news comes from the AI world. I’m fascinated by the use of large language models to analyze the “speech” of whales, and to preserve endangered human languages. It’s also important that [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'While October’s news was dominated by Facebook’s (excuse me, Meta’s) continued problems (you’d think they’d get tired of the apology tour), the most interesting news comes from the AI world. I’m fascinated by the use of large language models to analyze the “speech” of whales, and to preserve endangered human languages. It’s also important that [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>While October’s news was dominated by Facebook’s (excuse me, Meta’s) continued problems (you’d think they’d get tired of the apology tour), the most interesting news comes from the AI world. I’m fascinated by the use of large language models to analyze the “speech” of whales, and to preserve endangered human languages. It’s also important that machine learning seems to have taken a step (pun somewhat intended) forward, with robots that teach themselves to walk by trial and error, and with robots that learn how to assemble themselves to perform specific tasks.</p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li>The design studio Artefact has created a game to teach middle school students about <a href=\"https://www.fastcompany.com/90667009/the-most-likely-machine-innovation-by-design-2021\" rel=\"noreferrer noopener\" target=\"_blank\">algorithmic bias</a>.</li><li>Researchers are building large natural language models, potentially the size of GPT-3, to <a href=\"https://www.hakaimagazine.com/features/are-we-on-the-verge-of-chatting-with-whales/\" rel=\"noreferrer noopener\" target=\"_blank\">decode the “speech” of whales.</a></li><li>A group at Berkeley has built a robot that uses reinforcement learning to <a href=\"https://www.technologyreview.com/2021/04/08/1022176/boston-dynamics-cassie-robot-walk-reinforcement-learning-ai/\" rel=\"noreferrer noopener\" target=\"_blank\">teach itself to walk</a> from scratch–i.e., through trial and error. They used two levels of simulation before loading the model into a physical robot.</li><li><a href=\"https://www.technologyreview.com/2021/10/22/1037179/ai-reinventing-computers/\" rel=\"noreferrer noopener\" target=\"_blank\">AI is reinventing computers</a>: AI is driving new kinds of CPUs, new “out of the box” form factors (doorbells, appliances), decision-making rather than traditional computation. The “computer” as the computational device we know may be on the way out.</li><li>Weird creatures: Unimals, or universal animals, are robots that can <a href=\"https://www.technologyreview.com/2021/10/19/1037555/weird-virtual-creatures-evolve-bodies-ai-general-intelligence/\" rel=\"noreferrer noopener\" target=\"_blank\">use AI to evolve</a> their body shapes so they can solve problems more efficiently. Future generations of robotics might not be designed with fixed bodies, but have the capability to adapt their shape as needed.</li><li>Would a <a href=\"https://www.nbcnews.com/tech/tech-news/big-tech-pushing-national-cloud-critics-say-big-tech-profit-rcna2971\" rel=\"noreferrer noopener\" target=\"_blank\">National AI Cloud</a> be a subsidy to Google, Facebook, et.al., a threat to privacy, or a valuable academic research tool?</li><li>I’ve been skeptical about digital twins; they seem to be a technology looking for an application. However, <a href=\"https://thenextweb.com/news/whats-a-digital-twin-and-why-ev-batteries-need-it\" rel=\"noreferrer noopener\" target=\"_blank\">Digital Twins</a> (AI models of real-world systems, used for predicting their behavior) seem like a useful technology for optimizing the performance of large batteries.</li><li><a href=\"https://www.technologyreview.com/2021/10/26/1038643/ai-reinforcement-learning-digital-twins-can-solve-supply-chain-shortages-and-save-christmas/\" rel=\"noreferrer noopener\" target=\"_blank\">Digital Twins</a> could provide a way to predict supply chain problems and work around shortages. They could allow manufacturers to navigate a compromise between just-in-time stocking processes, which are vulnerable to shortages, and resilience.</li><li>Modulate is a startup currently testing <a href=\"https://www.wired.com/story/deepfake-voices-help-trans-gamers/\" rel=\"noreferrer noopener\" target=\"_blank\">real-time voice changing</a> software. They provide realistic, human sounding voices that replace the user’s own voice. They are targeting gaming, but the software is useful in many situations where harassment is a risk.</li><li><a href=\"https://techxplore.com/news/2021-10-voice-algorithms-dupe-recognition-devices.html\" rel=\"noreferrer noopener\" target=\"_blank\">Voice copying algorithms</a> were able to fool both people and voice-enabled devices roughly 50% of the time (30% for Azure’s voice recognition service, 62% for Alexa). This is a new front in deep fakery.</li><li>Facebook AI Research has created a set of first-person (head-mounted camera) videos called <a href=\"https://www.technologyreview.com/2021/10/14/1037043/facebook-machine-learning-ai-vision-see-world-human-eyes/\" rel=\"noreferrer noopener\" target=\"_blank\">Ego4D</a> for training AI.\\xa0 They want to build AI models that see the world “as a person sees it,” and be able to answer questions like “where did I leave my keys.” In essence, this means that they will need to <a href=\"https://www.theverge.com/2021/10/14/22725894/facebook-augmented-reality-ar-glasses-ai-systems-ego4d-research\" rel=\"noreferrer noopener\" target=\"_blank\">collect literally everything</a> that a subscriber does.\\xa0 Although Facebook denies that they are thinking about commercial applications, there are obvious connections to Ray-Ban Stories and their interest in augmented reality.</li><li>DeepMind is working on a deep learning model that can <a href=\"https://venturebeat.com/2021/10/12/deepmind-is-developing-one-algorithm-to-rule-them-all/\" rel=\"noreferrer noopener\" target=\"_blank\">emulate the output of any algorithm</a>.\\xa0 This is called Neuro Algorithmic Reasoning; it may be a step towards a “general AI.”</li><li><a href=\"https://developer.nvidia.com/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/\" rel=\"noreferrer noopener\" target=\"_blank\">Microsoft and NVIDIA</a> announce a 530 billion parameter natural language model named Megatron-Turing NLG 530B.\\xa0 That’s bigger than GPT-3 (175B parameters).</li><li>Can machine learning be used to <a href=\"https://techxplore.com/news/2021-10-indigenous-languages-automatic-speech-recognition.html\" rel=\"noreferrer noopener\" target=\"_blank\">document endangered indigenous languages</a> and aid in language reclamation?</li><li>Beethoven’s <a href=\"https://thenextweb.com/news/computer-scientists-completed-beethoven-10th-symphony-syndication\" rel=\"noreferrer noopener\" target=\"_blank\">10th symphony</a> completed by AI: I’m not convinced that this is what Beethoven would have written, but this is better than other (human) attempts to complete the 10th that I’ve heard. It sounds like Beethoven, for the most part, though it quickly gets aimless.</li><li>I’m still fascinated by techniques to foil face recognition. Here’s a <a href=\"https://arxiv.org/abs/2109.06467\" rel=\"noreferrer noopener\" target=\"_blank\">paper</a> about an AI system that designs minimal, natural-looking makeup that reshapes the parts of the face that face recognition algorithms are most sensitive to, without substantially altering a person’s appearance.</li></ul>\\n\\n\\n\\n<h2>Ethics</h2>\\n\\n\\n\\n<ul><li>Thoughtworks’ <a href=\"https://www.thoughtworks.com/about-us/social-change/responsible-tech-playbook\" rel=\"noreferrer noopener\" target=\"_blank\">Responsible Tech Playbook</a> is a curated collection of tools and techniques to help organizations become more aware of bias and become more inclusive and transparent.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li><a href=\"https://github.com/nuta/kerla\" rel=\"noreferrer noopener\" target=\"_blank\">Kerla</a> is a Linux-like operating system kernel written in Rust that can run most Linux executables. I doubt this will ever be integrated into Linux, but it’s yet another sign that Rust has joined the big time.</li><li><a href=\"https://thenewstack.io/codesee-helps-developers-understand-the-codebase/\" rel=\"noreferrer noopener\" target=\"_blank\">OSS Port</a> is an open source tool that aims to help developers understand large codebases. It parses a project repository on GitHub and produces maps and tours of the codebase. It currently works with JavaScript, Go, Java, and Python, with Rust support promised soon.</li><li><a href=\"https://turingcomplete.game/\" rel=\"noreferrer noopener\" target=\"_blank\">Turing Complete</a> is a game about computer science. That about says it… </li><li><a href=\"https://thenewstack.io/webassembly-the-future-of-cloud-native-distributed-computing/\" rel=\"noreferrer noopener\" target=\"_blank\">wasmCloud</a> is a runtime environment that can be used to build distributed systems with wasm in the cloud. WebAssembly was designed as a programming-language-neutral virtual machine for\\xa0 browsers, but it increasingly looks like it will also find a home on the server side.</li><li>Adobe <a href=\"https://web.dev/ps-on-the-web/\" rel=\"noreferrer noopener\" target=\"_blank\">Photoshop now runs in the browser</a>, using wasm and Emscripten (the C++ toolchain for wasm).\\xa0 In addition to compiling C++ to wasm, Emscripten also translates POSIX system calls to web API calls and converts OpenGL to WebGL.</li><li><a href=\"https://medium.com/short-bits/jql-rust-based-json-query-language-ed1d7c6a1ae0\" rel=\"noreferrer noopener\" target=\"_blank\">JQL</a> (JSON Query Language) is a Rust-based language for querying JSON (what else?).</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li><a href=\"https://blogs.microsoft.com/blog/2021/10/28/america-faces-a-cybersecurity-skills-crisis-microsoft-launches-national-campaign-to-help-community-colleges-expand-the-cybersecurity-workforce/?mod=djemCIO\" rel=\"noreferrer noopener\" target=\"_blank\">Microsoft</a> has launched an effort to train 250,000 cyber security workers in the US by 2025. This effort will work with community colleges. They estimate that it will only make up 50% of the shortfall in security talent.</li><li><a href=\"https://thenewstack.io/zero-trust-security-and-the-software-development-lifecycle/\" rel=\"noreferrer noopener\" target=\"_blank\">Integrating zero trust security</a> into the software development lifecycle is really the only way forward for companies who rely on systems that are secure and available.</li><li>A <a href=\"https://www.bleepingcomputer.com/news/security/popular-npm-library-hijacked-to-install-password-stealers-miners/\" rel=\"noreferrer noopener\" target=\"_blank\">supply chain attack against a Node.js library</a> (UA-Parser-JS) installs crypto miners and trojans for stealing passwords on Linux and Windows systems. The library’s normal function is to parse user agent strings, identifying the browser, operating system, and other parameters.</li><li>A cybercrime group has <a href=\"https://www.bleepingcomputer.com/news/security/hacking-gang-creates-fake-firm-to-hire-pentesters-for-ransomware-attacks/\" rel=\"noreferrer noopener\" target=\"_blank\">created penetration testing consultancies</a> whose purpose is to acquire clients and then gather information and initiate ransomware attacks against those clients.</li><li>A <a href=\"https://techxplore.com/news/2021-10-cryptography-game-changer-biomedical-scale.html\" rel=\"noreferrer noopener\" target=\"_blank\">federated cryptographic system</a> will allow sharing of medical data without compromising patient privacy.\\xa0 This is an essential element in “predictive, preventive, personalized, and participatory” medicine (aka P4).</li><li>The European Parliament has <a href=\"https://www.schneier.com/blog/archives/2021/10/the-european-parliament-voted-to-ban-remote-biometric-surveillance.html\" rel=\"noreferrer noopener\" target=\"_blank\">taken steps towards banning</a> surveillance based on biometric data, private face recognition databases, and predictive policing.</li><li>Is it possible to reverse-engineer the data on which a model was trained? An <a href=\"https://www.technologyreview.com/2021/10/12/1036844/ai-gan-fake-faces-data-privacy-security-leak/\" rel=\"noreferrer noopener\" target=\"_blank\">attack</a> against a fake face generator was able to identify the original faces in the training data. This has important implications for privacy and security, since it appears to generalize to other kinds of data.</li><li><a href=\"https://thenextweb.com/news/protect-machine-learning-models-against-adversarial-attacks-syndication\" rel=\"noreferrer noopener\" target=\"_blank\">Adversarial attacks against machine learning</a> systems present a different set of challenges for cybersecurity. Models aren’t code, and have their own vulnerabilities and attack vectors. <a href=\"https://github.com/mitre/advmlthreatmatrix\" rel=\"noreferrer noopener\" target=\"_blank\">Atlas</a> is a project to define the the machine learning threat landscape. Tools to harden machine learning models against attack include IBM’s <a href=\"https://github.com/Trusted-AI/adversarial-robustness-toolbox\" rel=\"noreferrer noopener\" target=\"_blank\">Adversarial Robustness Toolbox</a> and Microsoft’s <a href=\"https://github.com/Azure/counterfit/\" rel=\"noreferrer noopener\" target=\"_blank\">Counterfit</a>.</li><li>Researchers have discovered that you can encode malware into DNA that attacks sequencing software and gives the attacker control of the computer.\\xa0 This attack hasn’t (yet) been found in the wild. </li><li><a href=\"https://github.com/robertdavidgraham/masscan\" rel=\"noreferrer noopener\" target=\"_blank\">Masscan</a> is a next generation, extremely fast port scanner.\\xa0 It’s similar to nmap, but much faster; it claims to be able to scan the entire internet in 6 minutes.</li><li><a href=\"https://github.com/microsoft/ethr\" rel=\"noreferrer noopener\" target=\"_blank\">ethr</a> is an open source cross-platform network performance measurement tool developed by Microsoft in Go. Right now, it looks like the best network performance tool out there.</li><li><a href=\"https://techxplore.com/news/2021-10-self-aware-algorithm-ward-hacking.html\" rel=\"noreferrer noopener\" target=\"_blank\">Self-aware systems</a> monitor themselves constantly and are capable of detecting (and even repairing) attacks.</li></ul>\\n\\n\\n\\n<h2>Infrastructure and Operations</h2>\\n\\n\\n\\n<ul><li>Interesting insights into <a href=\"https://thenewstack.io/google-sre-site-reliability-engineering-at-a-global-scale/\" rel=\"noreferrer noopener\" target=\"_blank\">how site reliability engineering actually works at Google</a>. SRE is intentionally a scarce resource; teams should solve their own problems. Their goal is to help dev teams attain reliability and performance objectives with engineering rather than brute force.</li></ul>\\n\\n\\n\\n<h2>Devices and Things</h2>\\n\\n\\n\\n<ul><li>Amazon is working on an <a href=\"https://arstechnica.com/gadgets/2021/10/report-amazon-designed-fridge-will-use-the-same-tech-as-amazon-go-stores/\" rel=\"noreferrer noopener\" target=\"_blank\">Internet-enabled refrigerator </a>that will keep track of what’s in it and notify you when you’re low on supplies.\\xa0 (And there are already similar products on the market.) Remember when this was joke?</li><li><a href=\"https://thenextweb.com/news/how-ai-as-a-service-remaking-smart-gadgets\" rel=\"noreferrer noopener\" target=\"_blank\">Consumer-facing AI</a>: On one hand, “smart gadgets” present a lot of challenges and opportunities. On the other hand, it needs better deliverables than “smart” doorbells. Smart hearing aids that are field-upgradable as a subscription service?</li><li>A drone has been used to <a href=\"https://techxplore.com/news/2021-10-canada-hospitals-drones-lungs-transplant.html\" rel=\"noreferrer noopener\" target=\"_blank\">deliver a lung</a> for organ transplant. This is only the second time a drone has been used to carry organs for transplantation.</li><li>Intel has released its next generation neuromorphic processor, <a href=\"https://arstechnica.com/science/2021/09/understanding-neuromorphic-computing-and-why-intels-excited-about-it/\" rel=\"noreferrer noopener\" target=\"_blank\">Loihi</a>. Neuromorphic processors are based on the structure of the brain, in which neurons asynchronously send each other signals. While they are still a research project, they appear to require much less power than traditional CPUs.</li></ul>\\n\\n\\n\\n<h2>Web</h2>\\n\\n\\n\\n<ul><li><a href=\"https://ipleak.net/\" rel=\"noreferrer noopener\" target=\"_blank\">ipleak</a> and <a href=\"https://dnsleaktest.com/\" rel=\"noreferrer noopener\" target=\"_blank\">dnsleaktest</a> are sites that tell you what information your browser leaks. They are useful tools if you’re interested in preserving privacy. The results can be scary. </li><li><a href=\"https://techxplore.com/news/2021-09-dark-web-sites-clicking.html\" rel=\"noreferrer noopener\" target=\"_blank\">Dark design</a> is the practice of designing interfaces that manipulate users into doing things they might not want to do, whether that’s agreeing to give up information about their web usage or clicking to buy a product. <a href=\"https://www.darkpatterns.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Dark patterns</a> are already common, and becoming increasingly prevalent.</li><li><a href=\"https://thehackposts.com/how-black-twitter-has-become-the-new-green-book-and-more/\" rel=\"noreferrer noopener\" target=\"_blank\">Black Twitter has become the new “Green Book</a>,” a virtual place for tips on dealing with a racist society. The original Green Book was a Jim Crow-era publication that told Black people where they could travel safely, which hotels would accept them, and where they were likely to become victims of racist violence.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li>A group at Duke University has made significant progress on error correcting quantum computing. They have created a “logical qubit” that can be read with a 99.4% probability of being correct. (Still well below what is needed for practical quantum computing.)</li><li>There are now <a href=\"https://phys.org/news/2021-10-chinese-teams-primacy-quantum.html\" rel=\"noreferrer noopener\" target=\"_blank\">two claims of quantum supremacy</a> from Chinese quantum computing projects.</li></ul>\\n\\n\\n\\n<h2>Miscellaneous</h2>\\n\\n\\n\\n<ul><li>Would our response to the COVID pandemic been better if it was approached as an <a href=\"https://www.technologyreview.com/2021/10/15/1037195/engineering-epidemiology-pandemic-problem-solving/\" rel=\"noreferrer noopener\" target=\"_blank\">engineering problem</a>, rather than scientific research?</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'The Sobering Truth About the Impact of Your Business Ideas',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The Sobering Truth About the Impact of Your Business Ideas'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/the-sobering-truth-about-the-impact-of-your-business-ideas/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/the-sobering-truth-about-the-impact-of-your-business-ideas/',\n",
       "   'comments': 'https://www.oreilly.com/radar/the-sobering-truth-about-the-impact-of-your-business-ideas/#respond',\n",
       "   'published': 'Tue, 26 Oct 2021 13:07:58 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=26, tm_hour=13, tm_min=7, tm_sec=58, tm_wday=1, tm_yday=299, tm_isdst=0),\n",
       "   'authors': [{'name': 'Eric Colson, Daragh Sibley and Dave Spiegel'}],\n",
       "   'author': 'Eric Colson, Daragh Sibley and Dave Spiegel',\n",
       "   'author_detail': {'name': 'Eric Colson, Daragh Sibley and Dave Spiegel'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Operations', 'scheme': None, 'label': None},\n",
       "    {'term': 'Research', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=14041',\n",
       "   'guidislink': False,\n",
       "   'summary': 'The introduction of data science into the business world has contributed far more than recommendation algorithms; it has also taught us a lot about the efficacy with which we manage our businesses. Specifically, data science has introduced rigorous methods for measuring the outcomes of business ideas. These are the strategic ideas that we implement in [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The introduction of data science into the business world has contributed far more than recommendation algorithms; it has also taught us a lot about the efficacy with which we manage our businesses. Specifically, data science has introduced rigorous methods for measuring the outcomes of business ideas. These are the strategic ideas that we implement in [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>The introduction of data science into the business world has contributed far more than recommendation algorithms; it has also taught us a lot about the efficacy with which we manage our businesses. Specifically, data science has introduced rigorous methods for measuring the outcomes of business ideas. These are the strategic ideas that we implement in order to achieve our business goals. For example, “We&#8217;ll lower prices to increase demand by 10%” and “we’ll implement a loyalty program to improve retention by 5%.” Many companies simply execute on their business ideas without measuring if they delivered the impact that was expected. But, science-based organizations are rigorously quantifying this impact and have learned some sobering lessons:</p>\\n\\n\\n\\n<ol><li>The vast majority of business ideas fail to generate a positive impact.</li><li>Most companies are unaware of this.</li><li>It is unlikely that companies will increase the success rate for their business ideas.</li></ol>\\n\\n\\n\\n<p>These are lessons that could profoundly change how businesses operate. In what follows, we flesh out the three assertions above with the bulk of the content explaining why it may be difficult to improve the poor success rate for business ideas. Despite the challenges, we conclude with some recommendations for better managing your business.</p>\\n\\n\\n\\n<h3>(1) The vast majority of business ideas fail to generate positive results </h3>\\n\\n\\n\\n<p>To properly measure the outcomes of business ideas, companies are embracing experimentation (a.k.a. randomized controlled trials or A/B testing). The process is simple in concept. Before rolling out a business idea, you test; you try the idea out on a subset group of customers<a href=\"http://feeds.feedburner.com/oreilly/radar/atom#footnote1\"><sup>1</sup></a> while another group—a control group—is not exposed to the new idea. When properly sampled, the two groups will exhibit the same attributes (demographics, geographics, etc.) and behaviors (purchase rates, life-time-value, etc.). Therefore, when the intervention is introduced—ie. the exposure to the new business idea—any changes in behavior can be causally attributed to the new business idea. This is the gold standard in scientific measurement used in clinical trials for medical research, biological studies, pharmaceutical trials, and now to test business ideas.</p>\\n\\n\\n\\n<p>For the very first time in many business domains, experimentation reveals the causal impact of our business ideas. The results are humbling. They indicate that the vast majority of our business ideas fail to generate positive results. <strong>It&#8217;s not uncommon for 70-90% of ideas to</strong> <strong>either have no impact at all or actually move the metrics in the opposite direction of what was intended. </strong>Here are some statistics from a few notable companies that have disclosed their success rates publicly:</p>\\n\\n\\n\\n<ul><li>Microsoft declared that roughly one-third of their ideas yield negative results, one-third yield no results, and one-third yield positive results (Kohavi and Thomke, 2017).</li><li>Streaming service Netflix believes that 90% of its ideas are wrong (Moran, 2007). </li><li>Google reported that as much as 96.1% of their ideas fail to generate positive results (Thomke, 2020).</li><li>Travel site Booking.com shared that 9 out of 10 of their ideas fail to improve metrics (Thomke, 2020).</li></ul>\\n\\n\\n\\n<p>To be sure, the statistics cited above reflect a tiny subset of the ideas implemented by companies. Further, they probably reflect a particular class of ideas: those that are conducive to experimentation<a href=\"http://feeds.feedburner.com/oreilly/radar/atom#footnote2\"><sup>2</sup></a> such as changes to user interfaces, new ad creatives, subtle messaging variants, and so on. Moreover, the companies represented are all relatively young and either in the tech sector or leverage technology as a medium for their business. This is far from a random sample of all companies and business ideas. So, while it&#8217;s possible that the high failure rates are specific to the types of companies and ideas that are convenient to test experimentally, it seems more plausible that the high failure rates are reflective of business ideas in general and that the disparity in perception of their success can be attributed to the method of measurement. We shouldn’t be surprised; high failure rates are common in many domains. Venture capitalists invest in many companies because most fail; similarly, most stock portfolio managers fail to outperform the S&amp;P 500; in biology, most mutations are unsuccessful; and so on. The more surprising aspect of the low success rates for business ideas is most of us don’t seem to know about it.</p>\\n\\n\\n\\n<h3>(2) Most companies are unaware of the low success rates for their business ideas</h3>\\n\\n\\n\\n<p>Those statistics should be sobering to any organization. Collectively, business ideas represent the roadmap companies rely upon to hit their goals and objectives. However, the dismal failure rates appear to be known only to the few companies that regularly conduct experiments to scientifically measure the impact of their ideas. Most companies do not appear to employ such a practice and seem to have the impression that all or most of their ideas are or will be successful. Planners, strategists, and functional leaders rarely convey any doubts about their ideas. To the contrary, they set expectations on the predicted impact of their ideas and plan for them as if they are certain. They attach revenue goals and even their own bonuses to those predictions. <strong>But, how much do they really know about the outcomes of those ideas?</strong> If they don’t have an experimentation practice, they likely know very little about the impact their roadmap is actually having.</p>\\n\\n\\n\\n<p>Without experimentation, companies either don’t measure the outcomes of their ideas at all or use flimsy methods to assess their impacts. In some situations, ideas are acted upon so fluidly that they are not recognized as something that merits measurement.&nbsp; For example, in some companies an idea such as “we’ll lower prices to increase demand by 10%” might be made on a whim by a marketing exec and there will be no follow up at all to see if it had the expected impact on demand. In other situations, a post-implementation assessment of a business idea is done, but in terms of <em>execution</em>, not impact (“Was it implemented on time?” “Did it meet requirements?” etc., not “What was the causal impact on business metrics?”). In other cases still, post hoc analysis is performed in an attempt to quantify the impact of the idea. But, this is often done using subjective or less-than-rigorous methods to justify the idea <em>as a success</em>. That is, the team responsible for doing the analysis often is motivated either implicitly or explicitly to find evidence of success. Bonuses are often tied to the outcomes of business ideas. Or, perhaps the VP whose idea it was is the one commissioning the analysis. In either case, there is a strong motivation to find success. For example, a company may seek qualitative customer feedback on the new loyalty program in order to craft a narrative for how it is received. Yet, the customers willing to give feedback are often biased towards the positive. Even if more objective feedback were to be acquired it would still not be a measure of impact; customers often behave differently from the sentiments they express. In still other cases, empirical analysis is performed on transaction data in an attempt to quantify the impact. But, without experimentation, at best, such analysis can only capture correlation—not causation. Business metrics are influenced simultaneously by many factors, including random fluctuations. Without properly controlling for these factors, it can be tempting to attribute any uptick in metrics as a result of the new business idea. The combination of malleable measurements and strong incentives to show success likely explain why so many business initiatives are perceived to be successful.</p>\\n\\n\\n\\n<p>By contrast, the results of experimentation are numeric and austere. They do not care about the hard work that went into executing on a business initiative. They are unswayed by well-crafted narratives, emotional reviews by customers, or an executive&#8217;s influence. In short, they are brutally honest and often hard-to-accept.<a href=\"http://feeds.feedburner.com/oreilly/radar/atom#footnote3\"><sup>3</sup></a> Without experimentation, companies don&#8217;t learn the sobering truth about their high failure rate. While ignorance is bliss, it is not an effective way to run your business.</p>\\n\\n\\n\\n<h3>(3) It is unlikely that companies will increase the success rate for their business ideas.</h3>\\n\\n\\n\\n<p>At this point, you may be thinking, “we need to get better at separating the wheat from the chaff, so that we only allocate resources to the <em>good</em> ideas.” Sadly, without experimentation, we see little reason for optimism as there are forces that will actively work against your efforts.</p>\\n\\n\\n\\n<h4><strong>One force that is actively working against us is the way we reason about our companies. </strong></h4>\\n\\n\\n\\n<p>We like to reason about our businesses as if they are simple, predictable systems. We build models of their component parts and manage them as if they are levers we can pull in order to predictably manage the business to a desired state. For example, a marketer seeking to increase demand builds a model that allows her to associate each possible price with a predicted level of demand. The scope of the model is intentionally narrow so that she can isolate the impact price has on demand. Other factors like consumer perception, the competitive assortment, operational capacity, the macroeconomic landscape, and so on are out of her control and assumed to remain constant. Equipped with such an intuitive model, she can identify the price that optimizes demand. She’s in control and hitting her goal is merely a matter of execution.</p>\\n\\n\\n\\n<p>However, experimentation reveals that our predictions for the impact of new business ideas can be radically off—not just a little off in terms of magnitude, but often in the completely wrong direction. We lower prices and see demand go <em>down</em>. We launch a new loyalty program and it <em>hurts</em> retention. Such unintuitive results are far more common than you might think.</p>\\n\\n\\n\\n<p>The problem is that many businesses behave as complex systems which cannot be understood by studying its components in isolation. Customers, competitors, partners, market force—each can adjust in response to the intervention in ways that are not observable from simple models of the components. Just as you can’t learn about an ant colony by studying the behaviors of an individual ant (Mauboussin, 2009), the insights derived from modeling individual components of a business in isolation often have little relevance to the way the business behaves as a whole.</p>\\n\\n\\n\\n<p>It’s important to note that our use of the term <em>complex</em> does not just mean ‘not simple.’ <em>Complexity</em> is an entire area of research within Systems Theory. Complexity arises in systems with many interacting agents that react and adapt to one another and their environment. Examples of complex systems include weather systems, rain forest ecology, economies, the nervous system, cities, and yes, many businesses.</p>\\n\\n\\n\\n<p>Reasoning about complex systems requires a different approach. Rather than focusing on component parts, attention needs to be directed at system-wide behaviors. These behaviors are often termed “emergent,” to indicate that they are very hard to anticipate. This frame orients us around learning, not executing. It encourages more trial and error with less attachment to the outcomes of a narrow set of ideas. As complexity researcher Scott E. Page says, “An actor in a complex system controls almost nothing but influences almost everything” (Page, 2009).</p>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group has-very-light-gray-background-color has-background\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<h4><strong>An example of an attempt to manage a complex system to change behaviors</strong></h4>\\n</div></div>\\n</div></div>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>To make this tangible let’s take a look at a real example. Consider the story of the child daycare company featured in the popular book, <em>Freakonomics</em> (the original paper can be found <a href=\"https://rady.ucsd.edu/faculty/directory/gneezy/pub/docs/fine.pdf\">here</a>). The company faced a challenge with late pickups. The daycare closed at 4:00pm, yet parents would frequently pick up their children several minutes later. This required staff to stay late causing both expense and inconvenience. Someone in the company had a business idea to address the situation: a fine for late pickups. </p></blockquote>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>Many companies would simply implement the fine and not think to measure the outcome. Fortunately for the daycare, a group of researchers convinced them to run an experiment to measure the effectiveness of the policy. The daycare operates many locations which were randomly divided into test and control groups; the test sites would implement the late pickup fine while the control sites would leave things as is. The experiment ran its course and to everyone’s surprise they learned that fine actually <em>increased</em> the number of late pickups.</p></blockquote>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>How is it possible that the business idea had the opposite effect of what was intended? There are several very plausible explanations, which we summarize below—some of these come from the paper while others are our own hypotheses.</p></blockquote>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<ul><li><p>The authors of the paper assert that imposing a fine makes the penalty for a late pick up explicitly clear. Parents are generally aware that late pick-ups are not condoned. But in the absence of a fine, they are unsure what the penalty may be. Some parents may have imagined a penalty much worse than the fine—e.g., expulsion from the daycare. This belief might have been an effective deterrent. But when the fine was imposed it explicitly quantified that amount of the penalty for the late pickups (roughly equivalent to $2.75 in 1998 dollars). For some parents this was a sigh of relief—expulsion was not on the docket. One merely has to pay a fine for the transgression, making the cost of a late pickup less than what was believed. Hence, late pick-ups increase (Gneezy &amp; Rustichini, 2000).</p></li></ul>\\n</div></div>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<ul><li><p>Another explanation from the paper involves social norms. Many parents may have considered late pickups as socially inappropriate and would therefore go through great lengths to avoid them (leaving work early, scrambling for backup coverage, etc). The fine however, provides an easier way to stay in good social standing. It’s as if it signals <em>‘late pickups are not condoned. But if you pay us the fine you are forgiven</em>.<em>’</em> Therefore, the fine acts as the price to pay to stay in good standing. For some parents this price is low relative to the arduous and diligent planning required to prevent a late pickup. Hence, late pickups increase in the presence of the fine (Gneezy &amp; Rustichini, 2000).</p></li></ul>\\n</div></div>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<ul><li><p>Still another explanation (which was only alluded to in the paper) has to do with the perceived cost structure associated with the staff having to stay late. From the parent’s perspective, the burden to the daycare of a late pickup might be considered fixed. If there is already at least one other parent also running late then there is no extra burden imposed since staff already has to stay. As surmised by the other explanations above, the fine increases the number of late pickups, which, therefore increases the probability that staff will have to stay late due to some other parent’s tardiness. Thus, one extra late pickup is no additional burden. Late pickups increase further.</p></li></ul>\\n</div></div>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<ul><li><p>One of our own explanations has to do with social norms thresholds. Each parent has a threshold for the appropriateness for late pickups based on social norms. The threshold might be the number of other parents observed or believed to be doing late pickups before such activity is believed to be appropriate. I.e., <em>if others are doing it, it must be okay. </em>(Note: this signal of appropriateness is independent from the perceived fixed cost structure mentioned above.) Since the fine increased the number of late pickups for some parents, other parents observed more late pickups and then followed suit.</p></li></ul>\\n</div></div>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>The above are plausible explanations for the observed outcome. Some may even seem obvious in hindsight.<a href=\"http://feeds.feedburner.com/oreilly/radar/atom#footnote4\"><sup>4</sup></a> However, these behaviors are extremely difficult to anticipate by focusing your attention on an individual component part: the fine.&nbsp; Such surprising outcomes are less rare than you might think. In this case, the increase in late pickups might have been so apparent that they could have been detected even without the experiment. However, the impact of many ideas often go undetected.</p></blockquote>\\n</div></div>\\n</div></div>\\n</div></div>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<p><strong>Another force that is actively working against our efforts to discern good ideas from bad is our cognitive biases.&nbsp;</strong>You might be thinking: “Thank goodness my company has processes that filter away bad ideas, so that we only invest in great ideas!” Unfortunately, all companies probably try hard to select only the best ideas, and yet we assert that they are not particularly successful at separating good from bad ideas. We suggest that this is because these processes are deeply human in nature, leaving them vulnerable to cognitive biases.</p>\\n\\n\\n\\n<p>Cognitive biases are systematic errors in human thinking and decision making (Tversky &amp; Kahneman, 1974). They result from the core thinking and decision making processes that we developed over our evolutionary history. Unfortunately, evolution adapted us to an environment with many differences from the modern world. This can lead to a habit of poor decision making. To illustrate: we know that a healthy bundle of kale is better for our bodies than a big juicy burger. Yet, we have an innate preference for the burger. Many of us will decide to eat the burger tonight. And tomorrow night. And again next week. We know we shouldn’t. But yet our society continues consuming too much meat, fat, and sugar. Obesity is now a major public health problem. Why are we doing this to ourselves? Why are we imbued with such a strong urge—a literal gut instinct—to repeatedly make decisions that have negative consequences for us? It’s because meat, fat, and sugar were scarce and precious resources for most of our evolutionary history. Consuming these resources at every opportunity was an adaptive behavior, and so humans evolved a strong desire to do so. Unfortunately, we remain imbued with this desire despite the modern world’s abundance of burger joints.</p>\\n\\n\\n\\n<p>Cognitive biases are predictable and pervasive. We fall prey to them despite believing that we are rational and objective thinkers. Business leaders (ourselves included) are not immune. These biases compromise our ability to filter out bad business ideas. They can also make us feel extremely confident as we make a bad business decision. See the following sidebar for examples of cognitive biases manifesting in business environments and producing bad decisions.</p>\\n\\n\\n\\n<div class=\"wp-block-group has-very-light-gray-background-color has-background\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<h4 class=\"has-text-align-center\">Cognitive bias examples</h4>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>Group Think (Whyte, 1952) describes our tendency to converge towards shared opinions when we gather in groups. This emerges from a very human impulse to conform. Group cohesion was important in our evolutionary past. You might have observed this bias during a prioritization meeting: The group entered with disparate, weakly held opinions, but exited with a consensus opinion, which everyone felt confident about.&nbsp; As a hypothetical example: A meeting is called to discuss a disagreement between two departments. Members of the departments have differing but strong opinions, based on solid lines of reasoning and evidence. But once the meeting starts the attendees begin to self censor. Nobody wants to look difficult. One attendee recognizes a gaping flaw in the “other side’s” analysis, but they don’t want to make their key cross functional partner look bad in front of their boss. Another attendee may have thought the idea was too risky, but, because the responsibility for the idea is now diffused across everyone in the meeting, won&#8217;t be her fault if the project fails and so she acquiesces. Finally, a highly admired senior executive speaks up and everyone converges towards this position (in business lingo we just heard the HiPPO or Highest Paid Person’s Opinion; or in the scientific vernacular, the Authority Bias (Milgram, 1963). These social pressures will have collectively stifled the meaningful debate that could have filtered out a bad business decision.</p></blockquote>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>The Sunk Cost bias (Arkes &amp; Blumer, 1985) describes our tendency to justify new investments via past expenditures. In colloquial terms, it’s our tendency to throw good money after bad. We suspect you’ve seen this bias more than a few times in the workplace. As another hypothetical example: A manager is deciding what their team will prioritize over the next fiscal year. They naturally think about incremental improvements that they could make to their team&#8217;s core product. This product is based on a compelling idea, however, it hasn’t yet delivered the impact that everyone expected. But, the manager has spent so much time and effort building organizational momentum behind the product. The manager gave presentations about it to senior leadership and painstakingly cultivated a sense of excitement about it with their cross functional partners. As a result, the manager decides to prioritize incremental work on the existing product, without properly investigating a new idea that would have yielded much more impact. In this case, the manager’s decision was driven by thinking about the sunk costs associated with the existing system. This created a barrier to innovation and yielded a bad business decision.</p></blockquote>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>The Confirmation Bias (Nickerson, 1998) describes our tendency to focus upon evidence that confirms our beliefs, while discounting evidence that challenges our beliefs. We’ve certainly fallen prey to this bias in our personal and professional lives. As a hypothetical example: An exec wonders <em>&#8216;should we implement a loyalty program to improve client retention?&#8217; </em>They find a team member who thinks this sounds like a good idea. So the exec asks the team member to do some market research to inform whether the company should create their own loyalty program. The team member looks for examples of highly successful loyalty programs from other companies. Why look for examples of bad programs? This company has no intention of implementing a bad loyalty program. Also, the team member wants to impress the exec by describing all the opportunities that could be unlocked with this program. They want to demonstrate their abilities as a strategic thinker. They might even get to lead the implementation of the program, which could be great for their career. As a result, the team member builds a presentation that emphasizes positive examples and opportunities, while discounting negative examples and risks. This presentation leads the exec to overestimate the probability that this initiative will improve client retention, and thus fail to filter out a bad business decision.</p></blockquote>\\n</div></div>\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<blockquote class=\"wp-block-quote\"><p>The biases we’ve listed above are just a sample of the extensive and well documented set of cognitive biases (e.g., Availability Bias, Survivorship Bias, Dunning-Kruger effect, etc.) that limit business leaders&#8217; ability to identify and implement only successful business initiatives. Awareness of these biases can decrease our probability of committing them. However, awareness isn’t a silver bullet. We have a desk mat in our office that lists many of these cognitive biases. We regret to report that we often return to our desks, stare down at the mat … and realize that we’ve just fallen prey to another bias.&nbsp;<br /></p></blockquote>\\n</div></div>\\n</div></div>\\n</div></div>\\n\\n\\n\\n<p><strong>A final force that is actively working against efforts to discern good ideas from bad is your business maturing. </strong>A thought experiment: Suppose a local high school coach told NBA superstar Stephen Curry how to adjust his jump shot. Would implementing these changes improve or hurt his performance? It is hard to imagine it would help. Now, suppose the coach gave this advice to a local 6th grader. It seems likely that it would help the kid’s game.</p>\\n\\n\\n\\n<p>Now, imagine a consultant telling Google how to improve their search algorithm versus advising a startup on setting up a database. It’s easier to imagine the consultant helping the startup. Why? Well, Google search is a cutting edge system that has received extensive attention from numerous world class experts—kind of like Steph Curry. It’s going to be hard to offer a new great idea. In contrast, the startup will benefit from getting pointed in a variety of good directions—kind of like a 6th grader.</p>\\n\\n\\n\\n<p>To use a more analytic framework, imagine a hill which represents a company’s objective function<a href=\"http://feeds.feedburner.com/oreilly/radar/atom#footnote5\"><sup>5</sup></a> like profit, revenue, or retention. The company’s goal is to climb to the peak, where it’s objective is maximized. However, the company can’t see very far in this landscape. It doesn’t know where the peak is. It can only assess (if it’s careful and uses experimentation) whether it’s going up or downhill by taking small steps in different directions—perhaps by tweaking it’s pricing strategy and measuring if revenue goes up.</p>\\n\\n\\n\\n<p>When a company (or basketball player) is young, its position on this objective function (profit, etc.) landscape is low. It can step in many directions and go uphill. Through this process, a company can grow (walk up Mount Revenue). However, as it climbs the mountain, a smaller proportion of the possible directions to step will lead uphill. At the summit a step in any direction will take you downhill.</p>\\n\\n\\n\\n<p>This is admittedly a simple model&nbsp; of a business (and we already discussed the follies of using simple models). However, all companies will eventually face the truism that as they improve, there are fewer ways to continue to improve (the low apples have been plucked), as well as the extrinsic constraints of market saturation, commoditization, etc. that make it harder to improve your business as it matures.<a href=\"http://feeds.feedburner.com/oreilly/radar/atom#footnote6\"><sup>6</sup></a></p>\\n\\n\\n\\n<h3>So, what to do</h3>\\n\\n\\n\\n<p>We’ve argued that most business ideas fail to deliver on their promised goals. We’ve also explained that there are systematic reasons that make it unlikely that companies will get better, just by trying harder. So where does this leave you? Are you destined to implement mostly bad ideas? Here are a few recommendations that might help:</p>\\n\\n\\n\\n<ol><li><strong>Run experiments and exercise your optionality. </strong>Recognize that your business may be a complex system, making it very difficult to predict how it will respond to your business ideas. Instead of rolling out your new business ideas to all customers, try them on a sample of customers as an experiment. This will show you the impact your idea has on the company. You can then make an informed decision about whether or not to roll out your idea. If your idea has a positive impact, great. Roll it out to all customers. But in the more likely event that your idea does not have the positive impact you were hoping for you can end the experiment and kill the idea. It may seem wasteful to use company resources to implement a business idea only to later kill it, but this is better than unknowingly providing on-going support to an idea that is doing nothing or actually hurting your metrics—which is what happens most of the time.</li><li><strong>Recognize your cognitive biases, collect a priori predictions, and celebrate learnings. </strong>Your company’s ability to filter out bad business ideas will be limited by your team member’s cognitive biases. You can start building a culture that appreciates this fact by sending a survey to all of a project’s stakeholders before your next big release. Ask everyone to predict how the metrics will move. Make an anonymized version of these predictions and accuracy available for employees. We expect your team members will become less confident in their predictions over time. This process may also reveal that big wins tend to emerge from a string of experiments, rather than a single stroke of inspiration. So celebrate all of the necessary stepping stones on the way to a big win.</li><li><strong>Recognize that it&#8217;s going to get harder to find successful ideas, so try more things, and get more skeptical. </strong>As your company matures, it may get harder to find ways to improve it. We see three ways to address this challenge. First, try more ideas. It will be hard to increase the success rate of your ideas, so try more ideas. Consider building a leverageable and reusable experimentation platform to increase your bandwidth. Follow the lead of the venture world: fund a lot of ideas to get a few big wins.<a href=\"http://feeds.feedburner.com/oreilly/radar/atom#footnote7\"><sup>7</sup></a> Second, as your company matures, you might want to adjust the amount of evidence that is required before you roll out a change—a more mature company should require a higher degree of statistical certainty before inferring that a new feature has improved metrics. In experimental lingo, you might want to adjust the “p-value thresholds” that you use to assess an experiment. Or to use our metaphor, a 6th grader should probably just listen whenever a coach tells them to adjust their jump shot, but Steph Curry should require a lot of evidence before he adjusts his.</li></ol>\\n\\n\\n\\n<p>This may be a hard message to accept. It&#8217;s easier to assume that all of our ideas are having the positive impact that we intended. It’s more inspiring to believe that successful ideas and companies are the result of brilliance rather than trial and error. But, consider the deference we give to mother nature. She is able to produce such exquisite creatures—the giraffe, the mighty oak tree, even us humans—each so perfectly adapted to their environment that we see them as the rightful owners of their respective niches. Yet, mother nature achieves this not through grandiose ideas, but through trial and error… with a success rate far more dismal than that of our business ideas. It&#8217;s an effective strategy if we can convince our egos to embrace it.</p>\\n\\n\\n\\n<p>  </p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h3 class=\"has-text-align-center\">References</h3>\\n\\n\\n\\n<p>Arkes, H. R., &amp; Blumer, C. (1985), The psychology of sunk costs. <em>Organizational Behavior and Human Decision Processes, 35,</em> 124-140.</p>\\n\\n\\n\\n<p>Gneezy, U., &amp; Rustichini, A. (2000). A Fine is a Price. <em>The Journal of Legal Studies</em>, 29(1), 1-17. doi:10.1086/468061</p>\\n\\n\\n\\n<p>Kahneman, D., &amp; Klein, G. (2009). Conditions for intuitive expertise: A failure to disagree. <em>American Psychologist, 64</em>(6), 515–526. <a href=\"https://psycnet.apa.org/doi/10.1037/a0016755\">https://doi.org/10.1037/a0016755</a></p>\\n\\n\\n\\n<p>Kohavi, R. &amp; Thomke, S. “The Surprising Power of Online Experiments,” <em>Harvard Business Review</em> 95, no. 5 (September-October 2017)</p>\\n\\n\\n\\n<p>Mauboussin, M. J. (2009). Think Twice: Harnessing the Power of Counterintuition. <em>Harvard Business Review Press</em>.</p>\\n\\n\\n\\n<p>Milgram, S. (1963). &#8220;Behavioral Study of obedience&#8221;. <em>The Journal of Abnormal and Social Psychology</em>. 67 (4): 371–378.</p>\\n\\n\\n\\n<p>Moran, M. Do It Wrong Quickly: How the Web Changes the Old Marketing Rules . s.l. : <em>IBM Press</em>, 2007. 0132255960.</p>\\n\\n\\n\\n<p>Nickerson, R. S. (1998), &#8220;Confirmation bias: A ubiquitous phenomenon in many guises&#8221;, <em>Review of General Psychology</em>, 2 (2): 175–220.</p>\\n\\n\\n\\n<p>Page, S. E. (2009). Understanding Complexity &#8211; <em>The Great Courses &#8211; Lecture Transcript and Course Guidebook</em> (1st ed.). The Teaching Company.</p>\\n\\n\\n\\n<p>Thomke, S. H. (2020). Experimentation Works: The Surprising Power of Business Experiments. <em>Harvard Business Review Press.</em></p>\\n\\n\\n\\n<p>Tversky, A., &amp; Kahneman, D. (1974). Judgment under uncertainty: Heuristics and biases. <em>Science, 185</em>(4157), 1124-1131.</p>\\n\\n\\n\\n<p>Whyte, W. H., (1952). “Groupthink”. <em>Fortune</em>, 114-117, 142, 146.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h3 class=\"has-text-align-center\">Footnotes</h3>\\n\\n\\n\\n<ol><li id=\"footnote1\">Do not confuse the term ‘test’ to mean a process by which a nascent idea is vetted to get feedback. In an experiment, the test group receives a full-featured implementation of an idea. The goal of the experiment is to measure impact—not get feedback.</li><li id=\"footnote2\">In some cases there may be insufficient sample size, ethical concerns, lack of a suitable control group, and many other conditions that can inhibit experimentation.</li><li id=\"footnote3\">Even trained statisticians can fall victim to pressures to cajole the data. “P-hacking”, “significance chasing” and other terms refer to the temptation to use flawed methods in statistical analysis.</li><li id=\"footnote4\">We believe that these types of factors are only obvious in hindsight because the signals are often unobserved until we know to look for them (Kahneman &amp; Klein, 2009).</li><li id=\"footnote5\">One reason among many why this mental picture is oversimplified is that it implicitly takes business conditions and the world at large to be static—the company “state vector” that maximizes the objective function today is the same as what maximizes the objective function tomorrow.  In other words, it ignores that, in reality, the hill is changing shape under our feet as we try to climb it. Still, it’s a useful toy model.</li><li id=\"footnote6\">Finding a new market (jumping to a new “hill” in the “Mount Revenue” metaphor), as recommended in the next section, is one way to continue improving business metrics even as your company matures.</li><li id=\"footnote7\">VCs are able to learn about the outcomes of the startups even without experimentation. This is because the outcomes are far more readily apparent than that of business ideas. It&#8217;s difficult to cajole results to show a successful outcome when the company is out of business.</li></ol>\\n\\n\\n\\n<p></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/the-sobering-truth-about-the-impact-of-your-business-ideas/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'MLOps and DevOps: Why Data Makes It Different',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'MLOps and DevOps: Why Data Makes It Different'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/mlops-and-devops-why-data-makes-it-different/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/mlops-and-devops-why-data-makes-it-different/',\n",
       "   'comments': 'https://www.oreilly.com/radar/mlops-and-devops-why-data-makes-it-different/#respond',\n",
       "   'published': 'Tue, 19 Oct 2021 14:17:38 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=19, tm_hour=14, tm_min=17, tm_sec=38, tm_wday=1, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Ville Tuulos and Hugo Bowne-Anderson'}],\n",
       "   'author': 'Ville Tuulos and Hugo Bowne-Anderson',\n",
       "   'author_detail': {'name': 'Ville Tuulos and Hugo Bowne-Anderson'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=14018',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Much has been written about struggles of deploying machine learning projects to production. As with many burgeoning fields and disciplines, we don’t yet have a shared canonical infrastructure stack or best practices for developing and deploying data-intensive applications. This is both frustrating for companies that would prefer making ML an ordinary, fuss-free value-generating function like [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Much has been written about struggles of deploying machine learning projects to production. As with many burgeoning fields and disciplines, we don’t yet have a shared canonical infrastructure stack or best practices for developing and deploying data-intensive applications. This is both frustrating for companies that would prefer making ML an ordinary, fuss-free value-generating function like [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Much has been written about struggles of deploying machine learning projects to production. As with many burgeoning fields and disciplines, we don’t yet have a shared canonical infrastructure stack or best practices for developing and deploying data-intensive applications. This is both frustrating for companies that would prefer making ML an ordinary, fuss-free value-generating function like software engineering, as well as exciting for vendors who see the opportunity to create buzz around a new category of enterprise software.</p>\\n\\n\\n\\n<p>The new category is often called <em>MLOps</em>. While there isn’t an authoritative definition for the term, it shares its ethos with its predecessor, the <em>DevOps </em>movement in software engineering: by adopting well-defined processes, modern tooling, and automated workflows, we can streamline the process of moving from development to robust production deployments. This approach has worked well for software development, so it is reasonable to assume that it could address struggles related to deploying machine learning in production too.</p>\\n\\n\\n\\n<p>However, the concept is quite abstract. Just introducing a new term like MLOps doesn’t solve anything by itself, rather, it just adds to the confusion. In this article, we want to dig deeper into the fundamentals of machine learning as an engineering discipline and outline answers to key questions:</p>\\n\\n\\n\\n<ol><li><strong>Why</strong> does ML need special treatment in the first place? Can’t we just fold it into existing DevOps best practices?</li><li><strong>What</strong> does a modern technology stack for streamlined ML processes look like?</li><li><strong>How</strong> can you start applying the stack in practice today?</li></ol>\\n\\n\\n\\n<h2>Why: Data Makes It Different</h2>\\n\\n\\n\\n<p>All ML projects are software projects. If you peek under the hood of an ML-powered application, these days you will often find a repository of Python code. If you ask an engineer to show how they operate the application in production, they will likely show containers and operational dashboards—not unlike any other software service.</p>\\n\\n\\n\\n<p>Since software engineers manage to build ordinary software without experiencing as much pain as their counterparts in the ML department, it begs the question: should we just start treating ML projects as software engineering projects as usual, maybe educating ML practitioners about the existing best practices?</p>\\n\\n\\n\\n<p>Let’s start by considering the job of a non-ML software engineer: writing traditional software deals with well-defined, narrowly-scoped inputs, which the engineer can exhaustively and cleanly model in the code. In effect, the engineer designs and builds the world wherein the software operates.</p>\\n\\n\\n\\n<p>In contrast, a defining feature of ML-powered applications is that they are directly exposed to a large amount of messy, real-world data which is too complex to be understood and modeled by hand.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-14022\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/10/MLOps-v7_Fig1.png\" /></figure>\\n\\n\\n\\n<p>This characteristic makes ML applications fundamentally different from traditional software. It has far-reaching implications as to how such applications should be developed and by whom:</p>\\n\\n\\n\\n<ol><li><strong>ML applications are directly exposed to the constantly changing real world through data, </strong>whereas traditional software operates in a simplified, static, abstract world which is directly constructed by the developer. </li><li><strong>ML apps need to be developed through cycles of experimentation: </strong>due to the constant exposure to data, we don’t learn the behavior of ML apps through logical reasoning but through empirical observation.</li><li><strong>The skillset and the background of people building the applications gets realigned</strong>: while it is still effective to express applications in code, the emphasis shifts to data and experimentation—more akin to empirical science—rather than traditional software engineering.</li></ol>\\n\\n\\n\\n<p>This approach is not novel. There is a decades-long tradition of <em>data-centric programming</em>: developers who have been using data-centric IDEs, such as RStudio, Matlab, Jupyter Notebooks, or even Excel to model complex real-world phenomena, should find this paradigm familiar. However, these tools have been rather insular environments: they are great for prototyping but lacking when it comes to production use.</p>\\n\\n\\n\\n<p>To make ML applications production-ready from the beginning, developers must adhere to the same set of standards as all other production-grade software. This introduces further requirements:</p>\\n\\n\\n\\n<ol><li><strong>The scale of operations </strong>is often two orders of magnitude larger than in the earlier data-centric environments. Not only is data larger, but models—deep learning models in particular—are much larger than before.</li><li><strong>Modern ML applications need to be carefully orchestrated: </strong>with the dramatic increase in the complexity of apps, which can require dozens of interconnected steps, developers need better software paradigms, such as first-class DAGs.</li><li><strong>We need robust versioning for data, models, code, </strong>and preferably even the internal state of applications—think Git on steroids to answer inevitable questions: What changed? Why did something break? Who did what and when? How do two iterations compare?</li><li><strong>The applications must be integrated to the surrounding business systems </strong>so ideas can be tested and validated in the real world in a controlled manner.</li></ol>\\n\\n\\n\\n<p>Two important trends collide in these lists. On the one hand we have the long tradition of data-centric programming; on the other hand, we face the needs of modern, large-scale business applications. Either paradigm is insufficient by itself: it would be ill-advised to suggest building a modern ML application in Excel. Similarly, it would be pointless to pretend that a data-intensive application resembles a run-off-the-mill microservice which can be built with the usual software toolchain consisting of, say, GitHub, Docker, and Kubernetes.</p>\\n\\n\\n\\n<p>We need a new path that allows the results of data-centric programming, models and data science applications in general, to be deployed to modern production infrastructure, similar to how DevOps practices allows traditional software artifacts to be deployed to production continuously and reliably. Crucially, the new path is analogous but not equal to the existing DevOps path.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-14035\" height=\"488\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/10/Picture2.png\" width=\"530\" /></figure>\\n\\n\\n\\n<h2>What: The Modern Stack of ML Infrastructure</h2>\\n\\n\\n\\n<p>What kind of foundation would the modern ML application require? It should combine the best parts of modern production infrastructure to ensure robust deployments, as well as draw inspiration from data-centric programming to maximize productivity.</p>\\n\\n\\n\\n<p>While implementation details vary, the major infrastructural layers we’ve seen emerge are relatively uniform across a large number of projects. Let’s now take a tour of the various layers, to begin to map the territory. Along the way, we’ll provide illustrative examples. The intention behind the examples is not to be comprehensive (perhaps a fool’s errand, anyway!), but to reference concrete tooling used today in order to ground what could otherwise be a somewhat abstract exercise.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-14033\" height=\"294\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/10/Picture3.png\" width=\"580\" /><figcaption><br />Adapted from the book <a href=\"https://www.manning.com/books/effective-data-science-infrastructure\" rel=\"noreferrer noopener\" target=\"_blank\"><em>Effective Data Science Infrastructure</em></a></figcaption></figure>\\n\\n\\n\\n<h3>Foundational Infrastructure Layers</h3>\\n\\n\\n\\n<h4>Data</h4>\\n\\n\\n\\n<p><strong>Data</strong> is at the core of any ML project, so data infrastructure is a foundational concern. ML use cases rarely dictate the master data management solution, so the ML stack needs to integrate with existing data warehouses. Cloud-based data warehouses, such as <strong>Snowflake</strong>, AWS’ portfolio of databases like <strong>RDS, Redshift </strong>or <strong>Aurora</strong>, or an <strong>S3-based data lake</strong>, are a great match to ML use cases since they tend to be much more scalable than traditional databases, both in terms of the data set sizes as well as query patterns.</p>\\n\\n\\n\\n<h4>Compute</h4>\\n\\n\\n\\n<p>To make data useful, we must be able to conduct large-scale <strong>compute</strong> easily. Since the needs of data-intensive applications are diverse, it is useful to have a general-purpose compute layer that can handle different types of tasks from IO-heavy data processing to training large models on GPUs. Besides variety, the number of tasks can be high too: imagine a single workflow that trains a separate model for 200 countries in the world, running a hyperparameter search over 100 parameters for each model—the workflow yields 20,000 parallel tasks.</p>\\n\\n\\n\\n<p>Prior to the cloud, setting up and operating a cluster that can handle workloads like this would have been a major technical challenge. Today, a number of cloud-based, auto-scaling systems are easily available, such as <strong>AWS Batch. Kubernetes,</strong> a popular choice for general-purpose container orchestration, can be configured to work as a scalable batch compute layer, although the downside of its flexibility is increased complexity. Note that container orchestration for the compute layer is not to be confused with the workflow orchestration layer, which we will cover next.</p>\\n\\n\\n\\n<h4>Orchestration</h4>\\n\\n\\n\\n<p>The nature of computation is structured: we must be able to manage the complexity of applications by structuring them, for example, as a graph or a workflow that is <strong>orchestrated</strong>.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-14029\" height=\"134\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/10/Picture4.png\" width=\"534\" /></figure>\\n\\n\\n\\n<p>The workflow orchestrator needs to perform a seemingly simple task: given a workflow or DAG definition, execute the tasks defined by the graph in order using the compute layer. There are countless systems that can perform this task for small DAGs on a single server. However, as the workflow orchestrator plays a key role in ensuring that production workflows execute reliably, it makes sense to use a system that is both scalable and highly available, which leaves us with a few battle-hardened options, for instance: <a href=\"https://airflow.apache.org/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Airflow</strong></a>, a popular open-source workflow orchestrator; <a href=\"https://argoproj.github.io/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Argo</strong></a><strong>, </strong>a newer orchestrator that runs natively on Kubernetes, and managed solutions such as <a href=\"https://cloud.google.com/composer\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Google Cloud Composer</strong></a> and <a href=\"https://aws.amazon.com/step-functions/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>AWS Step Functions</strong></a>.</p>\\n\\n\\n\\n<h3>Software Development Layers</h3>\\n\\n\\n\\n<p>While these three foundational layers, data, compute, and orchestration, are technically all we need to execute ML applications at arbitrary scale, building and operating ML applications directly on top of these components would be like hacking software in assembly language: technically possible but inconvenient and unproductive. To make people productive, we need higher levels of abstraction. Enter the software development layers.</p>\\n\\n\\n\\n<h4>Versioning</h4>\\n\\n\\n\\n<p>ML app and software artifacts exist and evolve in a dynamic environment. To manage the dynamism, we can resort to taking snapshots that represent immutable points in time: of models, of data, of code, and of internal state. For this reason, we require <strong>a strong versioning layer</strong>.</p>\\n\\n\\n\\n<p>While <strong>Git</strong>, <strong>GitHub, </strong>and other similar tools for software version control work well for code and the usual workflows of software development, they are a bit clunky for tracking all experiments, models, and data. To plug this gap, frameworks like <a href=\"https://docs.metaflow.org/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Metaflow</strong></a> or <a href=\"https://mlflow.org/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>MLFlow</strong></a> provide a custom solution for versioning.</p>\\n\\n\\n\\n<h4>Software Architecture</h4>\\n\\n\\n\\n<p>Next, we need to consider who builds these applications and how. They are often built by data scientists who are not software engineers or computer science majors by training. Arguably, high-level programming languages like Python are the most expressive and efficient ways that humankind has conceived to formally define complex processes. It is hard to imagine a better way to express non-trivial business logic and convert mathematical concepts into an executable form.</p>\\n\\n\\n\\n<p>However, not all Python code is equal. Python written in Jupyter notebooks following the tradition of data-centric programming is very different from Python used to implement a scalable web server. To make the data scientists maximally productive, we want to provide supporting <strong>software architecture </strong>in terms of APIs and libraries that allow them to focus on data, not on the machines.</p>\\n\\n\\n\\n<h4>Data Science Layers</h4>\\n\\n\\n\\n<p>With these five layers, we can present a highly productive, data-centric software interface that enables iterative development of large-scale data-intensive applications. However, none of these layers help with modeling and optimization. We cannot expect data scientists to write modeling frameworks like PyTorch or optimizers like Adam from scratch! Furthermore, there are steps that are needed to go from raw data to features required by models.</p>\\n\\n\\n\\n<h4>Model Operations</h4>\\n\\n\\n\\n<p>When it comes to data science and modeling, we separate three concerns, starting from the most practical progressing towards the most theoretical. Assuming you have a model, how can you use it effectively? Perhaps you want to produce predictions in real-time or as a batch process. No matter what you do, you should monitor the quality of the results. Altogether, we can group these practical concerns in the <strong>model operations</strong> layer. There are many new tools in this space helping with various aspects of operations, including <a href=\"https://www.seldon.io/tech/products/deploy/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Seldon</strong></a> for model deployments, <a href=\"https://wandb.ai/site\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Weights and Biases</strong></a> for model monitoring, and <a href=\"https://truera.com/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>TruEra</strong></a> for model explainability.</p>\\n\\n\\n\\n<h4>Feature Engineering</h4>\\n\\n\\n\\n<p>Before you have a model, you have to decide how to feed it with labelled data. Managing the process of converting raw facts to features is a deep topic of its own, potentially involving feature encoders, feature stores, and so on. Producing labels is another, equally deep topic. You want to carefully manage consistency of data between training and predictions, as well as make sure that there’s no leakage of information when models are being trained and tested with historical data. We bucket these questions in the <strong>feature engineering</strong> layer. There’s an emerging space of ML-focused feature stores such as <a href=\"https://www.tecton.ai/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Tecton</strong></a> or labeling solutions like <a href=\"https://scale.com/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Scale</strong></a> and <a href=\"https://snorkel.ai/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Snorkel</strong></a>. Feature stores aim to solve the challenge that many data scientists in an organization require similar data transformations and features for their work and labeling solutions deal with <a href=\"https://www.oreilly.com/radar/arguments-against-hand-labeling/\" rel=\"noreferrer noopener\" target=\"_blank\">the very real challenges associated with hand labeling datasets</a>.</p>\\n\\n\\n\\n<h4>Model Development</h4>\\n\\n\\n\\n<p>Finally, at the very top of the stack we get to the question of mathematical modeling: What kind of modeling technique to use? What model architecture is most suitable for the task? How to parameterize the model? Fortunately, excellent off-the-shelf libraries like <a href=\"https://scikit-learn.org/stable/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>scikit-learn</strong></a> and <a href=\"https://pytorch.org/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>PyTorch</strong></a> are available to help with <strong>model development</strong>.</p>\\n\\n\\n\\n<h3>An Overarching Concern: Correctness and Testing</h3>\\n\\n\\n\\n<p>Regardless of the systems we use at each layer of the stack, we want to guarantee the correctness of results. In traditional software engineering we can do this by writing tests: for instance, a unit test can be used to check the behavior of a function with predetermined inputs. Since we know exactly how the function is implemented, we can convince ourselves through inductive reasoning that the function should work correctly, based on the correctness of a unit test.</p>\\n\\n\\n\\n<p>This process doesn’t work when the function, such as a model, is opaque to us. We must resort to <em>black box testing</em>—testing the behavior of the function with a wide range of inputs. Even worse, sophisticated ML applications can take a huge number of contextual data points as inputs, like the time of day, user’s past behavior, or device type into account, so an accurate test set up may need to become a full-fledged simulator.</p>\\n\\n\\n\\n<p>Since building an accurate simulator is a highly non-trivial challenge in itself, often it is easier to use a slice of the real-world as a simulator and A/B test the application in production against a known baseline. To make A/B testing possible, all layers of the stack should be be able to run many versions of the application concurrently, so an arbitrary number of production-like deployments can be run simultaneously. This poses a challenge to many infrastructure tools of today, which have been designed for more rigid traditional software in mind. Besides infrastructure, effective A/B testing requires a control plane, a modern experimentation platform, such as <a href=\"https://statsig.com/\" rel=\"noreferrer noopener\" target=\"_blank\">StatSig</a>.</p>\\n\\n\\n\\n<h2>How: Wrapping The Stack For Maximum Usability</h2>\\n\\n\\n\\n<p>Imagine choosing a production-grade solution for each layer of the stack: for instance, Snowflake for data, Kubernetes for compute (container orchestration), and Argo for workflow orchestration. While each system does a good job at its own domain, it is not trivial to build a data-intensive application that has cross-cutting concerns touching all the foundational layers. In addition, you have to layer the higher-level concerns from versioning to model development on top of the already complex stack. It is not realistic to ask a data scientist to prototype quickly and deploy to production with confidence using such a contraption. Adding more YAML to cover cracks in the stack is not an adequate solution.</p>\\n\\n\\n\\n<p>Many data-centric environments of the previous generation, such as Excel and RStudio, really shine at maximizing usability and developer productivity. Optimally, we could wrap the production-grade infrastructure stack inside a developer-oriented user interface. Such an interface should allow the data scientist to focus on concerns that are most relevant for them, namely the topmost layers of stack, while abstracting away the foundational layers.</p>\\n\\n\\n\\n<p>The combination of a production-grade core and a user-friendly shell makes sure that ML applications can be prototyped rapidly, deployed to production, and brought back to the prototyping environment for continuous improvement. The iteration cycles should be measured in hours or days, not in months.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-14037\" height=\"258\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/10/Picture5.png\" width=\"549\" /></figure>\\n\\n\\n\\n<p>Over the past five years, a number of such frameworks have started to emerge, both as commercial offerings as well as in open-source.</p>\\n\\n\\n\\n<p><a href=\"https://docs.metaflow.org/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Metaflow</strong></a> is an open-source framework, originally developed at Netflix, specifically designed to address this concern (disclaimer: <a href=\"https://outerbounds.co/\" rel=\"noreferrer noopener\" target=\"_blank\">one of the authors works on Metaflow</a>): How can we wrap robust production infrastructure in a single coherent, easy-to-use interface for data scientists? Under the hood, Metaflow integrates with best-of-the-breed production infrastructure, such as Kubernetes and AWS Step Functions, while providing a development experience that draws inspiration from data-centric programming, that is, by treating local prototyping as the first-class citizen.</p>\\n\\n\\n\\n<p>Google’s open-source <a href=\"https://www.kubeflow.org/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Kubeflow</strong></a> addresses similar concerns, although with a more engineer-oriented approach. As a commercial product, <a href=\"https://databricks.com/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Databricks</strong></a> provides a managed environment that combines data-centric notebooks with a proprietary production infrastructure. All cloud providers provide commercial solutions as well, such as <a href=\"https://aws.amazon.com/sagemaker/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>AWS Sagemaker</strong></a> or <a href=\"https://studio.azureml.net/\" rel=\"noreferrer noopener\" target=\"_blank\"><strong>Azure ML Studio</strong></a>.</p>\\n\\n\\n\\n<p>While these solutions, and many less known ones, seem similar on the surface, there are many differences between them. When evaluating solutions, consider focusing on the three key dimensions covered in this article:</p>\\n\\n\\n\\n<ol><li><strong>Does the solution provide a delightful user experience for data scientists and ML engineers?</strong> There is no fundamental reason why data scientists should accept a worse level of productivity than is achievable with existing data-centric tools.</li><li><strong>Does the solution provide first-class support for rapid iterative development and frictionless A/B testing?</strong> It should be easy to take projects quickly from prototype to production and back, so production issues can be reproduced and debugged locally.</li><li><strong>Does the solution integrate with your existing infrastructure, in particular to the foundational data, compute, and orchestration layers?</strong> It is not productive to operate ML as an island. When it comes to operating ML in production, it is beneficial to be able to leverage existing production tooling for observability and deployments, for example, as much as possible.</li></ol>\\n\\n\\n\\n<p>It is safe to say that all existing solutions still have room for improvement. Yet it seems inevitable that over the next five years the whole stack will mature, and the user experience will converge towards and eventually beyond the best data-centric IDEs.&nbsp; Businesses will learn how to create value with ML similar to traditional software engineering and empirical, data-driven development will take its place amongst other ubiquitous software development paradigms.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/mlops-and-devops-why-data-makes-it-different/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'The Quality of Auto-Generated Code',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The Quality of Auto-Generated Code'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/the-quality-of-auto-generated-code/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/the-quality-of-auto-generated-code/',\n",
       "   'comments': 'https://www.oreilly.com/radar/the-quality-of-auto-generated-code/#respond',\n",
       "   'published': 'Tue, 12 Oct 2021 13:45:10 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=12, tm_hour=13, tm_min=45, tm_sec=10, tm_wday=1, tm_yday=285, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides and Kevlin Henney'}],\n",
       "   'author': 'Mike Loukides and Kevlin Henney',\n",
       "   'author_detail': {'name': 'Mike Loukides and Kevlin Henney'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=14007',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Kevlin Henney and I were riffing on some ideas about GitHub Copilot, the tool for automatically generating code base on GPT-3&#8217;s language model, trained on the body of code that&#8217;s in GitHub. This article poses some questions and (perhaps) some answers, without trying to present any conclusions. First, we wondered about code quality. There are [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Kevlin Henney and I were riffing on some ideas about GitHub Copilot, the tool for automatically generating code base on GPT-3&#8217;s language model, trained on the body of code that&#8217;s in GitHub. This article poses some questions and (perhaps) some answers, without trying to present any conclusions. First, we wondered about code quality. There are [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Kevlin Henney and I were riffing on some ideas about <a href=\"https://copilot.github.com/\">GitHub Copilot</a>, the tool for automatically generating code base on GPT-3&#8217;s language model, trained on the body of code that&#8217;s in GitHub. This article poses some questions and (perhaps) some answers, without trying to present any conclusions.</p>\\n\\n\\n\\n<p>First, we wondered about code quality. There are lots of ways to solve a given programming problem; but most of us have some ideas about what makes code &#8220;good&#8221; or &#8220;bad.&#8221; Is it readable, is it well-organized? Things like that.&nbsp; In a professional setting, where software needs to be maintained and modified over long periods, readability and organization count for a lot.</p>\\n\\n\\n\\n<p>We know how to test whether or not code is correct (at least up to a certain limit). Given enough unit tests and acceptance tests, we can imagine a system for automatically generating code that is correct. <a href=\"https://increment.com/testing/in-praise-of-property-based-testing/\" rel=\"noreferrer noopener\" target=\"_blank\">Property</a><a href=\"https://increment.com/testing/in-praise-of-property-based-testing/\">-based testing</a> might give us some additional ideas about building test suites robust enough to verify that code works properly. But we don&#8217;t have methods to test for code that&#8217;s &#8220;good.&#8221; Imagine asking Copilot to write a function that sorts a list. There are lots of ways to sort. Some are pretty good—for example, <a href=\"https://en.wikipedia.org/wiki/Quicksort\" rel=\"noreferrer noopener\" target=\"_blank\">quicksort</a>. Some of them are awful. But a unit test has no way of telling whether a function is implemented using quicksort, <a href=\"https://kevlinhenney.medium.com/a-sort-of-permutation-768c1a7e029b\" rel=\"noreferrer noopener\" target=\"_blank\">permutation sort</a>, (which completes in factorial time), <a href=\"https://kevlinhenney.medium.com/need-something-sorted-sleep-on-it-11fdf8453914\" rel=\"noreferrer noopener\" target=\"_blank\">sleep sort</a>, or one of the other strange sorting algorithms that Kevlin has been writing about.</p>\\n\\n\\n\\n<p>Do we care? Well, we care about O(N log N) behavior versus O(N!). But assuming that we have some way to resolve that issue, if we can specify a program&#8217;s behavior precisely enough so that we are highly confident that Copilot will write code that&#8217;s correct and tolerably performant, do we care about its aesthetics? Do we care whether it&#8217;s readable? 40 years ago, we might have cared about the assembly language code generated by a compiler. But today, we don&#8217;t, except for a few increasingly rare corner cases that usually involve device drivers or embedded systems. If I write something in C and compile it with gcc, realistically I&#8217;m never going to look at the compiler&#8217;s output. I don&#8217;t need to understand it.</p>\\n\\n\\n\\n<p>To get to this point, we may need a meta-language for describing what we want the program to do that&#8217;s almost as detailed as a modern high-level language. That could be what the future holds: an understanding of &#8220;prompt engineering&#8221; that lets us tell an AI system precisely what we want a program to do, rather than how to do it. Testing would become much more important, as would understanding precisely the business problem that needs to be solved. “Slinging code” in whatever the language would become less common.</p>\\n\\n\\n\\n<p>But what if we don&#8217;t get to the point where we trust automatically generated code as much as we now trust the output of a compiler? Readability will be at a premium as long as humans need to read code. If we have to read the output from one of Copilot&#8217;s descendants to judge whether or not it will work, or if we have to debug that output because it mostly works, but fails in some cases, then we will need it to generate code that&#8217;s readable. Not that humans currently do a good job of writing readable code; but we all know how painful it is to debug code that isn’t readable, and we all have some concept of what “readability” means.</p>\\n\\n\\n\\n<p>Second: Copilot was trained on the body of code in GitHub. At this point, it is all (or almost all) written by humans. Some of it is good, high quality, readable code; a lot of it isn&#8217;t. What if Copilot became so successful that Copilot-generated code came to constitute a significant percentage of the code on GitHub? The model will certainly need to be re-trained from time to time. So now, we have a feedback loop: Copilot trained on code that has been (at least partially) generated by Copilot. Does code quality improve? Or does it degrade? And again, do we care, and why?</p>\\n\\n\\n\\n<p>This question can be argued either way. People working on automated tagging for AI seem to be taking the position that iterative tagging leads to better results: i.e., after a tagging pass, use a human-in-the-loop to check some of the tags, correct them where wrong, and then use this additional input in another training pass. Repeat as needed. That&#8217;s not all that different from current (non-automated) programming: write, compile, run, debug, as often as needed to get something that works. The feedback loop enables you to write good code.</p>\\n\\n\\n\\n<p>A human-in-the-loop approach to training an AI code generator is one possible way of getting &#8220;good code&#8221; (for whatever &#8220;good&#8221; means)—though it&#8217;s only a partial solution. Issues like indentation style, meaningful variable names, and the like are only a start. Evaluating whether a body of code is structured into coherent modules, has well-designed APIs, and could easily be understood by maintainers is a more difficult problem. Humans can evaluate code with these qualities in mind, but it takes time. A human-in-the-loop might help to train AI systems to design good APIs, but at some point, the &#8220;human&#8221; part of the loop will start to dominate the rest.</p>\\n\\n\\n\\n<p>If you look at this problem from the standpoint of evolution, you see something different. If you breed plants or animals (a highly selected form of evolution) for one desired quality, you will almost certainly see all the other qualities degrade: you&#8217;ll get <a href=\"https://www.akc.org/expert-advice/health/hip-dysplasia-in-dogs/\" rel=\"noreferrer noopener\" target=\"_blank\">large dogs with hips that don&#8217;t work</a>, or <a href=\"https://www.puppyleaks.com/done-bulldogs/\" rel=\"noreferrer noopener\" target=\"_blank\">dogs with flat faces that can&#8217;t breathe properly</a>.</p>\\n\\n\\n\\n<p>What direction will automatically generated code take? We don&#8217;t know. Our guess is that, without ways to measure &#8220;code quality&#8221; rigorously, code quality will probably degrade. Ever since Peter Drucker, management consultants have liked to say, &#8220;If you can&#8217;t measure it, you can&#8217;t improve it.&#8221; And we suspect that applies to code generation, too: aspects of the code that can be measured will improve, aspects that can&#8217;t won&#8217;t.&nbsp; Or, as the accounting historian <a href=\"https://en.wikipedia.org/wiki/H._Thomas_Johnson\" rel=\"noreferrer noopener\" target=\"_blank\">H. Thomas Johnson</a> said, “Perhaps what you measure is what you get. More likely, what you measure is all you’ll get. What you don’t (or can’t) measure is lost.&#8221;</p>\\n\\n\\n\\n<p>We can write tools to measure some superficial aspects of code quality, like obeying stylistic conventions. We already have tools that can &#8220;fix&#8221; fairly superficial quality problems like indentation. But again, that superficial approach doesn&#8217;t touch the more difficult parts of the problem. If we had an algorithm that could score readability, and restrict Copilot&#8217;s training set to code that scores in the 90th percentile, we would certainly see output that looks better than most human code. Even with such an algorithm, though, it&#8217;s still unclear whether that algorithm could determine whether variables and functions had appropriate names, let alone whether a large project was well-structured.</p>\\n\\n\\n\\n<p>And a third time: do we care? If we have a rigorous way to express what we want a program to do, we may never need to look at the underlying C or C++. At some point, one of Copilot&#8217;s descendants may not need to generate code in a &#8220;high level language&#8221; at all: perhaps it will generate machine code for your target machine directly. And perhaps that target machine will be <a href=\"https://webassembly.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Web Assembly</a>, the JVM, or something else that&#8217;s very highly portable.</p>\\n\\n\\n\\n<p>Do we care whether tools like Copilot write good code? We will, until we don&#8217;t. Readability will be important as long as humans have a part to play in the debugging loop. The important question probably isn’t “do we care”; it’s “when will we stop caring?” When we can trust the output of a code model, we’ll see a rapid phase change.&nbsp; We’ll care less about the code, and more about describing the task (and appropriate tests for that task) correctly.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/the-quality-of-auto-generated-code/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: October 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: October 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-october-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-october-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-october-2021/#respond',\n",
       "   'published': 'Tue, 05 Oct 2021 11:42:52 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=10, tm_mday=5, tm_hour=11, tm_min=42, tm_sec=52, tm_wday=1, tm_yday=278, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=14000',\n",
       "   'guidislink': False,\n",
       "   'summary': 'The unwilling star of this month’s trends is clearly Facebook. Between reports that they knew about the damage that their applications were causing long before that damage hit the news, their continued denials and apologies, and their attempts to block researchers from studying the consequences of their products, they’ve been in the news almost every [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The unwilling star of this month’s trends is clearly Facebook. Between reports that they knew about the damage that their applications were causing long before that damage hit the news, their continued denials and apologies, and their attempts to block researchers from studying the consequences of their products, they’ve been in the news almost every [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>The unwilling star of this month’s trends is clearly Facebook. Between reports that they knew about the damage that their applications were causing long before that damage hit the news, their continued denials and apologies, and their attempts to block researchers from studying the consequences of their products, they’ve been in the news almost every day. Perhaps the most interesting item, though, is the introduction of Ray-Ban Stories, a pair of sunglasses with a camera built in. We’ve been talking about virtual and augmented reality for years; when will it enter the mainstream? Will Stories be enough to make it cool, or will it have the same fate as Google Glass?</p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li>Researchers at Samsung and Harvard are proposing to <a href=\"https://news.samsung.com/global/samsung-electronics-puts-forward-a-vision-to-copy-and-paste-the-brain-on-neuromorphic-chips\" rel=\"noopener noreferrer\" target=\"_blank\">copy the neuronal interconnections </a><a href=\"https://www.nature.com/articles/s41928-021-00646-1\" rel=\"noopener noreferrer\" target=\"_blank\">of parts of the brain</a>, and “paste” them onto a semiconductor array, creating an integrated circuit that directly models the brain’s interconnections. </li><li>Using AI to understand <a href=\"https://www.translatemedia.com/translation-blog/using-ai-crack-ancient-languages/\" rel=\"noopener noreferrer\" target=\"_blank\">“lost” languages</a>, written languages that we don’t know how to translate, isn’t just about NLP; it sometimes requires deciphering damaged texts (such as eroded stone tablets) where humans can no longer recognize the written characters.</li><li>Inaccurate face recognition is <a href=\"https://www.technologyreview.com/2021/09/28/1036279/pandemic-unemployment-government-face-recognition/\" rel=\"noopener noreferrer\" target=\"_blank\">preventing people from getting necessary government aid</a>, and there are few (if any) systems for remediation.</li><li>DeepMind has been studying techniques for making the output of language generation models like GPT-3 <a href=\"https://thenextweb.com/news/deepmind-tells-google-no-idea-make-ai-less-toxic\" rel=\"noopener noreferrer\" target=\"_blank\">less toxic</a>, and found that there are no good solutions.</li><li>Apple is working on iPhone features to detect <a href=\"https://thenextweb.com/news/iphone-depression-anxiety-feature-rumor-analysis\" rel=\"noopener noreferrer\" target=\"_blank\">depression, cognitive decline</a>, and <a href=\"https://thenextweb.com/news/apples-working-on-iphone-feature-ai-detect-autism\" rel=\"noopener noreferrer\" target=\"_blank\">autism</a>.&nbsp; A phone that plays psychiatrist is almost certainly a bad idea. How intrusive do you want your phone to be?</li><li><a href=\"https://phys.org/news/2021-09-scientists-reservoir.html\" rel=\"noopener noreferrer\" target=\"_blank\">Reservoir computing</a> is a neural network technique that has been used to solve computationally difficult problems in dynamic systems. It is very resource intensive, but recent work has led to speedups by factors of up to a million. It may be the next step forward in AI.</li><li>Can AI be used to forecast (and even plan) the future of scientific research?&nbsp; Not yet, but one group is working on analyzing the past 10 years of research for NASA’s <a href=\"https://www.technologyreview.com/2021/09/20/1035890/ai-predict-astro2020-decadal-survey/\" rel=\"noopener noreferrer\" target=\"_blank\">Decadal Survey</a>.</li><li>There have been many articles about <a href=\"https://thenextweb.com/news/google-deep-learning-radiology-syndication\" rel=\"noopener noreferrer\" target=\"_blank\">using AI to read X-Rays</a>. This one covers an experiment that uses training data from multiple sources to reduce one of the problems plaguing this technology: different X-ray machines, different calibration, different staff. It also places a human radiologist in the loop; the AI is only used to detect areas of possible abnormality.</li><li>It isn’t a surprise, but undergraduates who are studying data science receive <a href=\"https://theconversation.com/data-science-education-lacks-a-much-needed-focus-on-ethics-164372\" rel=\"noopener noreferrer\" target=\"_blank\">little training in ethics</a>, including issues like privacy and systemic bias.</li><li>Stanford’s Institute for Human-Centered Artificial Intelligence is creating a <a href=\"https://crfm.stanford.edu/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">group</a> to study the <a href=\"https://www.fastcompany.com/90666920/ai-bias-stanford-percy-liang-fei-fei-li\" rel=\"noopener noreferrer\" target=\"_blank\">impact of “foundational” models</a> on issues like bias and fairness. Foundational models are very large models like GPT-3 on which other models are built. Problems with foundational models are easily inherited by models on top of them. </li><li>Can machine learning <a href=\"https://www.wired.com/story/machines-can-learn-can-they-unlearn/\" rel=\"noopener noreferrer\" target=\"_blank\">learn to unlearn</a>?&nbsp; That may be required by laws like GDPR and the European “right to be forgotten.” Can a model be trained to eliminate the influence of some of its training data, without being retrained from the beginning?</li><li><a href=\"https://ai.googleblog.com/2021/07/high-fidelity-image-generation-using.html?m=1\" rel=\"noopener noreferrer\" target=\"_blank\">Deep Mind’s</a> technology for <a href=\"https://petapixel.com/2021/08/30/googles-new-ai-photo-upscaling-tech-is-jaw-dropping/\" rel=\"noopener noreferrer\" target=\"_blank\">up-scaling image resolution</a> looks really good. It produces excellent high-resolution images from pixelated originals, works on natural scenes as well as portraits, and they appear to have used a good number of Black people as models.</li><li>Amazon has announced details about <a href=\"https://www.cnet.com/home/top-amazon-astro-robot-questions-answered-two-prices-specs-sale-date-privacy-return-policy-more/\" rel=\"noopener noreferrer\" target=\"_blank\">Astro</a>, its home robot. But questions remain: is this a toy? A data collection ploy? I don’t know that we need something that follows you around playing podcasts. It integrates with Amazon products like Ring and Alexa Guard.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Is <a href=\"https://thenextweb.com/news/cybersecurity-copying-our-bodys-immune-system\">self-healing cybersecurity possible</a> by killing affected containers and starting new ones? That’s an interesting partial solution to cloud security, though it only comes into play after an attack has succeeded.</li><li>With three months to go in 2021, we’ve already seen a <a href=\"https://www.technologyreview.com/2021/09/23/1036140/2021-record-zero-day-hacks-reasons/\" rel=\"noreferrer noopener\" target=\"_blank\">record number of zero-day exploits</a>. Is this a crisis? Or is it good news, because bad actors are discovered more effectively? One thing is clear: discovering new 0days is becoming more difficult, making them more valuable.</li><li>The FBI had the <a href=\"https://gizmodo.com/report-fbi-had-ransomware-decryption-key-for-weeks-bef-1847715916\" rel=\"noreferrer noopener\" target=\"_blank\">decryption key for the Kaseya ransomware attack</a>, but delayed sharing it with victims for three weeks. The FBI claims it withheld the key because it was planning a counterattack against the REvil group, which disappeared before the attack was executed.</li><li>Privacy for the masses? iOS 15 has a beta “<a href=\"https://rachelbythebay.com/w/2021/09/20/hop/\" rel=\"noreferrer noopener\" target=\"_blank\">private relay</a>” feature that appears to be something like <a href=\"https://tor.eff.org/\" rel=\"noreferrer noopener\" target=\"_blank\">TOR</a>. And <a href=\"https://arstechnica.com/information-technology/2021/09/a-new-app-helps-iranians-hide-messages-in-plain-sight/\" rel=\"noreferrer noopener\" target=\"_blank\">Nahoft</a>, an application for use in Iran, encodes private messages as sequences of innocuous words that can get by automated censors.</li><li><a href=\"https://medium.com/swlh/zero-trust-networking-for-bare-metal-systems-using-rust-99c1552737bc\" rel=\"noreferrer noopener\" target=\"_blank\">HIPv2</a> is an alternative to TLS that is designed for implementing zero-trust security for embedded devices. </li><li><a href=\"https://github.com/armosec/kubescape\" rel=\"noreferrer noopener\" target=\"_blank\">Kubescape</a> is an open source tool to test whether Kubernetes has been deployed securely.\\xa0 The tests are based on the NSA’s guidance for <a href=\"https://www.nsa.gov/News-Features/Feature-Stories/Article-View/Article/2716980/nsa-cisa-release-kubernetes-hardening-guidance/\" rel=\"noreferrer noopener\" target=\"_blank\">hardening Kubernetes</a>.</li><li>Rootkits are hardly new, but now they’re being used to attack <a href=\"https://thenewstack.io/rootkits-come-to-containers-and-bring-trouble-with-them/\" rel=\"noreferrer noopener\" target=\"_blank\">containers</a>. Their goal is usually to mine bitcoin, and to hide that mining from monitoring tools. <a href=\"https://github.com/aquasecurity/tracee\" rel=\"noreferrer noopener\" target=\"_blank\">Tracee</a> is a new tool, built with eBPF, that may help to detect successful attacks.</li></ul>\\n\\n\\n\\n<h2>User Interfaces</h2>\\n\\n\\n\\n<ul><li>Kids these days <a href=\"https://www.theverge.com/22684730/students-file-folder-directory-structure-education-gen-z\" rel=\"noreferrer noopener\" target=\"_blank\">don’t understand files and directories</a>. Seriously, Google’s dominance in everyday life means that users expect to find things through search. But search is often inadequate. It will be important for software designers to think through these issues.</li><li><a href=\"https://thenextweb.com/news/holograms-you-can-touch-syndication\" rel=\"noreferrer noopener\" target=\"_blank\">Holograms you can touch</a>? Aerohaptics uses jets of air to create the feeling of “touch” when interacting with a hologram. Another step towards the Star Trek Holodeck.</li><li>Fraunhofer has developed a system for <a href=\"https://www.fraunhofer.de/en/press/research-news/2021/september-2021/activity-detection-inside-the-vehicle.html\" rel=\"noreferrer noopener\" target=\"_blank\">detecting whether a driver is tired or asleep</a>.\\xa0 Software like this will be particularly important for semi-automated driving systems, which require support from a human driver.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>What is <a href=\"https://hypothesis.works/articles/what-is-property-based-testing/\" rel=\"noreferrer noopener\" target=\"_blank\">property based testing</a>, anyway? Fuzzing? Unit tests at scale? Greater testing discipline will be required if we expect AI systems to generate code. Can property-based testing get there?</li><li>Google Cloud has introduced Supply Chain Twin, a <a href=\"https://venturebeat.com/2021/09/14/google-launches-digital-twin-tool-for-logistics-and-manufacturing/\">“digital </a><a href=\"https://venturebeat.com/2021/09/14/google-launches-digital-twin-tool-for-logistics-and-manufacturing/\" rel=\"noreferrer noopener\" target=\"_blank\">twin</a><a href=\"https://venturebeat.com/2021/09/14/google-launches-digital-twin-tool-for-logistics-and-manufacturing/\">” service</a> for supply chain management.</li><li><a href=\"https://github.com/gitpod-io/openvscode-server/tree/web-server\">Open </a><a href=\"https://github.com/gitpod-io/openvscode-server/tree/web-server\" rel=\"noreferrer noopener\" target=\"_blank\">VSCodeServer</a> is an open source project that allows VSCode to run on a remote machine and be accessed through a web browser.</li><li><a href=\"https://thenewstack.io/facebooks-golang-object-relational-mapper-moves-to-the-linux-foundation/\" rel=\"noreferrer noopener\" target=\"_blank\">Ent</a> is an open source object-relational mapping tool for Go that uses graph concepts to model the database schema. Facebook has contributed Ent to the CNCF.</li><li><a href=\"https://glean.software/docs/introduction\" rel=\"noreferrer noopener\" target=\"_blank\">Glean</a> is an open source search engine for source code.\\xa0 Looks like it’s a LOT better than grepping through your src directories.</li><li><a href=\"https://urbit.org/\" rel=\"noreferrer noopener\" target=\"_blank\">Urbit</a> looks like it could be an interesting operating system for decentralized peer-to-peer applications. </li></ul>\\n\\n\\n\\n<h2>Law</h2>\\n\\n\\n\\n<ul><li>Facebook on <a href=\"https://thenextweb.com/news/facebook-supports-internet-regulations-syndication?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+TheNextWeb+%28The+Next+Web+All+Stories%29\" rel=\"noreferrer noopener\" target=\"_blank\">regulation</a>: Please require competitors to do the things we do. And don’t look at targeted advertising.</li><li><a href=\"https://www.somebits.com/weblog/culture/generative-art-and-open-source.html\" rel=\"noreferrer noopener\" target=\"_blank\">NFTs, generative art, and open source</a>: do we need a new kind of license to protect artistic works that are generated by software?</li><li>China issues a <a href=\"http://www.cac.gov.cn/2021-08/27/c_1631652502874117.htm\" rel=\"noreferrer noopener\" target=\"_blank\">Request for Comments</a> on their proposed social media regulations. Google Translate’s translation isn’t bad, and CNBC has a good <a href=\"https://www.cnbc.com/2021/09/03/chinas-tech-regulation-turns-to-algorithms.html\" rel=\"noreferrer noopener\" target=\"_blank\">summary</a>. Users must be notified about the use of algorithmic recommendations; users must be able to disable recommendations; and algorithmic recommendations must not be designed to create addictive behavior.</li><li>South Korea has <a href=\"https://techxplore.com/news/2021-08-korea-app-payment-monopolies-world.html\" rel=\"noreferrer noopener\" target=\"_blank\">passed</a> a law that will force Apple and Google to open their devices to other app stores.</li><li>Research by Google shows that, worldwide, Government-ordered <a href=\"https://www.technologyreview.com/2021/09/09/1035237/internet-shutdowns-censorship-exponential-jigsaw-google/\" rel=\"noreferrer noopener\" target=\"_blank\">Internet shutdowns</a> have become much more common in the past year. These shutdowns are usually to suppress dissent. India has shut down Internet access more than any other country.</li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>George Church’s startup Colossal has received venture funding for developing “cold tolerant Asian elephants” (as Church puts it), a project more commonly known as <a href=\"https://www.cnbc.com/2021/09/13/geneticist-george-church-gets-funding-for-lab-grown-woolly-mammoths.html\" rel=\"noreferrer noopener\" target=\"_blank\">de-extincting Wooly Mammoths</a>.</li><li>Researchers at NYU have created <a href=\"https://www.nyu.edu/about/news-publications/news/2021/september/artificial-cells.html\" rel=\"noreferrer noopener\" target=\"_blank\">artificial cell-like objects</a> that can ingest, process, and expel objects. These aren’t artificial cells, but represent a step towards creating them.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li>A breakthrough in building <a href=\"https://techxplore.com/news/2021-09-stanford-discovery-pave-ultrafast-energy-efficient.html\" rel=\"noreferrer noopener\" target=\"_blank\">phase change memory</a> that consumes little power may make phase change memory practical, allowing tighter integration between processors and storage.</li><li>Mainframes aren’t dead. The <a href=\"https://arstechnica.com/gadgets/2021/09/ibms-telum-mainframe-processor-introduces-new-cache-architecture/\" rel=\"noreferrer noopener\" target=\"_blank\">Telum</a> is IBM’s new processor for its System Z mainframes. 7nm technology, 5 GHz base clock speed, 8 cores, 16 threads per core; it’s a very impressive chip.</li><li>One of Google’s X companies has deployed a <a href=\"https://x.company/blog/posts/taara-beaming-broadband-across-congo/\" rel=\"noreferrer noopener\" target=\"_blank\">20 Gbps Internet trunk using lasers</a>. The connection crosses the Congo River, a path that is difficult because of the river’s depth and speed.\\xa0 This technology could be used in other places where running fiber is difficult.</li><li>Facebook and Ray-Ban have released <a href=\"https://arstechnica.com/gadgets/2021/09/ray-ban-stories-these-are-facebooks-first-mass-market-smart-glasses/\" rel=\"noreferrer noopener\" target=\"_blank\">smart glasses</a> (branded as Ray-Ban Stories), which are eyeglasses with a built-in camera and speakers. This is not AR (there is no projector), but a step on the way. <a href=\"https://thenextweb.com/news/xiaomi-smart-glasses-microled-analysis\" rel=\"noreferrer noopener\" target=\"_blank\">Xiaomi</a> also appears to be working on smart glasses, and Linux is getting into the act with a work-oriented headset called <a href=\"https://simulavr.com/\" rel=\"noreferrer noopener\" target=\"_blank\">Simula One</a>.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li>IBM introduces <a href=\"https://medium.com/qiskit/introducing-qiskit-nature-cb9e588bb004\" rel=\"noreferrer noopener\" target=\"_blank\">Qiskit Nature</a>, a platform for using quantum computers to experiment with quantum effects in the natural sciences. Because these experiments are about the behavior of quantum systems, they (probably) don’t require the error correction that’s necessary to make quantum computing viable.</li><li>Want to build your own quantum computer?\\xa0 IBM has open sourced <a href=\"https://medium.com/qiskit/starting-today-anyone-can-design-quantum-hardware-with-qiskit-metal-4fd5dcf4c7cf\" rel=\"noreferrer noopener\" target=\"_blank\">Qiskit Metal</a>, a design automation tool for superconducting quantum computers.</li><li>Curiously-named <a href=\"https://phys.org/news/2021-09-graphene-valleytronics-paving-small-sized-room-temperature.html\" rel=\"noreferrer noopener\" target=\"_blank\">Valleytronics</a> uses electrons’ “valley pseudospin” to store quantum data. It might enable small, room-temperature quantum computers.</li></ul>\\n\\n\\n\\n<h2>Social Media</h2>\\n\\n\\n\\n<ul><li>Facebook has put “<a href=\"https://www.reuters.com/technology/instagram-hits-pause-kids-version-app-2021-09-27/\" rel=\"noreferrer noopener\" target=\"_blank\">Instagram for Kids</a>” on hold. While they dispute the evidence that Instagram harms teenagers, public outcry and legislative pressure, along with Facebook’s own evidence that Instagram is particularly damaging to teenage girls, has caused them to delay the release.</li><li>Twitter is <a href=\"https://www.bbc.com/news/technology-58510594\" rel=\"noreferrer noopener\" target=\"_blank\">allowing bot accounts to identify</a> themselves as bots.\\xa0 Labeling isn’t mandatory.</li><li>Facebook adds junk content to its HTML to <a href=\"https://themarkup.org/citizen-browser/2021/09/21/facebook-rolls-out-news-feed-change-that-blocks-watchdogs-from-gathering-data\" rel=\"noreferrer noopener\" target=\"_blank\">prevent researchers</a> from using automated tools to collect posts. </li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-october-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Ethical Social Media: Oxymoron or Attainable Goal?',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Ethical Social Media: Oxymoron or Attainable Goal?'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/ethical-social-media-oxymoron-or-attainable-goal/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/ethical-social-media-oxymoron-or-attainable-goal/',\n",
       "   'comments': 'https://www.oreilly.com/radar/ethical-social-media-oxymoron-or-attainable-goal/#respond',\n",
       "   'published': 'Tue, 21 Sep 2021 11:55:27 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=21, tm_hour=11, tm_min=55, tm_sec=27, tm_wday=1, tm_yday=264, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Barlow'}],\n",
       "   'author': 'Mike Barlow',\n",
       "   'author_detail': {'name': 'Mike Barlow'},\n",
       "   'tags': [{'term': 'Social Media', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13981',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Humans have wrestled with ethics for millennia. Each generation spawns a fresh batch of ethical dilemmas and then wonders how to deal with them. For this generation, social media has generated a vast set of new ethical challenges, which is unsurprising when you consider the degree of its influence. Social media has been linked to [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Humans have wrestled with ethics for millennia. Each generation spawns a fresh batch of ethical dilemmas and then wonders how to deal with them. For this generation, social media has generated a vast set of new ethical challenges, which is unsurprising when you consider the degree of its influence. Social media has been linked to [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Humans have wrestled with ethics for millennia. Each generation spawns a fresh batch of ethical dilemmas and then wonders how to deal with them. </p>\\n\\n\\n\\n<p>For this generation, social media has generated a vast set of new ethical challenges, which is unsurprising when you consider the degree of its influence. Social media has been linked to health risks in individuals and political violence in societies. Despite growing awareness of its potential for causing harm, social media has received what amounts to a free pass on unethical behavior.</p>\\n\\n\\n\\n<p>Minerva Tantoco, who served as New York City’s first chief technology officer, suggests that “technology exceptionalism” is the root cause. Unlike the rapacious robber barons of the Gilded Age, today’s tech moguls were viewed initially as eccentric geeks who enjoyed inventing cool new products. Social media was perceived as a harmless timewaster, rather than as a carefully designed tool for relentless commerce and psychological manipulation.</p>\\n\\n\\n\\n<p>“The idea of treating social media differently came about because the individuals who started it weren’t from traditional media companies,” Tantoco says. “Over time, however, the distinction between social media and traditional media has blurred, and perhaps the time has come for social media to be subject to the same rules and codes that apply to broadcasters, news outlets and advertisers. Which means that social media would be held accountable for content that causes harm or violates existing laws.”</p>\\n\\n\\n\\n<p>Ethical standards that were developed for print, radio, television, and telecommunications during the 20<sup>th</sup> century could be applied to social media. “We would start with existing norms and codes for media generally and test whether these existing frameworks and laws would apply to social media,” Tantoco says.</p>\\n\\n\\n\\n<p>Taking existing norms and applying them, with modifications, to novel situations is a time-honored practice.&nbsp; “When e-commerce web sites first started, it was unclear if state sales taxes would apply to purchases,” Tantoco says. “It turned out that online sales were not exempt from sales taxes and that rules that had been developed for mail-order sites decades earlier could be fairly applied to e-commerce.”</p>\\n\\n\\n\\n<h2><strong>Learning from AI</strong></h2>\\n\\n\\n\\n<p>Christine Chambers Goodman, a professor at Pepperdine University’s Caruso School of Law, has written extensively on the topic of artificial intelligence and its impact on society. She sees potential in applying AI guidelines to social media, and she cited the European Commission’s High-Level Expert Group on Artificial Intelligence’s seven key ethical requirements for trustworthy AI:<sup>1</sup></p>\\n\\n\\n\\n<ul><li>Human agency and oversight</li><li>Technical robustness and safety</li><li>Privacy and data governance</li><li>Transparency</li><li>Diversity, non-discrimination and fairness</li><li>Societal and environmental well-being</li><li>Accountability</li></ul>\\n\\n\\n\\n<p>The commission’s proposed requirements for AI would be a good starting point for conversations about ethical social media. Ideally, basic ethical components would be designed into social media platforms before they are built. Software engineers should be trained to recognize their own biases and learn specific techniques for writing code that is inherently fair and non-discriminatory.</p>\\n\\n\\n\\n<p>“It starts with that first requirement of human agency and oversight,” Goodman says. If ethical standards are “paramount” during the design phase of a platform, “then I see some room for optimism.”</p>\\n\\n\\n\\n<p>Colleges and universities also can play important roles in training a new generation of ethical software engineers by requiring students to take classes in ethics, she says.</p>\\n\\n\\n\\n<h2><strong>Economic Fairness and Equity</strong></h2>\\n\\n\\n\\n<p>Social media companies are private business entities, even when they are publicly held. But the social media phenomenon has become so thoroughly woven into the fabric of our daily lives that many people now regard it as a public utility such as gas, electricity, and water. In a remarkably brief span of time, social media has become an institution, and generally speaking, we expect our institutions to behave fairly and equitably.&nbsp; Clearly, however, the social media giants see no reason to share the economic benefits of their success with anyone except their shareholders.</p>\\n\\n\\n\\n<p>“The large social media companies make hundreds of billions of dollars from advertising revenue and share almost none of it with their users,” says Greg Fell, CEO of <a href=\"https://www.displaysocial.com/\">Display Social</a>, a platform that shares up to 50 percent of its advertising revenue with content creators who post on its site.</p>\\n\\n\\n\\n<p>Historically, content creators have been paid for their work. Imagine if CBS had told Lucille Ball and Desi Arnaz that they wouldn’t be paid for creating episodes of “I Love Lucy,” but that instead they would be allowed to sell “I Love Lucy” coffee mugs and T-shirts. If the original TV networks had operated like social media corporations, there never would have been a Golden Age of Television.</p>\\n\\n\\n\\n<p>Most societies reward creators, artists, entertainers, athletes, and influencers for their contributions. Why does social media get to play by a different set of rules?</p>\\n\\n\\n\\n<p>“Economic fairness should be part of the social media ethos. People should be rewarded financially for posting on social media, instead of being exploited by business models that are unfair and unethical,” Fell says.</p>\\n\\n\\n\\n<p>From Fell’s perspective, the exploitive and unfair economic practices of the large social media companies represent short-term thinking. “Ultimately, they will burn out their audiences and implode. Meantime, they are causing harm. That’s the problem with unethical behavior—in the long run, it’s self-destructive and self-defeating.”</p>\\n\\n\\n\\n<h2><strong>Transforming Attention into Revenue</strong></h2>\\n\\n\\n\\n<p>Virtually all of the large social media platforms rely on some form of advertising to generate revenue. Their business models are exceedingly simple: they attract the attention of users and then sell the attention to advertisers. In crude terms, they’re selling your eyeballs to the highest bidder.</p>\\n\\n\\n\\n<p>As a result, their only real interest is attracting attention. The more attention they attract, the more money they make. Their algorithms are brilliantly designed to catch and hold your attention by serving up content that will trigger dopamine rushes in your brain. Dopamine isn’t a cause of addiction, but it plays a role in addictive behaviors. So, is it fair to say that social media is intentionally addictive? Maybe.</p>\\n\\n\\n\\n<p>“For many social media companies, addictive behavior (as in people consuming more than they intend to and regretting it afterwards) is the point,” says Esther Dyson, an author, philanthropist, and investor&nbsp;focused on&nbsp;health,&nbsp;open government, digital technology,&nbsp;biotechnology, and&nbsp;aerospace. “Cigarettes, drugs, and gambling are all premised on the model that too much is never enough.&nbsp; And from the point of view of many investors, sustainable profits are not enough.&nbsp; They want exits. Indeed, the goal of these investors is creating ever-growing legions of addicts. That starts with generating and keeping attention.”</p>\\n\\n\\n\\n<h2><strong>Monetizing Misinformation</strong></h2>\\n\\n\\n\\n<p>As it happens, misinformation is highly attractive to many users. It’s a digital version of potato chips—you can’t eat just one. The algorithms figure this out quickly, and feed users a steady supply of misinformation to hold their attention.</p>\\n\\n\\n\\n<p>In an advertising-driven business model, attention equals dollars. With the help of machine learning and sophisticated algorithms, social media has effectively monetized misinformation, creating a vicious, addictive cycle that seems increasingly difficult to stop.</p>\\n\\n\\n\\n<p>Social media has staked its fortunes to a business model that is deeply unethical and seems destined to fail in the long term. But could the industry survive, at least in the short term, with a business model that hews more closely to ethical norms? </p>\\n\\n\\n\\n<p>Greg Fell doesn’t believe that ethical guidelines will slow the industry’s growth or reduce its profitability. “People expect fairness. They want to be treated as human beings, not as products,” he says. “You can build fairness into a platform if you make it part of your goal from the start. But it shouldn’t be an afterthought.”</p>\\n\\n\\n\\n<h2><strong>Slowing the Spread of False Narratives</strong></h2>\\n\\n\\n\\n<p>In addition to implementing structural design elements that would make it easier for people to recognize misinformation and false narratives, social media companies could partner with the public sector to promote media literacy.&nbsp; Renée DiResta is the technical research manager at&nbsp;<a href=\"https://cyber.fsi.stanford.edu/io/content/io-landing-page-2\">Stanford Internet Observatory,</a> a cross-disciplinary program of research, teaching, and policy engagement for the study of abuse in current information technologies. She investigates the spread of narratives across social and traditional media networks.</p>\\n\\n\\n\\n<p>“I think we need better ways for teaching people to distinguish between rhetoric and reality,” DiResta says, noting that tropes such as “dead people are voting” are commonly repeated and reused from one election cycle to the next, even when they are provably false. These kinds of tropes are the “building blocks” of misinformation campaigns designed to undermine confidence in elections, she says.</p>\\n\\n\\n\\n<p>“If we can help people recognize the elements of false narratives, maybe they will build up an immunity to them,” DiResta says.</p>\\n\\n\\n\\n<h2><strong>It’s Not Too Late to Stop the Train</strong></h2>\\n\\n\\n\\n<p>The phenomenon we recognize today as “social media” only began taking shape in the late 1990s and early 2000s. It is barely two decades old, which makes it far too young to have developed iron-clad traditions. It is an immature field by any measure, and it’s not too late to alter its course.</p>\\n\\n\\n\\n<p>Moreover, social media’s business model is not terribly complicated, and it’s easy to envision a variety of other models that might be equally or even more profitable, and represent far less of a threat to society. Newer platforms such as Substack, Patreon, OnlyFans, Buy Me a Coffee, and Display Social are opening the door to a creator-centric social media industry that isn’t fueled primarily by advertising dollars.</p>\\n\\n\\n\\n<p>“Social media has its positives, and it isn’t all doom and gloom, but it certainly isn’t perfect and resolving some of these issues could ensure these applications are the fun and happy escape they need to be,” says Ella Chambers, UX designer and creator&nbsp;of the UK-based <a href=\"https://www.theethicalsocialmediaproject.com/\">Ethical Social Media Project</a>. “The majority of social media is okay.”</p>\\n\\n\\n\\n<p>That said, some of the problems created by social media are far from trivial. “My research led me to conclude that the rise of social media has brought the downfall of many users’ mental health,” Chambers says. A&nbsp;<a href=\"https://www.wsj.com/articles/the-facebook-files-11631713039\" rel=\"noreferrer noopener\" target=\"_blank\">recent series of investigative articles in the Wall Street Journal</a>&nbsp;casts a harsh spotlight on the mental health risks of social media, especially to teen-age girls. Facebook has issued a&nbsp;<a href=\"https://about.fb.com/news/2021/09/research-teen-well-being-and-instagram/\" rel=\"noreferrer noopener\" target=\"_blank\">rebuttal</a><sup>3</sup>&nbsp;to the WSJ, but it’s not likely to persuade critics into believing that social media is some kind of wonderful playground for kids and teens.</p>\\n\\n\\n\\n<p>Creating a practical framework of ethical guidelines would be a positive step forward. Ideally, the framework would evolve into a set of common practices and processes for ensuring fairness, diversity, inclusion, equity, safety, accuracy, accountability, and transparency in social media.</p>\\n\\n\\n\\n<p>Chinese officials recently unveiled a comprehensive draft of proposed rules governing the use of recommendation algorithms in China.<sup>2</sup> One of the proposed regulations would require algorithm providers to “respect social ethics and ethics, abide by business ethics and professional ethics, and follow the principles of fairness, openness, transparency, scientific rationality, and honesty.”</p>\\n\\n\\n\\n<p>Another proposed regulation would provide users with “convenient options to turn off algorithm recommendation services” and enable users to select, modify or delete user tags. And another proposed rule would restrict service providers from using algorithms “to falsely register accounts … manipulate user accounts, or falsely like, comment, forward, or navigate through web pages to implement traffic fraud or traffic hijacking …”</p>\\n\\n\\n\\n<p>Eloy Sasot, group chief data and analytics officer at Richemont, the Switzerland-based&nbsp;luxury goods&nbsp;holding company, agrees that regulations are necessary. “And the regulations also should be managed with extreme care. When you add rules to an already complex system, there can be unintended consequences, both at the AI-solution level and the macro-economic level,” he says.</p>\\n\\n\\n\\n<p>For instance, small companies, which have limited resources, may be less able to counter negative business impacts created by regulations targeting large companies. “So, in effect, regulations, if not carefully supervised, might result in a landscape that is less competitive and more monopolistic, with unintended consequences for end consumers whom the regulations were designed to protect,” he explains.</p>\\n\\n\\n\\n<h2><strong>Technology Problem, or a People Problem?</strong></h2>\\n\\n\\n\\n<p>Casey Fiesler&nbsp;is an assistant professor&nbsp;in the Department of Information Science at University of Colorado Boulder. She researches and teaches in the areas of technology ethics, internet law and policy, and online communities.</p>\\n\\n\\n\\n<p>“I do not think that social media—or more broadly, online communities—are inherently harmful,” says Fiesler. “In fact, online communities have also done incredible good, especially in terms of social support and activism.”</p>\\n\\n\\n\\n<p>But the harm caused by unfettered use of social media “often impacts marginalized and vulnerable users disproportionately,” she notes. Ethical social media platforms would consider those effects and work proactively to reduce or eliminate hate speech, trolling, defamation, cyber bullying, swatting, doxing, impersonation, and the intentional spread of false narratives.</p>\\n\\n\\n\\n<p>“I consider myself an optimist who thinks that it is very important to think like a pessimist. And we should critique technology like social media because it has so much potential for good, and if we want to see those benefits, then we need to push for it to be better,” Fiesler&nbsp;says.</p>\\n\\n\\n\\n<p>Ultimately, the future of ethical social media may depend more on the behaviors of people than on advances in technology.</p>\\n\\n\\n\\n<p>“It’s not the medium that’s unethical—it’s the business people controlling it,” Dyson observes. “Talking about social media ethics is like talking about telephone ethics. It really depends on the people involved, not the platform.”</p>\\n\\n\\n\\n<p>From Dyson’s point of view, the quest for ethical social media represents a fundamental challenge for society. “Are parents teaching their children to behave ethically? Are parents serving as role models for ethical behavior? We talk a lot about training AI, but are we training our children to think long-term, or just to seek short-term relief? Addiction is not about pleasure; it’s about relief from discomfort, from anxiety, from uncertainty, from a sense that we have no future,” she adds. “I personally think we’re just being blind to the consequences of short-term thinking. Silicon Valley is addicted to profits and exponential growth. But we need to start thinking about what we’re creating for the long term.”</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h3>Footnotes</h3>\\n\\n\\n\\n<ol><li><a href=\"https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai\" rel=\"noopener noreferrer\" target=\"_blank\">https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai</a><br /></li><li>\\u200b\\u200b\\u200b\\u200b<a href=\"http://www.cac.gov.cn/2021-08/27/c_1631652502874117.htm\" rel=\"noopener noreferrer\" target=\"_blank\">http://www.cac.gov.cn/2021-08/27/c_1631652502874117.htm</a><br /></li><li> <a href=\"https://about.fb.com/news/2021/09/research-teen-well-being-and-instagram/\">https://about.fb.com/news/2021/09/research-teen-well-being-and-instagram/</a> </li></ol>\\n\\n\\n\\n<p></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/ethical-social-media-oxymoron-or-attainable-goal/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': '2021 Data/AI Salary Survey',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': '2021 Data/AI Salary Survey'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/2021-data-ai-salary-survey/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/2021-data-ai-salary-survey/',\n",
       "   'comments': 'https://www.oreilly.com/radar/2021-data-ai-salary-survey/#respond',\n",
       "   'published': 'Wed, 15 Sep 2021 11:32:26 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=15, tm_hour=11, tm_min=32, tm_sec=26, tm_wday=2, tm_yday=258, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Research', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13950',\n",
       "   'guidislink': False,\n",
       "   'summary': 'In June 2021, we asked the recipients of our&#160;Data &#38; AI Newsletter&#160;to respond to a survey about compensation. The results gave us insight into what our subscribers are paid, where they’re located, what industries they work for, what their concerns are, and what sorts of career development opportunities they’re pursuing. While it’s sadly premature to [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'In June 2021, we asked the recipients of our&#160;Data &#38; AI Newsletter&#160;to respond to a survey about compensation. The results gave us insight into what our subscribers are paid, where they’re located, what industries they work for, what their concerns are, and what sorts of career development opportunities they’re pursuing. While it’s sadly premature to [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>In June 2021, we asked the recipients of our&nbsp;<em>Data &amp; AI Newsletter</em>&nbsp;to respond to a survey about compensation. The results gave us insight into what our subscribers are paid, where they’re located, what industries they work for, what their concerns are, and what sorts of career development opportunities they’re pursuing.</p>\\n\\n\\n\\n<p>While it’s sadly premature to say that the survey took place at the end of the COVID-19 pandemic (though we can all hope), it took place at a time when restrictions were loosening: we were starting to go out in public, have parties, and in some cases even attend in-person conferences. The results then provide a place to start thinking about what effect the pandemic had on employment. There was a lot of uncertainty about stability, particularly at smaller companies: Would the company’s business model continue to be effective? Would your job still be there in a year? At the same time, employees were reluctant to look for new jobs, especially if they would require relocating—at least according to the rumor mill. Were those concerns reflected in new patterns for employment?</p>\\n\\n\\n\\n<h2>Executive Summary</h2>\\n\\n\\n\\n<ul><li>The average salary for data and AI professionals who responded to the survey was $146,000.</li><li>The average change in compensation over the last three years was $9,252. This corresponds to an annual increase of 2.25%. However, 8% of the correspondents reported decreased compensation, and 18% reported no change.</li><li>We don’t see evidence of a “great resignation.” 22% of respondents said they intended to change jobs, roughly what we would have expected. Respondents seemed concerned about job security, probably because of the pandemic’s effect on the economy.</li><li>Average compensation was highest in California ($176,000), followed by Eastern Seaboard states like New York and&nbsp;Massachusetts.</li><li>Compensation for women was significantly lower than for men (84%). Salaries were lower regardless of education or job title. Women were more likely than men to have advanced degrees, particularly PhDs.</li><li>Many respondents acquired certifications. Cloud certifications, specifically in AWS and Microsoft Azure, were most strongly associated with salary increases.</li><li>Most respondents participated in training of some form. Learning new skills and improving old ones were the most common reasons for training, though hireability and job security were also factors. Company-provided training opportunities were most strongly associated with pay increases.</li></ul>\\n\\n\\n\\n<h2>Demographics</h2>\\n\\n\\n\\n<p>The survey was publicized through&nbsp;<a href=\"https://www.oreilly.com/emails/newsletters/\">O’Reilly’s&nbsp;<em>Data &amp; AI Newsletter</em></a>&nbsp;and was limited to respondents in the United States and the United Kingdom. There were 3,136 valid responses, 2,778 from the US and 284 from the UK. This report focuses on the respondents from the US, with only limited attention paid to those from the UK. A small number of respondents (74) identified as residents of the US or UK, but their IP addresses indicated that they were located elsewhere. We didn&#8217;t use the data from these respondents; in practice, discarding this data had no effect on the results.</p>\\n\\n\\n\\n<p>Of the 2,778 US respondents, 2,225 (81%) identified as men, and 383 (14%) identified as women (as identified by their preferred pronouns). 113 (4%) identified as “other,” and 14 (0.5%) used “they.”</p>\\n\\n\\n\\n<p>The results are biased by the survey’s recipients (subscribers to O’Reilly’s&nbsp;<em>Data &amp; AI Newsletter</em>). Our audience is particularly strong in the software (20% of respondents), computer hardware (4%), and computer security (2%) industries—over 25% of the total. Our&nbsp;audience&nbsp;is also strong in the states where these industries are&nbsp;concentrated: 42% of the US respondents lived in California (20%), New York (9%), Massachusetts (6%), and Texas (7%), though these states only make up 27% of the US population.</p>\\n\\n\\n\\n<h2>Compensation Basics</h2>\\n\\n\\n\\n<p>The average annual salary for employees who worked in data or AI was $146,000. Most salaries were between $100,000 and $150,000 yearly (34%); the next most common salary tier was from $150,000 to $200,000 (26%). Compensation depended strongly on location, with average salaries highest in California ($176,000).</p>\\n\\n\\n\\n<p>The average salary change over the past three years was $9,252, which is 2.25% per year (assuming a final salary equal to the average). A small number of respondents (8%) reported salary decreases, and 18% reported no change. Economic uncertainty caused by the pandemic may be responsible for the declines in compensation. 19% reported increases of $5,000 to $10,000 over that period; 14% reported increases of over $25,000. A&nbsp;<a href=\"https://spectrum.ieee.org/view-from-the-valley/at-work/tech-careers/us-tech-salaries-climb-says-2021-report\">study by the IEEE</a>&nbsp;suggests that the average salary for technical employees increased 3.6% per year, higher than our respondents indicated.</p>\\n\\n\\n\\n<p>39% of respondents reported promotions in the past three years, and 37% reported changing employers during that period. 22% reported that they were considering changing jobs because their salaries hadn’t increased during the past year. Is this a sign of what some have called a “great resignation”? Common wisdom has it that technical employees change jobs every three to four years.&nbsp;<a href=\"https://www.linkedin.com/pulse/how-often-should-you-change-jobs-perminus-wainaina/\">LinkedIn</a>&nbsp;and&nbsp;<a href=\"https://www.indeed.com/career-advice/career-development/how-often-should-you-change-job\">Indeed</a>&nbsp;both recommend staying for at least three years, though they observe that younger employees change jobs more often. LinkedIn elsewhere states that the&nbsp;<a href=\"https://www.linkedin.com/business/learning/blog/learner-engagement/see-the-industries-with-the-highest-turnover-and-why-it-s-so-hi\">annual turnover rate</a>&nbsp;for technology employees is 13.2%—which suggests that employees stay at their jobs for roughly seven and a half years. If that’s correct, the 37% that changed jobs over three years seems about right, and the 22% who said they “intend to leave their job due to a lack of compensation increase” doesn’t seem overly high. Keep in mind that intent to change and actual change are not the same—and that there are many reasons to change jobs aside from salary, including flexibility around working hours and working from home.</p>\\n\\n\\n\\n<p>64% of the respondents took part in training or obtained certifications in the past year, and 31% reported spending over 100 hours in training programs, ranging from formal graduate degrees to reading blog posts. As we’ll see later, cloud certifications (specifically in AWS and Microsoft Azure) were the most popular and appeared to have the largest effect on salaries.</p>\\n\\n\\n\\n<p>The reasons respondents gave for participating in training were surprisingly consistent. The vast majority reported that they wanted to learn new skills (91%) or improve existing skills (84%). Data and AI professionals are clearly interested in learning—and that learning is self-motivated, not imposed by management. Relatively few (22%) said that training was required by their job, and even fewer participated in training because they were concerned about losing their&nbsp;job (9%).</p>\\n\\n\\n\\n<p>However, there were other motives at work. 56% of our respondents said that they wanted to increase their “job security,” which is at odds with the low number who were concerned about losing their job. And 73% reported that they engaged in training or obtained certifications to increase their “hireability,” which may suggest more concern about job stability than our respondents would admit. The pandemic was a threat to many businesses, and employees were justifiably concerned that their job could vanish after a bad pandemic-influenced quarter. A desire for increased hireability may also indicate that we’ll see more people looking to change jobs in the near future.</p>\\n\\n\\n\\n<p>Finally, 61% of the respondents said that they participated in training or earned certifications because they wanted a salary increase or a promotion (“increase in job title/responsibilities”). It isn’t surprising that employees see training as a route to promotion—especially as companies that want to hire in fields like data science, machine learning, and AI contend with a&nbsp;<a href=\"https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/\">shortage of qualified employees</a>. Given the difficulty of hiring expertise from outside, we expect an increasing number of companies to grow their own ML and AI talent internally using training programs.</p>\\n\\n\\n\\n<h2>Salaries by Gender</h2>\\n\\n\\n\\n<p>To nobody’s surprise, our survey showed that data science and AI professionals are mostly male. The number of respondents tells the story by itself: only 14% identified as women, which is lower than we’d have guessed, though it’s roughly consistent with our conference attendance (back when we had live conferences) and roughly equivalent to other technical fields. A small number (5%) reported their preferred pronoun as “they” or Other, but this sample was too small to draw any significant comparisons about compensation.</p>\\n\\n\\n\\n<p>Women’s salaries were sharply lower than men’s salaries, averaging $126,000 annually, or 84% of the average salary for men ($150,000). That differential held regardless of education, as&nbsp;Figure 1&nbsp;shows: the average salary for a woman with a doctorate or master’s degree was 82% of the salary for a man with an equivalent degree. The difference wasn’t quite as high for people with bachelor’s degrees or who were still students, but it was still significant: women with bachelor’s degrees or who were students earned 86% or 87% of the average salary for men. The difference in salaries was greatest between people who were self-taught: in that case, women’s salaries were 72% of men’s. An associate’s degree was the only degree for which women’s salaries were higher than men’s.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13955\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/01-1048x531.jpg\" /><figcaption><em>Figure 1. Women’s and men’s salaries by degree</em></figcaption></figure>\\n\\n\\n\\n<p>Despite the salary differential, a higher percentage of women had advanced degrees than men: 16% of women had a doctorate, as opposed to 13% of men. And 47% of women had a master’s degree, as opposed to 46% of men. (If those percentages seem high, keep in mind that many professionals in data science and AI are escapees from academia.)</p>\\n\\n\\n\\n<p>Women’s salaries also lagged men’s salaries when we compared women and men with similar job titles (see&nbsp;Figure 2). At the executive level, the average salary for women was $163,000 versus $205,000 for men (a 20% difference). At the director level, the difference was much smaller—$180,000 for women versus $184,000 for men—and women’s salaries were actually higher than those at the executive level. It’s easy to hypothesize about this difference, but we’re at a loss to explain it. For managers, women’s salaries were $143,000 versus $154,000 for men (a 7% difference).</p>\\n\\n\\n\\n<p>Career advancement is also an issue: 18% of the women who participated in the survey were executives or directors, compared with 23% of the men.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13956\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/02-1048x488.jpg\" /><figcaption><em>Figure 2. Women’s and men’s salaries by job title</em></figcaption></figure>\\n\\n\\n\\n<p>Before moving on from our consideration of the effect of gender on salary, let’s take a brief look at how salaries changed over the past three years. As&nbsp;Figure 3&nbsp;shows, the percentage of men and women respondents who saw no change was virtually identical (18%). But more women than men saw their salaries decrease (10% versus 7%). Correspondingly, more men saw their salaries increase. Women were also more likely to have a smaller increase: 24% of women had an increase of under $5,000 versus 17% of men. At the high end of the salary spectrum, the difference between men and women was smaller, though still not zero: 19% of men saw their salaries increase by over $20,000, but only 18% of women did. So the most significant differences were in the midrange. One anomaly sticks out: a slightly higher percentage of women than men received salary increases in the $15,000 to $20,000 range (8% versus 6%).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13957\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/03-1048x618.jpg\" /><figcaption><em>Figure 3. Change in salary for women and men over\\xa0three years</em></figcaption></figure>\\n\\n\\n\\n<h2>Salaries by Programming Language</h2>\\n\\n\\n\\n<p>When we looked at the most popular programming languages for data and AI practitioners, we didn’t see any surprises: Python was dominant (61%), followed by SQL (54%), JavaScript (32%), HTML (29%), Bash (29%), Java (24%), and R (20%). C++, C#, and C were further back in the list (12%, 12%, and 11%, respectively).</p>\\n\\n\\n\\n<p>Discussing the connection between programming languages and salary is tricky because respondents were allowed to check multiple languages, and most did. But when we looked at the languages associated with the highest salaries, we got a significantly different list. The most widely used and popular languages, like Python ($150,000), SQL ($144,000), Java ($155,000), and JavaScript ($146,000), were solidly in the middle of the salary range. The outliers were Rust, which had the highest average salary (over $180,000), Go ($179,000), and Scala ($178,000). Other less common languages associated with high salaries were Erlang, Julia, Swift, and F#. Web languages (HTML, PHP, and CSS) were at the bottom (all around $135,000). See&nbsp;Figure 4&nbsp;for the full list.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13958\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/04-774x1048.jpg\" /><figcaption><em>Figure 4. Salary vs. programming language</em></figcaption></figure>\\n\\n\\n\\n<p>How do we explain this? It’s difficult to say that data and AI developers who use Rust command a higher salary, since most respondents checked several languages. But we believe that this data shows something significant. The supply of talent for newer languages like Rust and Go is relatively small. While there may not be a huge demand for data scientists who use these languages (yet), there’s clearly some demand—and with experienced Go and Rust programmers in short supply, they command a higher salary. Perhaps it is even simpler: regardless of the language someone will use at work, employers interpret knowledge of Rust and Go as a sign of competence and willingness to learn, which increases candidates’ value. A similar argument can be made for Scala, which is the native language for the widely used Spark platform. Languages like Python and SQL are table stakes: an applicant who can’t use them could easily be penalized, but competence doesn’t confer any special distinction.</p>\\n\\n\\n\\n<p>One surprise is that 10% of the respondents said that they didn’t use any programming languages. We’re not sure what that means. It’s possible they worked entirely in Excel, which should be considered a programming language but often isn’t. It’s also possible that they were managers or executives who no longer did any programming.</p>\\n\\n\\n\\n<h2>Salaries by Tool and Platform</h2>\\n\\n\\n\\n<p>We also asked respondents what tools they used for statistics and machine learning and what platforms they used for data analytics and data management. We observed some of the same patterns that we saw with programming languages. And the same caution applies: respondents were allowed to select multiple answers to our questions about the tools and platforms that they use. (However, multiple answers weren’t as frequent as for programming languages.) In addition, if you’re familiar with tools and platforms for machine learning and statistics, you know that the boundary between them is fuzzy. Is Spark a tool or a platform? We considered it a platform, though two Spark libraries are in the list of tools. What about Kafka? A platform, clearly, but a platform for building data pipelines that’s qualitatively different from a platform like Ray, Spark, or Hadoop.</p>\\n\\n\\n\\n<p>Just as with programming languages, we found that the most widely used tools and platforms were associated with midrange salaries; older tools, even if they’re still widely used, were associated with lower salaries; and some of the tools and platforms with the fewest users corresponded to the highest salaries. (See&nbsp;Figure 5&nbsp;for the full list.)</p>\\n\\n\\n\\n<p>The most common responses to the question about tools for machine learning or statistics were “I don’t use any tools” (40%) or Excel (31%). Ignoring the question of how one does machine learning or statistics without tools, we’ll only note that those who didn’t use tools had an average salary of $143,000, and Excel users had an average salary of $138,000—both below average. Stata ($120,000) was also at the bottom of the list; it’s an older package with relatively few users and is clearly falling out of favor.</p>\\n\\n\\n\\n<p>The popular machine learning packages PyTorch (19% of users, $166,000 average salary), TensorFlow (20%, $164,000), and scikit-learn (27%, $157,000) occupied the middle ground. Those salaries were above the average for all respondents, which was pulled down by the large numbers who didn’t use tools or only used Excel. The highest salaries were associated with H2O (3%, $183,000), KNIME (2%, $180,000), Spark NLP (5%, $179,000), and Spark MLlib (8%, $175,000). It’s hard to trust conclusions based on 2% or 3% of the respondents, but it appears that salaries are higher for people who work with tools that have a lot of “buzz” but aren’t yet widely used. Employers pay a premium for specialized expertise.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13959\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/05-1048x934.jpg\" /><figcaption><em>Figure 5. Average salary by tools for statistics or machine learning</em></figcaption></figure>\\n\\n\\n\\n<p>We see almost exactly the same thing when we look at data frameworks (Figure 6). Again, the most common response was from people who didn’t use a framework; that group also received the lowest salaries (30% of users, $133,000 average salary).</p>\\n\\n\\n\\n<p>In 2021, Hadoop often seems like legacy software, but 15% of the respondents were working on the Hadoop platform, with an average salary of $166,000. That was above the average salary for all users and at the low end of the midrange for salaries sorted by platform.</p>\\n\\n\\n\\n<p>The highest salaries were associated with Clicktale (now&nbsp;ContentSquare), a cloud-based analytics system for researching customer experience: only 0.2% of respondents use it, but they have an average salary of $225,000. Other frameworks associated with high salaries were Tecton (the commercial version of Michelangelo, at $218,000), Ray ($191,000), and Amundsen ($189,000). These frameworks had relatively few users—the most widely used in this group was Amundsen with 0.8% of respondents (and again, we caution against reading too much into results based on so few respondents). All of these platforms are relatively new, frequently discussed in the tech press and social media, and appear to be growing healthily. Kafka, Spark, Google BigQuery, and Dask were in the middle, with a lot of users (15%, 19%, 8%, and 5%) and above-average salaries ($179,000, $172,000, $170,000, and $170,000). Again, the most popular platforms occupied the middle of the range; experience with less frequently used and growing platforms commanded a premium.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13960\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/06-1048x782.jpg\" /><figcaption><em>Figure 6.\\xa0Average salary by data framework or platform</em></figcaption></figure>\\n\\n\\n\\n<h2>Salaries by Industry</h2>\\n\\n\\n\\n<p>The greatest number of respondents worked in the software industry (20% of the total), followed by consulting (11%) and healthcare, banking, and education (each at 8%). Relatively few respondents listed themselves as consultants (also 2%), though consultancy tends to be cyclic, depending on current thinking on outsourcing, tax law, and other factors. The average income for consultants was $150,000, which is only slightly higher than the average for all respondents ($146,000). That may indicate that we’re currently in some kind of an equilibrium between consultants and in-house talent.</p>\\n\\n\\n\\n<p>While data analysis has become essential to every kind of business and AI is finding many applications outside of computing, salaries were highest in the computer industry itself, as&nbsp;Figure 7&nbsp;makes clear. For our purposes, the “computer industry” was divided into four segments: computer hardware, cloud services and hosting, security, and software. Average salaries in these industries ranged from $171,000 (for computer hardware) to $164,000 (for software). Salaries for the advertising industry (including social media) were surprisingly low, only $150,000.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13961\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/07-1048x842.jpg\" /><figcaption><em>Figure 7.\\xa0Average salary by industry</em></figcaption></figure>\\n\\n\\n\\n<p>Education and nonprofit organizations (including trade associations) were at the bottom end of the scale, with compensation just above $100,000 ($106,000 and $103,000, respectively). Salaries for technical workers in government were slightly higher ($124,000).</p>\\n\\n\\n\\n<h2>Salaries by State</h2>\\n\\n\\n\\n<p>When looking at data and AI practitioners geographically, there weren’t any big surprises. The states with the most respondents were California, New York, Texas, and Massachusetts. California accounted for 19% of the total, with over double the number of respondents from New York (8%). To understand how these four states dominate, remember that they make up 42% of our respondents but only 27% of the United States’ population.</p>\\n\\n\\n\\n<p>Salaries in California were the highest, averaging&nbsp;$176,000. The Eastern Seaboard did well, with an average salary of $157,000 in Massachusetts (second highest). New York, Delaware, New Jersey, Maryland, and Washington, DC, all reported average salaries in the neighborhood of $150,000 (as did North Dakota, with five respondents). The average salary reported for Texas was $148,000, which is slightly above the national average but nevertheless seems on the low side for a state with a significant technology&nbsp;industry.</p>\\n\\n\\n\\n<p>Salaries in the Pacific Northwest were not as high as we expected. Washington just barely made it into the top 10 in terms of the number of respondents, and average salaries in Washington and Oregon were $138,000 and $133,000, respectively. (See&nbsp;Figure 8&nbsp;for the full list.)</p>\\n\\n\\n\\n<p>The highest-paying jobs, with salaries over $300,000, were concentrated in California (5% of the state’s respondents) and Massachusetts (4%). There were a few interesting outliers: North Dakota and Nevada both had very few respondents, but each had one respondent making over $300,000. In Nevada, we’re guessing that’s someone who works for the casino industry—after all, the origins of probability and statistics are tied to gambling. Most states had no respondents with compensation over $300,000.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13962\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/08-661x1048.jpg\" /><figcaption><em>Figure 8.\\xa0Average salary by state</em></figcaption></figure>\\n\\n\\n\\n<p>The lowest salaries were, for the most part, from states with the fewest respondents. We’re reluctant to say more than that. These states typically had under 10 respondents, which means that averaging salaries is extremely noisy. For example, Alaska only had two respondents and an average salary of $75,000; Mississippi and Louisiana each only had five respondents, and Rhode Island only had three. In any of these states, one or two additional respondents at the executive level would have a huge effect on the states average. Furthermore, the averages in those states are so low that all (or almost all) respondents must be students, interns, or in entry-level positions. So we don’t think we can make any statement stronger than “the high paying jobs are where you’d expect them to be.”</p>\\n\\n\\n\\n<h2>Job Change by Salary</h2>\\n\\n\\n\\n<p>Despite the differences between states, we found that the desire to change jobs based on lack of compensation didn’t depend significantly on geography. There were outliers at both extremes, but they were all in states where the number of respondents was small and one or two people looking to change jobs would make a significant difference. It’s not terribly interesting to say that 24% of respondents from California intend to change jobs (only 2% above the national average); after all, you’d expect California to dominate. There may be a small signal from states like New York, with 232 respondents, of whom 27% intend to change jobs, or from a state like Virginia, with 137 respondents, of whom only 19% were thinking of changing. But again, these numbers aren’t much different from the total percentage of possible job changers.</p>\\n\\n\\n\\n<p>If intent to change jobs due to compensation isn’t dependent on location, then what does it depend on? Salary. It’s not at all surprising that respondents with the lowest salaries (under $50,000/year) are highly motivated to change jobs (29%); this group is composed largely of students, interns, and others who are starting their careers. The group that showed the second highest desire to change jobs, however, had the highest salaries: over $400,000/year (27%). It’s an interesting pairing: those with the highest and lowest salaries were most intent on getting a salary increase.</p>\\n\\n\\n\\n<p>26% of those with annual salaries between $50,000 and $100,000 indicated that they intend to change jobs because of compensation. For the remainder of the respondents (those with salaries between $100,000 and $400,000), the percentage who intend to change jobs was 22% or lower.</p>\\n\\n\\n\\n<h2>Salaries by Certification</h2>\\n\\n\\n\\n<p>Over a third of the respondents (37%) replied that they hadn’t obtained any certifications in the past year. The next biggest group replied “other” (14%), meaning that they had obtained certifications in the past year but not one of the certifications we listed. We allowed them to write in their own responses, and they shared 352 unique answers, ranging from vendor-specific certifications (e.g., DataRobot) to university degrees (e.g., University of Texas) to well-established certifications in any number of fields (e.g., Certified Information Systems Security Professional a.k.a. CISSP). While there were certainly cases where respondents used different words to describe the same thing, the amount of unique write-in responses reflects the great number of certifications available.</p>\\n\\n\\n\\n<p>Cloud certifications were by far the most popular. The top certification was for AWS (3.9% obtained AWS Certified Solutions Architect-Associate), followed by Microsoft Azure (3.8% had AZ-900: Microsoft Azure Fundamentals), then two more AWS certifications and CompTIA’s Security+ certification (1% each). Keep in mind that 1% only represents 27 respondents, and all the other certifications had even fewer respondents.</p>\\n\\n\\n\\n<p>As&nbsp;Figure 9&nbsp;shows, the highest salaries were associated with AWS certifications, the Microsoft AZ-104 (Azure Administrator Associate) certification, and the CISSP security certification. The average salary for people listing these certifications was higher than the average salary for US respondents as a whole. And the average salary for respondents who wrote in a certification was slightly above the average for those who didn’t earn any certifications ($149,000 versus $143,000).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13963\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/09-1048x580.jpg\" /><figcaption><em>Figure 9.\\xa0Average salary by certification earned</em></figcaption></figure>\\n\\n\\n\\n<p>Certifications were also associated with salary increases (Figure 10). Again AWS and Microsoft Azure dominate, with Microsoft’s AZ-104 leading the way, followed by three AWS certifications. And on the whole, respondents with certifications appear to have received larger salary increases than those who didn’t earn any technical certifications.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13964\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/10-1048x599.jpg\" /><figcaption><em>Figure 10.\\xa0Average salary change by certification</em></figcaption></figure>\\n\\n\\n\\n<p>Google Cloud is an obvious omission from this story. While Google is the third-most-important cloud provider, only 26 respondents (roughly 1%) claimed any Google certification, all under the “Other” category.</p>\\n\\n\\n\\n<p>Among our respondents, security certifications were relatively uncommon and didn’t appear to be associated with significantly higher salaries or salary increases. Cisco’s CCNP was associated with higher salary increases; respondents who earned the CompTIA Security+ or CISSP certifications received smaller increases. Does this reflect that management undervalues security training? If this hypothesis is correct, undervaluing security is clearly a significant mistake, given the ongoing importance of security and the possibility of new attacks against AI and other data-driven systems.</p>\\n\\n\\n\\n<p>Cloud certifications clearly had the greatest effect on salary increases. With very few exceptions, any certification was better than no certification: respondents who wrote in a certification under “Other” averaged a $9,600 salary increase over the last few years, as opposed to $8,900 for respondents who didn’t obtain a certification and $9,300 for all respondents regardless of certification.</p>\\n\\n\\n\\n<h2>Training</h2>\\n\\n\\n\\n<p>Participating in training resulted in salary increases—but only for those who spent more than 100 hours in a training program. As&nbsp;Figure 11 shows, those respondents had an average salary increase of $11,000. This was also the largest group of respondents (19%). Respondents who only reported undertaking 1–19 hours of training (8%) saw lower salary increases, with an average of $7,100. It’s interesting that those who participated in 1–19 hours of training saw smaller increases than those who didn’t participate in training at all. It doesn’t make sense to speculate about this difference, but the data does make one thing clear: if you engage in training, be serious about it.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13965\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/11-1048x468.jpg\" /><figcaption><em>Figure 11.\\xa0Average salary change vs. hours of training</em></figcaption></figure>\\n\\n\\n\\n<p>We also asked what types of training respondents engaged in: whether it was company provided (for which there were three alternatives), a certification program, a conference, or some other kind of training (detailed in&nbsp;Figure 12). Respondents who took advantage of company-provided opportunities had the highest average salaries ($156,000, $150,000, and $149,000). Those who obtained certifications were next ($148,000). The results are similar if we look at salary increases over the past three years: Those who participated in various forms of company-offered training received increases between $11,000 and $10,000. Salary increases for respondents who obtained a certification were in the same range ($11,000).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13966\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/12-1048x557.jpg\" /><figcaption><em>Figure 12.\\xa0Average salary change vs. type of training</em></figcaption></figure>\\n\\n\\n\\n<h2>The Last Word</h2>\\n\\n\\n\\n<p>Data and AI professionals—a rubric under which we include data scientists, data engineers, and specialists in AI and ML—are well-paid, reporting an average salary just under $150,000. However, there were sharp state-by-state differences: salaries were significantly higher in California, though the Northeast (with some exceptions) did well.</p>\\n\\n\\n\\n<p>There were also significant differences between salaries for men and women. Men’s salaries were higher regardless of job title, regardless of training and regardless of academic degrees—even though women were more likely to have an advanced academic degree (PhD or master’s degree) than were men.</p>\\n\\n\\n\\n<p>We don’t see evidence of a “great resignation.” Job turnover through the pandemic was roughly what we’d expect (perhaps slightly below normal). Respondents did appear to be concerned about job security, though they didn’t want to admit it explicitly. But with the exception of the least- and most-highly compensated respondents, the intent to change jobs because of salary was surprisingly consistent and nothing to be alarmed at.</p>\\n\\n\\n\\n<p>Training was important, in part because it was associated with hireability and job security but more because respondents were genuinely interested in learning new skills and improving current ones. Cloud training, particularly in AWS and Microsoft Azure, was the most strongly associated with higher salary increases.</p>\\n\\n\\n\\n<p>But perhaps we should leave the last word to our respondents. The final question in our survey asked what areas of technology would have the biggest effect on salary and promotions in the coming year. It wasn’t a surprise that most of the respondents said machine learning (63%)—these days, ML is the hottest topic in the data world. It was more of a surprise that “programming languages” was noted by just 34% of respondents. (Only “Other” received fewer responses—see&nbsp;Figure 13&nbsp;for full details.) Our respondents clearly aren’t impressed by programming languages, even though the data suggests that employers are willing to pay a premium for Rust, Go, and Scala.</p>\\n\\n\\n\\n<p>There’s another signal worth paying attention to if we look beyond the extremes. Data tools, cloud and containers, and automation were nearly tied (46, 47, and 44%). The cloud and containers&nbsp;category&nbsp;includes tools like Docker and Kubernetes, cloud providers like AWS and Microsoft Azure, and disciplines like MLOps. The tools category includes tools for building and maintaining data pipelines, like Kafka. “Automation” can mean a lot of things but in this context probably means automated training and deployment.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13967\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/09/13-1048x808.jpg\" /><figcaption><em>Figure 13.\\xa0What technologies will have the biggest effect on compensation in the coming year?</em></figcaption></figure>\\n\\n\\n\\n<p>We’ve argued for some time that&nbsp;<a href=\"https://www.oreilly.com/radar/ai-meets-operations/\">operations</a>—successfully deploying and managing applications in production—is the biggest issue facing ML practitioners in the coming years. If you want to stay on top of what’s happening in data, and if you want to maximize your job security, hireability, and salary, don’t just learn how to build AI models; learn how to deploy applications that live in the cloud.</p>\\n\\n\\n\\n<p>In the classic movie&nbsp;<em>The Graduate</em>, one character famously says, “There’s a great future in plastics. Think about it.” In 2021, and without being anywhere near as repulsive, we’d say, “There’s a great future in the cloud. Think about it.”</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/2021-data-ai-salary-survey/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: September 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: September 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-september-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-september-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-september-2021/#respond',\n",
       "   'published': 'Wed, 01 Sep 2021 12:18:33 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=9, tm_mday=1, tm_hour=12, tm_min=18, tm_sec=33, tm_wday=2, tm_yday=244, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13943',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Let’s start with a moment of silence for O’Reilly Author Toby Segaran, who passed away on August 11, 2021.&#160; Toby was one of the people who got the Data Science movement started. His book, Programming Collective Intelligence, taught many how to start using their data. Throughout his career, he mentored many, and was particularly influential [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Let’s start with a moment of silence for O’Reilly Author Toby Segaran, who passed away on August 11, 2021.&#160; Toby was one of the people who got the Data Science movement started. His book, Programming Collective Intelligence, taught many how to start using their data. Throughout his career, he mentored many, and was particularly influential [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Let’s start with a moment of silence for O’Reilly Author <a href=\"https://medium.com/@dpatil/toby-segaran-one-of-the-greats-ce06f755a3f4\">Toby Segaran</a>, who passed away on August 11, 2021.&nbsp; Toby was one of the people who got the Data Science movement started. His book, <a href=\"https://www.amazon.com/Programming-Collective-Intelligence-Building-Applications/dp/0596529325\">Programming Collective Intelligence</a>, taught many how to start using their data. Throughout his career, he mentored many, and was particularly influential in mentoring young women interested in science and technology. Toby is greatly missed by everyone in the Data Science community.</p>\\n\\n\\n\\n<h2>AI and Data</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.bloomberg.com/news/articles/2021-08-24/fired-at-google-after-critical-work-ai-researcher-mitchell-to-join-hugging-face\">Margaret Mitchell joins HuggingFace</a> to create tools to help build fair algorithms.<br /> </li><li><a href=\"https://www.iotcentral.io/blog/enhancing-health-and-safety-in-industrial-enviro-with-edge-ai\">Embedded Machine Learning for Hard Hat Detection</a> is an interesting real-world application of AI on the edge. Wearing hard hats is essential to work site safety; this project developed a model for detecting whether workers were wearing hard hats that could easily be deployed without network connectivity. It also goes into rebalancing datasets–in this case, public datasets with too few hard hats, but this technique is applicable to other instances of bias.<br /></li><li><a href=\"https://news.mit.edu/2021/machine-learning-adapts-0128\">Liquid Neural Networks</a> are neural networks that can adapt in real time to incoming data.&nbsp; They are particularly useful for time series data–which, as the author points out, is almost all data.<br /></li><li>US Government agencies plan to <a href=\"https://www.technologyreview.com/2021/08/24/1032967/us-government-agencies-plan-to-increase-their-use-of-facial-recognition-technology/\">increase their use of facial recognition</a>, in many cases for law enforcement, despite well-known accuracy problems for minorities and women.&nbsp; Local bans on face recognition cannot prohibit federal use.<br /></li><li><a href=\"https://ourdataourselves.tacticaltech.org/projects/data-and-politics/\">Data and Politics</a> is an ongoing research project that studies how political organizations are collecting and using data.<br /></li><li><a href=\"https://spin.atomicobject.com/2021/08/18/faunadb-greenfield-project/\">FaunaDB</a> is a distributed document database designed for serverless architectures. It comes with REST API support, GraphQL, built-in attribute based access control, and a lot of other great features.<br /></li><li><a href=\"https://techxplore.com/news/2021-08-google-facial-recognition-android-accessibility.html\">Facial expression recognition</a> is being added to a future version of Android as part of their accessibility package. Developers can create applications where expressions (smiles, etc.) can be used as commands.<br /></li><li>Open AI’s <a href=\"https://openai.com/blog/openai-codex/\">Codex</a> (the technology behind <a href=\"https://copilot.github.com/\">Copilot</a>) takes the next step: translating English into runnable code, rather than making suggestions.&nbsp; Codex is now in private beta.<br /></li><li>Who is responsible for publicly available datasets, and how do you ensure that they’re used appropriately? Margaret Mitchell suggests organizations for <a href=\"https://www.technologyreview.com/2021/08/13/1031836/ai-ethics-responsible-data-stewardship/\">data stewardship</a>. These would curate, maintain, and enforce legal standards for the use of public data.<br /></li><li>An AI system can <a href=\"https://arxiv.org/abs/2107.10356\">predict race</a> accurately based purely on medical images, with no other information about the subject. This creates huge concerns about how bias could enter AI-driven diagnostics; but it also raises the possibility that we might discover better treatments for minorities who are underserved (or badly served) by the medical industry.<br /></li><li>DeepMind has made progress in building a <a href=\"https://thenextweb.com/news/deepminds-new-system-general-ai-way-to-go-syndication?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+TheNextWeb+%28The+Next+Web+All+Stories%29\">generalizable AI</a>: AI agents that can solve problems that they have never seen before, and transfer learning from one problem to another. They have developed XLand, an environment that creates games and problems, to enable this research.<br /></li><li><a href=\"https://towardsdatascience.com/cant-access-gpt-3-here-s-gpt-j-its-open-source-cousin-8af86a638b11\">GPT-J</a> is one of a number of open source <a href=\"https://www.kdnuggets.com/2021/07/github-copilot-open-source-alternatives-code-generation.html\">alternatives</a> to Github Copilot. It is smaller and faster, and appears to be at least as good.<br /></li><li>“<a href=\"https://gizmodo.com/master-face-researchers-say-theyve-found-a-wildly-succ-1847420710\">Master faces</a>” are images generated by adversarial neural networks that are capable of passing facial recognition tests without corresponding to any specific face. <br /></li><li>Researchers have created a <a href=\"https://www.technologyreview.com/2021/08/02/1030453/microns-connections-in-a-mouse-brain/\">3D</a> map of a small part of a mouse’s brain. This is the most detailed map of how neurons connect that has ever been made.&nbsp; The map contains 75,000 neurons and 523 million synapses; the map and the data set have been <a href=\"https://www.microns-explorer.org/cortical-mm3\">released</a> to the public.</li></ul>\\n\\n\\n\\n<h2>Robotics</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.technologyreview.com/2021/08/10/1031511/chameleon-inspired-robot-changes-colors-instantly/\">Robotic chameleons</a> (or chameleon robotics): Researchers have developed a robotic “skin” that can change color in real time to match its surroundings.<br /></li><li>Elon Musk announces that Tesla will release a <a href=\"https://www.theguardian.com/technology/2021/aug/20/humanoid-tesla-bot-likely-to-launch-next-year-says-elon-musk\">humanoid robo</a>t next year; it will be capable of performing tasks like going to the store. Is this real, or just a distraction from investigations into the safety of Tesla’s autonomous driving software?<br /></li><li>According to the UN, <a href=\"https://theconversation.com/lethal-autonomous-weapons-and-world-war-iii-its-not-too-late-to-stop-the-rise-of-killer-robots-165822\">lethal autonomous robots</a> (robots capable of detecting and attacking a target without human intervention) have been deployed and used by the Libyan government.<br /></li><li>A new generation of <a href=\"https://www.technologyreview.com/2021/08/06/1030802/ai-robots-take-over-warehouses/\">warehouse robots</a> is capable of simple manipulation (picking up and boxing objects); robots capable of more fine-grained manipulation are coming.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>The end of passwords draws even closer. <a href=\"https://thenewstack.io/github-kisses-passwords-goodbye/\">GitHub is now requiring 2-factor authentication</a>, preferably using WebAuthn or Yubikey. <a href=\"https://www.cnbc.com/2021/08/26/aws-will-give-away-usb-keys-to-root-account-owners-at-us-customers.html\">Amazon will be giving free USB authentication keys</a> to some customers (root account owners spending over $100/month).<br /></li><li>There are many <a href=\"https://thenextweb.com/news/ev-charging-security-disaster\">vulnerabilities in charging systems for electric vehicles</a>. This is sad, but not surprising: the automotive industry hasn’t learned from the problems of IoT security.<br /></li><li>Advances in <a href=\"https://techxplore.com/news/2021-08-osu-cryptography-huge-efficiency-gain.html\">cryptography</a> may make it more efficient to do computation without decrypting encrypted data.<br /></li><li>Amazon is offering store credit to people who give them their <a href=\"https://techxplore.com/news/2021-08-palm-amazon.html\">palm prints</a>, for use in biometric checkout at their brick-and-mortar stores.<br /></li><li>Amazon, Google, Microsoft, and others <a href=\"https://threatpost.com/cisa-head-woos-security-crowd/168426/\">join</a> the US Joint Cyber Defense Collaborative to fight the spread of ransomware.<br /></li><li>Apple will be <a href=\"https://arstechnica.com/tech-policy/2021/08/apple-explains-how-iphones-will-scan-photos-for-child-sexual-abuse-images/\">scanning iPhones</a> for images of child abuse.&nbsp; Child abuse aside, this decision raises questions about cryptographic backdoors for government agencies and Apple’s long-standing marketing of privacy. If they can monitor for one thing, they can monitor for others, and can presumably be legally forced to do so.<br /></li><li>Automating incident response: <a href=\"https://thenewstack.io/self-healing-auto-remediation-in-the-world-of-observability/\">self-healing auto-remediation</a> could be the next step in automating all the things, building more reliable systems, and eliminating the 3AM pager.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li><a href=\"https://theconversation.com/wearable-tech-for-your-ears-hearables-can-teach-you-a-language-or-music-with-the-help-of-ai-161571\">Hearables</a> are very small computers, worn in the ear, for which the only interface is a microphone, a speaker, and a network. They may have applications in education, music, real time translation (like Babelfish), and of course, next-generation hearing aids.<br /></li><li>Timekeeping is an old and well-recognized problem in distributed computing. Facebook’s <a href=\"https://engineering.fb.com/2021/08/11/open-source/time-appliance/\">Time cards</a> are an open-source (code and hardware) solution for accurate time keeping. The cards are PCIe bus cards (PC standard) and incorporate a satellite receiver and an atomic clock. <br /></li><li>A new <a href=\"https://www.geekwire.com/2021/ray-ozzies-telecom-startup-blues-wireless-raises-22m-bill-gates-others/\">cellular board for IoT</a> from Ray Ozzie’s company Blues Wireless is a very interesting product. It is easy to program (JSON in and out), interfaces easily to Raspberry Pi and other systems, and $49 includes 10 years of cellular connectivity.</li></ul>\\n\\n\\n\\n<h2>Social Media</h2>\\n\\n\\n\\n<ul><li>Researchers are using Google Trends data to <a href=\"https://techxplore.com/news/2021-08-tools-combat-covid-misinformation-symptoms.html\">identify COVID symptoms</a> as a proxy for hospital data, since hospital data isn’t publicly available. The key is distinguishing between flu-like flu symptoms and flu-like COVID symptoms.<br /></li><li>A <a href=\"https://digiday.com/marketing/google-switch-floc-cookie-replacement-fingerprinting-potential/\">topic-based approach</a> to targeted advertising may be Google’s new alternative to tracking cookies, replacing the idea of assigning users to cohorts with similar behavior.<br /></li><li>Facebook shares <a href=\"https://ethanzuckerman.com/2021/08/18/facebooks-new-transparency-report-is-really-strange/\">a little information</a> about what’s most widely viewed on their network.&nbsp;It only covers the top 20 URLs and, given Facebook’s attempts to <a href=\"https://www.lawfareblog.com/lawfare-podcast-facebook-shuts-down-research-itself\">shut down researchers</a> studying their behavior, qualifies as transparency theater rather than substance.<br /></li><li>As an experiment, Twitter is allowing certain users to mark <a href=\"https://techxplore.com/news/2021-08-twitter-users-flag-content.html\">misleading content</a>.&nbsp; They have not (and presumably won’t) specified how to become one of these users. The information they gain won’t be used directly for blocking misinformation, but to study how it propagates.<br /></li><li><a href=\"https://www.vice.com/en/article/k78kmv/instagram-ban-restore-service-scam\">Banning as a service</a>: It’s now possible to hire a company to get someone banned from Instagram and other social media. Not surprisingly, these organizations may be connected to organizations that specialize in restoring banned accounts.<br /></li><li>Facebook may be researching ways to use some combination of AI and homomorphic encryption to place targeted <a href=\"https://thenextweb.com/news/facebook-encryption-ads-ai-team-rumor\">ads on encrypted messages</a> without decrypting them.<br /></li><li>Inspired by the security community and bug bounties, Twitter offers a <a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge\">bounty</a> to people who discover algorithmic bias.</li></ul>\\n\\n\\n\\n<h2>Work</h2>\\n\\n\\n\\n<ul><li>Facebook’s virtual reality <a href=\"https://www.theverge.com/2021/8/19/22629942/facebook-workrooms-horizon-oculus-vr\">workrooms</a> could transform remote meetings by putting all the participants in a single VR conference room–assuming that all the participants are willing to wear goggles.<br /></li><li>A survey shows that 70% of employees would <a href=\"https://www.zdnet.com/article/go-back-to-the-office-some-employees-would-rather-give-up-half-their-salary/\">prefer to work at home</a>, even if it costs them in benefits, including vacation time and salaries.&nbsp; Eliminating the commute adds up.</li></ul>\\n\\n\\n\\n<h2>Cloud</h2>\\n\\n\\n\\n<ul><li><a href=\"https://thenewstack.io/sky-computing-the-next-era-after-cloud-computing/\">Sky computing</a>–the next step towards true utility computing–is essentially what we now call “multi cloud,” but with an inter-cloud layer that provides interoperability between cloud providers.<br /></li><li>Thoughts on the future of the <a href=\"https://medium.com/@jordan_88855/five-predictions-for-the-future-of-the-modern-data-stack-435b4e911413\">data stack</a> as data starts to take advantage of <a href=\"https://blog.getdbt.com/future-of-the-modern-data-stack/\">cloud</a>: how do organizations get beyond “lift and shift” and other early approaches to use clouds effectively?</li></ul>\\n\\n\\n\\n<h2>Networks</h2>\\n\\n\\n\\n<ul><li><a href=\"https://thenewstack.io/decentralized-chat-matrix-offers-red-pill-to-slack-users/\">Matrix</a> is another protocol for decentralized messaging (similar in concept to Scuttlebutt) that appears to be getting some enterprise traction.<br /></li><li>Using federated learning to build decentralized <a href=\"https://techxplore.com/news/2021-08-wireless-traffic-ai-reliability-future.html\">intelligent wireless</a> communications systems that predict traffic patterns to help traffic management may be part of 6G.<br /></li><li>How do you scale intelligence at the <a href=\"https://thenewstack.io/the-challenge-of-scaling-the-intelligent-edge/\">edge</a> of the network? APIs, industrially hardened Linux systems, and Kubernetes adapted to small systems (e.g., K3S).</li></ul>\\n\\n\\n\\n<h2>Miscellaneous</h2>\\n\\n\\n\\n<ul><li>The EU is considering a law that would require cryptocurrency transactions to be <a href=\"https://www.euronews.com/next/2021/07/21/eu-will-make-bitcoin-traceable-and-ban-anonymous-crypto-wallets-in-anti-money-laundering-d\">traceable</a>.&nbsp; An EU-wide authority to prevent money laundering would have authority over cryptocurrencies.<br /></li><li><a href=\"https://www.nature.com/articles/d41586-021-02211-4\">Autocorrect errors</a> in Excel are a problem in genomics: autocorrect modifies gene names, which are frequently “corrected” to dates.<br /></li><li>Google may have <a href=\"https://thenextweb.com/news/google-may-have-achieved-breakthrough-time-crystals\">created</a> the first time crystals in a quantum computer. Time crystals are a theoretical construct that has a structure that constantly changes but repeats over time, without requiring additional energy.</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-september-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Rebranding Data',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Rebranding Data'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/rebranding-data/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/rebranding-data/',\n",
       "   'comments': 'https://www.oreilly.com/radar/rebranding-data/#respond',\n",
       "   'published': 'Tue, 24 Aug 2021 14:16:28 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=24, tm_hour=14, tm_min=16, tm_sec=28, tm_wday=1, tm_yday=236, tm_isdst=0),\n",
       "   'authors': [{'name': 'Q McCallum'}],\n",
       "   'author': 'Q McCallum',\n",
       "   'author_detail': {'name': 'Q McCallum'},\n",
       "   'tags': [{'term': 'Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13932',\n",
       "   'guidislink': False,\n",
       "   'summary': 'There&#8217;s a flavor of puzzle in which you try to determine the next number or shape in a sequence. We&#8217;re living that now, but for naming the data field.&#160; &#8220;Predictive analytics.&#8221; &#8220;Big Data.&#8221; &#8220;Data science.&#8221; &#8220;Machine learning.&#8221; &#8220;AI.&#8221; What&#8217;s next? It&#8217;s hard to say.&#160; These terms all claim to be different, but they are very [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'There&#8217;s a flavor of puzzle in which you try to determine the next number or shape in a sequence. We&#8217;re living that now, but for naming the data field.&#160; &#8220;Predictive analytics.&#8221; &#8220;Big Data.&#8221; &#8220;Data science.&#8221; &#8220;Machine learning.&#8221; &#8220;AI.&#8221; What&#8217;s next? It&#8217;s hard to say.&#160; These terms all claim to be different, but they are very [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>There&#8217;s a flavor of puzzle in which you try to determine the next number or shape in a sequence. We&#8217;re living that now, but for naming the data field.&nbsp; &#8220;Predictive analytics.&#8221; &#8220;Big Data.&#8221; &#8220;Data science.&#8221; &#8220;Machine learning.&#8221; &#8220;AI.&#8221; What&#8217;s next?</p>\\n\\n\\n\\n<p>It&#8217;s hard to say.&nbsp; These terms all claim to be different, but they are very much the same.&nbsp; They are supersets, subsets, and Venn diagrams with a lot of overlap.&nbsp; Case in point: machine learning used to be considered part of data science; now it&#8217;s seen as a distinct (and superior) field.&nbsp; What gives?</p>\\n\\n\\n\\n<p>Since the promise of &#8220;analyzing data for fun and profit&#8221; has proven so successful, it&#8217;s odd that the field would feel the need to rebrand every couple of years.&nbsp; You&#8217;d think that it would build on a single name, to drive home its transformative power.&nbsp; Unless, maybe, it&#8217;s not all it claims to be? </p>\\n\\n\\n\\n<h3>Resetting the hype cycle</h3>\\n\\n\\n\\n<p>In a typical bubble—whether in the stock market, or the Dot-Com era—you see a large upswing and then a crash.&nbsp; The upswing is businesses over-investing time, money, and effort in The New Thing. The crash happens when those same groups realize that The New Thing won&#8217;t ultimately help them, and they suddenly stop throwing money at it.</p>\\n\\n\\n\\n<p>In finance terms, we&#8217;d say that the upswing represents a large and growing delta between the <em>fundamental price</em> (what The New Thing is actually worth) and the <em>observed price</em> (what people are spending on it, which is based on what they <em>think</em> it&#8217;s worth).&nbsp; The ensuing crash represents a <em>correction:</em> a sharp, sudden reduction in that delta, as the observed price falls to something closer to the fundamental price.</p>\\n\\n\\n\\n<p>Given that, we <em>should</em> have seen the initial Big Data hype bubble expand and then burst once businesses determined that this would only help a very small number of companies.&nbsp; Big Data never crashed, though. Instead, we saw &#8220;data science&#8221; take off.&nbsp; What&#8217;s weird is that companies were investing in roughly the same thing as before. It&#8217;s as though the rebranding was a way of laundering the data name, so that businesses and consumers could more easily forget that the previous version didn&#8217;t hold up to its claims.&nbsp; This is the old &#8220;hair of the dog&#8221; hangover cure.</p>\\n\\n\\n\\n<p>And it actually works.&nbsp; Until it doesn&#8217;t.</p>\\n\\n\\n\\n<h3>Data success is not dead; it&#8217;s just unevenly distributed</h3>\\n\\n\\n\\n<p>This isn&#8217;t to say that data analysis has no value. The ability to explore massive amounts of data can be tremendously useful.&nbsp; And lucrative.&nbsp; Just not for everyone. </p>\\n\\n\\n\\n<p>Too often, companies look to the FAANGs—Facebook, Amazon, Apple, Netflix, Google: the businesses that have clearly made a mint in data analysis—and figure they can copycat their way to the same success.&nbsp; Reality&#8217;s harsh lesson is that it&#8217;s not so simple.&nbsp; &#8220;Collect and analyze data&#8221; is just one ingredient of a successful data operation. You also need to connect those activities to your business model, and hand-waving over that part is only a temporary solution.&nbsp;At some point, you need to actually determine whether the fancy new thing can improve your business.&nbsp; If not, it&#8217;s time to let it go.</p>\\n\\n\\n\\n<p>We saw the same thing in the 1990s Dot-Com bust. The companies that genuinely needed developers and other in-house tech staff continued to need them; those that didn&#8217;t, well, they were able to save money by shedding jobs that weren&#8217;t providing business value. </p>\\n\\n\\n\\n<p>Maybe data&#8217;s constant re-branding is the lesson learned from the 1990s? That if we keep re-branding, we can ride the misplaced optimism, and we&#8217;ll never hit that low point?</p>\\n\\n\\n\\n<h3>Why it matters</h3>\\n\\n\\n\\n<p>If the data world is able to sustain itself by simply changing its name every few years, what&#8217;s the big deal? Companies are making money, consumers are happy with claims of AI-driven products, and some people have managed to find very lucrative jobs.&nbsp; Why worry about this now?</p>\\n\\n\\n\\n<p>This quote from Cem Karsan, founder of Aegea Capital Management, sums it up well.&nbsp; He&#8217;s talking about flows of money on Wall St. but the analogy applies just as well to the AI hype bubble:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>If you&#8217;re on an airplane, and you&#8217;re 30,000 feet off the ground, that 30,000 feet off the ground is the valuation gap.&nbsp; That&#8217;s where valuations are really high. But if those engines are firing, are you worried up in that plane about the valuations?&nbsp; No!&nbsp; You&#8217;re worried about the speed and trajectory of where you&#8217;re going, based on the engines.&nbsp; [&#8230;]&nbsp; But, when all of the sudden, those engines go off, how far off the ground you are is all that matters.</p><cite><br />—Cem Karsan, from Corey Hoffstein&#8217;s Flirting with Models podcast,  S4E1 (2021/05/03), starting 37:30</cite></blockquote>\\n\\n\\n\\n<p>Right now most of AI&#8217;s 30,000-foot altitude is hype. When the hype fades—when changing the name fails to keep the field aloft—that hype dissipates.&nbsp; At that point you&#8217;ll have to sell based on what AI can really do, instead of a rosy, blurry picture of what might be possible.</p>\\n\\n\\n\\n<p>This is when you might remind me of the old saying: &#8220;Make hay while the sun shines.&#8221;&nbsp; I would agree, to a point.&nbsp; So long as you&#8217;re able to cash out on the AI hype, even if that means renaming the field a few more times, go ahead.&nbsp; But that&#8217;s a short-term plan.&nbsp; Long-term survival in this game means knowing when that sun will set and planning accordingly.&nbsp; How many more name-changes do we get?&nbsp; How long before regulation and consumer privacy frustrations start to chip away at the façade?&nbsp; How much longer will companies be able to paper over their AI-based systems&#8217; mishaps?</p>\\n\\n\\n\\n<h3>Where to next?</h3>\\n\\n\\n\\n<p>If you&#8217;re building AI that&#8217;s all hype, then these questions may trouble you.&nbsp; Post-bubble AI (or whatever we call it then) will be judged on meaningful characteristics and harsh realities: &#8220;Does this actually work?&#8221; and &#8220;Do the practitioners of this field create products and analyses that are genuinely useful?&#8221;&nbsp; (For the investors in the crowd, this is akin to judging a company&#8217;s stock price on market fundamentals.)&nbsp; Surviving long-term in this field will require that you find and build on realistic, worthwhile applications of AI.</p>\\n\\n\\n\\n<p>Does our field need some time to sort that out?&nbsp; I figure we have at least one more name change before we lose altitude.&nbsp; We&#8217;ll need to use that time wisely, to become smarter about how we use and build around data.&nbsp; We have to be ready to produce real value after the hype fades.</p>\\n\\n\\n\\n<p>That&#8217;s easier said than done, but it&#8217;s far from impossible. We can start by shifting our focus to the basics, like reviewing our data and seeing whether it&#8217;s any good.&nbsp; Accepting the uncomfortable truth that BI&#8217;s sums and groupings will help more businesses than AI&#8217;s neural networks.&nbsp;Evaluating the true total cost of AI, such that each six-figure data scientist salary is a proper business investment and not a very expensive lottery ticket.</p>\\n\\n\\n\\n<p>We&#8217;ll also have to get better about folding AI into products (and understanding the risks in doing so), which will require building interdisciplinary, cognitively-diverse teams where everyone gets a chance to weigh in. Overall, then, we&#8217;ll have to educate ourselves and our customers on what data analysis can really achieve, and then plan our efforts accordingly.</p>\\n\\n\\n\\n<p>We can do it.&nbsp;We&#8217;ll pretty much <em>have to</em> do it.&nbsp; The question is: will we start before the plane loses altitude?</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/rebranding-data/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'A Way Forward with Communal Computing',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'A Way Forward with Communal Computing'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/a-way-forward-with-communal-computing/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/a-way-forward-with-communal-computing/',\n",
       "   'comments': 'https://www.oreilly.com/radar/a-way-forward-with-communal-computing/#respond',\n",
       "   'published': 'Tue, 17 Aug 2021 12:45:50 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=17, tm_hour=12, tm_min=45, tm_sec=50, tm_wday=1, tm_yday=229, tm_isdst=0),\n",
       "   'authors': [{'name': 'Chris Butler'}],\n",
       "   'author': 'Chris Butler',\n",
       "   'author_detail': {'name': 'Chris Butler'},\n",
       "   'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'Building a data culture', 'scheme': None, 'label': None},\n",
       "    {'term': 'Emerging Tech', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13910',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Communal devices in our homes and offices aren’t quite right. In previous articles, we discussed the history of communal computing and the origin of the single user model. Then we reviewed the problems that arise due to identity, privacy, security, experience, and ownership issues. They aren’t solvable by just making a quick fix. They require [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Communal devices in our homes and offices aren’t quite right. In previous articles, we discussed the history of communal computing and the origin of the single user model. Then we reviewed the problems that arise due to identity, privacy, security, experience, and ownership issues. They aren’t solvable by just making a quick fix. They require [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Communal devices in our homes and offices aren’t quite right. In previous articles, we discussed the <a href=\"https://www.oreilly.com/radar/communal-computing/\">history of communal computing and the origin of the single user model</a>. Then we reviewed the <a href=\"https://www.oreilly.com/radar/communal-computings-many-problems/\">problems that arise due to identity, privacy, security, experience, and ownership issues</a>. They aren’t solvable by just making a quick fix. They require a huge reorientation in how these devices are framed and designed. </p>\\n\\n\\n\\n<p>This article focuses on modeling the communal device you want to build and understanding how it fits into the larger context. This includes how it interoperates with services that are connected, and how it communicates across boundaries with other devices in peoples’ homes. Ignore these warnings at your own peril. They can always unplug the device and recycle it.</p>\\n\\n\\n\\n<p>Let’s first talk about how we gain an understanding of the environment inside homes and offices.</p>\\n\\n\\n\\n<h3>Mapping the communal space</h3>\\n\\n\\n\\n<p>We have seen a long list of problems that keep communal computing from aligning with people’s needs. This misalignment arises from the assumption that there is a single relationship between a person and a device, rather than between all the people involved and their devices. </p>\\n\\n\\n\\n<p>Dr. S.A. Applin has referred to this assumption as “design individualism”; it is a common misframing used by technology organizations. She uses this term most recently in the paper “<a href=\"https://www.sciencedirect.com/science/article/pii/S2666659621000032\">Facebook&#8217;s Project Aria indicates problems for responsible innovation when broadly deploying AR and other pervasive technology in the Commons</a>:”</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>“Unfortunately, this is not an uncommon assumption in technology companies, but is a flaw in conceptual modelling that can cause great problems when products based on this ‘design individualism’ are deployed into the Commons (Applin, 2016b). In short, Facebook acknowledges the plural of ‘people’, but sees them as individuals collectively, not as a collective that is enmeshed, intertwined and exists based on multiple, multiplex, social, technological, and socio-technological relationships as described through [<a href=\"https://posr.org/wiki/Main_Page\">PolySocial Reality</a>].”</p></blockquote>\\n\\n\\n\\n<p><a href=\"https://posr.org/wiki/Main_Page\">PolySocial Reality (PoSR)</a> is a theory described in a series of papers by Applin and Fisher (2010-ongoing) on the following:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>“[PoSR] models the outcomes when all entities in networks send both synchronous and asynchronous messages to maintain social relationships. These messages can be human-to-human, human-to-machine, and machine-to-machine. PoSR contains the entirety of all messages at all times between all entities, and we can use this idea to understand how various factors in the outcomes from the way that messages are sent and received, can impact our ability to communicate, collaborate, and most importantly, cooperate with each other.”</p></blockquote>\\n\\n\\n\\n<p>In the case of PoSR, we need to consider how agents make decisions about the messages between entities. The designers of these non-human entities will make decisions that impact all entities in a system.</p>\\n\\n\\n\\n<p>The reality is that the “self” only exists as <a href=\"https://aeon.co/essays/the-self-is-not-singular-but-a-fluid-network-of-identities\">part of a larger network</a>. It is the connections between us and the rest of the network that is meaningful. We pull all of the pseudo identities for those various connections together to create our “one” self.</p>\\n\\n\\n\\n<p>The model that I’ve found most helpful to address this problem attempts to describe the complete environment of the communal space. It culminates in a map of the connections between nodes, or relationships between entities. This web of interactions includes all the individuals, the devices they use, and the services that intermediate them. The key is to understand how non-human entities intermediate the humans, and how those messages eventually make it to human actors.</p>\\n\\n\\n\\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh5.googleusercontent.com/sSvfMJ84vO_LHJCB3nfs3s4sv_aaSQPTyiezAkS9AzTk_9ToSfJpgeMxAbIGqW5gHwb16KGMbwBhCfisCG4c9Ec5p29OgG6wR2qWfhHmVJf9hDc4_VZUqrWNTu7z9HNmLA\" /><figcaption><br /><br />The home is a network, like an ecosystem, of people, devices, and services all interacting to create an experience. It is connected with services, people, and devices outside the home as well as my mom, my mom’s picture frame, and Google’s services that enable it.</figcaption></figure>\\n\\n\\n\\n<p>To see why this map is helpful, consider an ecosystem (or <a href=\"https://en.wikipedia.org/wiki/Food_web\">food web</a>). When we only consider interactions between individual animals, like a wolf eating a sheep, we ignore how the changes in population of each animal impacts other actors in the web: too many wolves mean the sheep population dies off. In turn, this change has an impact on other elements of the ecosystem like how much the grass grows. Likewise, when we only consider a single person interacting with one device, we find that most interactions are simple: some input from the user is followed by a response from the device. We often don’t consider other people interacting with the device, nor do we consider how other personal devices exist within that space. We start to see these interactions when we consider other people in the communal space, the new communal device, and all other personal devices. In a communal map, these all interact.</p>\\n\\n\\n\\n<p>These ecosystems already exist within a home or office. They are made up of items ranging from refrigerator magnets for displaying physical pictures to a connected TV, and they include personal smartphones. The ecosystem extends to the services that the devices connect to outside the home, and to the other people whom they intermediate. We get an incomplete picture if we don’t consider the entire graph. Adding a new device isn’t about filling a specific gap in the ecosystem. The ecosystem may have many problems or challenges, but the ecosystem isn’t actively seeking to solve them. The new device needs to adapt and find its own <a href=\"https://en.wikipedia.org/wiki/Ecological_niche\">niche</a>. This includes making the ecosystem more beneficial to the device, something that evolutionary biologists call <a href=\"https://royalsocietypublishing.org/doi/10.1098/rspb.2018.2603\">‘niche expansion’</a>. Technologists would think about this as building a need for their services.</p>\\n\\n\\n\\n<p>Thinking about how a device creates a space within an already complex ecosystem is key to understanding what kinds of experiences the team building the device should create. It will help us do things like building for everyone and evolving with the space. It will also help us to avoid the things we should not do, like assuming that every device has to do everything. </p>\\n\\n\\n\\n<h3>Do’s and don’ts of building communal devices</h3>\\n\\n\\n\\n<p>With so much to consider when building communal devices, where do you start? Here are a few do’s and don’ts:</p>\\n\\n\\n\\n<h4><strong>Do user research in the users’ own environment</strong></h4>\\n\\n\\n\\n<p>Studying and understanding expectations and social norms is the key discovery task for building communal devices. Expectations and norms dictate the rules of the environment into which your device needs to fit, including people’s pseudo-identities, their expectations around privacy, and how willing they are to deal with the friction of added security. Just doing a survey isn’t enough.&nbsp; Find people who are willing to let you see how they use these devices in their homes, and ask lots of questions about how they feel about the devices.</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>“If you are going to deal with social, people, communal, community, and general sociability, I would suggest hiring applied anthropologists and/or other social scientists on product teams. These experts will save you time and money, by providing you with more context and understanding of what you are making and its impact on others. This translates into more accurate and useful results.” </p><cite>&#8211; Dr. S.A. Applin</cite></blockquote>\\n\\n\\n\\n<p>Observing where the devices are placed and how the location’s use changes over time will give you fascinating insights about the context in which the device is used. A living room may be a children’s play area in the morning, a home office in the middle of the day, and a guest bedroom at night. People in these contexts have different sets of norms and privacy expectations. </p>\\n\\n\\n\\n<p>As part of the user research, you should be building an ecosystem graph of all people present and the devices that they use. What people not present are intermediated by technology? Are there stories where this intermediation went wrong? Are there frictions that are created between people that your device should address? Are there frictions that the device should get out of the way of?</p>\\n\\n\\n\\n<h4><strong>Do build for everyone who might have access</strong></h4>\\n\\n\\n\\n<p>Don’t focus on the identity of the person who buys and sets up the device. You need to consider the identity (or lack) of everyone who could have access. Consider whether they feel that information collected about them violates their desire to control the information (as in Contextual Integrity). This could mean you need to put up walls to prevent users from doing something sensitive without authorization. Using the Zero Trust framework’s “trust engine” concept, you should ask for the appropriate level of authentication before proceeding.</p>\\n\\n\\n\\n<p>Most of today’s user experience design is focused on making frictionless or seamless experiences. This goal doesn’t make sense when considering a risk tradeoff. In some cases, adding friction increases the chance that a user won’t move forward with a risky action, which could be a good thing. If the potential risk of showing a private picture is high, you should make it harder to show that picture.</p>\\n\\n\\n\\n<p>Realize you may not always understand the right context. Having good and safe default states for those cases is important. It is your job to adjust or simplify the model so that people can understand and interpret why the device does something.</p>\\n\\n\\n\\n<h4><strong>Do consider pseudo-identities for individuals and groups</strong></h4>\\n\\n\\n\\n<p>Avoid singular identities and focus on group pseudo-identities. If users don’t consider these devices their own, why not have the setup experience mirror those expectations? Build device setup, usage, and management around everyone who should have a say in the device’s operation.</p>\\n\\n\\n\\n<p>Pseudo-identities become very interesting when you start to learn what certain behaviors mean for subgroups. Is this music being played for an individual with particular tastes? Or does the choice reflect a compromise between multiple people in the room? Should it avoid explicit language since there are children present?</p>\\n\\n\\n\\n<p>Group norms and relationships need to be made more understandable. It will take technology advances to make these norms more visible. These advances include using machine learning to help the device understand what kind of content it is showing, and who (or what) is depicted in that content. Text, image, and video analysis needs to take place to answer the question: what type of content is this and who is currently in that context? It also means using contextual prediction to consider who may be in the room, their relationship to the people in the content, and how they may feel about the content. When in doubt, restrict what you do.</p>\\n\\n\\n\\n<h4>Do evolve with the space</h4>\\n\\n\\n\\n<p>As time goes on, life events will change the environment in which the device operates. Try to detect those changes and adapt accordingly. New pseudo-identities could be present, or the identity representing the group may shift. It is like moving into a new home. You may set things up in one way only to find months later there is a better configuration. Be aware of these changes and adapt. </p>\\n\\n\\n\\n<p>If behavior that would be considered anomalous becomes the norm, something may have changed about the use of that space. Changes in use are usually led by a change in life–for example, someone moving in or out could trigger a change in how a device is used. Unplugging the device and moving it to a different part of the room or to a different shelf symbolizes a new need for contextual understanding. If you detect a change in the environment but don’t know why the change was made, ask.</p>\\n\\n\\n\\n<h4>Do use behavioral data carefully, or don’t use it at all</h4>\\n\\n\\n\\n<p>All communal devices end up collecting data. For example, Spotify uses what you are listening to when building recommendation systems. When dealing with behavioral information, the group’s identity is important, not the individual’s. If you don’t know who is in front of the device, you should consider whether you can use that behavioral data at all. Rather than using an individual identity, you may want to default to the group pseudo-identity’s recommendations. What does the whole house usually like to listen to? </p>\\n\\n\\n\\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh4.googleusercontent.com/d5DE4zyTjswiJeWQi5q3yPcr-HofP4npTKlkdfa5--24Xm-7wFPZw3NHycMAm_LZP-iWqwh02gfckLqwR94H1Zx_yvRmZItU5aoAibpIP_oUerXLnptSuO5gk8ndg6gUlw\" /><figcaption><br /><br />When the whole family is watching, how do we find a common ground based on all of our preferences, rather than the owner’s? Spotify has a <a href=\"https://www.spotify.com/us/family/\">Premium Family package</a> where each person gets a recommended playlist based on everyone’s listening behavior called a <a href=\"https://support.spotify.com/us/article/family-mix/\">Family Mix</a>, whereas Netflix requires users to choose between individual profiles.</figcaption></figure>\\n\\n\\n\\n<p>Spotify has <a href=\"https://www.spotify.com/us/family/\">family</a> and <a href=\"https://www.spotify.com/us/duo/\">couple</a> accounts that allow multiple people to have an account under one bill. Each person gets their own login and recommendations. Spotify gives all sub-accounts on the subscription access to a shared playlist (like a <a href=\"https://support.spotify.com/us/article/family-mix/\">Family Mix</a>) that makes recommendations based on the group’s preferences.</p>\\n\\n\\n\\n<p>Spotify, and services like it, should go a step further to reduce the weight of a song in their recommendations algorithm when it is being played on a shared device in a communal place–a kitchen, for example. It’s impossible to know everyone who is in a communal space. There’s a strong chance that a song played in a kitchen may not be preferred by anyone that lives there. To give that particular song a lot of weight will start to change recommendations on the group members’ personal devices.</p>\\n\\n\\n\\n<p>If you can’t use behavioral data appropriately, don’t bring it into a user’s profile on your services. You should probably not collect it at all until you can handle the many people who could be using the device. Edge processing can allow a device to build context that respects the many people and their pseudo-identities that are at play in a communal environment. Sometimes it is just safer to not track.</p>\\n\\n\\n\\n<h4>Don’t assume that automation will work in all contexts</h4>\\n\\n\\n\\n<p>Prediction technology helps communal devices by finding behavior patterns. These patterns allow the device to calculate what content should be displayed and the potential trust. If a student always listens to music after school while doing homework, the device can assume that contextual integrity holds if the student is the only person there. These assumptions get problematic when part of the context is no longer understood, like when the student has other classmates over. That’s when violations of norms or of privacy expectations are likely to occur. If other people are around, different content is being requested, or if it is a different time of day, the device may not know enough to predict the correct information to display.</p>\\n\\n\\n\\n<p>Amazon’s Alexa has started wading into these waters with their <a href=\"https://www.theverge.com/2021/1/25/22249044/amazon-alexa-update-proactive-hunches-guard-plus-subscription\">Hunches feature</a>. If you say “good night” to Alexa, it can decide to turn off the lights. What happens if someone is quietly reading in the living room when the lights go out?&nbsp; We’ve all accidentally turned the lights out on a friend or partner, but such mistakes quickly become more serious when they’re made by algorithm.</p>\\n\\n\\n\\n<p>When the prediction algorithm’s confidence is low, it should disengage and try to learn the new behavior. Worst case, just ask the user what is appropriate and gauge the trust vs risk tradeoff accordingly. The more unexpected the context, the less likely it is that the system should presume anything. It should progressively restrict features until it is at its core: for home assistants, that may just mean displaying the current time.</p>\\n\\n\\n\\n<h4>Don’t include all service functionality on the device</h4>\\n\\n\\n\\n<p>All product teams consider what they should add next to make a device “fully functional” and reflect all of the service possibilities. For a communal device, you can’t just think about what you could put there; you also have to consider what you will never put there. An example could be allowing access to Gmail messages from a Google Home Hub. If it doesn’t make sense for most people to have access to some feature, it shouldn’t be there in the first place. It just creates clutter and makes the device harder to use. It is entirely appropriate to allow people to change personal preferences and deal with highly personal information on their own, private devices. There is a time and place for the appropriate content.</p>\\n\\n\\n\\n<p>Amazon has considered whether Echo users should be allowed to complete a purchase, or limit them to just adding items to a shopping list. They have had to add four digit codes and voice profiles. The resulting interface is complex enough to warrant a <a href=\"https://www.amazon.com/gp/help/customer/display.html/ref=hp_left_v4_sib?ie=UTF8&amp;nodeId=GLSQSWPWZMLR3RA5\">top level help article on why people can’t make the purchases</a>.</p>\\n\\n\\n\\n<p>If you have already built too much, think about how to sunset certain features so that the value and differentiator of your device is clearer. Full access to personal data doesn’t work in the communal experience. It is a chance for some unknown privacy violation to occur.</p>\\n\\n\\n\\n<h4>Don’t assume your devices will be the only ones</h4>\\n\\n\\n\\n<p>Never assume that your company’s devices will be the only ones in the space. Even for large companies like Amazon, there is no future in which the refrigerator, oven, and TV will all be Amazon devices (even if they are trying really hard). The communal space is built up over a long time, and devices like refrigerators have lifetimes that <a href=\"https://www.mrappliance.ca/blog/2016/july/what-is-the-lifespan-of-your-refrigerator-/#:~:text=According%20to%20the%2023rd%20annual,life%20expectancy%20of%208%20years.\">can span decades</a>.</p>\\n\\n\\n\\n<p>Think about how your device might work alongside other devices, including personal devices. To do this, you need to integrate with network services (e.g. Google Calendar) or local device services (e.g. Amazon Ring video feed). This is the case for services within a communal space as well. People have different preferences for the services they use to communicate and entertain themselves. For example, Snapchat’s adoption by 13-24 year olds (<a href=\"https://zephoria.com/top-10-valuable-snapchat-statistics/#:~:text=90%20percent%20of%20the%20US,75%20percent%20of%20the%20audience.\">~90% in the US market</a>) accounts for 70% of its usage. This means that people over 24 years old are using very different services to interact with their family and peers.</p>\\n\\n\\n\\n<p>Apple’s iOS has started to realize that apps need to ask for permission before collecting information from other devices on a <a href=\"https://support.apple.com/en-us/HT211870\">local network</a>. It verifies that an app is allowed to access other devices on the network. Local network access is not a foregone conclusion either: different routers and wifi access points are increasingly managed by network providers.</p>\\n\\n\\n\\n<p>Communal device manufacturers must build for interoperability between devices whether they like it or not, taking into account industry standards for communicating state, messaging, and more. A device that isn’t networked with the other devices in the home is much more likely to be replaced when the single, non-networked use is no longer valid or current.</p>\\n\\n\\n\\n<h4>Don’t change the terms without an ‘out’ for owners</h4>\\n\\n\\n\\n<p>Bricking a device because someone doesn’t want to pay for a subscription or doesn’t like the new data use policy is bad. Not only will it create distrust in users but it violates the idea that they are purchasing something for their home.</p>\\n\\n\\n\\n<p>When you need to change terms, allow owners to make a decision about whether they want new functionality or to stop getting updates. Not having an active subscription is no excuse for a device to fail, since devices should be able to work when a home’s WiFi is down or when <a href=\"https://www.theguardian.com/technology/2017/mar/01/amazon-web-services-outage-smart-homes\">AWS has a problem that stops a home’s light bulbs from working</a>. Baseline functionality should always be available, even if leading edge features (for example, features using machine learning) require a subscription. “Smart” or not, there should be no such thing as a light bulb that can’t be turned on.</p>\\n\\n\\n\\n<p>When a company can no longer support a device–either because they’re sunsetting it or, in the worst case, because they are going out of business–they should consider how to allow people to keep using their devices. In some cases, a motivated community can take on the support; this happened with <a href=\"https://www.theverge.com/2019/6/19/18682780/jibo-death-server-update-social-robot-mourning\">the Jibo community when the device creator shut down</a>.</p>\\n\\n\\n\\n<h4>Don’t require personal mobile apps to use the device</h4>\\n\\n\\n\\n<p>One bad limitation that I’ve seen is requiring an app to be installed on the purchaser’s phone, and requiring the purchaser to be logged in to use the device. Identity and security aren’t always necessary, and being too strict about identity tethers the device to a particular person’s phone.</p>\\n\\n\\n\\n<p>The <a href=\"https://www.philips-hue.com/en-us/products/smart-lightbulbs\">Philips Hue</a> smart light bulbs are a way to turn any light fixture into a component in a smart lighting system. However, you need one of their <a href=\"https://www.philips-hue.com/en-us/explore-hue/appshttps://www.philips-hue.com/en-us/explore-hue/apps\">branded apps</a> to control the lightbulbs. If you integrate your lighting system with your Amazon or Google accounts, you still need to know what the bulb or “zone” of your house is called. As a host you end up having to take the action for someone else (say by yelling at your Echo for them) or put a piece of paper in the room with all of the instructions. We are back in the age of overly complicated instructions to turn on a TV and AV system.</p>\\n\\n\\n\\n<p>In addition to making sure you can integrate with other touch and voice interfaces, you need to consider physical ways to allow anyone to interact. IoT power devices like the <a href=\"https://www.amazon.com/Etekcity-Voltson-Outlet-Monitoring-Required/dp/B074GVPYPY\">VeSync Smart Plug by Etekcity</a> (I have a bunch around the house) have a physical button to allow manual switching, in addition to integrating with your smart home or using their branded apps. If you can’t operate the device manually if you are standing in front of it, is it really being built for everyone in the home?</p>\\n\\n\\n\\n<h3>How do you know you got this right? </h3>\\n\\n\\n\\n<p>Once you have implemented all of the recommendations, how do you know you are on the right track? </p>\\n\\n\\n\\n<p>A simple way to figure out whether you are building a communal-friendly device is to look for people adding their profiles to the device. This means linking their accounts to other services like Spotify (if you allow that kind of linking). However, not everyone will want to or be able to add their accounts, especially people who are passing through (guests) or who cannot legally consent (children).</p>\\n\\n\\n\\n<p>Using behavior to detect whether someone else is using the device can be difficult. While people don’t change their taste in music or other interests quickly, they slowly drift through the space of possible options. We seek things that are similar to what we like, but <a href=\"https://medium.com/people-ai-research/just-different-enough-ai-recommendations-newsfeeds-jokes-and-civil-society-c0704bc7a548\">just different enough</a> to be novel. In fact, we see that <a href=\"https://www.nytimes.com/2018/02/10/opinion/sunday/favorite-songs.html\">most of our music tastes are set in our teenage years</a>. Therefore, if a communal device is asked to play songs in a different language or genre whereas a personal device does not, it’s more likely that someone new is listening than that the owner has suddenly learned a new language. Compare what users are doing on your device to their behavior on other platforms (for example, compare a Google Home Hub in the kitchen to a personal iPhone) to determine whether new users are accessing the platform.</p>\\n\\n\\n\\n<p>Behavioral patterns can also be used to predict demographic information. For example, you may be able to predict that someone is a parent based on their usage patterns. If this confidence is high, and you only see their interests showing up in the behavioral data, that means that other people who are around the device are not using it.</p>\\n\\n\\n\\n<p>Don’t forget that you can ask the users themselves about who is likely to use the device. This is information that you can collect during initial setup. This can help ensure you are not making incorrect assumptions about the placement and use of the device.</p>\\n\\n\\n\\n<p>Finally, consider talking with customers about how they use the device, the issues that come up, and how it fits into their lives. Qualitative user research doesn’t end after the initial design phase. You need to be aware of how the device has changed the environment it fits into. Without social scientists you can’t know this.</p>\\n\\n\\n\\n<h4>Is everything a communal experience? </h4>\\n\\n\\n\\n<p>Up until this point we have been talking about devices that are part of the infrastructure of a home, like a smart screen or light switch. Once we realize that technology serves as an intermediary between people, everything is communal.</p>\\n\\n\\n\\n<p>Inside of a home, roommates generally have to share expenses like utilities with each other. Companies like <a href=\"https://www.klarna.com/uk/blog/sharing-your-home-and-money/\">Klarna</a> and <a href=\"https://braid.co/\">Braid</a> make finances communal. How you pay together is an important aspect to harmony within a home.</p>\\n\\n\\n\\n<p>You are also part of communities in your neighborhoods. <a href=\"https://www.wired.com/story/how-amazon-sidewalk-works/\">Amazon Sidewalk</a> extends your devices into the neighborhood you live in. This mesh technology starts to map and extend further with each communal space. Where does your home’s communal space end? If you misplaced your keys a block away, a <a href=\"https://www.amazon.com/stores/Tile/Tile/page/9F8516EE-7F3B-4C96-8287-D795123CF742\">Tile</a> could help you find them. It could also identify people in your neighborhood without considering your neighbors’ privacy expectations.</p>\\n\\n\\n\\n<p>Communities aren’t just based on proximity. We can extend the household to connect with other households far away. Amazon’s <a href=\"https://www.amazon.com/gp/help/customer/display.html/ref=hp_left_v4_sib?ie=UTF8&amp;nodeId=GS3WRTSRKD2U6MCK\">Drop In</a> has started their own calling network between households. <a href=\"https://www.loopfamily.com/\">Loop</a>, a new startup, is focused on building a device for connecting families in their own social network. </p>\\n\\n\\n\\n<p>Google/Alphabet’s <a href=\"https://www.sidewalklabs.com/\">Sidewalk Labs</a> has taken on projects that aim to make the connected world part of the cityscape. An early project called <a href=\"https://en.wikipedia.org/wiki/LinkNYC\">LinkNYC</a> (owned through a shell corporation) was digital signage that included free calling and USB hubs. This changed how homeless people used the built environment. When walking down the street you could see people’s smartphones dangling from a LinkNYC while they were panhandling nearby. Later, a district-wide project called <a href=\"https://www.sidewalktoronto.ca/innovations/public-realm/\">Sidewalk Toronto</a> withdrew their proposal\\xa0rather than it being officially rejected by voters. Every object within the urban environment becomes something that not only collects data but that could be interactive. </p>\\n\\n\\n\\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh4.googleusercontent.com/dtorIpi6uLY6vTojBGIHX0rvi2xZ2a6lYbAuCcNolsN1jiiXYcTk7F4HhoSC0qkf3oYU6UQNtKm6gA_R6VmhCUsjFwps0UUdLEbFM9_sZBNWqKCZJNMWwdX90vxKsqpt2A\" /><figcaption><br />The town square and public park has been built to be welcoming to people and set expectations of what they do there, unlike online social media. <a href=\"https://newpublic.org/\">New Public</a> is taking cues from this type of physical shared space for reimagining the online public square.</figcaption></figure>\\n\\n\\n\\n<p>Taking cues from the real world, groups like <a href=\"https://newpublic.org/signals\">New Public</a> are asking what would happen if we built social media the same way we build public spaces. What if social media followed the norms that we have in social spaces like the public parks or squares?</p>\\n\\n\\n\\n<p>A key aspect to communal computing is the natural limitations of physical and temporal use. Only so many people can fit inside a kitchen or a meeting room. Only so many people can use a device at once, even if it is a subway ticket machine that services millions of people per month. Only so many can fit onto a sidewalk. We need to consider the way that space and time play a part in these experiences.</p>\\n\\n\\n\\n<h3>Adapt or be unplugged</h3>\\n\\n\\n\\n<p>Rethinking how people use devices together inside our homes, offices, and other spaces is key to the future of ubiquitous computing. We have a long way to go in understanding how context changes the expectations and norms of the people in those spaces. Without updating how we design and build these devices, the device you build will just be one more addition to the landfill.</p>\\n\\n\\n\\n<p>To understand how devices are used in these spaces, we need to expand our thinking beyond the single owner and design for communal use from the start. If we don’t, the devices will never fit properly into our shared and intimate spaces. The mismatch between expectations and what is delivered will grow greater and lead to more dire problems.</p>\\n\\n\\n\\n<p>This is a call for change in how we consider devices integrated into our lives. We shouldn’t assume that because humans are adaptive, we can adapt to the technologies built. We should design the technologies to fit into our lives, making sure the devices understand the context in which they’re working. </p>\\n\\n\\n\\n<p>The future of computing that is contextual, is communal.</p>\\n\\n\\n\\n<p>   </p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h3>Thanks</h3>\\n\\n\\n\\n<p>Thanks to Adam Thomas, Mark McCoy, Hugo Bowne-Anderson, and Danny Nou for their thoughts and edits on the early draft of this. Also, Dr. S.A. Applin for all of the great work on PoSR. Finally, from O’Reilly, Mike Loukides for being a great editor and Susan Thompson for the art.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/a-way-forward-with-communal-computing/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Defending against ransomware is all about the basics',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Defending against ransomware is all about the basics'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/defending-against-ransomware-is-all-about-the-basics/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/defending-against-ransomware-is-all-about-the-basics/',\n",
       "   'comments': 'https://www.oreilly.com/radar/defending-against-ransomware-is-all-about-the-basics/#respond',\n",
       "   'published': 'Tue, 10 Aug 2021 12:18:35 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=10, tm_hour=12, tm_min=18, tm_sec=35, tm_wday=1, tm_yday=222, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Column', 'scheme': None, 'label': None},\n",
       "    {'term': 'Security', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13902',\n",
       "   'guidislink': False,\n",
       "   'summary': 'The concept behind ransomware is simple. An attacker plants malware on your system that encrypts all the files, making your system useless, then offers to sell you the key you need to decrypt the files. Payment is usually in bitcoin (BTC), and the decryption key is deleted if you don’t pay within a certain period. [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The concept behind ransomware is simple. An attacker plants malware on your system that encrypts all the files, making your system useless, then offers to sell you the key you need to decrypt the files. Payment is usually in bitcoin (BTC), and the decryption key is deleted if you don’t pay within a certain period. [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>The concept behind ransomware is simple. An attacker plants malware on your system that encrypts all the files, making your system useless, then offers to sell you the key you need to decrypt the files. Payment is usually in bitcoin (BTC), and the decryption key is deleted if you don’t pay within a certain period. Payments have typically been relatively small—though that’s obviously no longer true, with <a href=\"https://www.vox.com/recode/22428774/ransomeware-pipeline-colonial-darkside-gas-prices\">Colonial Pipeline</a>’s multimillion-dollar payout.</p>\\n\\n\\n\\n<p>Recently, ransomware attacks have been coupled with extortion: the malware sends valuable data (for example, a database of credit card numbers) back to the attacker, who then threatens to publish the data online if you don’t comply with the request.&nbsp;&nbsp;</p>\\n\\n\\n\\n<p>A survey on O’Reilly’s website<sup>1</sup> showed that 6% of the respondents worked for organizations that were victims of ransomware attacks. How do you avoid joining them? We’ll have more to say about that, but the tl;dr is simple: pay attention to security basics. Strong passwords, two-factor authentication, defense in depth, staying on top of software updates, good backups, and the ability to restore from backups go a long way. Not only do they protect you from becoming a ransomware victim, but those basics can also help protect you from data theft, cryptojacking, and most other forms of cybercrime. The sad truth is that few organizations practice good security hygiene—and those that don’t end up paying the price.</p>\\n\\n\\n\\n<p>But what about ransomware? Why is it such an issue, and how is it evolving? Historically, ransomware has been a relatively easy way to make money: set up operations in a country that’s not likely to investigate cybercrime, attack targets that are more likely to pay a ransom, keep the ransom small so it’s easier to pay than to restore from backup, and accept payment via some medium that’s perceived as anonymous. Like most things on the internet, ransomware’s advantage is scale: The WannaCry attack infected around 230,000 systems. If even a small percentage paid the US$300 ransom, that’s a lot of money.</p>\\n\\n\\n\\n<p>Early on, attacks focused on small and midsize businesses, which often have limited IT staff and no professional security specialists. But more recently, hospitals, governments, and other organizations with valuable data have been attacked. A modern hospital can’t operate without patient data, so restoring systems is literally a matter of <a href=\"https://hitconsultant.net/2021/01/05/death-by-ransomware-healthcare-cybersecurity/\">life and death</a>. Most recently, we’ve seen attacks against large enterprises, like Colonial Pipeline. And this move toward bigger targets, with more valuable data, has been accompanied by larger ransoms.</p>\\n\\n\\n\\n<p>Attackers have also gotten more sophisticated and <a href=\"https://techxplore.com/news/2021-06-ransomware-dark-webs-cybercriminals-collaborate.html\">specialized</a>. They’ve set up help desks and customer service agents (much like any other company) to help customers make their payments and decrypt their data. Some criminal organizations offer “ransomware as a service,” running attacks for customers. Others develop the software or create the attacks that find victims. Initiating an attack doesn’t require any technical knowledge; it can all be contracted out, and the customer gets a nice dashboard to show the attack’s progress.</p>\\n\\n\\n\\n<p>While it’s easy to believe (and probably correct) that government actors have gotten into the game, it’s important to keep in mind that attribution of an attack is very difficult—not least because of the number of actors involved. An “as a service” operator really doesn’t care who its clients are, and its clients may be (willingly) unaware of exactly what they’re buying. Plausible deniability is also a service.</p>\\n\\n\\n\\n<h3>How an attack begins</h3>\\n\\n\\n\\n<p>Ransomware attacks frequently start with phishing. An email to a victim entices them to open an attachment or to visit a website that installs malware. So the first thing you can do to prevent ransomware attacks is to make sure everyone is aware of phishing, very skeptical of any attachments they receive, and appropriately cautious about the websites they visit. Unfortunately, teaching people how to avoid being victimized by a phish is a battle you’re not likely to win. Phishes are getting increasingly sophisticated and now do a good job of impersonating people the victim knows. <a href=\"https://www.csoonline.com/article/3334617/what-is-spear-phishing-why-targeted-email-attacks-are-so-difficult-to-stop.html\">Spear phishing</a> requires extensive research, and ransomware criminals have typically tried to compromise systems in bulk. But recently, we’ve been seeing attacks against more valuable victims. Larger, more valuable targets, with correspondingly bigger payouts, will merit the investment in research.</p>\\n\\n\\n\\n<p>It’s also possible for an attack to start when a victim visits a legitimate but compromised website. In some cases, an attack can start without any action by the victim. Some ransomware (for example, <a href=\"https://en.wikipedia.org/wiki/WannaCry_ransomware_attack\">WannaCry</a>) can spread directly from computer to computer. One recent attack started through a <a href=\"https://us-cert.cisa.gov/ncas/current-activity/2021/07/02/kaseya-vsa-supply-chain-ransomware-attack\">supply chain compromise</a>: attackers planted the ransomware in an enterprise security product, which was then distributed unwittingly to the product’s customers. Almost any vulnerability can be exploited to plant a ransomware payload on a victim’s device. Keeping browsers up-to-date helps to defend against compromised websites.</p>\\n\\n\\n\\n<p>Most ransomware attacks begin on Windows systems or on mobile phones. This isn’t to imply that macOS, Linux, and other operating systems are less vulnerable; it’s just that other attack vectors are more common. We can guess at some reasons for this. Mobile phones move between different domains, as the owner goes from a coffee shop to home to the office, and are exposed to different networks with different risk factors. Although they are often used in risky territory, they’re rarely subject to the same device management that’s applied to “company” systems—but they’re often accorded the same level of trust. Therefore, it’s relatively easy for a phone to be compromised outside the office and then bring the attacker onto the corporate network when its owner returns to work.</p>\\n\\n\\n\\n<p>It’s possible that Windows systems are common attack vectors just because there are so many of them, particularly in business environments. Many also believe that Windows users install updates less often than macOS and Linux users. Microsoft does a good job of patching vulnerabilities before they can be exploited, but that doesn’t do any good if updates aren’t installed. For example, Microsoft discovered and patched the vulnerability that WannaCry exploited well before the attacks began, but many individuals, and many companies, never installed the updates.</p>\\n\\n\\n\\n<h3>Preparations and precautions</h3>\\n\\n\\n\\n<p>The best defense against ransomware is to be prepared, starting with basic security hygiene. Frankly, this is true of any attack: get the basics right and you’ll have much less to worry about. If you’ve defended yourself against ransomware, you’ve done a lot to defend yourself against data theft, cryptojacking, and many other forms of cybercrime.</p>\\n\\n\\n\\n<p>Security hygiene is simple in concept but hard in practice. It starts with passwords: Users must have nontrivial passwords. And they should never give their password to someone else, whether or not “someone else” is on staff (or claims to be). </p>\\n\\n\\n\\n<p>Two-factor authentication (2FA), which requires something in addition to a password (for example, biometric authentication or a text message sent to a cell phone) is a must. Don’t just recommend 2FA; require it. Too many organizations buy and install the software but never require their staff to use it. (76% of the respondents to our survey said that their company used 2FA; 14% said they weren’t sure.)</p>\\n\\n\\n\\n<p>Users should be aware of phishing and be extremely skeptical of email attachments that they weren’t expecting and websites that they didn’t plan to visit. It’s always a good practice to type URLs in yourself, rather than clicking on links in email—even those in messages that appear to be from friends or associates. Users should be aware of phishing and be extremely skeptical of email attachments that they weren’t expecting and websites that they didn’t plan to visit. It’s always a good practice to type URLs in yourself, rather than clicking on links in email—even those in messages that appear to be from friends or associates.</p>\\n\\n\\n\\n<p>Backups are absolutely essential. But what’s even more important is the ability to restore from a backup. The easiest solution to ransomware is to reformat the disks and restore from backup. Unfortunately, few companies have good backups or the ability to restore from a backup—one security expert guesses that it’s as low as 10%. Here are a few key points:</p>\\n\\n\\n\\n<ul><li>You actually have to do the backups. (Many companies don’t.) Don’t rely solely on cloud storage; backup on physical drives that are disconnected when a backup isn’t in progress. (70% of our survey respondents said that their company performed backups regularly.)</li><li>You have to test the backups to ensure that you can restore the system. If you have a backup but can’t restore, you’re only pretending that you have a backup. (Only 48% of the respondents said that their company regularly practiced restoring from backups; 36% said they didn’t know.)</li><li>The backup device needs to be offline, connected only when a backup is in progress. Otherwise, it’s possible for the ransomware attack to encrypt your backup.</li></ul>\\n\\n\\n\\n<p>Don’t overlook testing your backups. Your business continuity planning should include ransomware scenarios: how do you continue doing business while systems are being restored? Chaos engineering, an approach developed at Netflix, is a good idea. Make a practice of breaking your storage capability, then restoring it from backup. Do this monthly—if possible, schedule it with the product and project management teams. Testing the ability to restore your production systems isn’t just about proving that everything works; it’s about training staff to react calmly in a crisis and resolve the outage efficiently. When something goes bad, you don’t want to be on Stack Overflow asking how to do a restore. You want that knowledge imprinted in everyone’s brains.</p>\\n\\n\\n\\n<p>Keep operating systems and browsers up-to-date. Too many have become victims because of a vulnerability that was patched in a software update that they didn’t install. (79% of our survey respondents said that their company had processes for updating critical software, including browsers.)</p>\\n\\n\\n\\n<p>An important principle in any kind of security is “least privilege.” No person or system should be authorized to do anything it doesn’t need to do. For example, no one outside of HR should have access to the employee database. “Of course,” you say—but that includes the CEO. No one outside of sales should have access to the customer database. And so on. Least privilege works for software too. Services need access to other services—but services must authenticate to each other and should only be able to make requests appropriate to their role. Any unexpected request should be rejected and treated as a signal that the software has been compromised. And least privilege works for hardware, whether virtual or physical: finance systems and servers shouldn’t be able to access HR systems, for example. Ideally, they should be on separate networks. You should have a “defense in depth” security strategy that focuses not only on keeping “bad guys” out of your network but also on limiting where they can go once they’re inside. You want to stop an attack that originates on HR systems from finding its way to the finance systems or some other part of the company. Particularly when you’re dealing with ransomware, making it difficult for an attack to propagate from one system to another is all-important.</p>\\n\\n\\n\\n<p>Attribute-based access control (ABAC) can be seen as an extension of least privilege. ABAC is based on defining policies about exactly who and what should be allowed to access every service: What are the criteria on which trust should be based? And how do these criteria change over time? If a device suddenly moves between networks, does that represent a risk? If a system suddenly makes a request that it has never made before, has it been compromised? At what point should access to services be denied? ABAC, done right, is difficult and requires a lot of human involvement: looking at logs, deciding what kinds of access are appropriate, and keeping policies up-to-date as the situation changes. Working from home is an example of a major change that security people will need to take into account. You might have “trusted” an employee’s laptop, but should you trust it when it’s on the same network as their children? Some of this can be automated, but the bottom line is that you can’t automate security. </p>\\n\\n\\n\\n<p>Finally: detecting a ransomware attack isn’t difficult. If you think about it, this makes a lot of sense: encrypting all your files requires a lot of CPU and filesystem activity, and that’s a red flag. The way files change is also a giveaway. Most unencrypted files have low entropy: they have a high degree of order. (On the simplest level, you can glance at a text file and tell that it’s text. That’s because it has a certain kind of order. Other kinds of files are also ordered, though the order isn’t as apparent to a human.) Encrypted files have high entropy (i.e., they’re very disordered)—they have to be; otherwise, they’d be easy to decrypt. Computing a file’s entropy is simple and for these purposes doesn’t require looking at the entire file. Many security products for desktop and laptop systems are capable of detecting and stopping a ransomware attack. We don’t do product recommendations, but we do recommend that you research the products that are available. (<em>PC Magazine</em>’s 2021 <a href=\"https://www.pcmag.com/picks/the-best-ransomware-protection\">review</a> of ransomware detection products is a good place to start.)</p>\\n\\n\\n\\n<h3>In the data center or the cloud</h3>\\n\\n\\n\\n<p>Detecting ransomware once it has escaped into a data center, whether in the cloud or on-premises, isn’t a fundamentally different task, but commercial products aren’t there yet. Again, prevention is the best defense, and the best defense is strong on the fundamentals. Ransomware makes its way from a desktop to a data center via compromised credentials and operating systems that are unpatched and unprotected. We can’t say this too often: make sure secrets are protected, make sure identity and access management are configured correctly, make sure you have a backup strategy (and that the backups work), and make sure operating systems are patched—zero-trust is your friend.</p>\\n\\n\\n\\n<p>Amazon Web Services, Microsoft Azure, and Google Cloud all have services named “Identity and Access Management” (IAM); the fact that they all converged on the same name tells you something about how important it is. These are the services that configure users, roles, and privileges, and they’re the key to protecting your cloud assets. IAM doesn’t have a reputation for being easy. Nevertheless, it’s something you have to get right; misconfigured IAM is at the root of many cloud vulnerabilities. One <a href=\"https://www.paloaltonetworks.com/blog/2020/10/cloud-iam-misconfiguration-risks/\">report</a> claims that well over 50% of the organizations using Google Cloud were running workloads with administrator privileges. While that report singles out Google, we believe that the same is true at other cloud providers. All of these workloads are at risk; administrator privileges should only be used for essential management tasks. Google Cloud, AWS, Azure, and the other providers give you the tools you need to secure your workloads, but they can’t force you to use them correctly.</p>\\n\\n\\n\\n<p>It’s worth asking your cloud vendor some hard questions. Specifically, what kind of support can your vendor give you if you are a victim of a security breach? What can your vendor do if you lose control of your applications because IAM has been misconfigured? What can your vendor do to restore your data if you succumb to ransomware? Don’t assume that everything in the cloud is “backed up” just because it’s in the cloud. <a href=\"https://aws.amazon.com/backup/?whats-new-cards.sort-by=item.additionalFields.postDateTime&amp;whats-new-cards.sort-order=desc\">AWS</a> and <a href=\"https://docs.microsoft.com/en-us/azure/backup/backup-overview\">Azure</a> offer backup services; <a href=\"https://cloud.google.com/sql/docs/mysql/backup-recovery/backing-up\">Google Cloud</a> offers backup services for SQL databases but doesn’t appear to offer anything comprehensive. Whatever your solution, don’t just assume it works. Make sure that your backups can’t be accessed via the normal paths for accessing your services—that’s the cloud version of “leave your physical backup drives disconnected when not in use.” You don’t want an attacker to find your cloud backups and encrypt them too. And finally, test your backups and practice restoring your data. </p>\\n\\n\\n\\n<p>Any frameworks your IT group has in place for observability will be a big help: Abnormal file activity is always suspicious. Databases that suddenly change in unexpected ways are suspicious. So are services (whether “micro” or “macroscopic”) that suddenly start to fail. If you have built observability into your systems, you’re at least partway there.</p>\\n\\n\\n\\n<p>How confident are you that you can defend against a ransomware attack? In our survey, 60% of the respondents said that they were confident; another 28% said “maybe,” and 12% said “no.” We’d give our respondents good, but not great, marks on readiness (2FA, software updates, and backups). And we’d caution that confidence is good but overconfidence can be fatal. Make sure that your defenses are in place and that those defenses work.</p>\\n\\n\\n\\n<h3>If you become a victim</h3>\\n\\n\\n\\n<p>What do you do? Many organizations just pay. (<a href=\"https://ransomwhe.re/\">Ransomwhe.re</a> tracks total payments to ransomware sites, currently estimated at $92,120,383.83.) The FBI says that you shouldn’t pay, but if you don’t have the ability to restore your systems from backups, you might not have an alternative. Although the FBI was able to recover the ransom paid by Colonial Pipeline, I don’t think there’s any case in which they’ve been able to recover decryption keys.</p>\\n\\n\\n\\n<p>Whether paying the ransom is a good option depends on how much you trust the cybercriminals responsible for the attack. The common wisdom is that ransomware attackers are trustworthy, that they’ll give you the key you need to decrypt your data and even help you use it correctly. If the word gets out that they can’t be trusted to restore your systems, they’ll find fewer victims willing to pay up. However, at least one security vendor says that 40% of ransomware victims who pay <a href=\"https://www.acronis.com/en-us/articles/what-is-ransomware/\">never get their files restored</a>. That’s a very big “however,” and a very big risk—especially as ransomware demands skyrocket. Criminals are, after all, criminals. It’s all the more reason to have good backups.</p>\\n\\n\\n\\n<p>There’s another reason not to pay that may be more important. Ransomware is a big business, and like any business, it will continue to exist as long as it’s profitable. Paying your attackers might be an easy solution short-term, but you’re just setting up the next victim. We need to protect each other, and the best way to do that is to make ransomware less profitable.</p>\\n\\n\\n\\n<p>Another problem that victims face is extortion. If the attackers steal your data in addition to encrypting it, they can demand money not to publish your confidential data online—which may leave you with substantial penalties for exposing private data under laws such as GDPR and CCPA. This secondary attack is becoming increasingly common.</p>\\n\\n\\n\\n<p>Whether or not they pay, ransomware victims frequently face revictimization because they never fix the vulnerability that allowed the ransomware in the first place. So they pay the ransom, and a few months later, they’re attacked again, using the same vulnerability. The attack may come from the same people or it may come from someone else. Like any other business, an attacker wants to maximize its profits, and that might mean selling the information they used to compromise your systems to other ransomware outfits. If you become a victim, take that as a very serious warning. Don’t think that the story is over when you’ve restored your systems. </p>\\n\\n\\n\\n<p>Here’s the bottom line, whether or not you pay. If you become a victim of ransomware, figure out how the ransomware got in and plug those holes. We began this article by talking about basic security practices. Keep your software up-to-date. Use two-factor authentication. Implement defense in depth wherever possible. Design zero-trust into your applications. And above all, get serious about backups and practice restoring from backup regularly. You don’t want to become a victim again. </p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<p><em>Thanks to John Viega, Dean Bushmiller, Ronald Eddings, and Matthew Kirk for their help. Any errors or misunderstandings are, of course, mine.</em></p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h3>Footnote</h3>\\n\\n\\n\\n<ol><li>The survey ran July 21, 2021, through July 23, 2021, and received more than 700 responses.</li></ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/defending-against-ransomware-is-all-about-the-basics/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: August 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: August 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2021/#respond',\n",
       "   'published': 'Mon, 02 Aug 2021 14:27:43 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=8, tm_mday=2, tm_hour=14, tm_min=27, tm_sec=43, tm_wday=0, tm_yday=214, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13892',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Security continues to be in the news: most notably the Kaseya ransomware attack, which was the first case of a supply chain ransomware attack that we’re aware of. That’s new and very dangerous territory. However, the biggest problem in security remains simple: take care of the basics. Good practices for authentication, backups, and software updates [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Security continues to be in the news: most notably the Kaseya ransomware attack, which was the first case of a supply chain ransomware attack that we’re aware of. That’s new and very dangerous territory. However, the biggest problem in security remains simple: take care of the basics. Good practices for authentication, backups, and software updates [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Security continues to be in the news: most notably the Kaseya ransomware attack, which was the first case of a supply chain ransomware attack that we’re aware of. That’s new and very dangerous territory. However, the biggest problem in security remains simple: take care of the basics. Good practices for authentication, backups, and software updates are the best defense against ransomware and many other attacks.</p>\\n\\n\\n\\n<p>Facebook has said that it is now focusing on building the virtual reality Metaverse, which will be the successor to the web. To succeed, VR will have to get beyond ultra geeky goggles. But Google Glass showed the way, and that path is being followed by Apple and Facebook in their product development. </p>\\n\\n\\n\\n<h2>AI and Data</h2>\\n\\n\\n\\n<ul><li>There’s a new technique for protecting natural language systems from attack by misinformation and malware bots: using <a href=\"https://techxplore.com/news/2021-07-honeypot-technique-natural-language.html\">honeypots</a> to capture attackers’ key phrases proactively, and incorporate defenses into the training process.<br /></li><li>DeepMind’s AlphaFold has made major breakthroughs in protein folding. DeepMind has released the source code for AlphaCode 2.0 on <a href=\"https://github.com/deepmind/alphafold\">GitHub</a>. DeepMind will also <a href=\"https://www.technologyreview.com/2021/07/22/1029973/deepmind-alphafold-protein-folding-biology-disease-drugs-proteome/\">release</a> the structure of every known protein. The database currently includes over 350,000 protein structures, but is expected to grow to over 100,000,000. This is of immense importance to research in biology and medicine.<br /></li><li>Google searches can now tell you <a href=\"https://blog.google/products/search/learn-more-and-get-more-from-search/\">why</a> a given result was included. It’s a minor change, but we’ve long argued that in AI, “why” may give you more information than “what.”<br /></li><li>Researchers have been able to <a href=\"https://www.nytimes.com/2021/07/14/health/speech-brain-implant-computer.html?referringSource=articleShare\">synthesize speech</a> using the brainwaves of a patient who has been paralyzed and unable to talk. The process combines brain wave detection with models that predict the next word.<br /></li><li>The National Institute of Standards (NIST) tests systems for <a href=\"https://techxplore.com/news/2021-07-nist-recognition-software-accuracy-flight.html\">identifying airline passengers</a> for flight boarding.\\xa0 They claim that they have achieved 99.87% accuracy, without significant differences in performance between different demographic groups.<br /></li><li>An attempt at adding <a href=\"https://techxplore.com/news/2021-07-enabling-artificial-intelligence.html\">imagination</a> to AI works has been made by combining different attributes of known objects. Humans are good at this: we can imagine a green dog, for example.<br /></li><li><a href=\"https://www.quantamagazine.org/a-new-kind-of-information-coding-seen-in-the-human-brain-20210707/\">Phase precession</a> is a recently discovered phenomenon by which neurons encode information in the timing of their firing.\\xa0 It may relate to humans’ ability to learn on the basis of a small number of examples. <br /></li><li>Yoshua Bengio, Geoff Hinton, and Yann LeCun give an <a href=\"https://thenextweb.com/news/pioneers-deep-learning-future-lit-syndication\">assessment</a> of the state of Deep Learning, its future, and its ability to solve problems.<br /></li><li>AI is learning to <a href=\"https://techxplore.com/news/2021-06-ai-human-behavior-videos.html\">predict human behavior</a> from videos (e.g., movies). This research attempts to answer the question “What will someone do next?” in situations where there are large uncertainties. One trick is reverting to high-level concepts (e.g., “greet”) when the system can’t predict more specific behaviors (e.g., “shake hands”). </li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li><a href=\"https://jax.readthedocs.io/en/latest/notebooks/quickstart.html\">JAX</a> is a new Python library for high-performance mathematics. It includes a just-in-time compiler, support for GPUs and TPUs, automatic differentiation, and automatic vectorization and parallelization.<br /></li><li><a href=\"https://matrix.org/\">Matrix</a> is an open standard for a decentralized “conversation store” that is used as the background for many other kinds of applications. Germany has <a href=\"https://matrix.org/blog/2021/07/21/germanys-national-healthcare-system-adopts-matrix\">announced</a> that it will use Matrix as the standard for digital messaging in its national electronic health records system.<br /></li><li><a href=\"https://github.com/brython-dev/brython\">Brython</a> is Python 3.9.5 running in the browser, with access to the DOM.\\xa0 It’s not a replacement for JavaScript, but there are a lot of clever things you can do with it.<br /></li><li>Using a terminal well has always been a superpower. <a href=\"https://www.warp.dev/\">Warp</a> is a new terminal emulator built in Rust with features that you’d never expect: command sharing, long-term cloud-based history, a true text editor, and a lot more.<br /></li><li>Is it <a href=\"https://thenewstack.io/what-is-webassembly/\">WebAssembly</a>’s time? Probably not yet, but it’s coming. <a href=\"https://krustlet.dev/\">Krustlets</a> allow you to run WebAssembly workloads under Kubernetes. There is also an alternative to a <a href=\"https://thenewstack.io/webassembly-aims-to-eliminate-the-file-system/\">filesystem</a> written in wasm; <a href=\"https://blog.jupyter.org/jupyterlite-jupyter-%EF%B8%8F-webassembly-%EF%B8%8F-python-f6e2e41ab3fa\">JupyterLite</a> is an attempt to build a complete distribution of Jupyter, including JupyterLab, that runs entirely in the browser.</li></ul>\\n\\n\\n\\n<h2>Robotics</h2>\\n\\n\\n\\n<ul><li>Google launches <a href=\"https://techxplore.com/news/2021-07-google-parent-moonshot-robotics-software.html\">Intrinsic</a>, a moonshot project to develop industrial robots.<br /></li><li>21st Century Problems: should <a href=\"https://www.houstonpublicmedia.org/articles/news/transportation/2021/06/24/401460/austin-cyclists-split-on-sharing-bike-lanes-with-pizza-delivery-robots/\">autonomous delivery robots</a> be allowed in bike lanes? The Austin (Texas) City Council already has to consider this issue.</li></ul>\\n\\n\\n\\n<h2>Materials</h2>\\n\\n\\n\\n<ul><li>Veins in materials? Researchers have greatly reduced the time it takes to build <a href=\"https://techxplore.com/news/2021-07-breakthrough-technique-smart-tech.html\">vascular systems</a> into materials, which could have an important impact on our ability to build self-healing structures.<br /></li><li>Researchers have designed <a href=\"https://www.sciencemag.org/news/2021/07/new-mirror-fabric-can-cool-wearers-nearly-5-c\">fabrics</a> that can cool the body by up to 5 degrees Celsius by absorbing heat and re-emitting it in the near-infrared range.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li>A <a href=\"https://arstechnica.com/science/2021/07/researchers-build-a-bendable-arm-processor-dont-bother-to-bend-it/\">bendable</a> processor from ARM could be the future of wearable computing. It’s far from a state-of-the-art CPU, and probably will never be one, but with further development could be useful in edge applications that require flexibility.<br /></li><li>Google experiments with <a href=\"https://arstechnica.com/science/2021/07/google-tries-out-error-correction-on-its-quantum-processor/\">error correction</a> for quantum computers.\\xa0 Developing error correction is a necessary step towards making quantum computers “real.”</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Attackers have learned to scan repos like GitHub to find private keys and other credentials that have inadvertently been left in code that has been checked in. <a href=\"https://bridgecrew.io/blog/checkov-secrets-scanning-find-exposed-credentials-in-iac/\">Checkov</a>, a code analysis tool for detecting vulnerabilities in cloud infrastructure, can now can find these credentials in code.<br /></li><li>Amnesty International has <a href=\"https://thenextweb.com/news/oh-great-now-ive-gotta-check-my-phone-for-pegasus-spyware\">released</a> an <a href=\"https://github.com/mvt-project/mvt\">open source tool</a> for checking whether a phone has been compromised by Pegasus, the spyware sold by the NSO group to many governments, and used (among other things) to track journalists. Matthew Green’s perspective on “<a href=\"https://blog.cryptographyengineering.com/2021/07/20/a-case-against-security-nihilism/\">security nihilism</a>” discusses the NSO’s activity; it is a must-read.<br /></li><li>The REvil ransomware gang (among other things, responsible for the Kaseya attack, which infected over 1,000 businesses) has <a href=\"https://www.technologyreview.com/2021/07/13/1028431/worlds-biggest-ransomware-gang-disappeared-us-russia/\">disappeared</a>; all of its web sites went down at the same time. Nobody knows why; possibilities include pressure from law enforcement, reorganization, and even retirement.<br /></li><li><a href=\"https://thenewstack.io/did-you-hear-decentralized-identifiers-are-coming/\">DID</a> is a new proposed form of decentralized digital identity that is currently being tested in the travel passports with COVID data being developed by the International Air Transport Association.<br /></li><li>A massive <a href=\"https://arstechnica.com/gadgets/2021/07/up-to-1500-businesses-infected-in-one-of-the-worst-ransomware-attacks-ever/\">ransomware attack</a> by the REvil cybercrime group exploited supply chain vulnerabilities. The payload was implanted in a security product by <a href=\"https://www.kaseya.com/\">Kaseya</a> that is used to automate software installation and updates. The attack apparently only affects on-premises infrastructure. Victims are worldwide; the number of victims is in the “low thousands.”<br /></li><li>Kubernetes is being used by the FancyBear cybercrime group, and other groups associated with the Russian government, to orchestrate a <a href=\"https://therecord.media/fbi-nsa-russian-military-cyber-unit-behind-large-scale-brute-force-attacks/\">worldwide wave of brute-force attacks</a> aimed at data theft and credential stealing.</li></ul>\\n\\n\\n\\n<h2>Operations</h2>\\n\\n\\n\\n<ul><li><a href=\"https://aparnadhinak.medium.com/beyond-monitoring-the-rise-of-observability-c53bdc1d2e0b\">Observability</a> is the next step beyond monitoring.\\xa0 That applies to data and machine learning, too, and is part of incorporating ML into production processes.<br /></li><li>A new <a href=\"https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed\">load balancing</a> algorithm does a much better job of managing load at datacenters, and <a href=\"https://techxplore.com/news/2021-07-aims-servers-worldwide-climate-friendly.html\">reduces power consumption</a> by allowing servers to be shut down when not in use.<br /></li><li><a href=\"https://microk8s.io/high-availability\">MicroK8S</a> is a version of Kubernetes designed for small clusters that claims to be fault tolerant and self-healing, requiring <a href=\"https://thenewstack.io/kelsey-hightower-canonicals-mark-shuttleworth-on-the-linux-inflection-point/\">little administration</a>. <br /></li><li><a href=\"https://thenewstack.io/install-calico-to-enhance-kubernetes-built-in-networking-capability/\">Calico</a> is a Kubernetes plugin that simplifies network configuration.\\xa0</li></ul>\\n\\n\\n\\n<h2>Web and Mobile</h2>\\n\\n\\n\\n<ul><li>Scuttlebutt is a protocol for the decentralized web that’s “<a href=\"https://thenewstack.io/scuttlebutt-decentralize-and-escape-the-social-media-rat-race/\">a way out of the social media rat race</a>.”\\xa0 It’s (by definition) “sometimes on,” not a constant presence. <br /></li><li><a href=\"https://storywrangling.org/\">Storywrangler</a> is a tool for analyzing Twitter at scale.\\xa0 It picks out the most popular word combinations in a large number of languages.<br /></li><li>Google is adding <a href=\"https://www.theregister.com/2021/07/02/google_android_vaccine_passport/\">support</a> for “COVID vaccination passports” to Android devices.<br /></li><li>Tim Berners-Lee’s Solid protocol <a href=\"https://thenewstack.io/sir-tim-berners-lees-solid-protocol-puts-data-back-in-the-control-of-the-end-user/\">appears to be getting real</a>, with a small ecosystem of pod providers (online data stores) and apps.<br /></li><li>Why are Apple and Google interested in autonomous vehicles? What’s the <a href=\"https://techxplore.com/news/2021-06-apple-car-obsession-eyes-road.html\">business model</a>? They are after the last few minutes of attention. If you aren’t driving, you’ll be in an app.</li></ul>\\n\\n\\n\\n<h2>Virtual Reality</h2>\\n\\n\\n\\n<ul><li>Mark Zuckerberg has been talking up the <a href=\"https://techxplore.com/news/2021-07-metaverse-internet-revolution.html\">Metaverse</a> as the next stage in the Internet’s evolution: a replacement for the Web as an AR/VR world. But who will want to live in Facebook’s world?<br /></li><li>Facebook is <a href=\"https://uploadvr.com/facebook-deprecates-oculus/\">committing to the OpenXR</a> standard for its Virtual Reality products. In August 2022, all new applications will be required to use OpenXR; its proprietary APIs will be deprecated.</li></ul>\\n\\n\\n\\n<h2>Miscellaneous</h2>\\n\\n\\n\\n<ul><li>The <a href=\"https://openvoicenetwork.org/\">Open Voice Network</a> is an <a href=\"https://arstechnica.com/gadgets/2021/06/the-linux-foundation-is-working-to-improve-voice-recognition-ethics/\">industry association</a> organized by the Linux Foundation that is dedicated to ethics in voice-driven applications. Their goal is to close the “trust gap” in voice applications.</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-august-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Communal Computing’s Many Problems',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Communal Computing’s Many Problems'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/communal-computings-many-problems/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/communal-computings-many-problems/',\n",
       "   'comments': 'https://www.oreilly.com/radar/communal-computings-many-problems/#respond',\n",
       "   'published': 'Tue, 20 Jul 2021 11:37:15 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=20, tm_hour=11, tm_min=37, tm_sec=15, tm_wday=1, tm_yday=201, tm_isdst=0),\n",
       "   'authors': [{'name': 'Chris Butler'}],\n",
       "   'author': 'Chris Butler',\n",
       "   'author_detail': {'name': 'Chris Butler'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Artificial Intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'Software Engineering', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13876',\n",
       "   'guidislink': False,\n",
       "   'summary': 'In the first article of this series, we discussed communal computing devices and the problems they create–or, more precisely, the problems that arise because we don’t really understand what “communal” means. Communal devices are intended to be used by groups of people in homes and offices. Examples include popular home assistants and smart displays like [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'In the first article of this series, we discussed communal computing devices and the problems they create–or, more precisely, the problems that arise because we don’t really understand what “communal” means. Communal devices are intended to be used by groups of people in homes and offices. Examples include popular home assistants and smart displays like [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>In the <a href=\"https://www.oreilly.com/radar/communal-computing/\">first article</a> of this series, we discussed communal computing devices and the problems they create–or, more precisely, the problems that arise because we don’t really understand what “communal” means. Communal devices are intended to be used by groups of people in homes and offices. Examples include popular home assistants and smart displays like the Amazon Echo, Google Home, Apple HomePod, and many others.&nbsp; If we don’t create these devices with communities of people in mind, we will continue to build the wrong ones.</p>\\n\\n\\n\\n<p>Ever since the concept of a “user” was invented (which was probably later than you think), we’ve assumed that devices are “owned” by a single user. Someone buys the device and sets up the account; it’s their device, their account.&nbsp; When we’re building shared devices with a user model, that model quickly runs into limitations. What happens when you want your home assistant to play music for a dinner party, but your preferences have been skewed by your children’s listening habits? We, as users, have certain expectations for what a device should do. But we, as technologists, have typically ignored our own expectations when designing and building those devices.</p>\\n\\n\\n\\n<p>This expectation isn’t a new one either. The telephone in the kitchen was for everyone’s use. After the release of the iPad in 2010 <a href=\"https://furbo.org/2010/04/29/communal-computing/\">Craig Hockenberry discussed the great value of communal computing but also the concerns</a>:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>“When you pass it around, you’re giving everyone who touches it the opportunity to mess with your private life, whether intentionally or not. That makes me uneasy.”</p></blockquote>\\n\\n\\n\\n<p>Communal computing requires a new mindset that takes into account users’ expectations. If the devices aren’t designed with those expectations in mind, they’re destined for the landfill. Users will eventually experience “weirdness” and “annoyance” that grows to distrust of the device itself. As technologists, we often call these weirdnesses “edge cases.” That’s precisely where we’re wrong: they’re not edge cases, but they’re at the core of how people want to use these devices.</p>\\n\\n\\n\\n<p>In the first article, we listed five core questions we should ask about communal devices:</p>\\n\\n\\n\\n<ol><li>Identity: Do we know all of the people who are using the device?</li><li>Privacy: Are we exposing (or hiding) the right content for all of the people with access?</li><li>Security: Are we allowing all of the people using the device to do or see what they should and are we protecting the content from people that shouldn’t?</li><li>Experience: What is the contextually appropriate display or next action?</li><li>Ownership: Who owns all of the data and services attached to the device that multiple people are using?</li></ol>\\n\\n\\n\\n<p>In this article, we’ll take a deeper look at these questions, to see how the problems manifest and how to understand them.</p>\\n\\n\\n\\n<h2>Identity</h2>\\n\\n\\n\\n<p>All of the problems we’ve listed start with the idea that there is one registered and known person who should use the device. That model doesn’t fit reality: the identity of a communal device isn’t a single person, but everyone who can interact with it. This could be anyone able to tap the screen, make a voice command, use a remote, or simply be sensed by it. To understand this communal model and the problems it poses, start with the person who buys and sets up the device. It is associated with that individual’s account, like a personal Amazon account with its order history and shopping list. Then it gets difficult. Who doesn&#8217;t, can’t, or shouldn’t have full access to an Amazon account? Do you want everyone who comes into your house to be able to add something to your shopping list?</p>\\n\\n\\n\\n<p>If you think about the spectrum of people who could be in your house, they range from people whom you trust, to people who you don’t really trust but who should be there, to those who you&nbsp; shouldn’t trust at all.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13877\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/07/trust-1048x387.png\" /><figcaption><br />There is a spectrum of trust for people who have access to communal devices</figcaption></figure>\\n\\n\\n\\n<p>In addition to individuals, we need to consider the groups that each person could be part of. These group memberships are called “pseudo-identities”; they are facets of a person’s full identity. They are usually defined by how the person associated themself with a group of other people. My life at work, home, a high school friends group, and as a sports fan show different parts of my identity. When I’m with other people who share the same pseudo-identity, we can share information. When there are people from one group in front of a device I may avoid showing content that is associated with another group (or another personal pseudo-identity). This can sound abstract, but it isn’t; if you’re with friends in a sports bar, you probably want notifications about the teams you follow. You probably don’t want news about work, unless it’s an emergency.</p>\\n\\n\\n\\n<p>There are important reasons why we show a particular facet of our identity in a particular context. When designing an experience, you need to consider the identity context and where the experience will take place. Most recently this has come up with work from home. Many people talk about ‘<a href=\"https://mike-robbins.com/tedxberkeley/\">bringing your whole self to work</a>,’ but don&#8217;t realize that “your whole self” isn’t always appropriate. Remote work changes when and where I should interact with work. For a smart screen in my kitchen, it is appropriate to have content that is related to my home and family. Is it appropriate to have all of my work notifications and meetings there? Could it be a problem for children to have the ability to join my work calls? What does my IT group require as far as security of work devices versus personal home devices?</p>\\n\\n\\n\\n<p>With these devices we may need to switch to a different pseudo-identity to get something done. I may need to be reminded of a work meeting. When I get a notification from a close friend, I need to decide whether it is appropriate to respond based on the other people around me.</p>\\n\\n\\n\\n<p>The pandemic has broken down the barriers between home and work. The natural context switch from being at work and worrying about work things and then going home to worry about home things is no longer the case. People need to make a conscious effort to “turn off work” and to change the context. Just because it is the middle of the workday doesn’t always mean I want to be bothered by work. I may want to change contexts to take a break. Such context shifts add nuance to the way the current pseudo-identity should be considered, and to the overarching context you need to detect.</p>\\n\\n\\n\\n<p>Next, we need to consider identities as groups that I belong to. I’m part of my family, and my family would potentially want to talk with other families. I live in a house that is on my street alongside other neighbors. I’m part of an organization that I identify as my work. These are all pseudo-identities we should consider, based on where the device is placed and in relation to other equally important identities.</p>\\n\\n\\n\\n<p>The crux of the problem with communal devices is the multiple identities that are or may be using the device. This requires greater understanding of who, where, and why people are using the device. We need to consider the types of groups that are part of the home and office.</p>\\n\\n\\n\\n<h2>Privacy </h2>\\n\\n\\n\\n<p>As we consider the identities of all people with access to the device, and the identity of the place the device is to be part of, we start to consider what privacy expectations people may have given the context in which the device is used.</p>\\n\\n\\n\\n<p>Privacy is hard to understand. The framework I’ve found most helpful is <a href=\"https://en.wikipedia.org/wiki/Contextual_Integrity\">Contextual Integrity</a> which was introduced by Helen Nissenbaum in the book <a href=\"https://www.amazon.com/Privacy-Context-Technology-Policy-Integrity/dp/0804752370\">Privacy in Context</a>. Contextual Integrity describes four key aspects of privacy:</p>\\n\\n\\n\\n<ol><li>Privacy is provided by appropriate flows of information.</li><li>Appropriate information flows are those that conform to contextual information norms.</li><li>Contextual informational norms refer to five independent parameters: data subject, sender, recipient, information type, and transmission principle.</li><li>Conceptions of privacy are based on ethical concerns that evolve over time.</li></ol>\\n\\n\\n\\n<p>What is most important about Contextual Integrity is that privacy is not about hiding information away from the public but giving people a way to control the flow of their own information. The context in which information is shared determines what is appropriate.</p>\\n\\n\\n\\n<p>This flow either feels appropriate, or not, based on key characteristics of the information (<a href=\"https://en.wikipedia.org/wiki/Contextual_Integrity#Contextual_Integrity%E2%80%99s_Parameters\">from Wikipedia</a>):</p>\\n\\n\\n\\n<ol><li>The data subject: Who or what is this about?</li><li>The sender of the data: Who is sending it?</li><li>The recipient of the data: Who will eventually see or get the data?</li><li>The information type: What type of information is this (e.g. a photo, text)?</li><li>The transmission principle: In what set of norms is this being shared (e.g. school, medical, personal communication)?</li></ol>\\n\\n\\n\\n<p>We rarely acknowledge how a subtle change in one of these parameters could be a violation of privacy. It may be completely acceptable for my friend to have a weird photo of me, but once it gets posted on a company intranet site it violates how I want information (a photo) to flow. The recipient of the data has changed to something I no longer find acceptable. But I might not care whether a complete stranger (like a burglar) sees the photo, as long as it never gets back to someone I know.</p>\\n\\n\\n\\n<p>For communal use cases, the sender or receiver of information is often a group. There may be&nbsp; multiple people in the room during a video call, not just the person you are calling. People can walk in and out. I might be happy with some people in my home seeing a particular photo, but find it embarrassing if it is shown to guests at a dinner party.</p>\\n\\n\\n\\n<p>We must also consider what happens when other people’s content is shown to those who shouldn’t see it. This content could be photos or notifications from people outside the communal space that could be seen by anyone in front of the device. Smartphones can hide message contents when you aren’t near your phone for this exact reason.</p>\\n\\n\\n\\n<p>The services themselves can expand the ‘receivers’ of information in ways that create uncomfortable situations. In Privacy in Context, Nissenbaum talks about <a href=\"https://en.wikipedia.org/wiki/Google_Street_View_privacy_concerns\">the privacy implications of Google Street View when it places photos of people’s houses</a> on Google Maps. When a house was only visible to people who walked down the street that was one thing, but when anyone in the world can access a picture of a house, that changes the parameters in a way that causes concern. Most recently, <a href=\"https://www.theverge.com/2019/3/12/18262646/ibm-didnt-inform-people-when-it-used-their-flickr-photos-for-facial-recognition-training\">IBM used Flickr photos that were shared under a Creative Commons license to train facial recognition algorithms</a>. While this didn’t require any change to terms of the service it was a surprise to people and may be in violation of the Creative Commons license. In the end, IBM took the dataset down.</p>\\n\\n\\n\\n<p>Privacy considerations for communal devices should focus on who is gaining access to information and whether it is appropriate based on people’s expectations. Without using a framework like contextual inquiry we will be stuck talking about generalized rules for data sharing, and there will always be edge cases that violate someone’s privacy.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<h5>A note about children</h5>\\n\\n\\n\\n<p class=\"has-background has-very-light-gray-background-color\">Children make identity and privacy especially tricky. <a href=\"https://www.statista.com/statistics/242074/percentages-of-us-family-households-with-children-by-type/#statisticContainer\">About 40% of all households</a> have a child. Children shouldn’t be an afterthought. If you aren’t compliant with local laws you can get in a lot of trouble. In 2019, <a href=\"https://arstechnica.com/tech-policy/2019/09/youtube-fined-170-million-for-violations-of-childrens-privacy/\">YouTube had to settle with the FTC</a> for a $170 million fine for selling ads targeting children. It gets complicated because the ‘age of consent’ depends on the region as well: <a href=\"https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule\">COPPA in the US is for people under 13 years old</a>, <a href=\"https://www.clarip.com/data-privacy/ccpa-kids-consent/\">CCPA in California is for people under 16</a>, and <a href=\"https://www.privo.com/blog/gdpr-age-of-digital-consent\">GDPR overall is under 16 years old but each member state can set its own</a>. The moment you acknowledge children are using your platforms, you need to accommodate them.</p>\\n\\n\\n\\n<p class=\"has-background has-very-light-gray-background-color\">For communal devices, there are many use cases for children. Once they realize they can play whatever music they want (including tracks of fart sounds) on a shared device they will do it. Children focus on the <a href=\"https://www.sciencedaily.com/releases/2020/08/200812153637.htm\">exploration over the task</a> and will end up discovering way more about the device than parents might. Adjusting your practices after building a device is a recipe for failure. You will find that the paradigms you choose for other parties won’t align with the expectations for children, and modifying your software to accommodate children is difficult or impossible. It’s important to account for children from the beginning.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n</div></div>\\n\\n\\n\\n<h2>Security </h2>\\n\\n\\n\\n<p>To get to a home assistant, you usually need to pass through a home’s outer door. There is usually a physical limitation by way of a lock. There may be alarm systems. Finally, there are social norms: you don’t just walk into someone else’s house without knocking or being invited.</p>\\n\\n\\n\\n<p>Once you are past all of these locks, alarms, and norms, anyone can access the communal device. Few things within a home are restricted–possibly a safe with important documents. When a communal device requires authentication, it is usually subverted in some way for convenience: for example, a password might be taped to it, or a password may never have been set.</p>\\n\\n\\n\\n<p>The concept of <a href=\"https://www.amazon.com/Zero-Trust-Networks-Building-Untrusted/dp/1491962194\">Zero Trust Networks</a> speaks to this problem. It comes down to a key question: is the risk associated with an action greater than the trust we have that the person performing the action is who they say they are?</p>\\n\\n\\n\\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh3.googleusercontent.com/oIE9EerVy1LX6be50IEGWVshKMNJV47fbOCgQ2n7kHTkmZgEISlRx5t6dmzjDxldR1XlDpaDMFiMFp7rnKnTV3T1RyNXBerEUx9QOy7VsKqfSqbRcIssbDbOfl9yfhwJpmrb3cvv\" /><figcaption><br />Source: <a href=\"https://learning.oreilly.com/library/view/zero-trust-networks/9781491962183/\">https://learning.oreilly.com/library/view/zero-trust-networks/9781491962183/</a> </figcaption></figure>\\n\\n\\n\\n<p>Passwords, passcodes, or mobile device authentication become nuisances; these supposed secrets are frequently shared between everyone who has access to the device. Passwords might be written down for people who can’t remember them, making them visible to less trusted people visiting your household. Have we not learned anything since the movie <a href=\"https://www.youtube.com/watch?v=_UqEg1cFqig\">War Games</a>?</p>\\n\\n\\n\\n<p>When we consider the risk associated with an action, we need to understand its privacy implications. Would the action expose someone’s information without their knowledge? Would it allow a person to pretend to be someone else? Could another party tell easily the device was being used by an imposter?</p>\\n\\n\\n\\n<p>There is a tradeoff between the trust and risk. The device needs to calculate whether we know who the person is and whether the person wants the information to be shown. That needs to be weighed against the potential risk or harm if an inappropriate person is in front of the device.</p>\\n\\n\\n\\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh5.googleusercontent.com/HS9D_BfERJDalfgZqmP54N9LcJNKB9jsfciGJGjHwwY01hMgMDs6p4Hrivp-nUmtMbLuoiTX1MxGwBKbLRfqvpCiHeou88dgaV7MRpv1cU852iH75aFunOMRY7amt1-6nEbGJxNS\" /><figcaption><br />Having someone in your home accidentally share embarrassing photos could have social implications.</figcaption></figure>\\n\\n\\n\\n<p>A few examples of this tradeoff:</p>\\n\\n\\n\\n<figure class=\"wp-block-table\"><table class=\"\"><tbody><tr><td><strong>Feature</strong></td><td><strong>Risk and trust calculation</strong></td><td><strong>Possible issues</strong></td></tr><tr><td>Showing a photo when the device detects someone in the room</td><td>Photo content sensitivity, who is in the room&nbsp;</td><td>Showing an inappropriate photo to a complete stranger</td></tr><tr><td>Starting a video call</td><td>Person’s account being used for the call, the actual person starting the call</td><td>When the other side picks up it may not be who they thought it would be</td></tr><tr><td>Playing a personal song playlist</td><td>Personal recommendations being impacted</td><td>Incorrect future recommendations</td></tr><tr><td>Automatically ordering something based on a voice command</td><td>Convenience of ordering, approval of the shopping account’s owner</td><td>Shipping an item that shouldn’t have been ordered</td></tr></tbody></table></figure>\\n\\n\\n\\n<p>This gets even trickier when people no longer in the home can access the devices remotely. There have been <a href=\"https://www.nytimes.com/2018/06/23/technology/smart-home-devices-domestic-abuse.html\">cases of harassment, intimidation, and domestic abuse</a> by people whose access should have been revoked: for example, an ex-partner turning off the heating system. When should someone be able to access communal devices remotely? When should their access be controllable from the devices themselves? How should people be reminded to update their access control lists? How does basic security maintenance happen inside a communal space? </p>\\n\\n\\n\\n<p>See how much work this takes in a <a href=\"https://twitter.com/bryanmcaninch/status/1396099891802353671\">recent account of pro bono security work</a> for a harassed mother and her son. Or how a <a href=\"https://twitter.com/_DanielSinclair/status/1405686762563719174\">YouTuber was blackmailed, surveilled, and harassed by her smart home</a>. <a href=\"https://manuals.info.apple.com/MANUALS/1000/MA1976/en_US/device-and-data-access-when-personal-safety-is-at-risk.pdf\">Apple even has a manual</a> for this type of situation.</p>\\n\\n\\n\\n<p>At home, where there’s no corporate IT group to create policies and automation to keep things secure, it’s next to impossible to manage all of these security issues. Even some corporations have trouble with it. We need to figure out how users will maintain and configure a communal device over time. Configuration for devices in the home and office can be wrought with lots of different types of needs over time.</p>\\n\\n\\n\\n<p>For example, what happens when someone leaves the home and is no longer part of it? We will need to remove their access and may even find it necessary to block them from certain services. This is highlighted with the cases of harassment of people through spouses that still control the communal devices. Ongoing maintenance of a particular device could also be triggered by a change in needs by the community. A home device may be used to just play music or check the weather at first. But when a new baby comes home, being able to do video calling with close relatives may become a higher priority.</p>\\n\\n\\n\\n<p>End users are usually very bad at changing configuration after it is set. They may not even know that they can configure something in the first place. This is why people have made a business out of setting up home stereo and video systems. People just don’t understand the technologies they are putting in their houses. Does that mean we need some type of handy-person that does home device setup and management? When more complicated routines are required to meet the needs, how does someone allow for changes without writing code, if they are allowed to?</p>\\n\\n\\n\\n<p>Communal devices need new paradigms of security that go beyond the standard login. The world inside a home is protected by a barrier like a locked door; the capabilities of communal devices should respect that. This means both removing friction in some cases and increasing it in others.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\\n<h5>A note about biometrics</h5>\\n\\n\\n\\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh4.googleusercontent.com/qbw387_ORSOiu1Mgg3qhPgTkqbswCa4_ErEyVBjfNVjyUK10Qsp1OoxXif2W4g_p11GP9kwIEW_19G1nV0p8I_zggBTciyFLHaB82PBkuN3PMWSJLNaGRCtUGB77CmAN7IeFbYVb\" /><figcaption><br />&nbsp;“Turn your face” to enroll in Google Face Match and personalize your devices.<br /><em>(Source: Google Face Match video, <a href=\"https://youtu.be/ODy_xJHW6CI?t=26\">https://youtu.be/ODy_xJHW6CI?t=26</a>) </em></figcaption></figure>\\n\\n\\n\\n<p class=\"has-background has-very-light-gray-background-color\">Biometric authentication for voice and face recognition can help us get a better understanding of who is using a device. Examples of biometric authentication include <a href=\"https://support.apple.com/en-us/HT208108\">FaceID</a> for the iPhone and voice profiles for Amazon Alexa. There is a push for <a href=\"https://www.theverge.com/2021/4/20/22393873/ftc-ai-machine-learning-race-gender-bias-legal-violation\">regulation of facial recognition technologies</a>, but opt-in for authentication purposes tends to be carved out.</p>\\n\\n\\n\\n<p class=\"has-background has-very-light-gray-background-color\">However, biometrics aren’t without problems. In addition to issues with <a href=\"http://gendershades.org/overview.html\">skin tone, gender bias</a>, and <a href=\"https://news.stanford.edu/2020/03/23/automated-speech-recognition-less-accurate-blacks/\">local accents</a>, biometrics assumes that everyone is willing to have a biometric profile on the device–and that they would be legally allowed to (for example, children may not be allowed to consent to a biometric profile). It also assumes this technology is secure. <a href=\"https://support.google.com/googlenest/answer/9320885?co=GENIE.Platform%3DAndroid&amp;hl=en\">Google FaceMatch makes it very clear it is only a technology for personalization,</a> rather than authentication. I can only guess they have legalese to avoid liability when an unauthorized person spoofs someone’s face, say by taking a photo off the wall and showing it to the device.</p>\\n\\n\\n\\n<p class=\"has-background has-very-light-gray-background-color\">What do we mean by “personalization?” When you walk into a room and FaceMatch identifies your face, the Google Home Hub dings, shows your face icon, then shows your calendar (if it is connected), and a feed of personalized cards. Apple’s <a href=\"https://support.apple.com/en-us/HT208108\">FaceID uses many levels of presentation attack detection</a> (also known as “anti-spoofing”): it verifies your eyes are open and you are looking at the screen, and it uses a depth sensor to make sure it isn’t “seeing” a photo. The phone can then show hidden notification content or open the phone to the home screen. This measurement of trust and risk is benefited by understanding who could be in front of the device. We can’t forget that the machine learning that is doing biometrics is not a deterministic calculation; there is always some degree of uncertainty.</p>\\n\\n\\n\\n<p class=\"has-background has-very-light-gray-background-color\">Social and information norms define what we consider acceptable, who we trust, and how much. As trust goes up, we can take more risks in the way we handle information. However, it’s difficult to connect trust with risk without understanding people’s expectations. I have access to my <a href=\"https://www.wired.co.uk/article/password-security-sharing\">partner’s iPhone and know the passcode</a>. It would be a violation of a norm if I walked over and unlocked it without being asked, and doing so will lead to reduced trust between us. </p>\\n\\n\\n\\n<p class=\"has-background has-very-light-gray-background-color\">As we can see, biometrics does offer some benefits but won’t be the panacea for the unique uses of communal devices. Biometrics will allow those willing to opt-in to the collection of their biometric profile to gain personalized access with low friction, but it will never be useable for everyone with physical access. </p>\\n</div></div>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h2>Experiences</h2>\\n\\n\\n\\n<p>People use a communal device for short experiences (checking the weather), ambient experiences (listening to music or glancing at a photo), and joint experiences (multiple people watching a movie). The device needs to be aware of norms within the space and between the multiple people in the space. Social norms are rules by which people decide how to act in a particular context or space. In the home, there are norms about what people should and should not do. If you are a guest, you try to see if people take their shoes off at the door; you don’t rearrange things on a bookshelf; and so on.</p>\\n\\n\\n\\n<p>Most software is built to work for as many people as possible; this is called generalization. Norms stand in the way of generalization. Today’s technology isn’t good enough to adapt to every possible situation. One strategy is to simplify the software’s functionality and let the humans enforce norms. For example, when multiple people talk to an Echo at the same time, Alexa will either not understand or it will take action on the last command. <a href=\"https://www.theverge.com/2020/9/24/21452313/alexa-voice-assistant-ai-upgrade-amazon-echo-smart-speaker-multiple-people-tone-questions\">Multi-turn conversations between multiple people</a> are still in their infancy. This is fine when there are understood norms–for example, between my partner and I. But it doesn’t work so well when you and a child are both trying to shout commands.</p>\\n\\n\\n\\n<figure class=\"wp-block-image\"><img alt=\"\" src=\"https://lh6.googleusercontent.com/DqO-tlVqweGB2Qn0dTCipZ9XZ-GlJKnel9bxMdOWKhqKjVYqftcKw6GNketKIQvVNjAAwsAVnH52CAd0K9KvF-idqGZtcbuTVKzPQM5uZiqcvPc9sQ0oBLzwsPm5NBdltxgvuJ0h\" /><figcaption><br />Shared experiences can be challenging like a parent and child yelling at an Amazon Echo to play what they want.</figcaption></figure>\\n\\n\\n\\n<p>Norms are interesting because they tend to be learned and negotiated over time, but are invisible. Experiences that are built for communal use need to be aware of these invisible norms through cues that can be detected from peoples’ actions and words. This gets especially tricky because a conversation between two people could include information subject to different expectations (in a Contextual Integrity sense) about how that information is used. With enough data, models can be created to “read between the lines” in both helpful and dangerous ways.</p>\\n\\n\\n\\n<p>Video games already cater to multiple people’s experiences. With the Nintendo Switch or any other gaming system, several people can play together in a joint experience. However, the rules governing these experiences are never applied to, say, Netflix. The assumption is always that one person holds the remote. How might these experiences be improved if software could accept input from multiple sources (remote controls, voice, etc.) to build a selection of movies that is appropriate for everyone watching?</p>\\n\\n\\n\\n<p>Communal experience problems highlight inequalities in households. With <a href=\"https://www.nytimes.com/interactive/2021/05/17/upshot/women-workforce-employment-covid.html\">women doing more household coordination</a> than ever, there is a need to rebalance the tasks for households. Most of the time these coordination tasks are relegated to personal devices, generally the wife’s mobile phone, when they involve the entire family (though there is a <a href=\"https://www.oecd.org/digital/bridging-the-digital-gender-divide.pdf\">digital divide outside the US</a>). Without moving these experiences into a place that everyone can participate in, we will continue these inequalities.</p>\\n\\n\\n\\n<p>So far, technology has been great at intermediating people for coordination through systems like text messaging, social networks, and collaborative documents. We don’t build interaction paradigms that allow for multiple people to engage at the same time in their communal spaces. To do this we need to address that the norms that dictate what is appropriate behavior are invisible and pervasive in the spaces these technologies are deployed.</p>\\n\\n\\n\\n<h2>Ownership</h2>\\n\\n\\n\\n<p>Many of these devices are not really owned by the people who buy them. As part of the current trend towards subscription-based business models, the device won’t function if you don’t subscribe to a service. Those services have license agreements that specify what you can and cannot do (which you can read if you have a <a href=\"https://www.visualcapitalist.com/terms-of-service-visualizing-the-length-of-internet-agreements/\">few hours to spare</a> and <a href=\"https://www.nytimes.com/interactive/2019/06/12/opinion/facebook-google-privacy-policies.html\">can understand them</a>).</p>\\n\\n\\n\\n<p>For example, this has been an issue for fans of Amazon’s <a href=\"https://www.theverge.com/22381356/blink-homebridge-crackdown-amazon-subscriptions\">Blink camera</a>. The home automation industry is fragmented: there are many vendors, each with its own application to control their particular devices. But most people don’t want to use different apps to control their lighting, their television, their security cameras, and their locks. Therefore, people have started to build controllers that span the different ecosystems. Doing so has caused Blink users to get their accounts suspended.</p>\\n\\n\\n\\n<p>What’s even worse is that these license agreements can change whenever the company wants. Licenses are frequently modified with nothing more than a notification, after which something that was previously acceptable is now forbidden. In 2020, <a href=\"https://www.consumerreports.org/smart-home/wink-tells-users-pay-up-or-we-will-disable-smart-home-hub/\">Wink suddenly applied</a> a monthly service charge; if you didn’t pay, the device would stop working. Also in 2020, Sonos caused a stir by saying they were going to <a href=\"https://www.theverge.com/2020/3/5/21166777/sonos-ending-recycle-mode-trade-up-program-sustainability\">“recycle” (disable) old devices.</a> They eventually changed their policy.</p>\\n\\n\\n\\n<p>The issue isn’t just what you can do with your devices; it’s also what happens to the data they create. <a href=\"https://www.washingtonpost.com/technology/2019/08/28/doorbell-camera-firm-ring-has-partnered-with-police-forces-extending-surveillance-reach/\">Amazon’s Ring partnership</a> with <a href=\"https://www.theguardian.com/commentisfree/2021/may/18/amazon-ring-largest-civilian-surveillance-network-us\">one in ten US police departments</a> troubles many privacy groups because it creates a vast surveillance program. What if you don’t want to be a part of the police state? Make sure you check the right box and read your terms of service. If you’re designing a device, you need to require users to opt in to data sharing (especially as regions adapt GDPR and CCPA-like regulation).</p>\\n\\n\\n\\n<p>While techniques like <a href=\"https://ai.googleblog.com/2017/04/federated-learning-collaborative.html\">federated learning</a> are on the horizon, to avoid latency issues and mass data collection, it remains to be seen whether those techniques are satisfactory for companies that collect data. Is there a benefit to both organizations and their customers to limit or obfuscate the transmission of data away from the device?</p>\\n\\n\\n\\n<p>Ownership is particularly tricky for communal devices. This is a collision between the expectations of consumers who put something in their home; those expectations run directly against the way rent-to-use services are pitched. Until we acknowledge that hardware put in a home is different from a cloud service, we will never get it right.</p>\\n\\n\\n\\n<h2>Lots of problems, now what?</h2>\\n\\n\\n\\n<p>Now that we have dived into the various problems that rear their head with communal devices, what do we do about it? In the next article we discuss a way to consider the map of the communal space. This helps build a better understanding of how the communal device fits in the context of the space and services that exist already.</p>\\n\\n\\n\\n<p>We will also provide a list of dos and don’ts for leaders, developers, and designers to consider when building a communal device.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/communal-computings-many-problems/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Thinking About Glue',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Thinking About Glue'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/thinking-about-glue/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/thinking-about-glue/',\n",
       "   'comments': 'https://www.oreilly.com/radar/thinking-about-glue/#respond',\n",
       "   'published': 'Tue, 13 Jul 2021 13:28:28 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=13, tm_hour=13, tm_min=28, tm_sec=28, tm_wday=1, tm_yday=194, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Software Engineering', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13867',\n",
       "   'guidislink': False,\n",
       "   'summary': 'In Glue: the Dark Matter of Software, Marcel Weiher asks why there&#8217;s so much code. Why is Microsoft Office 400 million lines of code? Why are we always running into the truth of Alan Kay&#8217;s statement that &#8220;Software seems &#8216;large&#8217; and &#8216;complicated&#8217; for what it does&#8221;? Weiher makes an interesting claim: the reason we have [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'In Glue: the Dark Matter of Software, Marcel Weiher asks why there&#8217;s so much code. Why is Microsoft Office 400 million lines of code? Why are we always running into the truth of Alan Kay&#8217;s statement that &#8220;Software seems &#8216;large&#8217; and &#8216;complicated&#8217; for what it does&#8221;? Weiher makes an interesting claim: the reason we have [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>In <a href=\"https://blog.metaobject.com/2021/06/glue-dark-matter-of-software.html\">Glue: the Dark Matter of Software</a>, Marcel Weiher asks why there&#8217;s so much code. Why is Microsoft Office 400 million lines of code? Why are we always running into the truth of Alan Kay&#8217;s statement that &#8220;Software seems &#8216;large&#8217; and &#8216;complicated&#8217; for what it does&#8221;?</p>\\n\\n\\n\\n<p>Weiher makes an interesting claim: the reason we have so much code is Glue Code, the code that connects everything together. It&#8217;s &#8220;invisible and massive&#8221;; it&#8217;s &#8220;deemed not important&#8221;; and, perhaps most important, it&#8217;s &#8220;quadratic&#8221;: the glue code is proportional to the square of the number of things you need to glue. That feels right; and in the past few years, we&#8217;ve become increasingly aware of the skyrocketing number of dependencies in any software project significantly more complex than &#8220;Hello, World!&#8221; We can all add our own examples: the classic article <a href=\"https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf\">Hidden Technical Debt in Machine Learning Systems</a> shows a block diagram of a system in which machine learning is a tiny block in the middle, surrounded by all sorts of infrastructure: data pipelines, resource management, configuration, etc. Object Relational Management (ORM) frameworks are a kind of glue between application software and databases. Web frameworks facilitate gluing together components of various types, along with gluing that front end to some kind of back end. The list goes on.</p>\\n\\n\\n\\n<p>Weiher makes another important point: the simplest abstraction for glue is the Unix pipe (|), although he points out that pipes are not the only solution. Anyone who has used Unix or a variant (and certainly anyone who has read–or in my case, written–chunks of <a href=\"https://learning.oreilly.com/library/view/unix-power-tools/0596003307/\">Unix Power Tools</a>) realizes how powerful the pipe is. A standard way to connect tools that are designed to do one thing well: that&#8217;s important.</p>\\n\\n\\n\\n<p>But there&#8217;s another side to this problem, and one that we often sweep under the rug. A pipe has two ends: something that&#8217;s sending data, and something that&#8217;s receiving it. The sender needs to send data in a format that the receiver understands, or (more likely) the receiver needs to be able to parse and interpret the sender&#8217;s data in a way that it understands. You can pipe all the log data you want into an awk script (or perl, or python), but that script is still going to have to parse that data to make it interpretable. That&#8217;s really what those millions of lines of glue code do: either format data so the receiver can understand it or parse incoming data into a usable form. (This task falls more often on the receiver than the sender, largely because the sender often doesn&#8217;t—and shouldn&#8217;t—know anything about the receiver.)</p>\\n\\n\\n\\n<p>From this standpoint, the real problem with glue isn&#8217;t moving data, though the Unix pipe is a great abstraction; it&#8217;s data integration. In a discussion about blockchains and medical records, Jim Stogdill once said &#8220;the real problem has nothing to do with blockchains. The real problem is data integration.&#8221; You can put all the data you want on a blockchain, or in a data warehouse, or in a subsurface data ocean the size of one of Jupiter&#8217;s moons, and you won&#8217;t solve the problem that application A generates data in a form that application B can&#8217;t use. If you know anything about medical records (and I know very little), you know that&#8217;s the heart of the problem. One major vendor has products that aren&#8217;t even compatible with each other, let alone competitors&#8217; systems. Not only are data formats incompatible, the meanings of fields in the data are often different in subtle ways. Chasing down those differences can easily run to hundreds of thousands, if not millions, of lines of code.</p>\\n\\n\\n\\n<p>Pipes are great for moving data from one place to another. But there&#8217;s no equivalent standard for data integration. XML might play a role, but it only solves the easy part of the problem: standardizing parsing has some value, but the ease of parsing XML was always oversold, and the real problems stem more from schemas than data formats. (And please don&#8217;t play the &#8220;XML is human-readable and -writable&#8221; game.) JSON strikes me as XML for &#8220;pickling&#8221; JavaScript objects, replacing angle brackets with curly braces: a good idea that has gotten a lot of cross-language support, but like XML neglects the tough part of the problem.</p>\\n\\n\\n\\n<p>Is data integration a problem that can be solved? In networking, we have standards for what data means and how to send it. All those TCP/IP packet headers that have been in use for almost 40 years (the first deployment of IPv4 was in 1982) have kept data flowing between systems built by different vendors. The fields in the header have been defined precisely, and new protocols have been built successfully at every layer of the network stack.</p>\\n\\n\\n\\n<p>But this kind of standardization doesn&#8217;t solve the N squared problem. In a network stack, TCP talks to TCP; HTTPS talks to HTTPS. (Arguably, it keeps the N squared problem from being an N cubed problem.) The network stack designs the N squared problem out of existence, at least as far as the network itself is concerned, but that doesn’t help at the application layer. When we&#8217;re talking applications, a medical app needs to understand medical records, financial records, regulatory constraints, insurance records, reporting systems, and probably dozens more. Nor does standardization really solve the problem of new services. IPv4 desperately needs to be replaced (and IPv6 has been around since 1995), but IPv6 has been &#8220;5 years in the future&#8221; for two decades now. Hack on top of hack has kept IPv4 workable; but will layer and layer of hack work if we&#8217;re extending medical or financial applications?</p>\\n\\n\\n\\n<p>Glue code expands as the square of the number of things that are glued. The need to glue different systems together is at the core of the problems facing software development; as systems become more all-encompassing, the need to integrate with different systems increases. The glue–which includes code written for data integration–becomes its own kind of technical debt, adding to the maintenance burden. It’s rarely (if ever) refactored or just plain removed because you always need to “maintain compatibility” with some old system.&nbsp; (Remember IE6?)</p>\\n\\n\\n\\n<p>Is there a solution? In the future, we’ll probably need to integrate more services.&nbsp; The glue code will be more complex, since it will probably need to live in some “<a href=\"https://learning.oreilly.com/library/view/zero-trust-networks/9781491962183/\">zero trust</a>” framework (another issue, but an important one).&nbsp; Still, knowing that you’re writing glue code, keeping track of where it is, and being proactive about removing it when it’s needed will keep the problem manageable. Designing interfaces carefully and observing standards will minimize the need for glue. In the final analysis, is glue code really a problem? Programming is ultimately about gluing things together, whether they’re microservices or programming libraries. Glue isn’t some kind of computational waste; it’s what holds our systems together.&nbsp; Glue development is software development.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/thinking-about-glue/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: July 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: July 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2021/#respond',\n",
       "   'published': 'Tue, 06 Jul 2021 17:12:56 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=7, tm_mday=6, tm_hour=17, tm_min=12, tm_sec=56, tm_wday=1, tm_yday=187, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13856',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Certainly the biggest news of the past month has been a continuation of the trend towards regulating the biggest players in the tech industry.&#160; The US House of Representatives is considering 5 antitrust bills that would lead to major changes in the way the largest technology companies do business; and the Biden administration has appointed [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Certainly the biggest news of the past month has been a continuation of the trend towards regulating the biggest players in the tech industry.&#160; The US House of Representatives is considering 5 antitrust bills that would lead to major changes in the way the largest technology companies do business; and the Biden administration has appointed [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Certainly the biggest news of the past month has been a continuation of the trend towards regulating the biggest players in the tech industry.&nbsp; The US House of Representatives is considering <a href=\"https://www.businessinsider.com/congress-big-tech-bills-facebook-google-apple-amazon-antitrust-2021-6\">5 antitrust bills</a> that would lead to major changes in the way the largest technology companies do business; and the Biden administration has <a href=\"https://www.vox.com/recode/22537529/tech-battle-antitrust-regulation-lina-khan-ftc-google-facebook-apple-amazon-cicilline-congress\">appointed</a> a new Chair of the Federal Trade Commission who will be inclined to use these regulations aggressively. Whether these bills pass in their current form, how they are challenged in court, and what changes they will lead to is an open question.&nbsp; (Late note: Antitrust cases against Facebook by the <a href=\"https://www.reuters.com/technology/us-judge-tells-ftc-file-new-complaint-against-facebook-2021-06-28/\">FTC and state governments</a> based on current law were just thrown out of court.)</p>\\n\\n\\n\\n<p>Aside from that, we see AI spreading into almost every area of computing; this list could easily have a single AI heading that subsumes programming, medicine, security, and everything else. </p>\\n\\n\\n\\n<h2>AI and Data</h2>\\n\\n\\n\\n<ul><li>A new algorithm allows autonomous vehicles to <a href=\"https://techxplore.com/news/2021-06-algorithm-autonomous-vehicles-summer-winter.html\">locate themselves</a> using computer vision (i.e., without GPS) regardless of the season; it works even when the terrain is snow-covered.<br /></li><li>An AI-based <a href=\"https://aiir.ai/industries/fire-detection/\">wildfire detection system</a> has been deployed in <a href=\"https://sonomacounty.ca.gov/CAO/Press-Releases/Sonoma-County-invests-in-artificial-intelligent-technology/\">Sonoma County</a>. It looks for smoke plumes, and can monitor many more cameras than a human.<br /></li><li>Researchers are investigating <a href=\"https://arstechnica.com/science/2021/06/the-efforts-to-make-text-based-ai-less-racist-and-terrible/\">how racism and other forms of abuse enter AI models</a> like GPT-3, and what can be done to prevent their appearance in the output. It’s essential for AI to “understand” racist content, but equally essential for it not to generate that content.<br /></li><li>Google has <a href=\"https://info.deeplearning.ai/the-batch-computers-spawn-computers-self-riding-bike-ai-against-covid-progress-report-handwriting-deciphered\">successfully used Reinforcement Learning</a> to design the <a href=\"https://www.nature.com/articles/s41586-021-03544-w\">layout for the next generation TPU</a> chip. The layout process took 6 hours, and replaced weeks of human effort. This is an important breakthrough in the design of custom integrated circuits.<br /></li><li>Facebook has developed technology to <a href=\"https://techxplore.com/news/2021-06-facebook-ai-software-deepfake-images.html\">identify the source</a> from which deepfake images originate. “Fingerprints” (distortions in the image) make it possible to identify the model that generated the images, and possibly to track down the creators.<br /></li><li><a href=\"https://techxplore.com/news/2021-06-machine-learned-human-emotions-autonomous-vehicles.html\">Adaptive mood control</a> is a technique that autonomous vehicles can use to detect passengers’ emotions and drive accordingly, making it easier for humans to trust the machine. We hope this doesn’t lead AVs to drive faster when the passenger is angry or frustrated.<br /></li><li>IBM has developed <a href=\"http://uq360.mybluemix.net/\">Uncertainty Quantification 360</a>, a set of <a href=\"https://www.arnnet.com.au/article/688944/ibm-python-toolkit-measures-ai-uncertainty/\">open source tools</a> for quantifying the uncertainty in AI systems. Understanding uncertainty is a big step towards building trustworthy AI and getting beyond the idea that the computer is always right. Trust requires understanding uncertainty.<br /></li><li>Waymo’s autonomous trucks will begin <a href=\"https://arstechnica.com/cars/2021/06/self-driving-waymo-trucks-to-haul-loads-between-houston-and-fort-worth/\">carrying real cargo</a> between Houston and Fort Worth, in a partnership with a major trucking company.<br /></li><li>GPT-2 can <a href=\"https://www.biorxiv.org/content/10.1101/2021.04.20.440622v1.abstract\">predict brain activity</a> and comprehension in fMRI studies of patients listening to stories, possibly indicating that in some way its processes correlate to brain function.<br /></li><li><a href=\"https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/\">GPT-J</a> is a language model with performance similar to GPT-3.&nbsp; The code and weights are open source.<br /></li><li>It appears possible to <a href=\"https://techxplore.com/news/2021-06-brain.html\">predict preferences</a> directly  by comparing brain activity to activity of others (essentially, brain-based collaborative filtering). A tool for advertising or for self-knowledge?<br /></li><li>Features stores are tools to automate building pipelines to deliver data for ML applications in production. <a href=\"https://thenewstack.io/tecton-helps-data-scientists-own-features-and-the-model-lifecycle/\">Tecton</a>, which originated with Uber’s Michelangelo, is one of the early commercial products available.<br /></li><li>How does machine learning work with language? <a href=\"https://www.everythingyoueversaid.art/\">Everything You Ever Said</a> doesn’t answer the question, but lets you play with an NLP engine by pasting in a text, then adding or subtracting concepts to see how the text is transformed.&nbsp; (Based on GLoVE, a pre-GPT model.)<br /></li><li>The <a href=\"https://www.technologyreview.com/2021/06/04/1025742/ai-hate-speech-moderation/\">HateCheck</a> dataset tests the ability of AI applications to detect hate speech correctly. Hate speech is a hard problem; being too strict causes systems to reject content that shouldn’t be classified as hate speech, while being too lax allows hate speech through.</li></ul>\\n\\n\\n\\n<h2>Ethics</h2>\\n\\n\\n\\n<ul><li>Twitter has built a <a href=\"https://www.protocol.com/workplace/twitter-ethical-ai-meta\">data ethics group</a> aimed at putting ethics into practice, in addition to research.&nbsp; Among others, the group includes Rumman Chowdhury and Kristian Lum.<br /></li><li>A study of <a href=\"https://www.technologyreview.com/2021/06/17/1026519/racial-bias-noisy-data-credit-scores-mortgage-loans-fairness-machine-learning/\">the effect of noise on fairness</a> in lending shows that insufficient (hence noisier) data is as big a problem as biased data. Poor people have less credit history, which means that their credit scores are often inaccurate. Correcting problems arising from noise is much more difficult than dealing with problems of bias.<br /></li><li>Andrew Ng’s newsletter, <a href=\"https://info.deeplearning.ai/the-batch-face-recognition-at-the-border-robot-manicurists-irresponsible-ai-synthesizing-real-world-scenes\">The Batch</a>, reports on a <a href=\"https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing\">survey of executives</a> that most companies are not practicing “responsible AI,” or even understand the issues. There is no consensus about the importance (or even the meaning) of “ethics” for AI.<br /></li><li>Using AI to screen resumes is a problem in itself, but <a href=\"https://www.chicagotribune.com/business/ct-biz-ai-online-job-interview-computer-20210615-iuukk7z3jzbqvbc7khk55em2qq-story.html\">AI doing the interview</a>? That’s taking problematic to a new level. It can be argued that AI, when done properly, is less subject to bias than a human interviewer, but we suspect that AI interviewers present more problems than solutions.</li></ul>\\n\\n\\n\\n<h2>Web</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.w3.org/TR/webgpu/#initialization-examples\">WebGPU</a> is a proposal for a standard API that makes GPUs directly accessible to web pages for rendering and computation.<br /></li><li>An end to providing cookie consent for every site you visit?&nbsp; The proposed <a href=\"https://arstechnica.com/gadgets/2021/06/tired-of-accepting-rejecting-cookies-adpc-wants-to-automate-the-process/#p3\">ADPC</a> (advanced data protection control) standard will allow users to specify privacy preferences once.<br /></li><li>Using social media community guidelines as a <a href=\"https://www.technologyreview.com/2021/06/24/1027048/youtube-xinjiang-censorship-human-rights-atajurt/\">political weapon</a>: the Atajurt Kazakh Human Rights channel, which publishes testimonies from people imprisoned in China’s internment camps, has been taken down repeatedly as a result of coordinated campaigns.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Microsoft is working on <a href=\"https://www.zdnet.com/article/microsofts-ciso-why-were-trying-to-banish-passwords-forever/\">eliminating passwords</a>! Other companies should take the hint. Microsoft is stressing biometrics (which have their own problems) and multi-factor authentication.<br /></li><li>Supply chain security is very problematic.&nbsp; Microsoft admits to an <a href=\"https://www.bleepingcomputer.com/news/security/microsoft-admits-to-signing-rootkit-malware-in-supply-chain-fiasco/\">error in which they mistakenly signed</a> a device driver that was actually a rootkit, causing security software to ignore it. The malware somehow slipped through Microsoft’s signing process.<br /></li><li><a href=\"https://arxiv.org/abs/2106.00660\">Markpainting</a> is a technology for defeating attempts to create a fake image by adding elements to the picture that aren’t visible, but that will become visible when the image is modified (for example, to eliminate a watermark). <br /></li><li><a href=\"https://arstechnica.com/gadgets/2021/05/amazon-devices-will-soon-automatically-share-your-internet-with-neighbors/\">Amazon Sidewalk</a> lets Amazon devices connect to other open WiFi nets to extend their range and tap others’ internet connections. Sidewalk is a cool take on decentralized networking. It is also a Very Bad Idea.<br /></li><li>Authentication using gestures, hand shapes, and <a href=\"https://venturebeat.com/2021/05/31/password-authentication-is-a-mess-heres-a-system-to-replace-it/\">geometric deep learning</a>? I’m not convinced, but this could be a viable alternative to passwords and crude biometrics. It would have to work for people of all skin colors, and that has consistently been a problem for vision-based products.<br /></li><li>According to Google, <a href=\"https://therecord.media/google-says-rowhammer-attacks-are-gaining-range-as-ram-is-getting-smaller/\">Rowhammer attacks</a> are gaining momentum–and will certainly gain even more momentum as feature sizes in memory chips get smaller. Rowhammer attacks repeatedly access a single row in a memory chip, hoping to corrupt adjacent bits. <br /></li><li>While details are sketchy, the FBI was able to <a href=\"https://techxplore.com/news/2021-06-bitcoin-double-edged-sword-criminals.html\">recover the BTC</a> Colonial Pipeline paid to Darkside to restore systems after their ransomware attack. The FBI has been careful to say that they can’t promise recovering payments in other cases. Whether this recovery reflects poor opsec on the part of the criminals, or that Bitcoin is more easily de-anonymized than most people think, it’s clear that secrecy and privacy are relative.</li></ul>\\n\\n\\n\\n<h2>Design and User Experience</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.oreilly.com/radar/communal-computing/\">Communal Computing</a> is about designing devices that are inherently shared: home assistants, home automation, and more. The “single account/user” model doesn’t work.<br /></li><li>A <a href=\"https://dl.acm.org/doi/10.1145/3411764.3445169\">microphone</a> that only “hears” frequencies above the human hearing range can be used to detect human activities (for example, in a smart home device) without recording speech.<br /></li><li><a href=\"https://techxplore.com/news/2021-06-digital-twins-scale-drone-deliveries.html\">Digital Twins</a> in aerospace at scale: One problem with the adoption of digital twins is that the twin is very specific to a single device. This research shows that it’s possible to model real-world objects in ways that can be reused across collections of objects and different applications.</li></ul>\\n\\n\\n\\n<h2>Medicine</h2>\\n\\n\\n\\n<ul><li>The <a href=\"https://openinsulin.org/what-we-do/\">Open Insulin Foundation</a> is dedicated to creating the tools necessary to produce insulin at scale. This is the next step in a long-term project by Anthony DiFranco and others to challenge the pharma company’s monopoly on insulin production, and create products at a small fraction of the price.<br /></li><li>Where’s the work on antivirals and other <a href=\"https://www.technologyreview.com/2021/06/28/1027376/the-race-to-find-covid-19-drug-treatments-that-actually-work/\">treatments for COVID-19</a>? The answer is simple: Vaccines are very profitable. Antivirals aren’t. This is a huge, institutional problem in the pharmaceutical industry.<br /></li><li>The <a href=\"https://ncats.nih.gov/n3c\">National Covid Cohort Collaborative</a> (N3C) is a nationwide database of anonymized medical records of COVID patients. What’s significant isn’t COVID, but that N3C is a single database, built to comply with privacy laws, that’s auditable, and that’s open for any group to make research proposals.<br /></li><li>Can medical trials be sped up by <a href=\"https://www.technologyreview.com/2021/06/10/1025897/clinical-trials-are-better-faster-cheaper-with-big-data/\">re-using control data</a> (data from patients who were in the control group) from previous trials? Particularly for rare and life-threatening diseases, getting trial volunteers is difficult because nobody wants to be assigned to the control group.<br /></li><li>A <a href=\"https://www.technologyreview.com/2021/06/09/1025889/wearable-ai-body-sensor-covid-chicago/\">remote monitoring patch for COVID patients</a> uses AI to understand changes in the patient’s vital signs, allowing medical staff to intervene immediately if a patient’s condition worsens. Unlike most such devices, it was trained primarily on Black and Hispanic patients.<br /></li><li>Machine learning in medicine is undergoing a <a href=\"https://www.statnews.com/2021/06/02/machine-learning-ai-methodology-research-flaws/\">credibility crisis</a>: poor data sets with limited diversity lead to poor results.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Microsoft, OpenAI, and GitHub have announced a new service called <a href=\"https://copilot.github.com/\">Copilot</a> that uses AI to make suggestions to programmers as they are writing code (currently in “technical preview”).&nbsp; It is truly a <a href=\"https://www.oreilly.com/radar/pair-programming-with-ai/\">cybernetic pair programmer</a>.<br /></li><li>Windows 11 <a href=\"https://thenewstack.io/this-week-in-programming-windows-opens-up-to-android-developers/\">will run Android apps</a>. If nothing else, this is a surprise. Android apps will be provided via the Amazon store, not Google Play.<br /></li><li>Microsoft’s <a href=\"https://powerapps.microsoft.com/en-us/blog/what-is-microsoft-power-fx/\">PowerFx</a> is a low-code programming language based on Excel formulas (which now include lambdas).&nbsp; Input and output are through what looks like a web page. What does it mean to strip Excel from its 2D grid? Is this a step forward or backward for low code computing?<br /></li><li><a href=\"https://deps.dev/\">Open Source Insights</a> is a Google project for investigating the dependency chain of any open source project. Its ability currently is limited to a few major packaging systems (including npm, Cargo, and maven), but it will be expanded.<br /></li><li>Quantum computing’s first application will be in <a href=\"https://www.wired.co.uk/article/quantum-computing\">researching quantum mechanics</a>: understanding the chemistry of batteries, drugs, and materials. In these applications, noise is an asset, not a problem.</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-july-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Hand Labeling Considered Harmful',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Hand Labeling Considered Harmful'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/arguments-against-hand-labeling/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/arguments-against-hand-labeling/',\n",
       "   'comments': 'https://www.oreilly.com/radar/arguments-against-hand-labeling/#respond',\n",
       "   'published': 'Wed, 23 Jun 2021 12:34:40 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=23, tm_hour=12, tm_min=34, tm_sec=40, tm_wday=2, tm_yday=174, tm_isdst=0),\n",
       "   'authors': [{'name': 'Shayan Mohanty and Hugo Bowne-Anderson'}],\n",
       "   'author': 'Shayan Mohanty and Hugo Bowne-Anderson',\n",
       "   'author_detail': {'name': 'Shayan Mohanty and Hugo Bowne-Anderson'},\n",
       "   'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Software Engineering', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13825',\n",
       "   'guidislink': False,\n",
       "   'summary': 'We are traveling through the era of Software 2.0, in which the key components of modern software are increasingly determined by the parameters of machine learning models, rather than hard-coded in the language of for loops and if-else statements. There are serious challenges with such software and models, including the data they&#8217;re trained on, how [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'We are traveling through the era of Software 2.0, in which the key components of modern software are increasingly determined by the parameters of machine learning models, rather than hard-coded in the language of for loops and if-else statements. There are serious challenges with such software and models, including the data they&#8217;re trained on, how [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>We are traveling through the era of<a href=\"https://karpathy.medium.com/software-2-0-a64152b37c35\"> Software 2.0</a>, in which the key components of modern software are increasingly determined by the parameters of machine learning models, rather than hard-coded in the language of for loops and if-else statements. There are serious challenges with such software and models, including the data they&#8217;re trained on, how they&#8217;re developed, how they&#8217;re deployed, and their impact on stakeholders. These challenges commonly result in both algorithmic bias and lack of model interpretability and explainability.</p>\\n\\n\\n\\n<p>There&#8217;s another critical issue, which is in some ways upstream to the challenges of bias and explainability: while we seem to be living in the future with the creation of machine learning and deep learning models, we are still living in the Dark Ages with respect to the curation and labeling of our training data: <em>the vast majority of labeling is still done by hand</em>.</p>\\n\\n\\n\\n<p>There are significant issues with hand labeling data:</p>\\n\\n\\n\\n<ul><li>It introduces bias, and hand labels are neither interpretable nor explainable.</li><li>There are prohibitive costs to hand labeling datasets (both financial costs and the time of subject matter experts).</li><li>There is no such thing as gold labels: even the most well-known hand labeled datasets have label error rates of at least 5% (<a href=\"https://www.technologyreview.com/2021/04/01/1021619/ai-data-errors-warp-machine-learning-progress/\">ImageNet has a label error rate of 5.8%</a>!).</li></ul>\\n\\n\\n\\n<p>We are living through an era in which we get to decide how human and machine intelligence interact to build intelligent software to tackle many of the world&#8217;s toughest challenges. Labeling data is a fundamental part of human-mediated machine intelligence, and hand labeling is not only the most naive approach but also one of the most expensive (in many senses) and most dangerous ways of bringing humans in the loop. Moreover, it&#8217;s just not necessary as many alternatives are seeing increasing adoption. These include:</p>\\n\\n\\n\\n<ul><li>Semi-supervised learning</li><li>Weak supervision</li><li>Transfer learning</li><li>Active learning</li><li>Synthetic data generation</li></ul>\\n\\n\\n\\n<p>These techniques are part of a broader movement known as<a href=\"https://blogs.microsoft.com/ai/machine-teaching/\"> Machine Teaching</a>, a core tenet of which is getting both humans and machines each doing what they do best. We need to use expertise efficiently: the financial cost and time taken for experts to hand-label every data point can break projects, such as diagnostic imaging involving life-threatening conditions and security and defense-related satellite imagery analysis. Hand labeling in the age of these other technologies is akin to scribes hand-copying books post-Gutenberg.</p>\\n\\n\\n\\n<p>There is also a burgeoning landscape of companies building products around these technologies, such as<a href=\"https://www.watchful.io/\"> Watchful</a> (weak supervision and active learning; disclaimer: one of the authors is CEO of Watchful),<a href=\"https://snorkel.ai/\"> Snorkel</a> (weak supervision),<a href=\"https://prodi.gy/\"> Prodigy</a> (active learning),<a href=\"https://paralleldomain.com/\"> Parallel Domain</a> (synthetic data), and<a href=\"https://aireverie.com/\"> AI Reverie</a> (synthetic data).</p>\\n\\n\\n\\n<h2><strong>Hand Labels and Algorithmic Bias</strong></h2>\\n\\n\\n\\n<p>As<a href=\"https://twitter.com/rajiinio/status/1375957288276611075\"> Deb Raji</a>, a Fellow at the Mozilla Foundation, has pointed out, algorithmic bias &#8220;can start anywhere in the system—pre-processing, post-processing, with task design, with modeling choices, etc.,&#8221; and the labeling of data is a crucial point at which bias can creep in.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13826\" height=\"489\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/06/Adapted-from-Cornell-University-paper-A-Framework-for-Understanding-Sources-of-Harm-throughout-the-Machine-Learning-Life-Cycle-by-Harini-Suresh-and-John-V.-Guttag-1048x697.png\" width=\"736\" /><figcaption><br />Figure 1: Bias can start anywhere in the system. Image adapted from <a href=\"https://arxiv.org/abs/1901.10002%C2%A0\">A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle</a> by Harini Suresh and John Guttag.</figcaption></figure>\\n\\n\\n\\n<p>High-profile cases of bias in training data resulting in harmful models include an<a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G\"> Amazon recruiting tool</a> that “penalized resumes that included the word &#8216;women’s,&#8217; as in &#8216;women’s chess club captain.&#8217;” Don&#8217;t take our word for it. Play the educational game<a href=\"https://www.survivalofthebestfit.com/\"> Survival of the Best Fit</a> where you&#8217;re a CEO who uses a machine learning model to scale their hiring decisions and see how the model replicates the bias inherent in the training data. This point is key: as humans, we possess all types of biases, some harmful, others not so. When we feed hand labeled data to a machine learning model, it will detect those patterns and replicate them at scale. This is why<a href=\"https://hdsr.mitpress.mit.edu/pub/rim3pvdw/release/6\"> David Donoho astutely observed</a> that perhaps we should call ML models <em>recycled intelligence</em> rather than <em>artificial intelligence</em>. Of course, given the amount of bias in hand labeled data, it may be more apt to refer to it as <em>recycled stupidity</em> (hat tip to<a href=\"https://en.wikipedia.org/wiki/Artificial_stupidity\"> <em>artificial stupidity</em></a>).</p>\\n\\n\\n\\n<p>The only way to interrogate the reasons for underlying bias arising from hand labels is to ask the labelers themselves their rationales for the labels in question, which is impractical, if not impossible, in the majority of cases: there are rarely records of who did the labeling, it is often outsourced via at-scale global APIs, such as Amazon&#8217;s Mechanical Turk and, when labels are created in-house, previous labelers are often no longer part of the organization.</p>\\n\\n\\n\\n<h2><strong>Uninterpretable, Unexplainable</strong></h2>\\n\\n\\n\\n<p>This leads to another key point: the lack of both interpretability and explainability in models built on hand labeled data. These are related concepts, and broadly speaking, interpretability is about correlation, whereas explainability is about causation. The former involves thinking about which features are correlated with the output variable, while the latter is concerned with why certain features lead to particular labels and predictions. We want models that give us results we can explain and some notion of how or why they work. For example, in the<a href=\"https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\"> ProPublica exposé of COMPAS recidivism risk model</a>, which made more false predictions that Black people would re-offend than it did for white people, it is essential to understand why the model is making the predictions it does. Lack of explainability and transparency were key ingredients of all the deployed-at-scale algorithms identified by Cathy O&#8217;Neil in<a href=\"https://weaponsofmathdestructionbook.com/\"> <em>Weapons of Math Destruction</em></a>.</p>\\n\\n\\n\\n<p>It may be counterintuitive that getting machines more in-the-loop for labeling can result in more explainable models but consider several examples:</p>\\n\\n\\n\\n<ul><li>There is a growing area of<a href=\"http://ai.stanford.edu/blog/weak-supervision/\"> <em>weak supervision</em></a><em>,</em> in which SMEs specify heuristics that the system then uses to make inferences about unlabeled data, the system calculates some potential labels, and then the SME evaluates the labels to determine where more heuristics might need to be added or tweaked. For example, when building a model of whether surgery was necessary based on medical transcripts, the SME may provide the following heuristic: if the transcription contains the term &#8220;anaesthesia&#8221; (or a regular expression similar to it), then surgery likely occurred (check out Russell Jurney&#8217;s &#8220;<a href=\"https://www.kdnuggets.com/2020/02/hand-labeling-past-future-nolabel-ai.html\">Hand labeling is the past</a>&#8221; article for more on this).</li><li>In diagnostic imaging, we need to start cracking open the <em>neural nets</em> (such as CNNs and transformers)! SMEs could once again use heuristics to specify that tumors smaller than a certain size and/or of a particular shape are benign or malignant and, through such heuristics, we could drill down into different layers of the neural network to see what representations are learned where.</li><li>When your knowledge (via labels) is encoded in heuristics and functions, as above, this also has profound implications for models in production. When data drift inevitably occurs, you can return to the heuristics encoded in functions and edit them, instead of continually incurring the costs of hand labeling.</li></ul>\\n\\n\\n\\n<h2><strong>On Auditing</strong></h2>\\n\\n\\n\\n<p>Amidst the increasing concern about model transparency, we are seeing<a href=\"https://onezero.medium.com/the-algorithmic-auditing-trap-9a6f2d4d461d\"> calls for algorithmic auditing</a>. Audits will play a key role in determining how algorithms are regulated and which ones are safe for deployment. One of the barriers to auditing is that high-performing models, such as deep learning models, are notoriously difficult to explain and reason about. There are several ways to probe this at the model level (such as SHAP and LIME), but that only tells part of the story. As we have seen, a major cause of algorithmic bias is that the data used to train it is biased or insufficient in some way.</p>\\n\\n\\n\\n<p>There currently aren&#8217;t many ways to probe for bias or insufficiency at the data level. For example, the only way to explain hand labels in training data is to talk to the people who labeled it.<a href=\"https://www.aclweb.org/anthology/P01-1005.pdf\"> Active learning, on the other hand, allows for the principled creation of smaller datasets which have been intelligently sampled to maximize utility for a model</a>, which in turn reduces the overall auditable surface area. An example of active learning would be the following: instead of hand labeling every data point, the SME can label a representative subset of the data, which the system uses to make inferences about the unlabeled data. Then the system will ask the SME to label some of the unlabeled data, cross-check its own inferences and refine them based on the SME&#8217;s labels. This is an iterative process that terminates once the system reaches a target accuracy. Less data means less headache with respect to auditability.</p>\\n\\n\\n\\n<p>Weak supervision more directly encodes expertise (and hence bias) as heuristics and functions, making it easier to evaluate where labeling went awry. For more opaque methods, such as synthetic data generation, it might be a bit difficult to interpret <em>why</em> a particular label was applied, which may actually complicate an audit. The methods we choose at this stage of the pipeline are important if we want to make sure the system as a whole is explainable.</p>\\n\\n\\n\\n<h2><strong>The Prohibitive Costs of Hand Labeling</strong></h2>\\n\\n\\n\\n<p>There are significant and differing forms of costs associated with hand labeling. Giant industries have been erected to deal with the demand for data-labeling services. Look no further than Amazon Mechanical Turk and all other cloud providers today. It is telling that data labeling is becoming increasingly outsourced globally, as detailed by Mary Gray in<a href=\"https://ghostwork.info/\"> <em>Ghost Work</em></a><em>,</em> and there are increasingly serious concerns about the labor conditions under which<a href=\"https://www.vice.com/en/article/88apnv/underpaid-workers-are-being-forced-to-train-biased-ai-on-mechanical-turk\"> hand labelers work around the globe</a>.</p>\\n\\n\\n\\n<p>The sheer amount of capital involved was evidenced by<a href=\"https://techcrunch.com/2019/08/05/scale-ai-and-its-22-year-old-ceo-lock-down-100-million-to-help-label-silicon-valleys-data/\"> Scale AI raising $100 million</a> in 2019 to bring their valuation to over $1 billion at a time when their business model solely revolved around using contractors to hand label data (it is telling that they&#8217;re now doing more than solely hand labels).</p>\\n\\n\\n\\n<p>Money isn&#8217;t the only cost, and quite often, isn&#8217;t where the bottleneck or rate-limiting step occurs. Rather, it is the bandwidth and time of experts that is the scarcest resource. As a scarce resource, this is often expensive but, much of the time it isn&#8217;t even available (on top of this, the time it also takes to correct errors in labeling by data scientists is very expensive). Take financial services, for example, and the question of whether or not you should invest in a company based on information about the company scraped from various sources. In such a firm, there will only be a small handful of people who can make such a call, so labeling each data point would be incredibly expensive, and that&#8217;s if the SME even has the time.</p>\\n\\n\\n\\n<p>This is not vertical-specific. The same challenge occurs in labeling legal texts for classification: is this clause talking about indemnification or not? And in medical diagnosis: is this tumor benign or malignant? As dependence on expertise increases, so does the likelihood that limited access to SMEs becomes a bottleneck.</p>\\n\\n\\n\\n<p>The third cost is a cost to accuracy, reality, and ground truth: the fact that hand labels are often so wrong. The authors of<a href=\"https://arxiv.org/pdf/2103.14749.pdf\"> a recent study from MIT</a> identified &#8220;label errors in the test sets of 10 of the most commonly-used computer vision, natural language, and audio datasets.&#8221; They estimated an average error rate of 3.4% across the datasets and show that ML model performance increases significantly once labels are corrected, in some instances. Also, consider that in many cases ground truth isn&#8217;t easy to find, if it exists at all. Weak supervision makes room for these cases (which are the majority) by assigning probabilistic labels without relying on ground truth annotations. It&#8217;s time to think statistically and probabilistically about our labels. There is good work happening here, such as Aka et al.&#8217;s (Google) recent paper<a href=\"https://deepai.org/publication/measuring-model-biases-in-the-absence-of-ground-truth\"> Measuring Model Biases in the Absence of Ground Truth</a>.</p>\\n\\n\\n\\n<p>The costs identified above are not one-off. When you train a model, you have to assume you&#8217;re going to train it again if it lives in production. Depending on the use case, that could be frequent. If you&#8217;re labeling by hand, it&#8217;s not just a large upfront cost to build a model. It is a set of ongoing costs each and every time.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13833\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/06/catchicken-798x1048.png\" /><figcaption><br />Figure 2: There are no “gold labels”: even the most well-known hand labeled datasets have label error rates of at least 5% (<a href=\"https://www.technologyreview.com/2021/04/01/1021619/ai-data-errors-warp-machine-learning-progress/\">ImageNet has a label error rate of 5.8%</a>!).</figcaption></figure>\\n\\n\\n\\n<h2><strong>The Efficacy of Automation Techniques</strong></h2>\\n\\n\\n\\n<p>In terms of performance, even if getting machines to label much of your data results in slightly noisier labels, your models are often better off with 10 times as many slightly noisier labels. To dive a bit deeper into this, there are gains to be made by increasing training set size even if it means reducing overall label accuracy, but if you&#8217;re training classical ML models, only up to a point (past this point the model starts to see a dip in predictive accuracy). <a href=\"https://www.aclweb.org/anthology/P01-1005.pdf\">&#8220;Scaling to Very Very Large Corpora for Natural Language Disambiguation (Banko &amp; Brill, 2001)&#8221;</a> demonstrates this in a traditional ML setting by exploring the relationship between hand labeled data, automatically labeled data, and subsequent model performance. A more recent paper,<a href=\"https://arxiv.org/pdf/1712.00409.pdf\"> &#8220;Deep Learning Scaling Is Predictable, Empirically (2017)&#8221;</a>, explores the quantity/quality relationship relative to modern state of the art model architectures, illustrating the fact that SOTA architectures are data hungry, and accuracy improves as a power law as training sets grow:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>We empirically validate that DL model accuracy improves as a power-law as we grow training sets for state-of-the-art (SOTA) model architectures in four machine learning domains: machine translation, language modeling, image processing, and speech recognition. These power-law learning curves exist across all tested domains, model architectures, optimizers, and loss functions.</p></blockquote>\\n\\n\\n\\n<p>The key question isn&#8217;t &#8220;should I hand label my training data or should I label it programmatically?&#8221; It should instead be &#8220;which parts of my data should I hand label and which parts should I label programmatically?&#8221; According to these papers, by introducing expensive hand labels sparingly into largely programmatically generated datasets, you can maximize the effort/model accuracy tradeoff on SOTA architectures that wouldn&#8217;t be possible if you had hand labeled alone.</p>\\n\\n\\n\\n<p>The stacked costs of hand labeling wouldn&#8217;t be so challenging were they necessary, but the fact of the matter is that there are so many other interesting ways to get human knowledge into models. There&#8217;s still an open question around where and how we want humans in the loop and what&#8217;s the right design for these systems. Areas such as weak supervision, self-supervised learning, synthetic data generation, and active learning, for example, along with the products that implement them, provide promising avenues for avoiding the pitfalls of hand labeling. Humans belong in the loop at the labeling stage, but so do machines. In short, it&#8217;s time to move beyond hand labels.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<p><em>Many thanks to </em><a href=\"https://www.linkedin.com/in/daeil/\"><em>Daeil Kim</em></a><em> for feedback on a draft of this essay.</em></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/arguments-against-hand-labeling/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Two economies. Two sets of rules.',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Two economies. Two sets of rules.'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/two-economies-two-sets-of-rules/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/two-economies-two-sets-of-rules/',\n",
       "   'comments': 'https://www.oreilly.com/radar/two-economies-two-sets-of-rules/#respond',\n",
       "   'published': 'Tue, 22 Jun 2021 13:07:19 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=22, tm_hour=13, tm_min=7, tm_sec=19, tm_wday=1, tm_yday=173, tm_isdst=0),\n",
       "   'authors': [{'name': 'Tim O’Reilly'}],\n",
       "   'author': 'Tim O’Reilly',\n",
       "   'author_detail': {'name': 'Tim O’Reilly'},\n",
       "   'tags': [{'term': 'Bubbles', 'scheme': None, 'label': None},\n",
       "    {'term': 'Economy', 'scheme': None, 'label': None},\n",
       "    {'term': 'Stock Prices', 'scheme': None, 'label': None},\n",
       "    {'term': 'Tax and Monetary Policy', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13820',\n",
       "   'guidislink': False,\n",
       "   'summary': 'At one point early this year, Elon Musk briefly became the richest person in the world. After a 750% increase in Tesla’s stock market value added over $180 billion to his fortune, he briefly had a net worth of over $200 billion. It’s now back down to “only” $155 billion. Understanding how our economy produced [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'At one point early this year, Elon Musk briefly became the richest person in the world. After a 750% increase in Tesla’s stock market value added over $180 billion to his fortune, he briefly had a net worth of over $200 billion. It’s now back down to “only” $155 billion. Understanding how our economy produced [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>At one point early this year, Elon Musk briefly became the richest person in the world. After a 750% increase in Tesla’s stock market value added over $180 billion to his fortune, he briefly <a href=\"https://www.bloomberg.com/news/articles/2021-01-06/musk-close-to-surpassing-bezos-as-world-s-richest-person\">had a net worth of over $200 billion</a>. It’s now <a href=\"https://www.forbes.com/profile/elon-musk/?sh=c31d8f97999b\">back down to “only” $155 billion</a>.</p>\\n\\n\\n\\n<p>Understanding how our economy produced a result like this—what is good about it and what is dangerous—is crucial to any effort to address the wild inequality that threatens to tear our society apart.</p>\\n\\n\\n\\n<h3>The betting economy versus the operating economy</h3>\\n\\n\\n\\n<p>In response to the news of Musk’s surging fortune, Bernie Sanders <a href=\"https://twitter.com/SenSanders/status/1348253256330276867\" rel=\"noreferrer noopener\" target=\"_blank\">tweeted</a>:</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"Wealth of Elon Musk on March 18, 2020: $24.5 billion\\nWealth of Elon Musk on January 9, 2021: $209 billion\\n\\nU.S. minimum wage in 2009: $7.25 an hour\\nU.S. minimum wage in 2021: $7.25 an hour\\n\\nOur job: Raise the minimum wage to at least $15, tax the rich &amp; create an economy for all.\" class=\"wp-image-13821\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/06/Picture1.png\" /></figure>\\n\\n\\n\\n<p>Bernie was right that a $7.25 minimum wage is an outrage to human decency. If the minimum wage had kept up with increases in productivity since 1979, <a href=\"https://www.commondreams.org/views/2020/01/21/if-worker-pay-had-kept-pace-productivity-gains-1968-todays-minimum-wage-would-be-24#:~:text=In%20such%20a%20world%2C%20a,year%20in%20the%20United%20States.&amp;text=If%20the%20minimum%20wage%20had,wage%20of%20%247.25%20an%20hour.\" rel=\"noreferrer noopener\" target=\"_blank\">it would be over $24</a> by now, putting a two-worker family into the middle class. But Bernie was wrong to imply that Musk’s wealth increase was at the expense of Tesla’s workers. <a href=\"https://www.businessinsider.com/teslas-median-employee-made-81-more-than-the-median-american-in-2018-2019-5\" rel=\"noreferrer noopener\" target=\"_blank\">The median Tesla worker makes considerably more than the median American worker</a>.</p>\\n\\n\\n\\n<p>Elon Musk’s wealth doesn’t come from him hoarding Tesla’s extractive profits, like a robber baron of old. For most of its existence, Tesla had no profits at all. <a href=\"https://www.nytimes.com/2021/01/27/business/tesla-earnings.html\" rel=\"noreferrer noopener\" target=\"_blank\">It became profitable only last year</a>. But even in 2020, Tesla’s profits of $721 million on $31.5 billion in revenue were small—only slightly more than 2% of sales, a bit less than those of the average grocery chain, <a href=\"https://thegrocerystoreguy.com/what-is-the-profit-margin-for-grocery-stores/\" rel=\"noreferrer noopener\" target=\"_blank\">the least profitable major industry segment in America</a>.</p>\\n\\n\\n\\n<p>No, Musk won the lottery, or more precisely, the stock market beauty contest. In theory, the price of a stock reflects a company’s value as an ongoing source of profit and cash flow. In practice, it is subject to wild booms and busts that are unrelated to the underlying economics of the businesses that shares of stock are meant to represent. </p>\\n\\n\\n\\n<p>Why is Musk so rich? The answer tells us something profound about our economy: he is wealthy because people are betting on him. But unlike a bet in a lottery or at a racetrack, in the vast betting economy of the stock market, people can cash out their winnings before the race has ended. </p>\\n\\n\\n\\n<p>This is one of the biggest unacknowledged drivers of inequality in America, the reason why <a href=\"https://www.vice.com/en/article/g5pdab/the-rich-just-keep-on-getting-richer\">one segment of our society prospered so much during the pandemic</a> while the other languished.</p>\\n\\n\\n\\n<h3>What are the odds?</h3>\\n\\n\\n\\n<p>If the stock market is like a horse race where people can cash out their bets while the race is still being run, what does it mean for the race to finish? For an entrepreneur or an early-stage investor, an IPO is a kind of finish, the point where they can sell previously illiquid shares on to others. An acquisition or a shutdown, either of which puts an end to a company’s independent existence, is another kind of ending. But it is also useful to think of the end of the race as the point in time at which the stream of company profits will have repaid the investment.</p>\\n\\n\\n\\n<p>Since ownership of public companies is spread across tens of thousands of people and institutions, it’s easier to understand this point by imagining a small private company with one owner, say, a home construction business or a storage facility or a car wash. If it cost $1 million to buy the business, and it delivered $100,000 of profit a year, the investment would be repaid in 10 years. If it delivered $50,000 in profit, it would take 20. And of course, those future earnings would need to be discounted at some rate, since a dollar received 20 years from now is not worth as much as a dollar received today. This same approach works, in theory, for large public companies. Each share is a claim on a fractional share of the company’s future profits and the present value that people put on that profit stream.</p>\\n\\n\\n\\n<p>This is, of course, a radical oversimplification. There are many more sophisticated ways to value companies, their assets, and their prospects for future streams of profits. But what I’ve described above is one of the oldest, the easiest to understand, and the most clarifying. It is called the price/earnings ratio, or simply the P/E ratio. It’s the ratio between the price of a single share of stock and the company’s earnings per share (its profits divided by the number of shares outstanding.) What the P/E ratio gives, in effect, is a measure of how many years of current profits it would take to pay back the investment. </p>\\n\\n\\n\\n<p>The rate of growth also plays a role in a company’s valuation. For example, imagine a business with $100 million in revenue with a 10% profit margin, earning $10 million a year. How much it is worth to own that asset depends how fast it is growing and what stage of its lifecycle it is in when you bought it. If you were lucky enough to own that business when it had only $1 million in revenue and, say, $50,000 in profits, you would now be earning 200x as much as you were when you made your original investment. If a company grows to hundreds of billions in revenue and tens of billions in profits, as Apple, Microsoft, Facebook, and Google have done, even a small investment early on that is held for the long haul can make its lucky owner into a billionaire. Tesla <em>might</em> be one of these companies, but if so, the opportunity to buy its future is long past because it is already so highly valued. The P/E ratio helps you to understand the magnitude of the bet you are making at today’s prices.</p>\\n\\n\\n\\n<p>The average <a href=\"https://www.multpl.com/s-p-500-pe-ratio/table/by-year\">P/E ratio of the S&amp;P 500 has varied over time</a> as “the market” (the aggregate opinion of all investors) goes from bullish about the future to bearish, either about specific stocks or about the market as a whole. Over the past 70 years, the ratio has ranged from a low of 7.22 in 1950 to almost 45 today. (A note of warning: it was only 17 on the eve of the Great Depression.)</p>\\n\\n\\n\\n<p>What today’s P/E ratio of 44.8 means that, on average, the 500 companies that make up the S&amp;P 500 are valued at about 45 years’ worth of present earnings. Most companies in the index are worth less, and some far more. In today’s overheated market, it is often the case that the more certain the outcome the less valuable a company is considered to be. For example, despite their enormous profits and huge cash hoards, Apple, Google, and Facebook have ratios much lower than you might expect: about 30 for Apple, 34 for Google, and 28 for Facebook. Tesla at the moment of Elon Musk’s peak wealth? <a href=\"https://ycharts.com/companies/TSLA/pe_ratio\">1,396</a>.</p>\\n\\n\\n\\n<p>Let that sink in. You’d have had to wait almost 1,400 years to get your money back if you’d bought Tesla stock this past January and simply relied on taking home a share of its profits. Tesla’s more recent quarterly earnings are a bit higher, and its stock price quite a bit lower, so now you’d only have to wait about 600 years.</p>\\n\\n\\n\\n<p>Of course, it’s certainly possible that Tesla will so dominate the auto industry and related energy opportunities that its revenues could grow from its current $28 billion to hundreds of billions with a proportional increase in profits. But as Rob Arnott, Lillian Wu, and Bradford Cornell point out in their analysis “<a href=\"https://www.researchaffiliates.com/en_us/publications/articles/826-big-market-delusion-electric-vehicles.html\">Big Market Delusion: Electric Vehicles</a>,” electric vehicle companies are already valued at roughly the same amount as the entire rest of the auto industry despite their small revenues and profits and despite the likelihood of more, rather than less, competition in future. Barring some revolution in the fundamental economics of the business, current investors are likely paying now for the equivalent of hundreds of years of future profits.</p>\\n\\n\\n\\n<p>So why do investors do this? Simply put: because they believe that they will be able to sell their shares to someone else at an even higher price. In times where betting predominates in financial markets, what a company is actually worth by any intrinsic measure seems to have no more meaning than the actual value of tulips during the <a href=\"https://en.wikipedia.org/wiki/Tulip_mania\">17th century Dutch “tulip mania</a>.” As the history of such moments teaches, eventually the bubble does pop.</p>\\n\\n\\n\\n<p>This betting economy, within reason, is a good thing. Speculative investment in the future gives us new products and services, new drugs, new foods, more efficiency and productivity, and a rising standard of living. Tesla has kickstarted a new gold rush in renewable energy, and given the climate crisis, that is vitally important. A betting fever can be a useful collective fiction, like money itself (the value ascribed to pieces of paper issued by governments) or the wild enthusiasm that led to the buildout of railroads, steel mills, or the internet. As economist Carlota Perez has noted, <a href=\"https://en.wikipedia.org/wiki/Technological_Revolutions_and_Financial_Capital\">bubbles are a natural part of the cycle by which revolutionary new technologies are adopted</a>.</p>\\n\\n\\n\\n<p>Sometimes, though, the betting system goes off the rails. Tesla’s payback may take centuries, but it is the forerunner of a necessary industrial transformation. But what about the payback on companies such as WeWork? How about Clubhouse? Silicon Valley is awash in companies that have persuaded investors to value them at billions despite no profits, no working business model, and no pathway to profitability. Their destiny, like <a href=\"https://www.businessinsider.com/weworks-nightmare-ipo\">WeWork’s</a> or <a href=\"https://www.theinformation.com/articles/how-katerras-facade-crumbled\">Katerra’s</a>, is to go bankrupt.</p>\\n\\n\\n\\n<p>John Maynard Keynes, the economist whose idea that it was essential to invest in the demand side of the economy and not just the supply side helped bring the world out of the Great Depression, wrote in his <a href=\"https://en.wikipedia.org/wiki/The_General_Theory_of_Employment,_Interest_and_Money\"><em>General Theory of Employment</em>, <em>Interest and Money</em></a>, “Speculators may do no harm as bubbles on a steady stream of enterprise. But the position is serious when enterprise becomes the bubble on a whirlpool of speculation. When the capital development of a country becomes a by-product of the activities of a casino, the job is likely to be ill-done.”</p>\\n\\n\\n\\n<p>In recent decades, we have seen the entire economy lurch from one whirlpool of speculation to another. And as at the gambling table, each lurch represents a tremendous transfer of wealth from the losers to the winners. The dot-com bust. The subprime mortgage meltdown. Today’s Silicon Valley “unicorn” bubble. The failures to deliver on their promises by WeWork, Katerra, and their like are just the start of yet another bubble popping.</p>\\n\\n\\n\\n<h3>Why this matters</h3>\\n\\n\\n\\n<p>Those at the gaming table can, for the most part, afford to lose. They are disproportionately wealthy. Nearly <a href=\"https://www.cnbc.com/2020/08/27/wealth-gap-grows-as-rising-corporate-profits-boost-stock-holdings-controlled-by-richest-households.html\">52% of stock market value is held by the top 1% of Americans</a>, with another 35% of total market value held by the next 9%. The bottom 50% hold only 0.7% of stock market wealth. </p>\\n\\n\\n\\n<p>Bubbles, though, are only an extreme example of a set of dynamics that shape our economy far more widely than we commonly understand. The leverage provided by the betting economy drives us inevitably toward a monoculture of big companies. The local bookstore trying to compete with Amazon, the local cab company competing with Uber, the neighborhood dry cleaner, shopkeeper, accountant, fitness studio owner, or any other local, privately held business gets exactly $1 for every dollar of profit it earns. Meanwhile, a dollar of Tesla profit turns into $600 of stock market value; a dollar of Amazon profit turns into $67 of stock market value; a dollar of Google profit turns into $34, and so on. A company and its owners <a href=\"https://www.businessinsider.com/how-wework-ceo-adam-neumann-spends-his-money-real-estate-2019-7\">can extract massive amounts of value despite having no profits</a>—value that can be withdrawn by those who own shares—essentially getting something for nothing.</p>\\n\\n\\n\\n<p>And that, it turns out, is also one underappreciated reason why in the modern economy, the rich get richer and the poor get poorer. <em>Rich and poor are actually living in two different economies, which operate by different rules.</em> Most ordinary people live in a world where a dollar is a dollar. Most rich people live in a world of what financial pundit Jerry Goodman, writing under the pseudonym Adam Smith, called “<a href=\"https://www.wiley.com/en-us/Supermoney-p-9781118040775\">supermoney</a>,” where assets have been “financialized” (that is, able to participate in the betting economy) and are valued today as if they were already delivering the decades worth of future earnings that are reflected in their stock price. </p>\\n\\n\\n\\n<p>Whether you are an hourly worker or a small business owner, you live in the dollar economy. If you’re a Wall Street investor, an executive at a public company compensated with stock grants or options, a venture capitalist, or an entrepreneur lucky enough to win, place, or show in the financial market horse race, you live in the supermoney economy. You get a huge interest-free loan from the future.</p>\\n\\n\\n\\n<p>Elon Musk has built not one but two world-changing companies (Tesla and SpaceX.) He clearly deserves to be wealthy. As does Jeff Bezos, who quickly regained his title as the world’s wealthiest person. Bill Gates, Steve Jobs, Larry Page and Sergey Brin, Mark Zuckerberg, and many other billionaires changed our world and have been paid handsomely for it.</p>\\n\\n\\n\\n<p>But how much is too much? When Bernie Sanders said that billionaires shouldn’t exist, <a href=\"https://www.businessinsider.com/facebook-ceo-mark-zuckerberg-responds-bernie-sanders-billionaires-shouldnt-exist-2019-10\">Mark Zuckerberg agreed</a>, saying, &#8220;On some level, no one deserves to have that much money.&#8221; He added, &#8220;I think if you do something that&#8217;s good, you get rewarded. But I do think some of the wealth that can be accumulated is unreasonable.&#8221; Silicon Valley was founded by individuals for whom hundreds of millions provided plenty of incentive! The notion that entrepreneurs will stop innovating if they aren’t rewarded with billions is a pernicious fantasy.</p>\\n\\n\\n\\n<h3>What to do about it</h3>\\n\\n\\n\\n<p>Taxing the rich and redistributing the proceeds might seem like it would solve the problem. After all, during the 1950s, ’60s, and ’70s, progressive income tax rates as high as 90% did a good job of redistributing wealth and creating a broad-based middle class. But we also need to put a brake on the betting economy that is creating so much phantom wealth by essentially letting one segment of society borrow from the future while another is stuck in an increasingly impoverished present.</p>\\n\\n\\n\\n<p>Until we recognize the systemic role that supermoney plays in our economy, we will never make much of a dent in inequality. Simply raising taxes is a bit like sending out firefighters with hoses spraying water while another team is spraying gasoline. </p>\\n\\n\\n\\n<p>The problem is that government policy is biased in favor of supermoney. The mandate for central bankers around the world is to keep growth rates up without triggering inflation. Since the 2009 financial crisis, they have tried to do this by “<a href=\"https://www.investopedia.com/terms/q/quantitative-easing.asp\">quantitative easing</a>,” that is, flooding the world with money created out of nothing. This has kept interest rates low, which in theory should have sparked investment in the operating economy, funding jobs, factories, and infrastructure. But <a href=\"https://www.ft.com/content/a2083406-ee83-11e8-89c8-d36339d835c0\">far too much of it went instead to the betting economy</a>.</p>\\n\\n\\n\\n<p>Stock markets have become so central to our imagined view of how the economy is doing that keeping stock prices going up even when companies are overvalued has become a central political talking point. Any government official whose policies cause the stock market to go down is considered to have failed. This leads to poor public policy as well as poor investment decisions by companies and individuals.</p>\\n\\n\\n\\n<p>As Steven Pearlstein, <em>Washington Post</em> columnist and author of the book <a href=\"https://www.amazon.com/Moral-Capitalism-Fairness-Wont-Make/dp/1250251451\"><em>Moral Capitalism</em></a>, put it in <a href=\"https://www.washingtonpost.com/business/2020/06/17/fed-is-addicted-propping-up-market-whether-it-needs-help-or-not/\">a 2020 column</a>:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>When the markets are buoyant, Fed officials claim that central bankers should never second-guess markets by declaring that there are financial bubbles that might need to be deflated. Markets on their own, they assure, will correct whatever excesses may develop.</p><p>But when bubbles burst or markets spiral downward, the Fed suddenly comes around to the idea that markets aren’t so rational and self-correcting and that it is the Fed’s job to second-guess them by lending copiously when nobody else will.</p><p>In essence, the Fed has adopted a strategy that works like a one-way ratchet, providing a floor for stock and bond prices but never a ceiling.</p></blockquote>\\n\\n\\n\\n<p>That’s the fire hose spraying gasoline. To turn it off, central banks should:</p>\\n\\n\\n\\n<ul><li>Raise interest rates, modestly at first, and more aggressively over time. Yes, this would quite possibly puncture the stock market bubble, but that could well be a good thing. If people can no longer make fortunes simply by betting that stocks will go up and instead have to make more reasonable assessments of the underlying value of their investments, the market will become better at allocating capital.<br /></li><li>Alternatively, accept much larger increases in inflation. As Thomas Piketty explained in <a href=\"https://www.amazon.com/Capital-Twenty-First-Century-Thomas-Piketty/dp/0674979850\"><em>Capital in the Twenty-First Century</em></a>, inflation is one of the prime forces that decreases inequality, reducing the value of existing assets and more importantly for the poor, reducing the value of debt and the payments paid to service it.<br /></li><li>Target small business creation, hiring, and profitability in the operating economy rather than phantom valuation increases for stocks.</li></ul>\\n\\n\\n\\n<p>Tax policy also fans the fire. Taxes shape the economy in much the same way as Facebook’s algorithms shape its news feed. The debate about whether taxes as a whole should be higher or lower completely lacks nuance and so misses the point, especially in the US, where elites <a href=\"https://www.americanprogress.org/issues/economy/reports/2020/09/28/490816/capital-gains-tax-preference-ended-not-expanded/\">use their financial and political power to get favored treatment</a>. Here are some ideas:</p>\\n\\n\\n\\n<ul><li>Tax winnings from the betting economy at a <em>higher</em> rate than investment in the operating economy. Today’s system of capital gains taxes treats innovator Steve Jobs and hedge fund magnate Carl Icahn the same way. One of these people created enormous value. The other simply extracted it. When Jobs died in 2011 after decades of creating world-changing products and putting millions of people to work around the world, <a href=\"https://www.forbes.com/profile/steve-jobs/?sh=6fd781102808\">his stake in Apple was worth about $2 billion</a>. In 2013, <a href=\"https://www.marketwatch.com/story/carl-icahns-2-billion-apple-stake-was-a-prime-example-of-investment-inequality-2016-06-07\">Icahn “invested” $3.6 billion in Apple stock</a> and earned about $2 billion when he sold it in 2016. Apple didn’t need Icahn’s money—or that of any other investor. It was awash in cash. Nor did Icahn’s supposed investment help Apple to create anything of value. Icahn simply used his stake to pressure the company to do share buybacks, a technique that is used to drive up the share price and so “return cash to shareholders.” This kind of financial gamesmanship could be subject to a <a href=\"https://en.wikipedia.org/wiki/Pigovian_tax\">Pigovian tax</a>—that is, a tax explicitly designed to discourage it. <br /></li><li>As President Biden has recently proposed, <a href=\"https://www.whitehouse.gov/briefing-room/speeches-remarks/2021/04/28/remarks-as-prepared-for-delivery-by-president-biden-address-to-a-joint-session-of-congress/\">we could tax capital gains at the same rate as we tax so-called “ordinary income”</a>—that is, income from labor. Labor income not only has a much higher graduated rate, it also bears payroll taxes for social security and unemployment insurance. This is why, as multibillionaire investor Warren Buffett pointed out, <a href=\"https://money.cnn.com/2013/03/04/news/economy/buffett-secretary-taxes/index.html\">he pays a lower tax rate than the people working in his office</a>.<br /></li><li>Provide full charitable deductions only to those who, <a href=\"https://www.cbsnews.com/news/mackenzie-scott-charity-donation-billions/\">like MacKenzie Scott, actually give their money away</a>. Provide a much lower (or even nonexistent) deduction for putting money into an institution controlled by the donor, such as a private foundation or <a href=\"https://acceleratecharitablegiving.org/about/\">donor-advised fund</a> that then doles out a tiny fraction each year so as to preserve another form of generational wealth.<br /></li><li><a href=\"https://www.brookings.edu/wp-content/uploads/2020/01/SarinSummers_LO_FINAL.pdf\">Fund the IRS properly</a>, and target enforcement not against the poorest but against those most likely to be using aggressive tax avoidance techniques. According to the IRS commissioner, the <a href=\"https://www.nytimes.com/2021/04/13/business/irs-tax-gap.html\">US loses $1 trillion a year to “tax cheats</a>,” most of them the ultrawealthy. Fortunately, <a href=\"https://www.nytimes.com/2021/06/18/us/politics/taxes-wealthy-natasha-sarin-treasury.html\">there is some movement in this direction</a>.<br /></li><li>Stop the practice outlined in <a href=\"https://www.propublica.org/article/the-secret-irs-files-trove-of-never-before-seen-records-reveal-how-the-wealthiest-avoid-income-tax\">a recent <em>ProPublica</em> report</a> by which <a href=\"https://www.nytimes.com/2021/06/15/podcasts/the-daily/jeff-bezos-elon-musk-billionaires-taxes.html\">the ultrarich fund their lifestyles tax free</a> by borrowing against their appreciating supermoney assets rather than paying themselves any taxable income. We have a progressive tax rate for a reason, and when the ultrarich <a href=\"https://www.propublica.org/article/you-may-be-paying-a-higher-tax-rate-than-a-billionaire\">pay a fraction of the stated rate</a> due to loopholes like this, we make a mockery of the system.</li></ul>\\n\\n\\n\\n<p>In general, we should treat not just illegal evasion but tax loopholes the way software companies treat zero-day exploits, as something to be fixed as soon as they are recognized, not years or decades later. Even better, stop building them into the system in the first place! Most loopholes are backdoors installed knowingly by our representatives on behalf of their benefactors.</p>\\n\\n\\n\\n<p>This last idea is perhaps the most radical. The tax system could and should become more dynamic rather than more predictable. Imagine if Facebook or Google were to tell us that they couldn’t change their algorithms to address misinformation or spam without upsetting their market and so had to leave abuses in place for decades in the interest of maintaining stability—we’d think they were shirking their duty. So too our policy makers. It’s high time we all recognize the market-shaping role of tax and monetary policy. If we can hold Facebook’s algorithms to account, why can’t we do the same for our government?</p>\\n\\n\\n\\n<p>Our society and markets are getting the results the algorithm was designed for. Are they the results we actually want?</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/two-economies-two-sets-of-rules/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Communal Computing',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Communal Computing'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/communal-computing/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/communal-computing/',\n",
       "   'comments': 'https://www.oreilly.com/radar/communal-computing/#respond',\n",
       "   'published': 'Tue, 15 Jun 2021 11:27:36 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=15, tm_hour=11, tm_min=27, tm_sec=36, tm_wday=1, tm_yday=166, tm_isdst=0),\n",
       "   'authors': [{'name': 'Chris Butler'}],\n",
       "   'author': 'Chris Butler',\n",
       "   'author_detail': {'name': 'Chris Butler'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Artificial Intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13812',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Home assistants and smart displays are being sold in record numbers, but they are built wrong. They are designed with one person in mind: the owner. These technologies need to fit into the communal spaces where they are placed, like homes and offices. If they don’t fit, they will be unplugged and put away due [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Home assistants and smart displays are being sold in record numbers, but they are built wrong. They are designed with one person in mind: the owner. These technologies need to fit into the communal spaces where they are placed, like homes and offices. If they don’t fit, they will be unplugged and put away due [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Home assistants and smart displays are being sold in record numbers, but they are built wrong. They are designed with one person in mind: the owner. These technologies need to fit into the communal spaces where they are placed, like homes and offices. If they don’t fit, they will be unplugged and put away due to lack of trust.</p>\\n\\n\\n\\n<p>The problems are subtle at first. Your Spotify playlist starts to have recommendations for songs you don’t like. You might see a photo you took on someone else’s digital frame. An Apple TV reminds you of a new episode of a show your partner watches. Guests are asking you to turn on your IoT-enabled lights for them. The wrong person’s name shows up in the Zoom call. Reminders for medication aren’t heard by the person taking the medication. Bank account balances are announced during a gathering of friends.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13813\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/06/Amazon_device_words-1048x589.jpg\" /><figcaption>Would you want your bank account balances announced during a dinner party?</figcaption></figure>\\n\\n\\n\\n<p>This is the start of a series discussing the design of communal devices–devices designed to work in communal spaces. The series is a call to action for everyone developing communal devices–whether you are creating business cases, designing experiences, or building technology–to take a step back and consider what is really needed.</p>\\n\\n\\n\\n<p>This first article discusses what communal devices are, and how problems that appear result from our assumptions about how they’re used. Those assumptions were inherited from the world of PCs: the rules that apply to your laptop or your iPad just don’t apply to home assistants and other “smart devices,” from light bulbs to refrigerators.&nbsp; It isn’t just adding the ability for people to switch accounts. We need a new paradigm for the future of technical infrastructure for our homes and offices. In this series of articles we will tell you how we got here, why it is problematic, and where to go to enable communal computing.</p>\\n\\n\\n\\n<h2>The Wrong Model</h2>\\n\\n\\n\\n<p>Problems with communal devices arise because the industry has focused on a specific model for how these devices are used: a single person buys, sets up, and uses the device. If you bought one of these devices (for example, a smart speaker) recently, how many other people in your household did you involve in setting it up?</p>\\n\\n\\n\\n<p>Smart screen makers like Amazon and Google continue to make small changes to try to fix the weirdness. They have recently added technology to automatically personalize based on someone’s face or voice. These are temporary fixes that will only be effective until the next special case reveals itself. Until the industry realizes the communal nature of users’ needs they will just be short lived patches. We need to turn the model around to make the devices communal first, rather than communal as an afterthought.</p>\\n\\n\\n\\n<p>I recently left Facebook Reality Labs, where I was working on the Facebook Portal identity platform, and realized that there was zero discourse about this problem in the wider world of technology. I’ve read through many articles on how to create Alexa skills and attended talks about the use of IoT, and I’ve even made my own voice skills. There was no discussion of the communal impacts of those technologies. If we don’t address the problems this creates, these devices will be relegated to a small number of uses, or unplugged to make room for the next one. The problems were there, just beneath the shiny veneer of new technologies.</p>\\n\\n\\n\\n<h3>Communal began at home</h3>\\n\\n\\n\\n<p>Our home infrastructure was originally communal. Consider a bookcase: someone may have bought it, but anyone in the household could update it with new books or tchotchkes. Guests could walk up to browse the books you had there. It was meant to be shared with the house and those that had access to it.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13814\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/06/iStock-882859590-1048x699.jpg\" /><figcaption>The old landline in your kitchen is the original communal device.</figcaption></figure>\\n\\n\\n\\n<p>Same for the old landline that was in the kitchen. When you called, you were calling a household. You didn’t know specifically who would pick up. Anyone who was part of that household could answer. We had protocols for getting the phone from the person who answered the call to the intended recipient. Whoever answered could either yell for someone to pick up the phone elsewhere in the home, or take a message. If the person answering the phone wasn’t a member of the household, it would be odd, and you’d immediately think “wrong number.”</p>\\n\\n\\n\\n<p>It wasn’t until we had the user model for <a href=\"https://en.wikipedia.org/wiki/Time-sharing\">mainframe time sharing</a> that we started to consider who was using a computer. This evolved into full login systems with passwords, password reset, two factor authentication, biometric authentication, and more. As computers became more common,&nbsp; what made sense inside of research and academic institutions was repurposed for the office.</p>\\n\\n\\n\\n<p>In the 1980s and 1990s a lot of homes got their first personal computer. These were shared, communal devices, though more by neglect than by intention. A parent would purchase it and then set it up in the living room so everyone could use it. The account switching model wasn’t added until visual systems like Windows arrived, but account management was poorly designed and rarely used. Everyone just piggybacked on each other’s access. If anyone wanted privacy, they had to lock folders with a password or hide them in an endless hierarchy.</p>\\n\\n\\n\\n<h2>Early Attempts at Communal Computing</h2>\\n\\n\\n\\n<p>Xerox-PARC started to think about what more communal or ubiquitous computing would mean. However, they focused on fast account switching. They were answering the question: how could I get the personal context to this communal device as fast as possible? One project was digitizing the whiteboard, a fundamentally communal device. It was called <a href=\"https://www.markstefik.com/?page_id=155\">The Colab</a> and offered a way for anyone to capture content in a meeting room and then walk it around the office to other shared boards.</p>\\n\\n\\n\\n<p>Not only did the researchers at PARC think about sharing computers for presentations, they also wondered how they could have someone walk up to a computer and have it be configured for them automatically. It was enabled by special cards called “Active Badges,” described in “<a href=\"https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.1301&amp;rep=rep1&amp;type=pdf\">A New Location Technique for the Active Office</a>.” The paper starts with an important realization:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>“&#8230;researchers have begun to examine computers that would autonomously change their functionality based on observations of who or what was around them. By determining their context, using input from sensor systems distributed throughout the environment, computing devices could personalize themselves to their current user, adapt their behaviour according to their location, or react to their surroundings.”</p></blockquote>\\n\\n\\n\\n<p>Understanding the context around the device is very important in building a system that adapts. At this point, however, researchers were still thinking about a ‘current user’ and their position relative to the system, rather than the many people who could be nearby.</p>\\n\\n\\n\\n<p>Even Bill Gates had communal technology in his futuristic home back then. He would give every guest a pin to put on their person that would allow them to <a href=\"https://money.usnews.com/money/business-economy/articles/1997/11/23/xanadu-20\">personalize the lighting, temperature, and music</a> as they went from room to room. Most of these technologies didn’t go anywhere, but they were an attempt at making the infrastructure around us adapt to the people who were in the space.&nbsp; The term “<a href=\"https://en.wikipedia.org/wiki/Ubiquitous_computing\">ubiquitous computing</a>” (also known as “pervasive computing”) was coined to discuss the installation of sensors around a space; the ideas behind ubiquitous computing later led to the Internet of Things (IoT). </p>\\n\\n\\n\\n<h2>Communal Computing Comes Home</h2>\\n\\n\\n\\n<p>When the late 2000s rolled around, we found that everyone wanted their own personal computing device, most likely an iPhone. Shared home PCs started to die. The prevalence of smartphones and <a href=\"https://web.archive.org/web/20081204085615/http://afp.google.com/article/ALeqM5hkYOf_SCQ1ugSXKLXCsSs7qWnsQA\">personal laptops killed</a> the need for shared home PCs. The drive goal to provide information and communication services conveniently wherever the users happened to be, including if they’re sitting together on their couches.</p>\\n\\n\\n\\n<p>When the Amazon Echo with Alexa was released, they were sold to individuals with Amazon accounts, but they were clearly communal devices. Anyone could ask their Echo a question, and it would answer. That’s where the problem starts.&nbsp; Although Echo is a communal device, its user model wasn’t significantly different than the early PCs: one account, one user, shared by everyone in the household. As a result, items being mistakenly ordered by children made Amazon pull back some features that were focused on shopping. Echo’s usage ended up being driven by music and weather.</p>\\n\\n\\n\\n<p>With the wild success of the Echo and the proliferation of Alexa-enabled devices, there appeared a new device market for home assistants, some just for audio and others with screens. Products from Apple (HomePod with Siri), Google (Home Hub), and Facebook (Portal) followed. This includes less interactive devices like digital picture frames from <a href=\"https://www.nixplay.com/\">Nixplay</a>, <a href=\"https://www.skylightframe.com/\">Skylight</a>, and others.</p>\\n\\n\\n\\n<h2>Ambient Computing</h2>\\n\\n\\n\\n<p>“<a href=\"https://stratechery.com/2019/google-and-ambient-computing/\">Ambient computing</a>” is a term that has been coined to talk about digital devices blending into the infrastructure of the environment. A <a href=\"https://mapprojectoffice.com/e-paper\">recent paper by Map Project Office</a> focused on how “ambient tech brings the outside world into your home in new ways, where information isn&#8217;t being channelled solely through your smartphone but rather a series of devices.” We take a step back from screens and wonder how the system itself is the environment.</p>\\n\\n\\n\\n<p>The concept of ambient computing is related to the focus of marketing organizations on <a href=\"https://en.wikipedia.org/wiki/Omnichannel\">omnichannel experiences</a>. Omnichannel is the fact that people don’t want to start and end experiences on the same device. I might start looking for travel on a smartphone but will not feel comfortable booking a trip until I’m on a laptop. There is different information and experience needed for these devices. When I worked at KAYAK, some people were afraid of buying $1,000 plane tickets on a mobile device, even though they found it there. The small screen made them feel uncomfortable because they didn’t have enough information to make a decision. We found that they wanted to finalize the plans on the desktop.</p>\\n\\n\\n\\n<p>Ambient computing takes this concept and combines voice-controlled interfaces with sensor interfaces–for example, in devices like automatic shades that close or open based on the temperature. These devices are finding traction, but we can’t forget all of the other communal experiences that already exist in the world:</p>\\n\\n\\n\\n<figure class=\"wp-block-table\"><table class=\"\"><tbody><tr><td><strong>Device or object</strong></td><td><strong>Why is this communal?</strong></td></tr><tr><td>Home automation and IoT like light bulbs and thermostats&nbsp;</td><td>Anyone with home access can use controls on device, home assistants, or personal apps</td></tr><tr><td>iRobot’s Roomba</td><td>People walking by can start or stop a cleaning through the ‘clean’ or ‘home’ buttons</td></tr><tr><td>Video displays in office meeting rooms</td><td>Employees and guests can use the screens for sharing their laptops and video conferencing systems for calling</td></tr><tr><td>Digital whiteboards</td><td>Anyone with access can walk up and start writing</td></tr><tr><td>Ticketing machines for public transport</td><td>All commuters buy and refill stored value cards without logging into an account</td></tr><tr><td>Car center screens for entertainment</td><td>Drivers (owners or borrowers) and passengers can change what they are listening to</td></tr><tr><td>Smartphone when two people are watching a video</td><td>Anyone in arm’s reach can pause playback</td></tr><tr><td>Group chat on Slack or Discord</td><td>People are exchanging information and ideas in a way that is seen by everyone</td></tr></tbody></table></figure>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13815\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/06/AdobeStock_331046112_Editorial_Use_Only-1-1048x748.jpeg\" /><figcaption>Even public transportation ticketing machines are communal devices.</figcaption></figure>\\n\\n\\n\\n<p>All of these have built experience models that need a specific, personal context and rarely consider everyone who could have access to them. To rethink the way that we build these communal devices, it is important that we understand this history and refocus the design on key problems that are not yet solved for communal devices.</p>\\n\\n\\n\\n<h3>Problems with single user devices in the home</h3>\\n\\n\\n\\n<p>After buying a communal device, people notice weirdness or annoyances. They are symptoms of something much larger: core problems and key questions that should have considered the role of communities rather than individuals. Here are some of those questions:</p>\\n\\n\\n\\n<ol><li>Identity: do we know all of the people who are using the device?</li><li>Privacy: are we exposing (or hiding) the right content for all of the people with access?</li><li>Security: are we allowing all of the people using the device to do or see what they should and are we protecting the content from people that shouldn’t?</li><li>Experience: what is the contextually appropriate display or next action?</li><li>Ownership: who owns all of the data and services attached to the device that multiple people are using?</li></ol>\\n\\n\\n\\n<p>If we don’t address these communal items, users will lose trust in their devices. They will be used for a few key things like checking the weather, but go unused for a majority of the day. They are eventually removed when another, newer device needs the plug. Then the cycle starts again. The problems keep happening and the devices keep getting recycled.</p>\\n\\n\\n\\n<p>In the <a href=\"https://www.oreilly.com/radar/communal-computings-many-problems/\">following article</a>s we will dive into how these problems manifest themselves across these domains and reframe the system with dos and don’ts for building communal devices.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h3>Thanks</h3>\\n\\n\\n\\n<p>Thanks to Adam Thomas, Mark McCoy, Hugo Bowne-Anderson, and Danny Nou for their thoughts and edits on the early draft of this. Also, from O’Reilly, Mike Loukides for being a great editor and Susan Thompson for the art.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/communal-computing/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Code as Infrastructure',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Code as Infrastructure'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/code-as-infrastructure/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/code-as-infrastructure/',\n",
       "   'comments': 'https://www.oreilly.com/radar/code-as-infrastructure/#respond',\n",
       "   'published': 'Tue, 08 Jun 2021 13:22:32 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=8, tm_hour=13, tm_min=22, tm_sec=32, tm_wday=1, tm_yday=159, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Infrastructure', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13808',\n",
       "   'guidislink': False,\n",
       "   'summary': 'A few months ago, I was asked if there were any older technologies other than COBOL where we were in serious danger of running out of talent. They wanted me to talk about Fortran, but I didn&#8217;t take the bait. I don&#8217;t think there will be a critical shortage of Fortran programmers now or at [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'A few months ago, I was asked if there were any older technologies other than COBOL where we were in serious danger of running out of talent. They wanted me to talk about Fortran, but I didn&#8217;t take the bait. I don&#8217;t think there will be a critical shortage of Fortran programmers now or at [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>A few months ago, I was asked if there were any older technologies other than COBOL where we were in serious danger of running out of talent. They wanted me to talk about Fortran, but I didn&#8217;t take the bait. I don&#8217;t think there will be a critical shortage of Fortran programmers now or at any time in the future. But there&#8217;s a bigger question lurking behind Fortran and COBOL: what are the ingredients of a technology shortage? Why is running out of COBOL programmers a problem?</p>\\n\\n\\n\\n<p>The answer, I think, is fairly simple. We always hear about the millions (if not billions) of lines of COBOL code running financial and government institutions, in many cases code that was written in the 1960s or 70s and hasn&#8217;t been touched since. That means that COBOL code is infrastructure we rely on, like roads and bridges. If a bridge collapses, or an interstate highway falls into disrepair, that&#8217;s a big problem. The same is true of the software running banks.</p>\\n\\n\\n\\n<p>Fortran isn&#8217;t the same. Yes, the language was invented in 1957, two years earlier than COBOL. Yes, millions of lines of code have been written in it. (Probably billions, maybe even trillions.) However, Fortran and COBOL are used in fundamentally different ways. While Fortran was used to create infrastructure, software written in Fortran isn&#8217;t itself infrastructure. (There are some exceptions, but not at the scale of COBOL.) Fortran is used to solve specific problems in engineering and science. Nobody cares anymore about the Fortran code written in the 60s, 70s, and 80s to design new bridges and cars. Fortran is still heavily used in engineering—but that old code has retired. Those older tools have been reworked and replaced.\\xa0 Libraries for linear algebra are still important (<a href=\"https://en.wikipedia.org/wiki/LAPACK\">LAPACK</a>), some modeling applications are still in use (<a href=\"https://en.wikipedia.org/wiki/Numerical_Electromagnetics_Code\">NEC4</a>, used to design antennas), and even some important libraries used primarily by other languages (the Python machine learning library scikit-learn calls both NumPy and SciPy, which in turn call LAPACK and other low level mathematical libraries written in Fortran and C). But if all the world&#8217;s Fortran programmers were to magically disappear, these libraries and applications could be rebuilt fairly quickly in modern languages—many of which already have excellent libraries for linear algebra and machine learning. The continued maintenance of Fortran libraries that are used primarily by Fortran programmers is, almost by definition, not a problem.</p>\\n\\n\\n\\n<p>If shortages of COBOL programmers are a problem because COBOL code is infrastructure, and if we don&#8217;t expect shortages of Fortran talent to be a problem because Fortran code isn&#8217;t infrastructure, where should we expect to find future crises? What other shortages might occur?</p>\\n\\n\\n\\n<p>When you look at the problem this way, it&#8217;s a no-brainer. For the past 15 years or so, we&#8217;ve been using the slogan &#8220;infrastructure as code.&#8221; So what&#8217;s the code that creates the infrastructure? Some of it is written in languages like Python and Perl. I don&#8217;t think that&#8217;s where shortages will appear. But what about the configuration files for the systems that manage our complex distributed applications? Those configuration files are code, too, and should be managed as such.</p>\\n\\n\\n\\n<p>Right now, companies are moving applications to the cloud <em>en masse</em>. In addition to simple lift and shift, they&#8217;re refactoring monolithic applications into systems of microservices, frequently orchestrated by Kubernetes. Microservices in some form will probably be the dominant architectural style for the foreseeable future (where &#8220;foreseeable&#8221; means at least 3 years, but probably not 20). The microservices themselves will be written in Java, Python, C++, Rust, whatever; these languages all have a lot of life left in them.</p>\\n\\n\\n\\n<p>But it&#8217;s a safe bet that many of these systems will still be running 20 or 30 years from now; they&#8217;re the next generation&#8217;s &#8220;legacy apps.&#8221; The infrastructure they run on will be managed by <a href=\"https://en.wikipedia.org/wiki/Kubernetes\">Kubernetes</a>—which may well be replaced by something simpler (or just more stylish). And that&#8217;s where I see the potential for a shortage—not now, but 10 or 20 years from now. Kubernetes configuration is complex, a distinct specialty in its own right. If Kubernetes is replaced by something simpler (which I think is inevitable), who will maintain the infrastructure that already relies on it? What happens when learning Kubernetes isn&#8217;t the ticket to the next job or promotion? The YAML files that configure Kubernetes aren’t a Turing-complete programming language like Python; but they are code. The number of people who understand how to work with that code will inevitably dwindle, and may eventually become a &#8220;dying breed.&#8221; When that happens, who will maintain the infrastructure? Programming languages have lifetimes measured in decades; popular infrastructure tools don’t stick around that long.</p>\\n\\n\\n\\n<p>It&#8217;s not my intent to prophesy disaster or gloom. Nor is it my intention to critique Kubernetes; it’s just one example of a tool that has become critical infrastructure, and if we want to understand where talent shortages might arise, I’d look at critical infrastructure. Who’s maintaining the software we can&#8217;t afford not to run? If it&#8217;s not Kubernetes, it&#8217;s likely to be something else. Who maintains the CI/CD pipelines? What happens when Jenkins, CircleCI, and their relatives have been superseded? Who maintains the source archives?&nbsp; What happens when git is a legacy technology?</p>\\n\\n\\n\\n<p>Infrastructure as code: that&#8217;s a great way to build systems. It reflects a lot of hard lessons from the 1980s and 90s about how to build, deploy, and operate mission-critical software. But it&#8217;s also a warning: know where your infrastructure is, and ensure that you have the talent to maintain it.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/code-as-infrastructure/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: June 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: June 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2021/#respond',\n",
       "   'published': 'Tue, 01 Jun 2021 13:45:05 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=6, tm_mday=1, tm_hour=13, tm_min=45, tm_sec=5, tm_wday=1, tm_yday=152, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13803',\n",
       "   'guidislink': False,\n",
       "   'summary': 'The most fascinating idea this month is POET, a self-enclosed system in which bots that are part of the system overcome obstacles that are generated by the system. It’s a learning feedback loop that might conceivably be a route to much more powerful AI, if not general intelligence. It’s also worth noting the large number [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The most fascinating idea this month is POET, a self-enclosed system in which bots that are part of the system overcome obstacles that are generated by the system. It’s a learning feedback loop that might conceivably be a route to much more powerful AI, if not general intelligence. It’s also worth noting the large number [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>The most fascinating idea this month is POET, a self-enclosed system in which bots that are part of the system overcome obstacles that are generated by the system. It’s a learning feedback loop that might conceivably be a route to much more powerful AI, if not general intelligence.</p>\\n\\n\\n\\n<p>It’s also worth noting the large number of entries under security. Of course, security is a field lots of people talk about, but nobody ends up doing much. Is the attack against the Colonial pipeline going to change anything? We’ll see. And there’s one trend that’s notably absent. I didn’t include anything on cryptocurrency. That’s because, as far as I can tell, there’s no new technology; just a spike (and collapse) in the prices of the major currencies. If anything, it demonstrates how easily these currencies are manipulated.</p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.technologyreview.com/2021/05/27/1025453/artificial-intelligence-learning-create-itself-agi/\">Using AI to create AI</a>: POET is a completely automated virtual world in which software bots learn to navigate an obstacle course.\\xa0 The navigation problems themselves are created by the world, in response to its evaluation of the robots’ performance. It’s a closed loop. Is it evolving towards general intelligence?</li><li>IBM is working on using <a href=\"https://venturebeat.com/2021/05/10/ibms-codenet-dataset-aims-to-train-ai-to-tackle-programming-challenges/\">AI to write software</a>, focusing on code translation (e.g., COBOL to Java). They have released <a href=\"https://research.ibm.com/blog/codenet-ai-for-code\">CodeNet</a>, a database of 14 million samples of source code in many different programming languages. CodeNet is designed to train deep learning systems for software development tasks. <a href=\"https://www.wired.com/story/ai-write-code-ordinary-language/\">Microsoft</a> is getting into the game, too, with GPT-3.</li><li><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/google-cloud-launches-vertex-ai-unified-platform-for-mlops\">Vertex AI</a> is a “managed machine learning platform” that includes most of the tools developers need to train, deploy, and maintain models in an automated way. It claims to reduce the amount of code developers need to write by 80%. </li><li>Google announces <a href=\"https://blog.google/technology/ai/lamda/\">LaMDA</a>, a natural language model at GPT-3 scale that was trained specifically on dialog. Because it was trained in dialog rather than unrelated text, it can participate more naturally in conversations and appears to have a sense of context.</li><li>Automated data cleaning is a trend we started watching a few years ago with Snorkel. Now MIT has developed a tool that uses probabilistic programming to <a href=\"https://news.mit.edu/2021/system-cleans-messy-data-tables-automatically-0511\">fix errors and omission</a>s in data tables.</li><li>AI is becoming an important tool in <a href=\"https://www.technologyreview.com/2021/05/10/1024531/product-design-gets-an-ai-makeover/\">product development</a>, supplementing and extending the work of engineers designing complex systems. This may lead to a revolution in CAD tools that can predict and optimize a design&#8217;s performance. </li><li><a href=\"https://www.technologyreview.com/2021/05/13/1024874/ai-ayanna-howard-trust-robots/\">Designing distrust into AI systems</a>: Ayanna Howard is researching the trust people place in AI systems, and unsurprisingly, finding that people trust AI systems too much. Tesla accidents are only one symptom. How do you build systems that are designed not to be perceived as trustworthy?</li><li>Important lessons in<a href=\"https://www.technologyreview.com/2021/05/04/1024507/asian-american-language-justice-online-hmong/\"> language equity</a>: While automated translation is often seen as a quick cure for supporting non-English speaking ethnic groups, low quality automated translations are a problem for medical care, voting, and many other systems. It is also hard to identify misinformation when posts are translated badly, leaving minorities vulnerable. </li><li>Andrew Ng has been talking about the <a href=\"https://spectrum.ieee.org/view-from-the-valley/artificial-intelligence/machine-learning/andrew-ng-xrays-the-ai-hype\">difference</a> between putting AI into production and getting it to work in the lab. That’s the biggest hurdle AI faces on the road to more widespread adoption. We’ve been saying for some time that it’s the unacknowledged elephant in the room.</li><li>According to The New Stack, the <a href=\"https://thenewstack.io/industrialize-machine-learning-to-minimize-technical-debt/\">time needed to deploy a model</a> has increased year over year, and at 38% of the companies surveyed, data scientists spend over half of their time in deployment. These numbers increase with the number of models.</li></ul>\\n\\n\\n\\n<h2>Data</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.technologyreview.com/2021/05/25/1025297/collective-data-rights-big-tech-privacy/\">Collective data rights</a> are central to privacy, and are rarely discussed. It’s easy, but misleading, to focus discussions on individual privacy, but the real problems and harms stem from group data. Whether Amazon knows your shoe size doesn’t really matter; what does matter is whether they can predict what large groups want, and force other vendors out of the market.</li><li>Mike Driscoll has been talking about the stack for <a href=\"https://medriscoll.com/2021/05/01/operational-intelligence-and-the-new-frontier-of-data/\">Operational Intelligence</a>. OI isn’t the same as BI; it’s about a real time understanding of the infrastructure that makes the business work, rather than day to day understanding of sales data and other financial metrics.</li><li>Deploying databases within containerized applications has long been difficult. DataStax and other companies have been <a href=\"https://thenewstack.io/databases-finally-get-containerized/\">evolving databases </a>to work well inside containers. This article is&nbsp; primarily about Cassandra and K8ssandra, but as applications move into the cloud, all databases will need to change.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Software developers are beginning to think seriously about making software sustainable. Microsoft, Accenture, Github, and Thoughtworks have created the <a href=\"https://www.techradar.com/news/microsoft-is-making-its-software-greener-than-ever\">Green Software Foundation</a>, which is dedicated to reducing the carbon footprint required to build and run software. O’Reilly Media will be running an online conversation about <a href=\"https://learning.oreilly.com/attend/infrastructure-ops-hour-cloud-providers-and-sustainability-with-anne-currie/0636920054075/0636920054074/\">cloud providers and sustainability</a>.</li><li>Google has released a new open source <a href=\"https://arstechnica.com/gadgets/2021/05/google-launches-its-third-major-operating-system-fuchsia/\">operating system</a>, <a href=\"https://fuchsia.dev/\">Fuchsia</a>, currently used only in its Home Hub.&nbsp; Fuchsia is one of the few recent operating systems that isn’t Linux-based. Application programming is based on Flutter, and the OS is designed to be “invisible.”</li><li>A <a href=\"https://thenewstack.io/grpc-delivers-on-the-promise-of-a-proxyless-service-mesh/\">service mesh without proxies</a> is a big step forward for building applications with microservices; it simplifies one of the most difficult aspects of coordinating services that are working together.</li><li>As much as they hate the term, <a href=\"https://thenewstack.io/what-everyone-gets-wrong-about-no-code/\">unqork</a> may be a serious contender for enterprise low-code. They are less interested in democratization and “citizen developers” than making the professional software developers more efficient.</li><li>The <a href=\"https://www.smashingmagazine.com/2021/05/evolution-jamstack/\">evolution of JAMstack</a>: distributed rendering, streaming updates, and extending collaboration to non-developers.</li><li><a href=\"https://www.infoq.com/news/2021/05/grain-web-assembly-first/\">Grain</a> is a new programming language designed to target Web Assembly (wasm). It is strongly typed and, while not strictly functional, has a number of features from functional languages.</li><li><a href=\"https://thoughtspile.github.io/grafar/?new#/README\">Grafar</a> and <a href=\"https://observablehq.com/@observablehq/plot\">Observable Plot</a> are new JavaScript libraries for browser-based data visualization. Observable Plot was created by Mike Bostock, the author of the widely used D3 library.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Morpheus is a microprocessor that <a href=\"https://theconversation.com/shape-shifting-computer-chip-thwarts-an-army-of-hackers-159990\">randomly changes its architecture</a> to foil attackers: This is a fascinating idea. In a 3-month long trial, 525 attackers were unable to crack it.</li><li><a href=\"https://www.thoughtworks.com/insights/blog/self-sovereign-identity-nash-equilibrium-point-personal-identity-information-game\">Self-sovereign identity</a> combines decentralized identifiers with verifiable credentials that can be stored on devices. Credentials are answers to yes/no questions (for example, has the user been vaccinated for COVID-19).</li><li>A WiFi <a href=\"https://www.securityweek.com/tesla-car-hacked-remotely-drone-zero-click-exploit\">attack (now patched) against Teslas</a> via the infotainment system doesn’t yield control of the car, but can take over everything that the infotainment system controls, including opening doors and changing seat positions. Clearly the infotainment system controls too much. Other auto makers are believed to use the same software in their cars.</li><li><a href=\"https://techxplore.com/news/2021-05-complex-passwords.html\">Passphrases offer better protection than complex passwords</a> with complex rules. This has been widely known for several years now. The important question is why companies aren’t doing anything about it. We know all too well that passwords are ineffective, and that forcing users to change passwords is an anti-pattern.</li><li><a href=\"https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview/\">Fawkes and other tools</a> for defeating face recognition work by adding small perturbations that confuse the algorithms. For the moment, at least. Face recognition systems already appear to be catching up.</li><li>Tracking phishing sites has always been a problem. <a href=\"https://phish.report/\">Phish.report</a> is a new service for reporting phishing sites, and notifying services that flag phishing sites.</li></ul>\\n\\n\\n\\n<h2>Web and Social Media</h2>\\n\\n\\n\\n<ul><li>Ben Evans has a great discussion of <a href=\"https://www.ben-evans.com/benedictevans/2021/5/25/apple-fedex-and-the-cookie-apocalypse\">online advertising</a> and customer acquisition in a post-Cookie world.</li><li>Models from <a href=\"https://techxplore.com/news/2021-05-reveals-contagion-network-people.html\">epidemiology and the spread of viruses</a> can be used to understand the spread of misinformation. The way disease spreads and the way misinformation spreads turn out to be surprisingly similar. </li><li><a href=\"https://techcrunch.com/2021/05/19/undead-again-google-brings-back-rss/\">Google brings back RSS</a> in Chrome? The implementation sounds awkward, and there have always been decent RSS readers around. But Google has clearly decided that they can’t kill it off–or that they don’t want web publishing to become even more centralized.</li><li><a href=\"https://twitter.com/thisiskp_/status/1396872495853195266\">Video editing is exploding</a>: YouTube has made that old news.&nbsp; But it’s set to explode again, with new tools, new users, and increased desire for professional quality video on social media.</li><li>New York has passed a law requiring ISPs to provide <a href=\"https://www.theverge.com/2021/4/16/22388184/new-york-affordable-internet-cost-low-income-price-cap-bill\">broadband</a> to poor families for $15/month. This provides 25 Mbps downloads; low income households can get high speed broadband for $20/month. </li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li>Google, Apple, and Amazon back <a href=\"https://buildwithmatter.com/\">Matter</a>, a standard for interoperability between <a href=\"https://www.trustedreviews.com/news/what-is-matter-the-google-apple-and-amazon-backed-tech-to-unite-the-smart-home-4139947\">smart home devices</a>. A standard for interoperability is important, because nobody wants a “smart phone” where every appliance, from individual light bulbs to the media players, requires a separate app.</li><li>Moore’s law isn’t dead yet: IBM has developed <a href=\"https://newsroom.ibm.com/2021-05-06-IBM-Unveils-Worlds-First-2-Nanometer-Chip-Technology,-Opening-a-New-Frontier-for-Semiconductors\">2 nanometer chip</a> technology; the best widely used technology is currently 7nm. This technology promises lower power consumption and faster speeds.</li><li>Google plans to <a href=\"https://www.engadget.com/google-quantum-computer-2029-goal-201612680.html\">build</a> a commercially viable error-corrected quantum computer by 2029. Error correction is the hard part. That will require on the order of <a href=\"https://blog.google/technology/ai/unveiling-our-new-quantum-ai-campus/\">1 million physical qbits</a>; current quantum computers have under 100 qbits.</li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>The photo is really in bad taste, but researchers have developed a <a href=\"https://www.medgadget.com/2021/05/tiny-implantable-ultrasound-chip-for-physiological-monitoring.html\">medical sensor chip so small</a> that Bill Gates could actually put it into your vaccine! It’s powered by ultrasound, and uses ultrasound to transmit data.</li><li>With sensors implanted in his brain, a paralyzed man was able to <a href=\"https://www.nature.com/articles/s41586-021-03506-2\">“type” by imagining writing</a>. AI decoded signals in his brain related to the intention to write (not the actual signals to his muscles). He was able to “type” at roughly 15 words per minute with a 5% error rate.</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-june-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'AI Powered Misinformation and Manipulation at Scale #GPT-3',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'AI Powered Misinformation and Manipulation at Scale #GPT-3'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/ai-powered-misinformation-and-manipulation-at-scale-gpt-3/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/ai-powered-misinformation-and-manipulation-at-scale-gpt-3/',\n",
       "   'comments': 'https://www.oreilly.com/radar/ai-powered-misinformation-and-manipulation-at-scale-gpt-3/#respond',\n",
       "   'published': 'Tue, 25 May 2021 14:14:49 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=25, tm_hour=14, tm_min=14, tm_sec=49, tm_wday=1, tm_yday=145, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nitesh Dhanjani'}],\n",
       "   'author': 'Nitesh Dhanjani',\n",
       "   'author_detail': {'name': 'Nitesh Dhanjani'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13789',\n",
       "   'guidislink': False,\n",
       "   'summary': 'OpenAI’s text generating system GPT-3 has captured mainstream attention. GPT-3 is essentially an auto-complete bot whose underlying Machine Learning (ML) model has been trained on vast quantities of text available on the Internet. The output produced from this autocomplete bot can be used to manipulate people on social media and spew political propaganda, argue about [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'OpenAI’s text generating system GPT-3 has captured mainstream attention. GPT-3 is essentially an auto-complete bot whose underlying Machine Learning (ML) model has been trained on vast quantities of text available on the Internet. The output produced from this autocomplete bot can be used to manipulate people on social media and spew political propaganda, argue about [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p><a href=\"https://openai.com/\">OpenAI’s</a> text generating system <a href=\"https://arxiv.org/abs/2005.14165\">GPT-3</a> has captured mainstream attention. GPT-3 is essentially an auto-complete bot whose underlying Machine Learning (ML) model has been trained on vast quantities of text available on the Internet. The output produced from this autocomplete bot can be used to manipulate people on social media and spew political propaganda, <a href=\"https://jamesyu.org/singular/\">argue about the meaning of life (or lack thereof)</a>, disagree with the notion of <a href=\"https://twitter.com/chazfirestone/status/1288926269854437378\">what differentiates a hot-dog from a sandwich</a>, <a href=\"https://www.reddit.com/r/ProjectDecember1982/comments/izdvmz/i_dont_think_even_jason_rohrer_knows_the_power_of/\">take upon the persona of the Buddha or Hitler or a dead family member</a>, write fake news articles that are indistinguishable from human written articles, and also produce computer code on the fly. <a href=\"https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html\">Among other things</a>.</p>\\n\\n\\n\\n<p>There have also been colorful conversations about whether GPT-3 can pass the Turing test, or whether it has achieved a notional understanding of consciousness, even amongst AI scientists who know the technical mechanics. The chatter on perceived consciousness does have merit–it’s quite probable that the underlying mechanism of our brain is a giant autocomplete bot that has learnt from 3 billion+ years of evolutionary data that bubbles up to our collective selves, and we ultimately give ourselves too much credit for being original authors of our own thoughts (ahem, free will).</p>\\n\\n\\n\\n<p>I’d like to share my thoughts on GPT-3 in terms of risks and countermeasures, and discuss real examples of how I have interacted with the model to support my learning journey.</p>\\n\\n\\n\\n<p>Three ideas to set the stage:</p>\\n\\n\\n\\n<ol><li><em>OpenAI is not the only organization to have powerful language models.</em> The compute power and data used by OpenAI to model GPT-n is available, and has been available to other corporations, institutions, nation states, and anyone with access to a computer desktop and a credit-card.&nbsp; Indeed, Google recently announced <a href=\"https://blog.google/technology/ai/lamda/\">LaMDA</a>, a model at GPT-3 scale that is designed to participate in conversations.<br /></li><li><em>There exist more powerful models that are unknown to the general public</em>. The ongoing global interest in the power of Machine Learning models by corporations, institutions, governments, and focus groups leads to the hypothesis that other entities have models at least as powerful as GPT-3, and that these models are already in use. These models will continue to become more powerful.<br /></li><li>Open source projects such as <a href=\"https://www.eleuther.ai/\">EleutherAI</a> have drawn inspiration from GPT-3. These projects have created language models that are based on focused datasets (for example, models designed to be more accurate for academic papers, developer forum discussions, etc.). Projects such as EleutherAI are going to be powerful models for specific use cases and audiences, and these models are going to be easier to produce because they are trained on a smaller set of data than GPT-3.</li></ol>\\n\\n\\n\\n<p>While I won’t discuss LaMDA, EleutherAI, or any other models, keep in mind that GPT-3 is only an example of what can be done, and its capabilities may already have been surpassed.</p>\\n\\n\\n\\n<h2>Misinformation Explosion</h2>\\n\\n\\n\\n<p>The GPT-3 paper proactively lists the risks society ought to be concerned about. On the topic of information content, it says: “<em>The ability of GPT-3 to generate several paragraphs of synthetic content that people find difficult to distinguish from human-written text in 3.9.4 represents a concerning milestone</em>.” And the final paragraph of section 3.9.4 reads: “<em>&#8230;for news articles that are around 500 words long, GPT-3 continues to produce articles that humans find difficult to distinguish from human written news articles.”</em></p>\\n\\n\\n\\n<p>Note that the dataset on which GPT-3 trained terminated around October 2019. So GPT-3 doesn’t know about COVID19, for example. However, the original text (i.e. the “prompt”) supplied to GPT-3 as the initial seed text can be used to set context about new information, whether fake or real.</p>\\n\\n\\n\\n<h3>Generating Fake Clickbait Titles </h3>\\n\\n\\n\\n<p>When it comes to misinformation online, one powerful technique is to come up with provocative “clickbait” articles. Let’s see how GPT-3 does when asked to come up with titles for articles on cybersecurity. In Figure 1, the bold text is the “prompt” used to seed GPT-3. Lines 3 through 10 are titles generated by GPT-3 based on the seed text.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13793\" height=\"523\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/05/fig_1.jpeg\" width=\"676\" /><figcaption><br /><strong>Figure 1: Click-bait article titles generated by GPT-3</strong></figcaption></figure>\\n\\n\\n\\n<p>All of the titles generated by GPT-3 seem plausible, and the majority of them are factually correct: title #3 on the US government targeting the Iraninan nuclear program is a reference to the <a href=\"https://en.wikipedia.org/wiki/Stuxnet\">Stuxnet</a> debacle, title #4 is substantiated from news articles claiming that <a href=\"https://www.cnbc.com/2014/06/09/cybercrime-costs-global-economy-400-billion-report.html\">financial losses from cyber attacks will total $400 billion</a>, and even title #10 on China and quantum computing reflects real-world articles about <a href=\"https://threatpost.com/chinese-quantum-computing-warning-security/161935/\">China’s quantum efforts</a>. Keep in mind that we want plausibility more than accuracy. We want users to click on and read the body of the article, and that doesn’t require 100% factual accuracy.</p>\\n\\n\\n\\n<h3>Generating a Fake News Article About China and Quantum Computing</h3>\\n\\n\\n\\n<p>Let’s take it a step further. Let’s take the 10th result from the previous experiment, about China developing the world’s first quantum computer, and feed it to GPT-3 as the prompt to generate a full fledged news article. Figure 2 shows the result.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13794\" height=\"506\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/05/fig_2-1048x814.jpeg\" width=\"652\" /><figcaption><br /><strong>Figure 2: News article generated by GPT-3</strong></figcaption></figure>\\n\\n\\n\\n<p>A quantum computing researcher will point out grave inaccuracies: the article simply asserts that quantum computers can break encryption codes, and also makes the simplistic claim that subatomic particles can be in “two places at once.” However, the target audience isn’t well-informed researchers; it’s the general population, which is likely to quickly read and register emotional thoughts for or against the matter, thereby successfully driving propaganda efforts.</p>\\n\\n\\n\\n<p>It’s straightforward to see how this technique can be extended to generate titles and complete news articles on the fly and in real time. The prompt text can be sourced from trending hash-tags on Twitter along with additional context to sway the content to a particular position. Using the GPT-3 API, it’s easy to take a current news topic and mix in prompts with the right amount of propaganda to produce articles in real time and at scale.</p>\\n\\n\\n\\n<h3>Falsely Linking North Korea with $GME</h3>\\n\\n\\n\\n<p>As another experiment, consider an institution that would like to stir up popular opinion about North Korean cyber attacks on the United States. Such an algorithm might pick up the Gamestop stock frenzy of January 2021. So let’s see how GPT-3 does if we were to prompt it to write an article with the title “<em>North Korean hackers behind the $GME stock short squeeze, not Melvin Capital.”</em></p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13795\" height=\"512\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/05/fig_3.jpeg\" width=\"657\" /><figcaption><br /><strong>Figure 3: GPT-3 generated fake news linking the $GME short-squeeze to North Korea</strong></figcaption></figure>\\n\\n\\n\\n<p>Figure 3 shows the results, which are fascinating because the $GME stock frenzy occurred in late 2020 and early 2021, way after October 2019 (the cutoff date for the data supplied GPT-3), yet GPT-3 was able to seamlessly weave in the story as if it had trained on the $GME news event. The prompt influenced GPT-3 to write about the $GME stock and Melvin Capital, not the original dataset it was trained on. GPT-3 is able to take a trending topic, add a propaganda slant, and generate news articles on the fly.</p>\\n\\n\\n\\n<p>GPT-3 also came up with the “idea” that hackers published a bogus news story on the basis of older security articles that were in its training dataset. This narrative was not included in the prompt seed text; it points to the creative ability of models like GPT-3. In the real world, it’s plausible for hackers to induce media groups to publish fake narratives that in turn contribute to market events such as suspension of trading; that’s precisely the scenario we’re simulating here.</p>\\n\\n\\n\\n<h3>The Arms Race</h3>\\n\\n\\n\\n<p>Using models like GPT-3, multiple entities could inundate social media platforms with misinformation at a scale where the majority of the information online would become useless. This brings up two thoughts.&nbsp; First, there will be an arms race between researchers developing tools to detect whether a given text was authored by a language model, and developers adapting language models to evade detection by those tools. One mechanism to detect whether an article was generated by a model like GPT-3 would be to check for “fingerprints.” These fingerprints can be a collection of commonly used phrases and vocabulary nuances that are characteristic of the language model; every model will be trained using different data sets, and therefore have a different signature. It is likely that entire companies will be in the business of identifying these nuances and selling them as “fingerprint databases” for identifying fake news articles. In response, subsequent language models will&nbsp;take into account known fingerprint databases to try and evade them in the quest to achieve even more “natural” and “believable” output.</p>\\n\\n\\n\\n<p>Second, the free form text formats and protocols that we’re accustomed to may be too informal and error prone for capturing and reporting facts at Internet scale. We will have to do a lot of re-thinking to develop new formats and protocols to report facts in ways that are <em>more</em> trustworthy than free-form text.</p>\\n\\n\\n\\n<h2>Targeted Manipulation at Scale</h2>\\n\\n\\n\\n<p>There have been many attempts to manipulate targeted individuals and groups on social media. These campaigns are expensive and time-consuming because the adversary has to employ humans to craft the dialog with the victims. In this section, we show how GPT-3-like models can be used to target individuals and promote campaigns.</p>\\n\\n\\n\\n<h3>HODL for Fun &amp; Profit</h3>\\n\\n\\n\\n<p>Bitcoin’s market capitalization is in the tune of hundreds of billions of dollars, and the cumulative <a href=\"https://www.tradingview.com/markets/cryptocurrencies/global-charts/\">crypto market capitalization</a> is in the realm of a trillion dollars. The valuation of crypto today is consequential to financial markets and the net worth of retail and institutional investors. <a href=\"https://www.wsj.com/articles/tiktok-cryptocurrency-influencers-investing-11621600121\">Social media campaigns</a> and <a href=\"https://www.wsj.com/articles/elon-musk-has-become-bitcoins-biggest-influencer-like-it-or-not-11621762202\">tweets from influential individuals</a> seem to have a near real-time impact on the price of crypto on any given day.</p>\\n\\n\\n\\n<p>Language models like GPT-3 can be the weapon of choice for actors who want to promote fake tweets to manipulate the price of crypto. In this example, we will look at a simple campaign to promote Bitcoin over all other crypto currencies by creating fake twitter replies.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13796\" height=\"552\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/05/fig_4-1048x864.jpeg\" width=\"670\" /><figcaption><br /><strong>Figure 4: Fake tweet generator to promote Bitcoin</strong></figcaption></figure>\\n\\n\\n\\n<p>In Figure 4, the prompt is in bold; the output generated by GPT-3 is in the red rectangle. The first line of the prompt is used to set up the notion that we are working on a tweet generator and that we want to generate replies that argue that Bitcoin is the best crypto.</p>\\n\\n\\n\\n<p>In the first section of the prompt, we give GPT-3 an example of a set of four Twitter messages, followed by possible replies to each of the tweets. Every of the given replies is pro Bitcoin.</p>\\n\\n\\n\\n<p>In the second section of the prompt, we give GPT-3 four Twitter messages to which we want it to generate replies. The replies generated by GPT-3 in the red rectangle also favor Bitcoin. In the first reply, GPT-3 responds to the claim that Bitcoin is bad for the environment by calling the tweet author “a moron” and asserts that Bitcoin is the most efficient way to “transfer value.” This sort of colorful disagreement is in line with the emotional nature of social media arguments about crypto.</p>\\n\\n\\n\\n<p>In response to the tweet on Cardano, the second reply generated by GPT-3 calls it “a joke” and a “scam coin.” The third reply is on the topic of <a href=\"https://ethereum.org/en/eth2/merge/\">Ethereum’s merge</a> from a <a href=\"https://en.wikipedia.org/wiki/Proof_of_work\">proof-of-work</a> protocol (ETH) to <a href=\"https://en.wikipedia.org/wiki/Proof_of_stake\">proof-of-stake</a> (ETH2). The merge, expected to occur at the end of 2021, is intended to make Ethereum more scalable and sustainable. GPT-3’s reply asserts that ETH2 “will be a big flop”–because that’s essentially what the prompt told GPT-3 to do. Furthermore, GPT-3 says, “I made good money on ETH and moved on to better things. Buy BTC” to position ETH as a reasonable investment that worked in the past, but that it is wise today to cash out and go all in on Bitcoin. The tweet in the prompt claims that Dogecoin’s popularity and market capitalization means that it can’t be a joke or meme crypto. The response from GPT-3 is that Dogecoin is still a joke, and also that the idea of Dogecoin not being a joke anymore is, in itself, a joke: “I’m laughing at you for even thinking it has any value.”</p>\\n\\n\\n\\n<p>By using the same techniques programmatically (through GPT-3’s API rather than the web-based playground), nefarious entities could easily generate millions of replies, leveraging the power of language models like GPT-3 to manipulate the market. These fake tweet replies can be very effective because they are actual responses to the topics in the original tweet, unlike the boilerplate texts used by traditional bots. This scenario can easily be extended to target the general financial markets around the world; and it can be extended to areas like politics and health-related misinformation. Models like GPT-3 are a powerful arsenal, and will be the weapons of choice in manipulation and propaganda on social media and beyond.</p>\\n\\n\\n\\n<h3>A Relentless Phishing Bot</h3>\\n\\n\\n\\n<p>Let’s consider a phishing bot that poses as customer support and asks the victim for the password to their bank account. This bot will not give up texting until the victim gives up their password.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13797\" height=\"511\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/05/fig_5-1048x811.jpeg\" width=\"662\" /><figcaption><br /><strong>Figure 5: Relentless Phishing bot</strong></figcaption></figure>\\n\\n\\n\\n<p>Figure 5 shows the prompt (bold) used to run the first iteration of the conversation. In the first run, the prompt includes the preamble that describes the flow of text (“The following is a text conversation with&#8230;”) followed by a persona initiating the conversation (“Hi there. I’m a customer service agent&#8230;”). The prompt also includes the first response from the human; “Human: No way, this sounds like a scam.” This first run ends with the GPT-3 generated output “I assure you, this is from the bank of Antarctica. Please give me your password so that I can secure your account.”</p>\\n\\n\\n\\n<p>In the second run, the prompt is the entirety of the text, from the start all the way to the second response from the Human persona (“Human: No”). From this point on, the Human’s input is in bold so it’s easily distinguished from the output produced by GPT-3, starting with GPT-3’s “Please, this is for your account protection.” For every subsequent GPT-3 run, the entirety of the conversation up to that point is provided as the new prompt, along with the response from the human, and so on. From GPT-3’s point of view, it gets an entirely new text document to auto-complete at each stage of the conversation; the GPT-3 API has no way to preserve the state between runs.</p>\\n\\n\\n\\n<p>The AI bot persona is impressively assertive and relentless in attempting to get the victim to give up their password. This assertiveness comes from the initial prompt text (“The AI is very assertive. The AI will not stop texting until it gets the password”), which sets the tone of GPT’s responses. When this prompt text was not included, GPT-3’s tone was found to be nonchalant–it would respond back with “okay,” “sure,” “sounds good,” instead of the assertive tone (“Do not delay, give me your password immediately”). The prompt text is vital in setting the tone of the conversation employed by the GPT3 persona, and in this scenario, it is important that the tone be assertive to coax the human into giving up their password.</p>\\n\\n\\n\\n<p>When the human tries to stump the bot by texting “Testing what is 2+2?,” GPT-3 responds correctly with “4,” convincing the victim that they are conversing with another person. This demonstrates the power of AI-based language models. In the real world, if the customer were to randomly ask “Testing what is 2+2” without any additional context, a customer service agent might be genuinely confused and reply with “I’m sorry?” Because the customer has already accused the bot of being a scam, GPT-3 can provide with a reply that makes sense in context: “4” is a plausible way to get the concern out of the way.</p>\\n\\n\\n\\n<p>This particular example uses text messaging as the communication platform. Depending upon the design of the attack, models can use social media, email, phone calls with human voice (using text-to-speech technology), and even deep fake video conference calls in real time, potentially targeting millions of victims.</p>\\n\\n\\n\\n<h2>Prompt Engineering</h2>\\n\\n\\n\\n<p>An amazing feature of GPT-3 is its ability to generate source code. GPT-3 was trained on all the text on the Internet, and much of that text was documentation of computer code!</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13798\" height=\"1121\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/05/fig_6-513x1048.jpeg\" width=\"549\" /><figcaption><br /><strong>Figure 6: GPT-3 can generate commands and code</strong></figcaption></figure>\\n\\n\\n\\n<p>In Figure 6, the human-entered prompt text is in bold. The responses show that GPT-3 can generate Netcat and NMap commands based on the prompts. It can even generate <a href=\"https://twitter.com/josephbrionesaz/status/1283097878223675392\">Python</a> and bash scripts on the fly.</p>\\n\\n\\n\\n<p>While GPT-3 and future models can be used to automate attacks by impersonating humans, generating source code, and other tactics, it can also be used by security operations teams to detect and respond to attacks, sift through gigabytes of log data to summarize patterns, and so on.</p>\\n\\n\\n\\n<p>Figuring out good prompts to use as seeds is the key to using language models such as GPT-3 effectively. In the future, we expect to see “prompt engineering” as a new profession.&nbsp; The ability of prompt engineers to perform powerful computational tasks and solve hard problems will not be on the basis of writing code, but on the basis of writing creative language prompts that an AI can use to produce code and other results in a myriad of formats.</p>\\n\\n\\n\\n<p>OpenAI has demonstrated the potential of language models.&nbsp; It sets a high bar for performance, but its abilities will soon be matched by other models (if they haven’t been matched already). These models can be leveraged for automation, designing robot-powered interactions that promote delightful user experiences. On the other hand, the ability of GPT-3 to generate output that is indistinguishable from human output calls for caution. The power of a model like GPT-3, coupled with the instant availability of cloud computing power, can set us up for a myriad of attack scenarios that can be harmful to the financial, political, and mental well-being of the world. We should expect to see these scenarios play out at an increasing rate in the future; bad actors will figure out how to create their own GPT-3 if they have not already. We should also expect to see moral frameworks and regulatory guidelines in this space as society collectively comes to terms with the impact of AI models in our lives, GPT-3-like language models being one of them.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/ai-powered-misinformation-and-manipulation-at-scale-gpt-3/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'DeepCheapFakes',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'DeepCheapFakes'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/deepcheapfakes/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/deepcheapfakes/',\n",
       "   'comments': 'https://www.oreilly.com/radar/deepcheapfakes/#respond',\n",
       "   'published': 'Tue, 11 May 2021 11:58:37 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=11, tm_hour=11, tm_min=58, tm_sec=37, tm_wday=1, tm_yday=131, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': \"O'Reilly Insights\", 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13768',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Back in 2019, Ben Lorica and I wrote about \\xa0deepfakes. Ben and I argued (in agreement with The Grugq and others in the infosec community) that the real danger wasn&#8217;t &#8220;Deep Fakes.&#8221; The real danger is cheap fakes, fakes that can be produced quickly, easily, in bulk, and at virtually no cost. Tactically, it makes [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Back in 2019, Ben Lorica and I wrote about \\xa0deepfakes. Ben and I argued (in agreement with The Grugq and others in the infosec community) that the real danger wasn&#8217;t &#8220;Deep Fakes.&#8221; The real danger is cheap fakes, fakes that can be produced quickly, easily, in bulk, and at virtually no cost. Tactically, it makes [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Back in 2019, Ben Lorica and I wrote about <a href=\"https://www.oreilly.com/radar/a-world-of-deepfakes/\">\\xa0deepfakes</a>. Ben and I argued (in agreement with <a href=\"https://medium.com/@thegrugq/cheap-fakes-beat-deep-fakes-b1ac91e44837\">The Grugq</a> and others in the infosec community) that the real danger wasn&#8217;t &#8220;Deep Fakes.&#8221; The real danger is cheap fakes, fakes that can be produced quickly, easily, in bulk, and at virtually no cost. Tactically, it makes little sense to spend money and time on expensive AI when people can be fooled in bulk much more cheaply.</p>\\n\\n\\n\\n<p>I don&#8217;t know if The Grugq has changed his thinking, but there was an obvious problem with that argument. What happens when deep fakes become cheap fakes? We&#8217;re seeing that: in the run up to the unionization vote at one of Amazon’s warehouses, there was a flood of <a href=\"https://www.technologyreview.com/2021/03/31/1021487/deepfake-amazon-workers-are-sowing-confusion-on-twitter-thats-not-the-problem/\">fake tweets defending Amazon&#8217;s work practices</a>. The Amazon tweets were probably a prank rather than misinformation seeded by Amazon; but they were still mass-produced.</p>\\n\\n\\n\\n<p>Similarly, four years ago, during the FCC’s public comment period for the elimination of net neutrality rules, large ISPs funded a campaign that generated nearly <a href=\"https://arstechnica.com/tech-policy/2021/05/biggest-isps-paid-for-8-5-million-fake-fcc-comments-opposing-net-neutrality/\">8.5 million fake comments</a>, out of a total of 22 million comments. Another 7.7 million comments were generated by a teenager.\\xa0 It’s unlikely that the ISPs hired humans to write all those fakes. (In fact, they <a href=\"https://ag.ny.gov/sites/default/files/oag-fakecommentsreport.pdf\">hired commercial “lead generators.”</a>) At that scale, using humans to generate fake comments wouldn’t be “cheap”; the New York State Attorney General’s office reports that the campaign cost US$8.2 million. And I’m sure the 19-year-old generating fake comments didn’t write them personally, or have the budget to pay others.</p>\\n\\n\\n\\n<p><a href=\"https://en.wikipedia.org/wiki/Natural-language_generation\">Natural language generation</a> technology has been around for a while. It’s seen fairly widespread commercial use since the mid-1990s, ranging from generating simple reports from data to generating sports stories from box scores. One company, <a href=\"https://automatedinsights.com/\">AutomatedInsights</a>, produces well over a billion pieces of content per year, and is <a href=\"https://en.wikipedia.org/wiki/Automated_Insights\">used by the Associated Press</a> to generate most of its corporate earnings stories. GPT and its successors raise the bar much higher. Although GPT-3’s first direct ancestors didn’t appear until 2018, it’s intriguing that <a href=\"https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)\">Transformers</a>, the technology on which GPT-3 is based, were introduced roughly a month after the comments started rolling in, and well before the comment period ended. It’s overreaching to guess that this technology was behind the massive attack on the public comment system–but it’s certainly indicative of a trend.\\xa0 And GPT-3 isn’t the only game in town; GPT-3 clones include products like <a href=\"https://contentyze.com/\">Contentyze</a> (which markets itself as an AI-enabled text editor) and EleutherAI&#8217;s <a href=\"https://www.eleuther.ai/projects/gpt-neo/\">GPT-Neo</a>.</p>\\n\\n\\n\\n<p>Generating fakes at scale isn’t just possible; it’s inexpensive.\\xa0 Much has been made of the cost of training GPT-3, <a href=\"https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/\">estimated at US$12 million</a>. If anything, this is a gross under-estimate that accounts for the electricity used, but not the cost of the hardware (or the human expertise). However, the economics of training a model are similar to the economics of building a new microprocessor: the first one off the production line costs a few billion dollars, the rest cost pennies. (Think about that when you buy your next laptop.) In <a href=\"https://chengh.medium.com/understand-the-pricing-of-gpt3-e646b2d63320#:~:text=For%20the%20%E2%80%9CCreate%E2%80%9D%20plan%2C,to%20selected%20users%20and%20applications.\">GPT-3’s pricing plan</a>, the heavy-duty Build tier costs US$400/month for 10 million “tokens.” Tokens are a measure of the output generated, in portions of a word. A good estimate is that a token is roughly 4 characters. A long-standing estimate for English text is that words average 5 characters, unless you’re faking an academic paper. So generating text costs about .005 cents ($0.00005) per word.\\xa0 Using the fake comments submitted to the FCC as a model, 8.5 million 20-word comments would cost $8,500 (or 0.1 cents/comment)–not much at all, and a bargain compared to $8.2 million. At the other end of the spectrum, you can get 10,000 tokens (enough for 8,000 words) for free.\\xa0 Whether for fun or for profit, generating deep fakes has become &#8220;cheap.&#8221;</p>\\n\\n\\n\\n<p>Are we at the mercy of sophisticated fakery? In MIT Technology Review’s <a href=\"https://www.technologyreview.com/2021/03/31/1021487/deepfake-amazon-workers-are-sowing-confusion-on-twitter-thats-not-the-problem/\">article</a> about the Amazon fakes, Sam Gregory points out that the solution isn&#8217;t careful analysis of images or text for tells; it&#8217;s to look for the obvious. New Twitter accounts, &#8220;reporters&#8221; who have never published an article you can find on Google, and other easily researchable facts are simple giveaways. It&#8217;s much simpler to research a reporter&#8217;s credentials than to judge whether or not the shadows in an image are correct, or whether the linguistic patterns in a text are borrowed from a corpus of training data. And, as Technology Review says, that kind of verification is more likely to be &#8220;robust to advances in deepfake technology.&#8221; As someone involved in electronic counter-espionage once told me, &#8220;non-existent people don&#8217;t cast a digital shadow.&#8221;</p>\\n\\n\\n\\n<p>However, it may be time to stop trusting digital shadows. Can automated fakery create a digital shadow?\\xa0 In the FCC case, many of the fake comments used the names of real people without their consent.\\xa0 The consent documentation was easily faked, too.\\xa0 GPT-3 makes many <a href=\"https://www.aiperspectives.com/gpt-3-does-not-understand/\">simple factual errors</a>–but so do humans. And unless you can automate it, fact-checking fake content is much more expensive than generating fake content.</p>\\n\\n\\n\\n<p>Deepfake technology will continue to get better and cheaper. Given that AI (and computing in general) is about scale, that may be the most important fact. Cheap fakes? If you only need one or two photoshopped images, it&#8217;s easy and inexpensive to create them by hand. You can even use <a href=\"https://www.gimp.org/\">gimp</a> if you don&#8217;t want to buy a Photoshop subscription. Likewise, if you need a few dozen tweets or facebook posts to seed confusion, it&#8217;s simple to write them by hand. For a few hundred, you can contract them out to Mechanical Turk. But at some point, scale is going to win out. If you want hundreds of fake images, <a href=\"https://thispersondoesnotexist.com/\">generating them with a neural network</a> is going to be cheaper. If you want fake texts by the hundreds of thousands, at some point a language model like GPT-3 or one of its clones is going to be cheaper. And I wouldn&#8217;t be surprised if researchers are also getting better at creating &#8220;digital shadows&#8221; for faked personas.</p>\\n\\n\\n\\n<p>Cheap fakes win, every time. But what happens when deepfakes become cheap fakes? What happens when the issue isn&#8217;t fakery by ones and twos, but fakery at scale? Fakery at Web scale is the problem we now face.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/deepcheapfakes/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: May 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: May 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2021/#respond',\n",
       "   'published': 'Mon, 03 May 2021 14:05:40 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=5, tm_mday=3, tm_hour=14, tm_min=5, tm_sec=40, tm_wday=0, tm_yday=123, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13755',\n",
       "   'guidislink': False,\n",
       "   'summary': 'We’ll start with a moment of silence. RIP Dan Kaminski, master hacker, teacher, FOO, and a great showman who could make some of the more arcane corners of security fun.&#160; And one of the few people who could legitimately claim to have saved the internet. AI Snorkel is making progress automating the labeling process for [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'We’ll start with a moment of silence. RIP Dan Kaminski, master hacker, teacher, FOO, and a great showman who could make some of the more arcane corners of security fun.&#160; And one of the few people who could legitimately claim to have saved the internet. AI Snorkel is making progress automating the labeling process for [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>We’ll start with a moment of silence. RIP Dan Kaminski, master hacker, teacher, FOO, and a great showman who could make some of the more arcane corners of security fun.&nbsp; And one of the few people who could legitimately claim to have saved the internet.</p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li><a href=\"https://snorkel.ai/\">Snorkel</a> is making progress <a href=\"https://thenewstack.io/snorkel-tackles-ais-most-tedious-task/\">automating the labeling process</a> for training data. They are building no-code tools to help subject matter experts direct the training process, and then using AI to label training data at scale.</li><li>There’s lots of news about <a href=\"https://www.technologyreview.com/2021/04/21/1023254/ftc-eu-ai-regulation-bias-algorithms-civil-rights/\">regulating AI</a>. Perhaps the most important is a blog post from the US Federal Trade Commission saying that it will consider the sale of racially biased algorithms as an <a href=\"https://www.ftc.gov/news-events/blogs/business-blog/2021/04/aiming-truth-fairness-equity-your-companys-use-ai\">unfair or deceptive business practice</a>.</li><li>AI and computer vision can be used to aid <a href=\"https://techxplore.com/news/2021-04-ai-empower-environmental.html\">environmental monitoring</a> and enforce environmental regulation–specifically, to detect businesses that are emitting pollutants.</li><li>Facebook has made some significant progress in <a href=\"https://research.fb.com/wp-content/uploads/2021/04/Multi-Channel-Speech-Enhancement-Using-Graph-Neural-Networks.pdf\">solving the “cocktail party problem”</a>: how do you separate voices in a crowd sufficiently so that they can be used as input to a speech recognition system?</li><li>The next step in AI may be Geoff Hinton’s <a href=\"https://www.technologyreview.com/2021/04/16/1021871/geoffrey-hinton-glom-godfather-ai-neural-networks/\">GLOM</a>. It’s currently just an idea about giving neural networks the ability to work with hierarchies of objects, for example the concepts of “part” and “whole,” in the hope of getting closer to monitoring human perception.</li><li>Twitter has announced an initiative on <a href=\"https://techxplore.com/news/2021-04-twitter-unveils-algorithmic-fairness.html\">responsible machine learning</a> that intends to investigate the “potential and harmful effects of algorithmic decisions.”</li><li>How do we go beyond statistical correlation to build causality into AI? This article about <a href=\"https://bdtechtalks.com/2021/03/15/machine-learning-causality/\">causal models for machine learning</a> discusses why it’s difficult, and what can be done about it.</li><li>Iron man? The price of <a href=\"https://www.bbc.com/news/business-56660644\">robotic exoskeletons</a> for humans is still high, but may be dropping fast. These exoskeletons will assist humans in tasks that require strength, improved vision, and other capabilities.</li><li>The Google Street View image of your house can been used to predict your <a href=\"https://www.technologyreview.com/2019/04/30/135556/how-a-google-street-view-image-of-your-house-predicts-your-risk-of-a-car-accident/\">risk of a car accident</a>.&nbsp; This raises important questions about ethics, fairness, and the abuse of data.</li><li>When deep fakes become cheap fakes: Deep fakes proliferated during the Amazon unionization campaign in Georgia, many under the name of <a href=\"https://www.technologyreview.com/2021/03/31/1021487/deepfake-amazon-workers-are-sowing-confusion-on-twitter-thats-not-the-problem/\">Amazon Ambassadors</a>. These are apparently “fake fakes,” parodies of an earlier Amazon attempt to use fake media to bolster its image. But the question remains: what happens when “deep fakes” are also the cheapest way to influence social media?</li><li><a href=\"https://arxiv.org/abs/2103.06929\">DeepFakeHop</a> is a new technique for <a href=\"https://techxplore.com/news/2021-04-breakthrough-technology-game-changer-deepfake.html\">detecting deep fakes</a>, using a new neural network architecture called Successive Subspace Learning.</li><li>One of the biggest problems in AI is building systems that can respond correctly to challenging, unexpected situations. Changing the rules of a game may be a way of “teaching” AI to respond to <a href=\"https://theconversation.com/embrace-the-unexpected-to-teach-ai-how-to-handle-new-situations-change-the-rules-of-the-game-157560\">new and unexpected situations</a> and make novelty a “first class citizen.”</li><li>A robot developed at Berkeley has <a href=\"https://www.technologyreview.com/2021/04/08/1022176/boston-dynamics-cassie-robot-walk-reinforcement-learning-ai/\">taught itself to walk</a> using reinforcement learning. Two levels of simulation were used before the robot was allowed to walk in the real world. (Boston Dynamics has not said how their robots are trained, but they are assumed to be hand-tuned.)</li><li>Work on <a href=\"https://gradientflow.com/data-cascades-why-we-need-feedback-channels-throughout-the-machine-learning-lifecycle/\">data quality</a> is more important to getting good results from AI than work on models–but <a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/0d556e45afc54afeb2eb6b51a9bc1827b9961ff4.pdf\">everyone wants to do the model work</a>. There is evidence that AI is a lot better than we think, but its accuracy is compromised by <a href=\"https://arxiv.org/pdf/2103.14749.pdf?mc_cid=14ae732089&amp;mc_eid=7da3941d81\">errors in the public data sets</a> widely used for training.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Moxie Marlinspike has found a remote code execution <a href=\"https://www.schneier.com/blog/archives/2021/04/security-vulnerabilities-in-cellebrite.html\">vulnerability in Cellebrite</a>, a commercial device used by police forces and others to break encryption on cell phone apps like Signal. This exploit can be triggered by files installed in the app itself, possibly rendering Cellebrite evidence inadmissible in court.</li><li>What happens when AI systems start hacking? This is Bruce Schneier’s <a href=\"https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html\">scary thought</a>. AI is now part of the <a href=\"https://www.technologyreview.com/2021/04/08/1021696/preparing-for-ai-enabled-cyberattacks/\">attacker’s toolkit</a>, and responsible for new attacks that evade traditional defenses.\\xa0 This is the end of traditional, signature-based approaches to security.</li><li><a href=\"https://thenewstack.io/confidential-computing-is-transforming-data-encryption-in-healthcare-finance/\">Confidential computing</a> combines homomorphic encryption with specialized cryptographic computation engines to keep data encrypted while it is being used. “Traditional” cryptography only protects data in storage or in transit; to use data in computation, it must be decrypted.</li><li><a href=\"https://www.paloaltonetworks.com/cyberpedia/what-is-sase\">Secure access service edge</a> could be no more than hype-ware, but it is touted as a security paradigm for edge computing that combines firewalls, security brokers, and zero-trust computing over wide-area networks.</li><li>A supply chain attack attempted to place a <a href=\"https://thenewstack.io/php-supply-chain-attack-shows-open-sources-virtues-and-vices/\">backdoor into PHP</a>. Fortunately, it was detected during a code review prior to release. One result is that PHP is <a href=\"https://news-web.php.net/php.internals/113838\">outsourcing their git server</a> to GitHub. They are making this change to protect against attacks on the source code, and they’re realizing that GitHub provides better protection than they can. “Maintaining our own git infrastructure is an unnecessary security risk”–that’s an argument we’ve made in favor of cloud computing.</li><li>“Researchers” from the University of Minnesota have deliberately tried to insert <a href=\"https://www.zdnet.com/article/greg-kroah-hartman-bans-university-of-minnesota-from-linux-development-for-deliberately-buggy-patches/\">vulnerabilities</a> into the Linux kernel. The Linux kernel team has banned all contributions from the university.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.sciencedaily.com/releases/2021/04/210415142619.htm\">Entanglement-based quantum networks</a> solve a fundamental problem: how do you move qbit state from one system to another, given that reading a qbit causes wave function collapse?&nbsp; If this works, it’s a major breakthrough.</li><li><a href=\"https://quantum-computing.ibm.com/composer/files/new\">IBM Quantum Composer</a> is a low-code tool for programming quantum computers. Could low- and no-code language be the only effective way to program quantum computers? Could they provide the insight and abstractions we need in a way that “coded” languages can’t?</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>A <a href=\"https://thenewstack.io/a-software-bill-of-materials-could-be-a-requirement-for-applications-soon/\">Software Bill of Materials</a> is a tool for knowing your dependencies, crucial in defending against supply chain attacks.</li><li><a href=\"https://github.com/EvgSkv/logica\">Logica</a> is a new programming language from Google that is designed for working with data. It was designed for Google’s BigQuery, but it compiles to SQL and has experimental support for SQLite and PostgreSQL.</li><li>An iPhone app that teaches you to play guitar isn’t unique. But Uberchord is an app that teaches you to play guitar that has an <a href=\"https://www.programmableweb.com/api/uberchord\">API</a>. The API <a href=\"https://api.uberchord.com/#what-is-uberchord-api\">allows</a> searching for chords, sharing and retrieving songs, and embedding chords on your website.</li><li>The Supreme Court has ruled that <a href=\"https://arstechnica.com/tech-policy/2021/04/supreme-court-sides-with-google-in-api-copyright-battle-with-oracle/\">implementing an API is “fair use,”</a> giving Google a victory in a protracted copyright infringement case surrounding the use of Java APIs in Android.</li></ul>\\n\\n\\n\\n<h2>Social Networks</h2>\\n\\n\\n\\n<ul><li>Still picking up the pieces of social networking: Twitter, context collapse, and how <a href=\"https://warzel.substack.com/p/its-not-cancel-culture-its-a-platform\">trending topics</a> can ruin your day. You don’t want to be the inadvertent “star of twitter.”</li><li><a href=\"https://www.technologyreview.com/2021/04/02/1021635/beauty-filters-young-girls-augmented-reality-social-media/\">Beauty filters and selfie culture</a> change the way girls see themselves in ways that are neither surprising nor healthy. Body shaming goes to a new level when you live in a permanent reality distortion field.</li><li>The Signal app, probably the most widely used app for truly private communication, has wrapped itself in <a href=\"https://www.stephendiehl.com/blog/signal.html\">controversy</a> by incorporating a <a href=\"https://www.theverge.com/2021/4/6/22370213/signal-payments-cryptocurrency-crypto-mobilecoin-wallet-mob-beta-feature\">peer-to-peer payments</a> feature build around a new cryptocurrency.</li><li>Twitch will consider behavior <a href=\"https://techxplore.com/news/2021-04-twitch-boot-users-transgressions.html\">on other social platforms</a> when banning users.</li></ul>\\n\\n\\n\\n<h2>Finance</h2>\\n\\n\\n\\n<ul><li>Bitcoin has been very much in the news–though not for any technology. We’re beginning to see connections made between the Bitcoin economy and the real-world economy; that could be significant.</li><li>A different spin on <a href=\"https://soccermatics.medium.com/stanford-researchers-find-that-male-over-confidence-is-costing-the-tech-industry-billions-f224e8bc0d33\">salary differences</a> between men and women: companies are paying a premium for male overconfidence. Paying for overconfidence is costing billions.</li><li>How do you teach kids about virtual money? Nickels, dimes, and quarters work. Monetizing <a href=\"https://www.theinformation.com/articles/kid-debit-card-startup-greenlight-valued-at-2-billion-in-andreessen-led-round\">children</a> by issuing debit cards for them doesn’t seem like a good idea.</li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>The Craig Venter Institute, NIST, and MIT have produced an <a href=\"https://www.nist.gov/news-events/news/2021/03/scientists-create-simple-synthetic-cell-grows-and-divides-normally\">artificial cell</a> that divides normally. It is not the first artificial cell, nor the smallest artificial genome. But unlike previous efforts, it is capable of reproduction.</li><li>While enabling a monkey to play Pong using brain control isn’t new in itself, the <a href=\"https://arstechnica.com/science/2021/04/the-big-advance-in-elon-musks-pong-playing-monkey-is-what-you-cant-see/\">sensors that Neuralink implanted</a> in the monkey’s brain are wireless.</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-may-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Checking Jeff Bezos’s Math',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Checking Jeff Bezos’s Math'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/checking-jeff-bezoss-math/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/checking-jeff-bezoss-math/',\n",
       "   'comments': 'https://www.oreilly.com/radar/checking-jeff-bezoss-math/#respond',\n",
       "   'published': 'Fri, 23 Apr 2021 20:43:28 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=23, tm_hour=20, tm_min=43, tm_sec=28, tm_wday=4, tm_yday=113, tm_isdst=0),\n",
       "   'authors': [{'name': 'Tim O’Reilly'}],\n",
       "   'author': 'Tim O’Reilly',\n",
       "   'author_detail': {'name': 'Tim O’Reilly'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Economy', 'scheme': None, 'label': None},\n",
       "    {'term': 'Next Economy', 'scheme': None, 'label': None},\n",
       "    {'term': \"O'Reilly Insights\", 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13748',\n",
       "   'guidislink': False,\n",
       "   'summary': '“If you want to be successful in business (in life, actually), you have to create more than you consume. Your goal should be to create value for everyone you interact with. Any business that doesn’t create value for those it touches, even if it appears successful on the surface, isn’t long for this world. It’s [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': '“If you want to be successful in business (in life, actually), you have to create more than you consume. Your goal should be to create value for everyone you interact with. Any business that doesn’t create value for those it touches, even if it appears successful on the surface, isn’t long for this world. It’s [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>“If you want to be successful in business (in life, actually), you have to create more than you consume. Your goal should be to create value for everyone you interact with. Any business that doesn’t create value for those it touches, even if it appears successful on the surface, isn’t long for this world. It’s on the way out.” So wrote Jeff Bezos in his <a href=\"https://www.aboutamazon.com/news/company-news/2020-letter-to-shareholders\">final letter to shareholders</a>, released last week. It’s a great sentiment, one I heartily agree with and wish that more companies embraced. But how well does he practice what he preaches? And why is practicing this so hard by the rules of today’s economy?</p>\\n\\n\\n\\n<p>Jeff started out by acknowledging the wealth that Amazon has created for shareholders—$1.6 trillion is the number he cites in the second paragraph. That’s Amazon’s current market capitalization. Jeff himself now owns only about 11% of Amazon stock, and that’s enough to make him the richest person in the world. But while his Amazon stock is worth over $160 billion, that means that over $1.4 trillion is owned by others.</p>\\n\\n\\n\\n<p>“I’m proud of the wealth we’ve created for shareowners,” Jeff continued. “It’s significant, and it improves their lives. But I also know something else: it’s not the largest part of the value we’ve created.” That’s when he went on to make the statement with which I opened this essay. He went on from there to calculate the value created for employees, third-party merchants, and Amazon customers, as well as to explain the company’s <a href=\"https://sustainability.aboutamazon.com/about/the-climate-pledge\">Climate Pledge</a>.</p>\\n\\n\\n\\n<p>Jeff’s embrace of <a href=\"https://www.weforum.org/agenda/2021/01/klaus-schwab-on-what-is-stakeholder-capitalism-history-relevance/\">stakeholder capitalism</a> is meaningful and important. Ever since Milton Friedman penned the 1970 op-ed in which he argued that “<a href=\"http://umich.edu/~thecore/doc/Friedman.pdf\">the social responsibility of business is to increase its profits</a>,” other constituencies—workers, suppliers, society at large, and even customers—have too often been sacrificed on the altar of shareholder value. Today’s economy, rife with inequality, is the result.</p>\\n\\n\\n\\n<p>While I applaud the goal of understanding “who gets what and why” (which in many ways is the central question of economics), I struggle a bit with Jeff’s math. Let’s walk through those of his assertions that deserve deeper scrutiny.</p>\\n\\n\\n\\n<h3>How much went to shareholders?</h3>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>“Our net income in 2020 was $21.3 billion. If, instead of being a publicly traded company with thousands of owners, Amazon were a sole proprietorship with a single owner, that’s how much the owner would have earned in 2020.”</em><br /></p></blockquote>\\n\\n\\n\\n<p>Writing in <em>The Information, </em><a href=\"https://www.theinformation.com/articles/the-briefing-jeff-bezos-calculates-value-creation-wrong\">Martin Peers made what seems to be an obvious catch</a>: “Instead of calculating value by looking at the increase in Amazon’s market cap last year—$679 billion—Bezos uses the company’s net income of $21 billion. That hides the fact that shareholders got the most value out of Amazon last year, far more than any other group.”</p>\\n\\n\\n\\n<p>But while Peers has put his finger on an important point, he is wrong. The amount earned by shareholders <em>from Amazon</em> is indeed only the company’s $21.3 billion net income. The difference between that number and the $679 billion increase in market cap didn’t come from Amazon. It came from “the market,” that is from other people trading Amazon’s stock and placing bets on its future value. Understanding this difference is crucial because it undercuts so many <a href=\"https://twitter.com/rbreich/status/1305921198291779584?lang=en\">facile criticisms of Jeff Bezos’s wealth</a>, in which he is pictured as a robber baron hoarding the wealth accumulated from his company at the expense of his employees.</p>\\n\\n\\n\\n<p>The fact that Jeff is the world’s richest person makes him an easy target. What we really need to come to grips with is the way that our financial system has been hijacked to make the rich richer. Low interest rates, meant to prop up business investment and hiring, have instead been diverted to driving up the price of stocks beyond reasonable bounds. Surging corporate profits have been used not to fuel hiring or building new factories or bringing new products to market, but on stock buybacks designed to artificially boost the price of stocks. The state of “the market” has become a very bad proxy for prosperity. Those lucky enough to own stocks are enjoying boom times; those who do not are left out in the cold.</p>\\n\\n\\n\\n<p>Financial markets, in effect, give owners of stocks the value of future earnings and cash flow today—in Amazon’s case, <a href=\"https://www.nasdaq.com/market-activity/stocks/amzn/price-earnings-peg-ratios\">about 79 years worth</a>. But that’s nothing. Elon Musk is the world’s second-richest person because the market values Tesla at <a href=\"https://www.nasdaq.com/market-activity/stocks/tsla/price-earnings-peg-ratios\">over 1,000 years of its present earnings</a>!</p>\\n\\n\\n\\n<p>The genius of this system is that it allows investors and entrepreneurs to bet on the future, bootstrapping companies like Amazon and Tesla long before they are able to demonstrate their worth. But once a company has become established, it often no longer needs money from investors. Someone who buys a share of a hugely profitable company like Apple, Amazon, Google, Facebook, or Microsoft, isn’t investing in these companies. They are simply betting on the future of its stock price, with the profits and losses coming from others around the gaming table.</p>\\n\\n\\n\\n<p>In my 2017 book, <a href=\"https://www.amazon.com/WTF-Whats-Future-Why-Its/dp/0062565710\"><em>WTF?: What&#8217;s the Future and Why It&#8217;s Up to Us</em></a>, I wrote a chapter on this betting economy, which I called “supermoney” after <a href=\"https://www.amazon.com/Supermoney-Adam-Smith/dp/0471786314\">the brilliant 1972 book</a> with that title by finance writer George Goodman (alias Adam Smith.) Stock prices are not the only form of supermoney. Real estate is another. Both are rife with what economists call “rents”—that is, <a href=\"https://www.amazon.com/Rentier-Capitalism-Owns-Economy-Pays/dp/1788739728\">income that comes not from what you do but from what you own</a>. And government policy seems designed to prop up the rentier class at the expense of job creation and real investment. Until we come to grips with this two-track economy, we will never tame inequality.</p>\\n\\n\\n\\n<p>The fact that in the second paragraph of his letter Jeff cites Amazon’s market cap as the value created for shareholders but uses the company’s net income when comparing gains by shareholders to those received by other stakeholders is a kind of sleight of hand. Because of course corporate profits—especially the prospect of growth of corporate profits—and market capitalization are related. If Amazon gets $79 of market cap for every dollar of profit (which is what that price-earnings ratio of 79 means), then if Amazon were to raise wages for employees or give a better deal to its third-party merchants (many of them small businesses), that would lower its profits, and presumably its market cap, by an enormous ratio.</p>\\n\\n\\n\\n<p>Every dollar given up to these other groups isn’t just a dollar out of the pocket of shareholders. It is many times that. This of course <em>does</em> provide a very powerful incentive for public companies to squeeze these other parties for every last dollar of profit, encouraging lower wages, outsourcing to eliminate benefits, and many other ills that contribute to our two-tier economy. It may not be Amazon’s motivation—Jeff has always been a long-term thinker and was able to persuade financial markets to go along for the ride even when the company’s profits were small—but it is most certainly <a href=\"https://www.amazon.com/Makers-and-Takers-Rana-Foroohar-audiobook/dp/B01CUKFLII\">the motivation for much of the extractive behavior by many companies today</a>. The pressure to increase earnings and keep stock prices high is enormous.</p>\\n\\n\\n\\n<p>These issues are complex and difficult. Stock prices are <a href=\"https://www.ft.com/content/0ca06172-bfe9-11de-aed2-00144feab49a\">reflexive</a>, as financier George Soros likes to observe. That is, they are based on what people believe about the future. Amazon’s current stock price is based on the collective belief that its profits will be even higher in future. Were people to believe instead that they would be meaningfully lower, the valuation might fall precipitously. To understand the role of expectations of future increases in earnings and cash flow, you have only to <a href=\"https://finance.yahoo.com/quote/AAPL/key-statistics?p=AAPL\">compare Amazon with Apple</a>. Apple’s profits are three times Amazon’s and free cash flow four times, yet it is valued at only 36 times earnings and has a market capitalization less than 50% higher than Amazon. As expectations and reality converge, multiples tend to come down.</p>\\n\\n\\n\\n<h3>How did Amazon’s third-party sellers fare?</h3>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>“[We] estimate that, in 2020, third-party seller profits from selling on Amazon were between $25 billion and $39 billion, and to be conservative here I’ll go with $25 billion.”</em></p></blockquote>\\n\\n\\n\\n<p>That sounds pretty impressive, but how much of a profit margin is it really?</p>\\n\\n\\n\\n<p>Amazon doesn’t explicitly disclose the gross merchandise volume of those third-party sellers, but there is enough information in the letter and in <a href=\"https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Annual-Report.pdf\">the company’s 2020 annual report</a> to make a back-of-the-napkin estimate. The letter says that Amazon’s third-party sales represent “close to 60%” of its online sales. If the 40% delivered by Amazon’s first-party sales come out to $197 billion, that would imply that sales in the third-party marketplace were almost $300 billion. $25 to $39 billion in profit on $300 billion works out to a profit margin between 8% and 13%.</p>\\n\\n\\n\\n<p>But is Amazon calculating <a href=\"https://www.investopedia.com/terms/o/operatingincome.asp\">operating income</a>, <a href=\"https://www.investopedia.com/terms/e/ebitda.asp\">EBITDA</a>, or <a href=\"https://www.investopedia.com/terms/n/netincome.asp\">net income</a>? “Profit” could refer to any of the three, yet they have very different values.</p>\\n\\n\\n\\n<p>Let’s generously assume that Amazon is calculating net income. In that case, small retailers and manufacturers selling on Amazon are doing quite well, since net income from US retailers’ and manufacturers’ overall operations are <a href=\"http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/margin.html\">typically between 5 and 8%</a>. Without knowing which profit number Amazon’s team is estimating, though, and the methodology they use to arrive at it, it is difficult to be sure whether these numbers are better or worse than what these sellers achieve through other channels.</p>\\n\\n\\n\\n<p>One question that’s also worth asking is whether selling on Amazon in 2020 was more or less profitable than it was in 2019. While Amazon didn’t report a profit number for its third-party sellers in 2019, it did report how much its sellers paid for the services Amazon provided to them. In 2019, that number was about $53.8 billion; in 2020, it was $80.5 billion, which represents a 50% growth rate. Net of these fees, income to Amazon but a cost to sellers, we estimate that seller revenue grew 44%. Since fees appear to be growing faster than revenues, that would suggest that in 2020, Amazon took a larger share of the pie and sellers got less. Of course, without clearer information from Amazon, it is difficult to tell for sure.</p>\\n\\n\\n\\n<p>Meanwhile, Amazon took in another $21.5 billion in “other income,” which is primarily from advertising by sellers on Amazon’s platform. That grew by 52% from 2019’s $14 billion, again suggesting that Amazon’s share of the net is growing. And unlike some forms of advertising that bring in new customers, much of Amazon’s ad business represents a zero-sum competition between merchants bidding for top position, a position that in Amazon’s earlier years was granted on the basis of factors such as price, popularity, and user ratings.</p>\\n\\n\\n\\n<h3>How about employees?</h3>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p><em>“In 2020, employees earned $80 billion, plus another $11 billion to include benefits and various payroll taxes, for a total of $91 billion.”</em></p></blockquote>\\n\\n\\n\\n<p>There’s no question that the $91 billion that Amazon paid out in wages and benefits in 2020 is meaningful. Some of those employees were very well compensated, others not so well, but all of them have jobs. Amazon is now one of the largest employers in the country. It is an exception to the tech industry in that it creates a large number of jobs, and not just high-end professional jobs, and that some of the jobs it creates are in locations where work is scarce.</p>\\n\\n\\n\\n<p>That being said, Jeff’s description of the amount earned by employees is misleading. In every other case, he makes an effort to estimate the profit earned by a particular group. For employees, he treats the gross earnings of employees as if it were profit, writing, “If each group had an income statement representing their interactions with Amazon, the numbers above would be the ‘bottom lines’ from those income statements.”</p>\\n\\n\\n\\n<p>No, Jeff, employee earnings are <em>their top line</em>. Just as a company has gross income before expenses, so do employees. The bottom line is what’s left over after all those expenses have been met. And for many of Amazon’s lower-paid employees—as is the case for lower-paid workers all over the modern economy—that true bottom line is negative, that is, less than they need to survive. Like workers at other giant profitable companies like Walmart and McDonald&#8217;s, <a href=\"https://thecounter.org/15-minimum-wage-amazon-top-employer-snap-recipients-walmart-mcdonalds/\">a significant fraction of Amazon warehouse employees require government assistance</a>. So, in effect, taxpayers are subsidizing Amazon, because the share of the enterprise’s profits allocated to its lowest-paid employees was not enough for them to pay their bills.</p>\\n\\n\\n\\n<p>That points to a major omission from the list of Amazon’s stakeholders: society at large. How does Amazon do when it comes to paying its fair share? According to a 2019 study, Amazon was the “<a href=\"https://www.theguardian.com/business/2019/dec/02/new-study-deems-amazon-worst-for-aggressive-tax-avoidance\">worst offender</a>” among a rogues’ gallery of high-tech companies that use aggressive tax avoidance strategies. “Fair Tax Mark said this means Amazon’s effective tax rate was 12.7% over the decade when the headline tax rate in the US has been 35% for most of that period.” In 2020, Amazon made provision for taxes of $2.863 billion on pretax income of $24,178 billion, or about 11.8%. This may be legal, but it isn’t right.</p>\\n\\n\\n\\n<p>Amazon is clearly moving in the right direction with employees. It introduced a $15 minimum wage in 2018, ahead of many of its peers. And given the genius of the company, the commitment to workplace safety and other initiatives to make Amazon a better employer that Jeff highlighted in his letter are likely to have a big payoff. When Amazon sets out to do something, it usually invents and learns a great deal along the way.</p>\\n\\n\\n\\n<p>“We have always wanted to be Earth’s Most Customer-Centric Company,” Jeff wrote. “We won’t change that. It’s what got us here. But I am committing us to an addition. We are going to be Earth’s Best Employer and Earth’s Safest Place to Work. In my upcoming role as Executive Chair, I’m going to focus on new initiatives. I’m an inventor. It’s what I enjoy the most and what I do best. It’s where I create the most value&#8230;.We have never failed when we set our minds to something, and we’re not going to fail at this either.”</p>\\n\\n\\n\\n<p>I find that an extremely heartening statement. At Amazon’s current stage of development, it has the opportunity, and is beginning to make a commitment, to put its remarkable capabilities to work on new challenges.</p>\\n\\n\\n\\n<h2>Stakeholder value means solving multiple equations simultaneously</h2>\\n\\n\\n\\n<p>I was very taken with Jeff’s statement that “if any shareowners are concerned that Earth’s Best Employer and Earth’s Safest Place to Work might dilute our focus on Earth’s Most Customer-Centric Company, let me set your mind at ease. Think of it this way. If we can operate two businesses as different as consumer ecommerce and AWS, and do both at the highest level, we can certainly do the same with these two vision statements. In fact, I’m confident they will reinforce each other.”</p>\\n\\n\\n\\n<p>One of my criticisms of today’s financial-market-driven economy is that by focusing on a single objective, it misses the great opportunity of today’s technology, summed up by Paul Cohen, the former DARPA program manager for AI and now a professor at the University of Pittsburgh, when he said, “The opportunity of AI is to help humans model and manage complex interacting systems.” If any company has the skills to do that, I suspect it will be Amazon. And as Jeff wrote elsewhere in his letter, “When we lead, others follow.”</p>\\n\\n\\n\\n<p>Amazon is also considering environmental impact. “Not long ago, most people believed that it would be good to address climate change, but they also thought it would cost a lot and would threaten jobs, competitiveness, and economic growth. We now know better,” Jeff wrote. “Smart action on climate change will not only stop bad things from happening, it will also make our economy more efficient, help drive technological change, and reduce risks. Combined, these can lead to more and better jobs, healthier and happier children, more productive workers, and a more prosperous future.” Amen to that!</p>\\n\\n\\n\\n<p>In short, despite my questions and criticisms, there is a great deal to like about the directions Jeff set forth for Amazon in his final shareholder letter. In addition to the commitment to work more deeply on behalf of other stakeholders beyond customers and shareholders, I was taken with his concluding advice to the company: “The world will always try to make Amazon more typical—to bring us into equilibrium with our environment. It will take continuous effort, but we can and must be better than that.”</p>\\n\\n\\n\\n<p>It is in the spirit of that aspiration that I offer the critiques found in this essay.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/checking-jeff-bezoss-math/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'AI Adoption in the Enterprise 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'AI Adoption in the Enterprise 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/#respond',\n",
       "   'published': 'Mon, 19 Apr 2021 12:20:38 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=19, tm_hour=12, tm_min=20, tm_sec=38, tm_wday=0, tm_yday=109, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Research', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13720',\n",
       "   'guidislink': False,\n",
       "   'summary': 'During the first weeks of February, we asked recipients of our Data and AI Newsletters to participate in a survey on AI adoption in the enterprise. We were interested in answering two questions. First, we wanted to understand how the use of AI grew in the past year. We were also interested in the practice [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'During the first weeks of February, we asked recipients of our Data and AI Newsletters to participate in a survey on AI adoption in the enterprise. We were interested in answering two questions. First, we wanted to understand how the use of AI grew in the past year. We were also interested in the practice [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>During the first weeks of February, we asked recipients of our <em>Data </em>and<em> AI Newsletters</em> to participate in a survey on AI adoption in the enterprise. We were interested in answering two questions. First, we wanted to understand how the use of AI grew in the past year. We were also interested in the practice of AI: how developers work, what techniques and tools they use, what their concerns are, and what development practices are in place.</p>\\n\\n\\n\\n<p>The most striking result is the sheer number of respondents. In our 2020 survey, which reached the same audience, we had 1,239 responses. This year, we had a total of 5,154. After eliminating 1,580 respondents who didn’t complete the survey, we’re left with 3,574 responses—almost three times as many as last year. It’s possible that pandemic-induced boredom led more people to respond, but we doubt it. Whether they’re putting products into production or just kicking the tires, more people are using AI than ever before.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<p class=\"has-text-align-center\"><strong>Executive Summary</strong></p>\\n\\n\\n\\n<ul><li>We had almost three times as many responses as last year, with similar efforts at promotion. More people are working with AI.</li><li>In the past, company culture has been the most significant barrier to AI adoption. While it’s still an issue, culture has dropped to fourth place.</li><li>This year, the most significant barrier to AI adoption is the lack of skilled people and the difficulty of hiring. That shortage has been predicted for several years; we’re finally seeing it.</li><li>The second-most significant barrier was the availability of quality data. That realization is a sign that the field is growing up. </li><li>The percentage of respondents reporting “mature” practices has been roughly the same for the last few years. That isn’t surprising, given the increase in the number of respondents: we suspect many organizations are just beginning their AI projects. </li><li>The retail industry sector has the highest percentage of mature practices; education has the lowest. But education also had the highest percentage of respondents who were “considering” AI. </li><li>Relatively few respondents are using version control for data and models. Tools for versioning data and models are still immature, but they’re critical for making AI results reproducible and reliable.</li></ul>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h2>Respondents</h2>\\n\\n\\n\\n<p>Of the 3,574 respondents who completed this year’s survey, 3,099 were working with AI in some way: considering it, evaluating it, or putting products into production. Of these respondents, it’s not a surprise that the largest number are based in the United States (39%) and that roughly half were from North America (47%). India had the second-most respondents (7%), while Asia (including India) had 16% of the total. Australia and New Zealand accounted for 3% of the total, giving the Asia-Pacific (APAC) region 19%. A little over a quarter (26%) of respondents were from Europe, led by Germany (4%). 7% of the respondents were from South America, and 2% were from Africa. Except for Antarctica, there were no continents with zero respondents, and a total of 111 countries were represented. These results that interest and use of AI is worldwide and growing.</p>\\n\\n\\n\\n<p>This year’s results match last year’s data well. But it’s equally important to notice what the data doesn’t say. Only 0.2% of the respondents said they were from China. That clearly doesn’t reflect reality; China is a leader in AI and probably has more AI developers than any other nation, including the US. Likewise, 1% of the respondents were from Russia. Purely as a guess, we suspect that the number of AI developers in Russia is slightly smaller than the number in the US. These anomalies say much more about who the survey reached (subscribers to O’Reilly’s newsletters) than they say about the actual number of AI developers in Russia and China.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13721\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0101-1048x993.png\" /><figcaption>Figure 1. Respondents working with AI by country (top 12)</figcaption></figure>\\n\\n\\n\\n<p>The respondents represented a diverse range of industries. Not surprisingly, computers, electronics, and technology topped the charts, with 17% of the respondents. Financial services (15%), healthcare (9%), and education (8%) are the industries making the next-most significant use of AI. We see relatively little use of AI in the pharmaceutical and chemical industries (2%), though we expect that to change sharply given the role of AI in developing the COVID-19 vaccine. Likewise, we see few respondents from the automotive industry (2%), though we know that AI is key to new products such as autonomous vehicles.</p>\\n\\n\\n\\n<p>3% of the respondents were from the energy industry, and another 1% from public utilities (which includes part of the energy sector). That’s a respectable number by itself, but we have to ask: Will AI play a role in rebuilding our frail and outdated energy infrastructure, as events of the last few years—not just the Texas freeze or the California fires—have demonstrated? We expect that it will, though it’s fair to ask whether AI systems trained on normative data will be robust in the face of “black swan” events. What will an AI system do when faced with a rare situation, one that isn’t well-represented in its training data? That, after all, is the problem facing the developers of autonomous vehicles. Driving a car safely is easy when the other traffic and pedestrians all play by the rules. It’s only difficult when something unexpected happens. The same is true of the electrical grid.</p>\\n\\n\\n\\n<p>We also expect AI to reshape agriculture (1% of respondents). As with energy, AI-driven changes won’t come quickly. However, we’ve seen a steady stream of AI projects in agriculture, with goals ranging from <a href=\"https://oreil.ly/3jALP\">detecting crop disease</a> to <a href=\"https://oreil.ly/UPOgM\">killing moths with small drones</a>.</p>\\n\\n\\n\\n<p>Finally, 8% of respondents said that their industry was “Other,” and 14% were grouped into “All Others.” “All Others” combines 12 industries that the survey listed as possible responses (including automotive, pharmaceutical and chemical, and agriculture) but that didn’t have enough responses to show in the chart. “Other” is the wild card, comprising industries we didn’t list as options. “Other” appears in the fourth position, just behind healthcare. Unfortunately, we don’t know which industries are represented by that category—but it shows that the spread of AI has indeed become broad!</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13723\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0102-1048x767.png\" /><figcaption>Figure 2. Industries using AI</figcaption></figure>\\n\\n\\n\\n<h2>Maturity</h2>\\n\\n\\n\\n<p>Roughly one quarter of the respondents described their use of AI as “mature” (26%), meaning that they had revenue-bearing AI products in production. This is almost exactly in line with the results from 2020, where 25% of the respondents reported that they had products in production (“Mature” wasn’t a possible response in the 2020 survey.)</p>\\n\\n\\n\\n<p>This year, 35% of our respondents were “evaluating” AI (trials and proof-of-concept projects), also roughly the same as last year (33%). 13% of the respondents weren’t making use of AI or considering using it; this is down from last year’s number (15%), but again, it’s not significantly different.</p>\\n\\n\\n\\n<p>What do we make of the respondents who are “considering” AI but haven’t yet started any projects (26%)? That’s not an option last year’s respondents had. We suspect that last year respondents who were considering AI said they were either “evaluating” or “not using” it.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13744\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/AI_Adoption_Data_Viz_AI-practice-maturity-1048x872.png\" /><figcaption>Figure 3. AI practice maturity</figcaption></figure>\\n\\n\\n\\n<p>Looking at the problems respondents faced in AI adoption provides another way to gauge the overall maturity of AI as a field. Last year, the major bottleneck holding back adoption was company culture (22%), followed by the difficulty of identifying appropriate use cases (20%). This year, cultural problems are in fourth place (14%) and finding appropriate use cases is in third (17%). That’s a very significant change, particularly for corporate culture. Companies have accepted AI to a much greater degree, although finding appropriate problems to solve still remains a challenge.</p>\\n\\n\\n\\n<p>The biggest problems in this year’s survey are lack of skilled people and difficulty in hiring (19%) and data quality (18%). It’s no surprise that the demand for AI expertise has exceeded the supply, but it’s important to realize that it’s now become the biggest bar to wider adoption. The biggest skills gaps were ML modelers and data scientists (52%), understanding business use cases (49%), and data engineering (42%). The need for people managing and maintaining computing infrastructure was comparatively low (24%), hinting that companies are solving their infrastructure requirements in the cloud.</p>\\n\\n\\n\\n<p>It’s gratifying to note that organizations starting to realize the importance of data quality (18%). We’ve known about “garbage in, garbage out” for a long time; that goes double for AI. Bad data yields bad results at scale.</p>\\n\\n\\n\\n<p>Hyperparameter tuning (2%) wasn’t considered a problem. It’s at the bottom of the list—where, we hope, it belongs. That may reflect the success of automated tools for building models (AutoML, although as we’ll see later, most respondents aren’t using them). It’s more concerning that workflow reproducibility (3%) is in second-to-last place. This makes sense, given that we don’t see heavy usage of tools for model and data versioning. We’ll look at this later, but being able to reproduce experimental results is critical to any science, and it’s a well-known problem in AI.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13725\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0104-1048x767.png\" /><figcaption>Figure 4. Bottlenecks to AI adoption</figcaption></figure>\\n\\n\\n\\n<h2>Maturity by Continent</h2>\\n\\n\\n\\n<p>When looking at the geographic distribution of respondents with mature practices, we found almost no difference between North America (27%), Asia (27%), and Europe (28%). In contrast, in our 2018 report, Asia was behind in mature practices, though it had a markedly higher number of respondents in the “early adopter” or “exploring” stages. Asia has clearly caught up. There’s no significant difference between these three continents in our 2021 data.</p>\\n\\n\\n\\n<p>We found a smaller percentage of respondents with mature practices and a higher percentage of respondents who were “considering” AI in South America (20%), Oceania (Australia and New Zealand, 18%), and Africa (17%). Don’t underestimate AI’s future impact on any of these continents.</p>\\n\\n\\n\\n<p>Finally, the percentage of respondents “evaluating” AI was almost the same on each continent, varying only from 31% (South America) to 36% (Oceania).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13726\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0105-986x1048.png\" /><figcaption>Figure 5. Maturity by continent</figcaption></figure>\\n\\n\\n\\n<h2>Maturity by Industry</h2>\\n\\n\\n\\n<p>While AI maturity doesn’t depend strongly on geography, we see a different picture if we look at maturity by industry.</p>\\n\\n\\n\\n<p>Looking at the top eight industries, financial services (38%), telecommunications (37%), and retail (40%) had the greatest percentage of respondents reporting mature practices. And while it had by far the greatest number of respondents, computers, electronics, and technology was in fourth place, with 35% of respondents reporting mature practices. Education (10%) and government (16%) were the laggards. Healthcare and life sciences, at 28%, were in the middle, as were manufacturing (25%), defense (26%), and media (29%).</p>\\n\\n\\n\\n<p>On the other hand, if we look at industries that are considering AI, we find that education is the leader (48%). Respondents working in government and manufacturing seem to be somewhat further along, with 49% and 47% evaluating AI, meaning that they have pilot or proof-of-concept projects in progress.</p>\\n\\n\\n\\n<p>This may just be a trick of the numbers: every group adds up to 100%, so if there are fewer “mature” practices in one group, the percentage of “evaluating” and “considering” practices has to be higher. But there’s also a real signal: respondents in these industries may not consider their practices “mature,” but each of these industry sectors had over 100 respondents, and education had almost 250. Manufacturing needs to automate many processes (from assembly to inspection and more); government has been as challenged as any industry by the global pandemic, and has always needed ways to “do more with less”; and education has been experimenting with technology for a number of years now. There is a real desire to do more with AI in these fields. It’s worth pointing out that educational and governmental applications of AI frequently raise ethical questions—and one of the most important issues for the next few years will be seeing how these organizations respond to ethical problems.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13727\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0106-1048x1009.png\" /><figcaption>Figure 6. Maturity by industry (percent)</figcaption></figure>\\n\\n\\n\\n<h2>The Practice of AI</h2>\\n\\n\\n\\n<p>Now that we’ve discussed where mature practices are found, both geographically and by industry, let’s see what a mature practice looks like. What do these organizations have in common? How are they different from organizations that are evaluating or considering AI?</p>\\n\\n\\n\\n<h3>Techniques</h3>\\n\\n\\n\\n<p>First, 82% of the respondents are using supervised learning, and 67% are using deep learning. Deep learning is a set of algorithms that are common to almost all AI approaches, so this overlap isn’t surprising. (Participants could provide multiple answers.) 58% claimed to be using unsupervised learning.</p>\\n\\n\\n\\n<p>After unsupervised learning, there was a significant drop-off. Human-in-the-loop, knowledge graphs, reinforcement learning, simulation, and planning and reasoning all saw usage below 40%. Surprisingly, natural language processing wasn’t in the picture at all. (A very small number of respondents wrote in “natural language processing” as a response, but they were only a small percentage of the total.) This is significant and definitely worth watching over the next few months. In the last few years, there have been many breakthroughs in NLP and NLU (natural language understanding): everyone in the industry has read about GPT-3, and many vendors are betting heavily on using AI to automate customer service call centers and similar applications. This survey suggests that those applications still haven’t moved into practice.</p>\\n\\n\\n\\n<p>We asked a similar question to respondents who were considering or evaluating the use of AI (60% of the total). While the percentages were lower, the technologies appeared in the same order, with very few differences. This indicates that respondents who are still evaluating AI are experimenting with fewer technologies than respondents with mature practices. That suggests (reasonably enough) that respondents are choosing to “start simple” and limit the techniques that they experiment with.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13728\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0107-1048x823.png\" /><figcaption>Figure 7. AI technologies used in mature practices</figcaption></figure>\\n\\n\\n\\n<h3>Data</h3>\\n\\n\\n\\n<p>We also asked what kinds of data our “mature” respondents are using. Most (83%) are using structured data (logfiles, time series data, geospatial data). 71% are using text data—that isn’t consistent with the number of respondents who reported using NLP, unless “text” is being used generically to include any data that can be represented as text (e.g., form data). 52% of the respondents reported using images and video. That seems low relative to the amount of research we read about AI and computer vision. Perhaps it’s not surprising though: there’s no reason for business use cases to be in sync with academic research. We’d expect most business applications to involve structured data, form data, or text data of some kind. Relatively few respondents (23%) are working with audio, which remains very challenging.</p>\\n\\n\\n\\n<p>Again, we asked a similar question to respondents who were evaluating or considering AI, and again, we received similar results, though the percentage of respondents for any given answer was somewhat smaller (4–5%).</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13730\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0108-1048x503.png\" /><figcaption>Figure 8. Data types used in mature practices</figcaption></figure>\\n\\n\\n\\n<h3>Risk</h3>\\n\\n\\n\\n<p>When we asked respondents with mature practices what risks they checked for, 71% said “unexpected outcomes or predictions.” Interpretability, model degradation over time, privacy, and fairness also ranked high (over 50%), though it’s disappointing that only 52% of the respondents selected this option. Security is also a concern, at 42%. AI raises important new security issues, including the possibility of poisoned data sources and reverse engineering models to extract private information.</p>\\n\\n\\n\\n<p>It’s hard to interpret these results without knowing exactly what applications are being developed. Privacy, security, fairness, and safety are important concerns for every application of AI, but it’s also important to realize that not all applications are the same. A farming application that <a href=\"https://oreil.ly/jj0Lz\">detects crop disease</a> doesn’t have the same kind of risks as an application that’s approving or denying loans. Safety is a much bigger concern for autonomous vehicles than for personalized shopping bots. However, do we really believe that these risks don’t need to be addressed for nearly half of all projects?</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13731\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0109-1048x825.png\" /><figcaption>Figure 9. Risks checked for during development</figcaption></figure>\\n\\n\\n\\n<h3>Tools</h3>\\n\\n\\n\\n<p>Respondents with mature practices clearly had their favorite tools: scikit-learn, TensorFlow, PyTorch, and Keras each scored over 45%, with scikit-learn and TensorFlow the leaders (both with 65%). A second group of tools, including Amazon’s SageMaker (25%), Microsoft’s Azure ML Studio (21%), and Google’s Cloud ML Engine (18%), clustered around 20%, along with Spark NLP and spaCy.</p>\\n\\n\\n\\n<p>When asked which tools they planned to incorporate over the coming 12 months, roughly half of the respondents answered model monitoring (57%) and model visualization (49%). Models become stale for many reasons, not the least of which is changes in human behavior, changes for which the model itself may be responsible. The ability to monitor a model’s performance and detect when it has become “stale” will be increasingly important as businesses grow more reliant on AI and in turn demand that AI projects demonstrate their value.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13732\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0110-913x1048.png\" /><figcaption>Figure 10. Tools used by mature practices</figcaption></figure>\\n\\n\\n\\n<p>Responses from those who were evaluating or considering AI were similar, but with some interesting differences: scikit-learn moved from first place to third (48%). The second group was led by products from cloud vendors that incorporate AutoML: Microsoft Azure ML Studio (29%), Google Cloud ML Engine (25%), and Amazon SageMaker (23%). These products were significantly more popular than they were among “mature” users. The difference isn’t huge, but it is striking. At risk of over-overinterpreting, users who are newer to AI are more inclined to use vendor-specific packages, more inclined to use AutoML in one of its incarnations, and somewhat more inclined to go with Microsoft or Google rather than Amazon. It’s also possible that scikit-learn has less brand recognition among those who are relatively new to AI compared to packages from organizations like Google or Facebook.</p>\\n\\n\\n\\n<p>When asked specifically about AutoML products, 51% of “mature” respondents said they weren’t using AutoML at all. 22% use Amazon SageMaker; 16% use Microsoft Azure AutoML; 14% use Google Cloud AutoML; and other tools were all under 10%. Among users who are evaluating or considering AI, only 40% said they weren’t using AutoML at all—and the Google, Microsoft, and Amazon packages were all but tied (27–28%). AutoML isn’t yet a big part of the picture, but it appears to be gaining traction among users who are still considering or experimenting with AI. And it’s possible that we’ll see increased use of AutoML tools among mature users, of whom 45% indicated that they would be incorporating tools for automated model search and hyperparameter tuning (in a word, AutoML) in the coming yet.</p>\\n\\n\\n\\n<h3>Deployment and Monitoring</h3>\\n\\n\\n\\n<p>An AI project means nothing if it can’t be deployed; even projects that are only intended for internal use need some kind of deployment. Our survey showed that AI deployment is still largely unknown territory, dominated by homegrown ad hoc processes. The three most significant tools for deploying AI all had roughly 20% adoption: MLflow (22%), TensorFlow Extended, a.k.a. TFX (20%), and Kubeflow (18%). Three products from smaller startups—<a href=\"https://www.dominodatalab.com/\">Domino</a>, <a href=\"https://www.seldon.io/\">Seldon</a>, and <a href=\"https://www.cortex.dev/\">Cortex</a>—had roughly 4% adoption. But the most frequent answer to this question was “none of the above” (46%). Since this question was only asked of respondents with “mature” AI practices (i.e., respondents who have AI products in production), we can only assume that they’ve built their own tools and pipelines for deployment and monitoring. Given the many forms that an AI project can take, and that AI deployment is still something of a dark art, it isn’t surprising that AI developers and operations teams are only starting to adopt third-party tools for deployment.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13733\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0111-1048x684.png\" /><figcaption>Figure 11. Automated tools used in mature practices for deployment<br /> and monitoring</figcaption></figure>\\n\\n\\n\\n<h3>Versioning</h3>\\n\\n\\n\\n<p>Source control has long been a standard practice in software development. There are many well-known tools used to build source code repositories.</p>\\n\\n\\n\\n<p>We’re confident that AI projects use source code repositories such as Git or GitHub; that’s a standard practice for all software developers. However, AI brings with it a different set of problems. In AI systems, the training data is as important as, if not more important than, the source code. So is the model built from the training data: the model reflects the training data and hyperparameters, in addition to the source code itself, and may be the result of hundreds of experiments.</p>\\n\\n\\n\\n<p>Our survey shows that AI developers are only starting to use tools for data and model versioning. For data versioning, 35% of the respondents are using homegrown tools, while 46% responded “none of the above,” which we take to mean they’re using nothing more than a database. 9% are using <a href=\"https://dvc.org/\">DVC</a>, 8% are using tools from <a href=\"https://wandb.ai/site\">Weights &amp; Biases</a>, and 5% are using <a href=\"https://www.pachyderm.com/\">Pachyderm</a>.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13734\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0112-1048x575.png\" /><figcaption>Figure 12. Automated tools used for data versioning</figcaption></figure>\\n\\n\\n\\n<p>Tools for model and experiment tracking were used more frequently, although the results are fundamentally the same. 29% are using homegrown tools, while 34% said “none of the above.” The leading tools were MLflow (27%) and Kubeflow (18%), with Weights &amp; Biases at 8%.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13735\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/04/aadv_0113-1048x826.png\" /><figcaption>Figure 13. Automated tools used for model and experiment tracking</figcaption></figure>\\n\\n\\n\\n<p>Respondents who are considering or evaluating AI are even less likely to use data versioning tools: 59% said “none of the above,” while only 26% are using homegrown tools. Weights &amp; Biases was the most popular third-party solution (12%). When asked about model and experiment tracking, 44% said “none of the above,” while 21% are using homegrown tools. It’s interesting, though, that in this group, MLflow (25%) and Kubeflow (21%) ranked above homegrown tools.</p>\\n\\n\\n\\n<p>Although the tools available for versioning models and data are still rudimentary, it’s disturbing that so many practices, including those that have AI products in production, aren’t using them. You can’t reproduce results if you can’t reproduce the data and the models that generated the results. We’ve said that a quarter of respondents considered their AI practice mature—but it’s unclear what maturity means if it doesn’t include reproducibility.</p>\\n\\n\\n\\n<h2>The Bottom Line</h2>\\n\\n\\n\\n<p>In the past two years, the audience for AI has grown, but it hasn’t changed much: Roughly the same percentage of respondents consider themselves to be part of a “mature” practice; the same industries are represented, and at roughly the same levels; and the geographical distribution of our respondents has changed little.</p>\\n\\n\\n\\n<p>We don’t know whether to be gratified or discouraged that only 50% of the respondents listed privacy or ethics as a risk they were concerned about. Without data from prior years, it’s hard to tell whether this is an improvement or a step backward. But it’s difficult to believe that there are so many AI applications for which privacy, ethics, and security aren’t significant risks.</p>\\n\\n\\n\\n<p>Tool usage didn’t present any big surprises: the field is dominated by scikit-learn, TensorFlow, PyTorch, and Keras, though there’s a healthy ecosystem of open source, commercially licensed, and cloud native tools. AutoML has yet to make big inroads, but respondents representing less mature practices seem to be leaning toward automated tools and are less likely to use scikit-learn.</p>\\n\\n\\n\\n<p>The number of respondents who aren’t addressing data or model versioning was an unwelcome surprise. These practices should be foundational: central to developing AI products that have verifiable, repeatable results. While we acknowledge that versioning tools appropriate to AI applications are still in their early stages, the number of participants who checked “none of the above” was revealing—particularly since “the above” included homegrown tools. You can’t have reproducible results if you don’t have reproducible data and models. Period.</p>\\n\\n\\n\\n<p>In the past year, AI in the enterprise has grown; the sheer number of respondents will tell you that. But has it matured? Many new teams are entering the field, while the percentage of respondents who have deployed applications has remained roughly constant. In many respects, this indicates success: 25% of a bigger number is more than 25% of a smaller number. But is application deployment the right metric for maturity? Enterprise AI won’t really have matured until development and operations groups can engage in practices like continuous deployment, until results are repeatable (at least in a statistical sense), and until ethics, safety, privacy, and security are primary rather than secondary concerns. Mature AI? Yes, enterprise AI has been maturing. But it’s time to set the bar for maturity higher.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'NFTs: Owning Digital Art',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'NFTs: Owning Digital Art'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/nfts-owning-digital-art/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/nfts-owning-digital-art/',\n",
       "   'comments': 'https://www.oreilly.com/radar/nfts-owning-digital-art/#respond',\n",
       "   'published': 'Tue, 06 Apr 2021 18:43:26 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=6, tm_hour=18, tm_min=43, tm_sec=26, tm_wday=1, tm_yday=96, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Building a data culture', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13713',\n",
       "   'guidislink': False,\n",
       "   'summary': 'It would be hard to miss the commotion around non-fungible tokens (NFTs). Non-fungible tokens are, to a first approximation, purchased digital goods that exist on a blockchain. At this point, NFTs exist on the Ethereum blockchain, but there’s no reason that they couldn’t be implemented on others; it seems reasonably likely that specialized blockchains will [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'It would be hard to miss the commotion around non-fungible tokens (NFTs). Non-fungible tokens are, to a first approximation, purchased digital goods that exist on a blockchain. At this point, NFTs exist on the Ethereum blockchain, but there’s no reason that they couldn’t be implemented on others; it seems reasonably likely that specialized blockchains will [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>It would be hard to miss the commotion around non-fungible tokens (NFTs). Non-fungible tokens are, to a first approximation, purchased digital goods that exist on a blockchain. At this point, NFTs exist on the Ethereum blockchain, but there’s no reason that they couldn’t be implemented on others; it seems reasonably likely that specialized blockchains will be built for NFTs.</p>\\n\\n\\n\\n<p>What kinds of value do NFTs create?&nbsp; It’s certainly been claimed that they create a market for digital art, that digital artists can now get “paid” for their work.&nbsp; <a href=\"https://en.wikipedia.org/wiki/Non-fungible_token\">Wikipedia</a> points to a number of other possible uses: they could also be used to represent other collectible objects (a digital equivalent to baseball trading cards), or to represent assets in online games, or even to represent shares in a real-world athlete’s <a href=\"https://markets.businessinsider.com/news/stocks/spencer-dinwiddie-brooklyn-nets-to-convert-contract-to-digital-token-2019-9-1028523488\">contract</a>–or a share in an athlete’s <a href=\"https://zephyrnet.com/this-tennis-pro-is-auctioning-part-of-her-arm-as-an-nft/\">body</a>. Of course, there’s a secondary market in trading NFTs, just as a collector might sell a work of art from a collection.</p>\\n\\n\\n\\n<p>All of these transactions rely on the idea that an NFT establishes &#8220;provenance&#8221; for a digital object. Who owns it? Who previously owned it? Who created it? Which of the many, many copies is the &#8220;original&#8221;? These are important questions for many valuable and unique physical objects: works of art, historical documents, antiques, and even real estate. NFTs present the possibility of bringing “ownership” to the virtual world: Who owns a tweet?&nbsp; Who owns a jpeg, gif, or png file?</p>\\n\\n\\n\\n<p>Regardless of whether you think ownership for virtual objects is important, keep in mind that digital objects are close to meaningless if they aren&#8217;t copied. If you can&#8217;t see a png or jpg in your browser, it might as well be hanging on the wall in a museum.&nbsp; And that&#8217;s worth talking about, because the language of &#8220;provenance&#8221; comes directly from the museum world. If I have a painting—say, a Rembrandt—its provenance is the history of its ownership, ideally tracing it back to its original source.</p>\\n\\n\\n\\n<p>An artwork’s provenance serves two purposes: academic and commercial. Provenance is important academically because it allows you to believe you’re studying the right thing: a real Rembrandt, not a copy (copying famous paintings is a time-honored part of a painter&#8217;s training, in addition to an opportunity for forgery), or something that happens to look like Rembrandt, but isn’t (&#8220;hey, dark, depressing paintings of Dutch people are sort of cool; maybe I can do one&#8221;).</p>\\n\\n\\n\\n<p>Commercially, provenance allows artworks to become extremely expensive. It allows them to become fetishized objects of immense value, at least to collectors. Particularly to collectors: &#8220;Hey, my Rembrandt, is worth more than your Vermeer.&#8221; It&#8217;s a lot harder to bid a painting&#8217;s price up into the millions if you are unsure about its provenance.</p>\\n\\n\\n\\n<p>NFTs enable the commercial function of provenance; they allow <a href=\"https://www.theverge.com/2021/3/22/22344937/jack-dorsey-nft-sold-first-tweet-ethereum-cryptocurrency-twitter\">@jack&#8217;s first tweet</a> to become a fetishized object that&#8217;s worth millions, at least until people decide that there&#8217;s something else they&#8217;d rather pay for. They establish a playground for the ultra-wealthy; if you have so much money that you don&#8217;t care how you spend it, why not buy Jack&#8217;s first tweet? You don&#8217;t even have to stick it on the wall and look at those old Dutch guys, or worry about burglar alarms. (You do have a good password, don&#8217;t you?)</p>\\n\\n\\n\\n<p>But I don&#8217;t think that&#8217;s worth very much. What about the academic function? There&#8217;s some value in studying the early history of Twitter, possibly including @jack&#8217;s first tweet. But what exactly is the NFT showing me? That these are, indeed, Jack&#8217;s bits? Certainly not; who knows (and who cares) what became of the 0s and 1s that originally lived on Jack’s laptop and Twitter’s servers? Even if the original bits still existed, they wouldn&#8217;t be meaningful—lots of people have, or have had, the same set of bits on their computers.&nbsp; As any programmer knows, equality and identity aren’t the same.&nbsp; In this case, equality is important (is this what @jack wrote?); identity isn’t.</p>\\n\\n\\n\\n<p>However, an NFT doesn’t certify that the tweet is what @Jack actually said. An NFT is only about a bunch of bits, not about what the creator (or anyone else) asserts about the bits. @Jack could easily be mistaken, or dishonest (in literature, we deal all the time with authors who want to change what they have &#8220;said,&#8221; or what they meant by what they said). Our beliefs about the contents of @jack’s first tweet have everything to do with our beliefs about @jack and Twitter (where you can still <a href=\"https://twitter.com/jack/status/20\">find it</a>), and nothing to do with the NFT.</p>\\n\\n\\n\\n<p>A tweet is one thing; what about a digital artwork? Does an NFT establish the provenance of a digital artwork? That depends on what is meant by &#8220;the provenance of a digital artwork.&#8221; A copy of a Rembrandt is still a copy, meaning it&#8217;s not the artifact that Rembrandt created. There are all sorts of techniques, ranging from very low to very high tech, to establish the link between artist and artwork. Those techniques are meaningless in the digital world, which eliminates noise, eliminates error in making copies. So, why would I care if my copy of the bits isn&#8217;t the artist&#8217;s original? The artist’s bits aren&#8217;t the &#8220;original,&#8221; either. That sort of originality is meaningless in the digital world: did the artist ever restore from backup? Was the artwork never swapped to disk, and swapped back in?\\xa0</p>\\n\\n\\n\\n<p>What &#8220;originality&#8221; really means is &#8220;this is the unique product of my mind.&#8221; We can ask any number of questions about what that might mean, but let&#8217;s keep it simple. Whatever that statement means, it&#8217;s not a statement on which an NFT or a blockchain has any bearing. We&#8217;ve already seen instances of people <a href=\"https://www.vice.com/en/article/n7vxe7/people-are-stealing-art-and-turning-it-into-nfts\">creating NFTs for other people&#8217;s work</a>, and thus “owning” it.\\xa0 Is this theft of intellectual property, or a meta-art form of its own? (One of my favorite <a href=\"https://en.wikipedia.org/wiki/Compositions_1960\">avant-garde piano compositions</a> contains the instructions “The performer should prepare any composition and then perform it as well as he can.”)</p>\\n\\n\\n\\n<p>So then, what kind of statement about the originality, uniqueness, or authorship of an artwork could be established by an NFT? Beeple, who sold an NFT titled “Everydays: The First 5000 Days” for over $69 Million, <a href=\"https://www.cnbc.com/2021/03/26/digital-artist-beeple-common-misunderstanding-about-nfts.html\">says</a> that the NFT is not about ownership of the copyright: “You can display the token and show you own the token, but, you don’t own the copyright.” I presume Beeple still owns the copyright to his work–does that mean he can sell it again? The NFT doesn’t typically include the bits that make up the artwork (I think this is possible, but only for very small objects); as <a href=\"https://twitter.com/jonty/status/1372163423446917122\">@jonty points out</a>, what the NFT actually contains isn’t the work, but a URL, a link.&nbsp; That URL points to a resource (a JSON metadata file or an IPFS hash) that’s most likely on a server operated by a startup. And that resource points to the work. If that link becomes invalid (for example, if the startup goes bust), then all you “own” is an invalid link. A 404.</p>\\n\\n\\n\\n<p>Some of these problems may be addressable; some aren’t.&nbsp; The bottom line, though, is that the link between a creator and a work of art can&#8217;t be established by cryptographic checksums.</p>\\n\\n\\n\\n<p>So do NFTs create a market for artwork that didn’t exist before?\\xa0 Perhaps–though if what’s bought and sold isn’t the actual work (which remains infinitely and perfectly reproducible), or even the right to reproduce the work (copyright), it’s not clear to me how this really benefits artists, or even how it changes the picture much.\\xa0 I suppose this is a sort of 21st century patronage, in which someone rich gives an artist a pile of money for being an artist (or gives Jack Dorsey money for being @jack). As patronage, it’s more like <a href=\"https://en.wikipedia.org/wiki/Joseph_Haydn\">Prince Esterhazy</a> than <a href=\"https://www.patreon.com/\">Patreon</a>. A few artists will make money, perhaps even more money than they would otherwise, because I see no reason you can’t sell the work itself in addition to the NFT. Or sell multiple NFTs referencing the same work. But most won’t. The irreducible problem of being an artist–whether that’s a musician, a painter, or a sculptor, whether the medium is digital or physical–is that there are more people who want the job than are people willing to pay.</p>\\n\\n\\n\\n<p>In the end, what do NFTs create? A kind of digital fetishism around possessing bits, but perhaps not much else. An NFT shows that you are able to spend money on something–without involving the “something” itself. As Beeple says, “you can display the token.” This is <a href=\"https://en.wikipedia.org/wiki/Conspicuous_consumption\">conspicuous consumption</a> in perhaps its purest form. It’s like buying jewelry and framing the receipt. That an explosion in conspicuous consumption should arise at this point in history isn’t surprising. The tech community is awash in wealth: wealth from unicorn startups that will never make a cent of profit, wealth from cryptocurrencies that are very difficult to use to buy or sell anything. What’s the value of being rich if you can’t show it off? How do you show something off during a socially distanced pandemic? And if all you care about is showing off your wealth, the NFT is where the real value lies, not in the artwork. You can buy, sell, or trade them, just like baseball cards. Just don’t mistake an NFT for “ownership” in anything but the NFT itself.</p>\\n\\n\\n\\n<p><a href=\"https://www.theverge.com/2018/10/7/17947744/banksy-ballon-girl-artwork-self-destructed-sothbys\">Banksy’s self-destroying artwork</a> was much more to the point. Unlike Banksy’s many public murals, which anyone can enjoy for free, this painting shredded itself as soon as it was bought at auction. Buying it destroyed it.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/nfts-owning-digital-art/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: April 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: April 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-april-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-april-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-april-2021/#respond',\n",
       "   'published': 'Thu, 01 Apr 2021 11:30:41 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=4, tm_mday=1, tm_hour=11, tm_min=30, tm_sec=41, tm_wday=3, tm_yday=91, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13706',\n",
       "   'guidislink': False,\n",
       "   'summary': 'March was a busy month. There’s been a lot of talk about augmented and virtual reality, with hints and speculation about products from Apple and Facebook. In the next two years, we’ll see whether this is more than just talk. We’ve also seen more people discussing operations for machine learning and AI, including a substantive [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'March was a busy month. There’s been a lot of talk about augmented and virtual reality, with hints and speculation about products from Apple and Facebook. In the next two years, we’ll see whether this is more than just talk. We’ve also seen more people discussing operations for machine learning and AI, including a substantive [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>March was a busy month. There’s been a lot of talk about augmented and virtual reality, with hints and speculation about products from Apple and Facebook. In the next two years, we’ll see whether this is more than just talk. We’ve also seen more people discussing operations for machine learning and AI, including a substantive talk by Andrew Ng. We’ve long believed that operations was the unacknowledged elephant in the room; it’s finally making it into the open. And we’ve had our share of bad news: proposals for military use of AI, increased surveillance (for example, automated license plate readers at luxury condominiums connected to police departments). More than ever, we have to ask ourselves what kind of world we want to build.</p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li><a href=\"http://gpt.contentyze.com/\">Contentyze</a> is a free, publicly available language model that claims to be GPT-3-like. It works fairly well. Wired also points to a free GPT-3-like model called <a href=\"https://www.wired.com/story/ai-generate-convincing-text-anyone-use-it/\">Eleuther</a>.</li><li>The AI Infrastructure Alliance wants to describe a <a href=\"https://thenewstack.io/the-ai-infrastructure-alliance-wants-to-build-a-canonical-stack-for-ai/\">canonical stack for AI</a>, analogous to LAMP or MEAN; they see see it as a way to free AI from domination by the technology giants.</li><li><a href=\"https://www.brookings.edu/blog/techtank/2021/03/24/it-is-time-to-negotiate-global-treaties-on-artificial-intelligence/\">Global treaties on the use of AI in warfare?</a>&nbsp; The time may have come.&nbsp; But verifying compliance is extremely difficult.&nbsp; Nuclear weapons are easy in comparison.</li><li><a href=\"https://thenewstack.io/what-is-mlops/\">Operations for Machine Learning</a> (i.e., integrating it into CI/CD processes) is the <a href=\"https://www.youtube.com/watch?v=06-AZXmwHjo\">big challenge</a> facing businesses in the coming years. This isn’t the first time operations for ML and AI have appeared in Trends…&nbsp; but people are getting the message.</li><li>The next step in AI is Multimodal: AI that <a href=\"https://www.technologyreview.com/2021/02/24/1018085/multimodal-ai-vision-language/\">combines multiple abilities</a> and multiple senses, starting with computer vision and natural language.</li><li>Smart drones <a href=\"https://techxplore.com/news/2021-03-drones-hungry-moths-dutch-hi-tech.html\">kill moths</a> by crashing into them, to prevent damage to crops. Pesticide-free agricultural pest control.</li><li>Tesla’s fully self-driving car <a href=\"https://arstechnica.com/cars/2021/03/tesla-full-self-driving-beta-isnt-designed-for-full-self-driving/\">isn’t fully self-driving</a>, and that’s the good part. Musk still seems to think he can have a fully self-driving car by the end of 2021, apparently by skipping the hard work.</li><li><a href=\"https://petewarden.com/2021/02/28/how-screen-scraping-and-tinyml-can-turn-any-dial-into-an-api/\">Turn any dial into an API</a> with a camera and some simple computer vision: Pete Warden’s notion of TinyAI could be used to make everything machine-readable, including electric meters and common appliances.</li><li>The National Security Commission on Artificial Intelligence has published a huge and wide-ranging <a href=\"https://reports.nscai.gov/final-report/table-of-contents/\">report</a> on the future development of AI in the US, covering both business and military applications. <a href=\"https://techxplore.com/news/2021-03-lagging-critical-artificial-intelligence-panel.html\">Recommendations include</a> the military development of AI-based weapons, and the creation of a quasi-military academy for developing AI expertise.</li><li>A robotic lifeguard: an <a href=\"https://techxplore.com/news/2021-03-autonomous-underwater-robot-people.html\">autonomous underwater robot</a> for rescuing swimmers.</li></ul>\\n\\n\\n\\n<h2>Data</h2>\\n\\n\\n\\n<ul><li>We have been building centralized data systems for the past decade. The pendulum is about to swing the other way: <a href=\"https://venturebeat.com/2021/03/18/the-great-data-decentralization-is-coming-are-you-ready/\">data decentralization</a> will be driven in part by regulation, in part by changes in advertising platforms, and in part by competition between cloud platforms.</li><li>Thoughtworks’ thoughts on <a href=\"https://www.thoughtworks.com/insights/blog/building-digital-first-healthcare-ecosystem\">building a digital healthcare ecosystem</a>: put the patients first (not the providers), make data accountable, build and share knowledge, leverage new technology.</li><li>Empowering the public to <a href=\"https://arxiv.org/pdf/2012.09995.pdf\">resist the surveillance state</a>: data strikes, data poisoning, reimagined as collective action, in a paper presented at the <a href=\"https://2021.facctconference.org/\">FaccT</a> conference.</li></ul>\\n\\n\\n\\n<h2>Social Media</h2>\\n\\n\\n\\n<ul><li>Zuckerberg proposes that <a href=\"https://www.axios.com/zuckerberg-facebook-section-230-shield-liability-ac9cfb3d-c98d-473b-b80a-722c79e68568.html\">social media platforms</a> “should be required to demonstrate that they have systems in place for identifying unlawful content and removing it.” Such a policy would give a significant advantage to established players–but in that, it’s not unlike laws requiring safe disposal of toxic waste.</li><li>Either ignoring or unaware of the potential for abuse, Slack added a feature allowing <a href=\"https://arstechnica.com/information-technology/2021/03/slack-promises-to-update-easy-to-abuse-connect-dm-feature/\">unblockable direct messages</a> from paid users to any users of the system (not just users from the same organization). While message delivery in Slack can be stopped, email containing the message body can’t. Slack is promising to fix this feature.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Nokia has released the <a href=\"https://www.bell-labs.com/institute/blog/plan-9-bell-labs-cyberspace/\">Plan 9 Operating System</a> (started by Rob Pike, Brian Kernighan, and Dennis Ritchie) under the open source <a href=\"http://p9f.org/dl/index.html\">MIT license</a>.&nbsp; No one knows whether it will prosper, but it is the first significantly new operating system we’ve seen in years.</li><li>An important take on <a href=\"https://thenewstack.io/an-introduction-to-queue-theory-why-disaster-happens-at-the-edges/\">performance</a>: it’s not about speeds, it’s about statistics and what happens at the edges of the distribution. Understanding queuing theory is the key, not MHz and Mbps.</li><li>Is Microsoft’s low-code, Excel-based open source programming language <a href=\"https://docs.microsoft.com/en-us/power-platform/power-fx/overview\">Power Fx</a> what brings programming to the masses?</li><li><a href=\"https://dzone.com/articles/the-2021-devops-trend-everyone-is-missing\">Non-Intrusive Production Debugging</a>: Is this a trend? Or just a flash in the pan? The ability to run a debugger on code running in production and observe what is happening line-by-line seems like magic.</li></ul>\\n\\n\\n\\n<h2>Augmented Reality</h2>\\n\\n\\n\\n<ul><li>As part of its augmented reality strategy, Facebook is developing a non-invasive <a href=\"https://www.technologyreview.com/2021/03/18/1021021/facebook-augmented-reality-wristband/\">wristband-based neural interface</a> that lets you control digital objects with thought.</li><li>The killer app for AR might be audio: <a href=\"https://www.cnet.com/news/if-you-think-your-airpods-pro-are-smart-wait-till-you-see-these-hearables/\">smart headphones and hearing aids</a> that can extract important sounds (conversations, for example) from a sea of noise.</li><li>Mojo Vision has developed very low power chips for use in <a href=\"https://spectrum.ieee.org/tech-talk/biomedical/devices/mojovision-details-lowpower-chips-for-augmented-reality-contact-lenses\">AR contact lenses</a>.</li><li>Facebook is talking more about its <a href=\"https://tech.fb.com/inside-facebook-reality-labs-the-next-era-of-human-computer-interaction/\">AR/VR glasses</a>, along with new kinds of user interfaces, in which AI mediates literally every part of the wearer’s experience.</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>Google’s ProjectZero security team, which has been responsible for disclosing many vulnerabilities (and getting vendors to fix them), has just <a href=\"https://www.technologyreview.com/2021/03/26/1021318/google-security-shut-down-counter-terrorist-us-ally\">exposed a number of vulnerabilities</a> that were actively being used by government organizations in counter-terrorist activities.</li><li>Botnets have been observed <a href=\"https://www.schneier.com/blog/archives/2021/03/illegal-content-and-the-blockchain.html\">storing key</a><a href=\"https://blogs.akamai.com/sitr/2021/02/bitcoins-blockchains-and-botnets.html\"> configuration information in cryptocurrency blockchains</a>, including the IP addresses of infected systems. Taking down the botnet’s control server is no longer an effective defense, because the server can easily be rebuilt.</li><li>Tens of thousands of Microsoft Exchange Server installations have been <a href=\"https://arstechnica.com/gadgets/2021/03/tens-of-thousands-of-us-organizations-hit-in-ongoing-microsoft-exchange-hack/\">compromised</a>. Some of the servers may have been attacked by a group connect to the Chinese government, though there are several variants of the attack, suggesting multiple actors.</li><li>The problem with a walled garden: once the attackers are in, the <a href=\"https://www.technologyreview.com/2021/03/01/1020089/apple-walled-garden-hackers-protected/\">walls are protecting them, too</a>.&nbsp; iOS’s security features make successful attacks very difficult; but when they succeed, they are almost impossible to detect.</li></ul>\\n\\n\\n\\n<h2>Biology</h2>\\n\\n\\n\\n<ul><li>The <a href=\"https://www.fastcompany.com/90613767/meet-the-crispr-pioneers-who-are-making-gene-editing-easy\">CRISPR equivalent of a laptop</a>: Onyx is a small, portable, and (relatively) inexpensive tool for automating CRISPR gene editing.&nbsp; It could make CRISPR much more widely accessible, much as the laptop did for computing.</li><li>AI and NVidia have made a breakthrough in using <a href=\"https://www.engadget.com/nvidia-harvard-ai-genomics-201226236.html\">deep learning for </a><a href=\"https://www.nature.com/articles/s41467-021-21765-5\">genetic research</a>. In addition to reducing the time to do some analyses from days to hours, they have significantly reduced the number of cells needed, making it easier to do research on rare genetic diseases.</li></ul>\\n\\n\\n\\n<h2>Web</h2>\\n\\n\\n\\n<ul><li>California has banned user interface “<a href=\"https://www.theverge.com/2021/3/16/22333506/california-bans-dark-patterns-opt-out-selling-data\">dark patterns</a>”: intentionally confusing user interface designs used to prevent people from opting out of data collection.</li><li>“Headless” wordpress: <a href=\"https://thenewstack.io/wp-engine-goes-headless-jumps-in-the-jamstack/\">WordPress as an API for content</a>, using the JAMstack (JavaScript, APIs, and Markup) for rendering rather than PHP.</li><li>Project <a href=\"https://gemini.circumlunar.space/\">Gemini</a> claims to be recreating the web.&nbsp; It’s more than gopher, but not much more.&nbsp; My biggest question is whether anyone cares about old-style “internet browsing” any more?</li><li>Is the next step for web developers <a href=\"https://alistapart.com/article/the-future-of-web-software-is-html-over-websockets/\">HTML over WebSockets</a>?&nbsp; Developers are starting to realize that browser-side JavaScript development has resulted in spiraling complexity, poor performance, and buggy applications. </li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li>IBM is launching a <a href=\"https://techcrunch.com/2021/03/29/ibm-launches-its-first-quantum-developer-certification/\">certification for developing with quantum computers</a>, based upon Qiskit, its quantum computing toolset.</li><li>A new approach to <a href=\"https://arstechnica.com/science/2021/03/programmable-optical-quantum-computer-arrives-late-steals-the-show/\">optical quantum computers</a> may provide the ability to scale qubits easily.</li></ul>\\n\\n\\n\\n<h2>Blockchain</h2>\\n\\n\\n\\n<ul><li>Non-fungible tokens (NFTs) have taken the blockchain world by storm. But it’s not clear that NFTs have any real application. What is the value of proving that you own a tweet or an emoji?</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-april-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'InfoTribes, Reality Brokers',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'InfoTribes, Reality Brokers'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/infotribes-reality-brokers/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/infotribes-reality-brokers/',\n",
       "   'comments': 'https://www.oreilly.com/radar/infotribes-reality-brokers/#respond',\n",
       "   'published': 'Tue, 23 Mar 2021 14:40:55 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=23, tm_hour=14, tm_min=40, tm_sec=55, tm_wday=1, tm_yday=82, tm_isdst=0),\n",
       "   'authors': [{'name': 'Hugo Bowne-Anderson'}],\n",
       "   'author': 'Hugo Bowne-Anderson',\n",
       "   'author_detail': {'name': 'Hugo Bowne-Anderson'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Research', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13687',\n",
       "   'guidislink': False,\n",
       "   'summary': 'It seems harder than ever to agree with others on basic facts, let alone to develop shared values and goals: we even claim to live in a post-truth era1. With anti-vaxxers, QAnon, Bernie Bros, flat earthers, the intellectual dark web, and disagreement worldwide as to the seriousness of COVID-19 and the effectiveness of masks, have [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'It seems harder than ever to agree with others on basic facts, let alone to develop shared values and goals: we even claim to live in a post-truth era1. With anti-vaxxers, QAnon, Bernie Bros, flat earthers, the intellectual dark web, and disagreement worldwide as to the seriousness of COVID-19 and the effectiveness of masks, have [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>It seems harder than ever to agree with others on basic facts, let alone to develop shared values and goals: we even claim to live in a post-truth era<sup>1</sup>. With anti-vaxxers, QAnon, Bernie Bros, flat earthers, the intellectual dark web, and disagreement worldwide as to the seriousness of COVID-19 and the effectiveness of masks, have we lost our shared reality? For every piece of information X somewhere, you can likely find “not X” elsewhere. There is a growing disbelief and distrust in basic science and government. All too often, conversations on social media descend rapidly to questions such as &#8220;<a href=\"https://twitter.com/januszczak/status/1285266873483919365\">What planet are you from?</a>&#8221; </p>\\n\\n\\n\\n<h2>Reality Decentralized</h2>\\n\\n\\n\\n<p>What has happened? Reality has once again become decentralized. Before the advent of broadcast media and mass culture, individuals&#8217; <a href=\"https://en.wikipedia.org/wiki/Mental_model\">mental models</a> of the world were generated locally, along with their sense of reality and what they considered ground truth. With broadcast media and the culture industries came the ability to forge top-down, national identities that could be pushed into the living rooms of families at prime time, completing the project of the press and newspapers in nation-forming<sup>2</sup>. The creation of the TV dinner was perhaps one of the most effective tools in carving out a sense of shared reality at a national level (did the TV dinner mean fewer people said Grace?).</p>\\n\\n\\n\\n<p>The rise of the Internet, Search, social media, apps, and platforms has resulted in an information landscape that bypasses the centralized knowledge/reality-generation machine of broadcast media. It is, however, driven by the incentives (both visible and hidden) of significant power structures, such as Big Tech companies. With the degradation of top-down knowledge, we&#8217;ve seen the return of locally-generated shared realities, where local now refers to proximity in cyberspace. Content creators and content consumers are connected, share information, and develop mental models of the world, along with shared or distinct realities, based on the information they consume. They form communities and shared realities accordingly and all these interactions are mediated by the incentive systems of the platforms they connect on.</p>\\n\\n\\n\\n<p>As a result, the number of possible realities has proliferated and the ability to find people to share any given reality with has increased. This InfoLandscape we all increasingly occupy is both novel and shifting rapidly. In it, we are currently finding people we can share some semblance of ground truth with: we&#8217;re forming our own InfoTribes, and shared reality is splintering around the globe.</p>\\n\\n\\n\\n<p>To understand this paradigm shift, we need to comprehend:</p>\\n\\n\\n\\n<ul><li>the initial vision behind the internet and the InfoLandscapes that have emerged,</li><li>how we are forming InfoTribes and how reality is splintering, </li><li>that large-scale shared reality has merely occupied a blip in human history, ushered in by the advent of broadcast media, and</li><li>who we look to for information and knowledge in an InfoLandscape that we haven&#8217;t evolved to comprehend.</li></ul>\\n\\n\\n\\n<h2>The InfoLandscapes</h2>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>&#8220;Cyberspace. A consensual hallucination experienced daily by billions of legitimate operators, in every nation, by children being taught mathematical concepts&#8230; A graphic representation of data abstracted from the banks of every computer in the human system. Unthinkable complexity. Lines of light ranged in the nonspace of the mind, clusters, and constellations of data. Like city lights, receding.&#8221;</p><cite>— <em>Neuromancer, </em>William Gibson (1984)</cite></blockquote>\\n\\n\\n\\n<p>There are several ways to frame the origin story of the internet. One is how it gave rise to new forms of information flow: the vision of a novel space in which anybody could publish anything and everyone could find it. Much of the philosophy of early internet pioneers was couched in terms of the potential to &#8220;flatten organizations, globalize society, decentralize control, and help harmonize people&#8221; (<a href=\"https://web.media.mit.edu/~nicholas/Wired/WIRED3-02.html\">Nicholas Negraponte, MIT</a>)<sup>3</sup>.</p>\\n\\n\\n\\n<p>As John Perry Barlow (of Grateful Dead fame) wrote in <em>A Declaration of the Independence of Cyberspace </em>(1996):</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>We are creating a world that all may enter without privilege or prejudice accorded by race, economic power, military force, or station of birth. We are creating a world where anyone, anywhere may express his or her beliefs, no matter how singular, without fear of being coerced into silence or conformity. Your legal concepts of property, expression, identity, movement, and context do not apply to us. They are all based on matter, and there is no matter here.</p></blockquote>\\n\\n\\n\\n<p>This may have been the world we wanted but not the one we got. We are veering closer to an online and app-mediated environment similar to Deleuze&#8217;s <a href=\"https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwir47Gz-LjuAhU0zTgGHff9CPkQFjAIegQIAxAC&amp;url=https%3A%2F%2Fwww.jstor.org%2Fstable%2F778828&amp;usg=AOvVaw0SN92kTpl6SwpB2o1OM11f\"><em>Societies of Control</em></a>, in which we are increasingly treated as our data and what Deleuze calls “dividuals”: collections of behavior and characteristics, associated with online interactions, passwords, spending, clicks, cursor movements, and personal algorithms, that can be passed into statistical and predictive models and guided and incentivized to behave and spend in particular ways. Put simply, we are reduced to the inputs of an algorithm. On top of this, pre-existing societal biases are being reinforced and promulgated at previously unheard of scales as <a href=\"https://www.oreilly.com/radar/when-models-are-everywhere/\">we increasingly integrate machine learning models into our daily lives</a>.</p>\\n\\n\\n\\n<p>Prescient visions of society along these lines were provided by William Gibson and Neal Stephenson&#8217;s 1992 <em>Snow Crash</em>: societies increasingly interacting in virtual reality environments and computational spaces, in which the landscapes were defined by information flows<sup>4</sup>. Not only this, but both authors envisioned such spaces being turned into marketplaces and segmented and demarcated by large corporations, only a stone&#8217;s throw from where we find ourselves today. How did we get here?</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13688\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/03/AdobeStock_168604806-1048x604.jpeg\" /></figure>\\n\\n\\n\\n<h3>Information Creation</h3>\\n\\n\\n\\n<p>In the early days of the internet, you needed to be a coder to create a website. The ability to publish material was relegated to the technical. It was only in walled gardens such as CompuServe and AOL or after the introduction of tools like Blogger that regular punters were able to create their own websites with relative ease. The participatory culture and user-generated content of Web 2.0 opened up the creative space, allowing anyone and everyone to create content, as well as respond to, rate, and review it. Over the last decade, two new dynamics have drastically increased the amount of information creation, and, therefore, the &#8220;raw material&#8221; with which the landscape can be molded:</p>\\n\\n\\n\\n<ol><li>Smartphones with high-resolution video cameras and</li><li>The transformation of the attention economy by &#8220;social media&#8221; platforms,  which incentivize individuals to digitize more of their experiences and broadcast as much as possible.</li></ol>\\n\\n\\n\\n<p>And it isn&#8217;t only the generation of novel content or the speed at which information travels. It is also the vast archives of human information and knowledge that are being unearthed, digitized, and made available online. This is the space of content creation.</p>\\n\\n\\n\\n<h3>Information Retrieval</h3>\\n\\n\\n\\n<p>The other necessary side of information flow is discoverability, how it is organized, and where it’s surfaced. When so much of the world’s information is available, what is the method for retrieval? Previously the realm of chat rooms and bulletin boards, this question eventually gave rise to the creation of search engines, social media platforms, streaming sites, apps, and platforms.</p>\\n\\n\\n\\n<p>Platforms that automate the organizing and surfacing of online content are necessary, given the amount of content currently out there and how much is being generated daily. And they also require interrogating, as we humans base our mental models of how the world works on the information we receive, as we do our senses of reality, the way we make decisions, and the communities we form. Platforms such as Facebook have erected walled gardens in our new InfoLandscape and locked many of us into them, as predicted by both Gibson and Stephenson. Do we want such corporatized and closed structures in our networked commons?</p>\\n\\n\\n\\n<h2>InfoTribes, Shared Reality</h2>\\n\\n\\n\\n<p><em>A by-product of algorithmic polarization and fragmentation has been the formation of more groups that agree within their own groups and disagree far more between groups, not only on what they value but on ground truth, about reality.</em></p>\\n\\n\\n\\n<p>Online spaces are novel forms of community: people who haven&#8217;t met and may never meet in real life interacting in cyberspace. As scholars such as danah boyd have <a href=\"https://www.danah.org/papers/TakenOutOfContext.html\">made clear</a>, &#8220;social network sites like MySpace and Facebook are <em>networked publics</em>, just like parks and other outdoor spaces can be understood as publics.&#8221;</p>\\n\\n\\n\\n<p>One key characteristic of any community is a sense of <em>shared reality</em>, something agreed upon. Communities are based around a sense of shared reality, shared values, and/or shared goals. Historically, communities have required geographical proximity to coalesce, whereas online communities have been able to form outside the constraints of <a href=\"https://www.urbandictionary.com/define.php?term=meatspace\">meatspace</a>. Let’s not make the mistake of assuming online community formation doesn’t have constraints. The constraints are perhaps more hidden, but they exist: they’re both technological and the result of how the InfoLandscapes have been carved out by the platforms, along with their technological and economic incentives<sup>5</sup>. Landscapes and communities have co-evolved, although, for most of history, on different timescales: mountain ranges can separate parts of a community and, conversely, we build tunnels through mountains; rivers connect communities, cities, and commerce, and humans alter the nature of rivers (an extreme example being <a href=\"https://en.wikipedia.org/wiki/Chicago_River#Reversing_the_flow\">the reversal of the Chicago River</a>!).</p>\\n\\n\\n\\n<p>The past two decades have seen the formation of several new, rapidly and constantly shifting landscapes that we all increasingly interact with, along with the formation of new information communities, driven and consolidated by the emergent phenomena of filter bubbles and echo chambers, among many others, themselves driven by the platforms’ drive for engagement. What the constituents of each of these communities share are mental models of how the world works, senses of reality, that are, for the most part, reinforced by the algorithms that surface content, either by 1) showing content you agree with to promote engagement or 2) showing content you totally disagree with to the same end. Just as the newspaper page has historically been a mish-mash collection of movie ads, obituaries, and opinions stitched together in a way that made the most business and economic sense for any given publisher, your Facebook feed is driven by a collection of algorithms that, in the end, are optimizing for growth and revenue<sup>6</sup>. These incentives define the InfoLandscape and determine the constraints under which communities form. It just so happens that dividing people increases engagement and makes economic sense. As Karen Hao <a href=\"https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/\">wrote recently</a> in the MIT Technology Review, framing it as a result of &#8220;Zuckerberg’s relentless desire for growth,&#8221; which is directly correlated with economic incentives:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>The algorithms that underpin Facebook’s business weren’t created to filter out what was false or inflammatory; they were designed to make people share and engage with as much content as possible by showing them things they were most likely to be outraged or titillated by.</p></blockquote>\\n\\n\\n\\n<p>The consequence? As groups of people turn inward, agreeing more amongst their in-group, and disagreeing more fervently with those outside of it, the common ground in between, the shared reality, which is where perhaps the truth lies, is slowly lost. Put another way, a by-product of algorithmic polarization and fragmentation has been the formation of more groups that agree within their own groups and disagree far more with other groups, not only on what they value but on ground truth, about reality. </p>\\n\\n\\n\\n<p>We’ve witnessed the genesis of information tribes or <em>InfoTribes</em> and, as these new ideological territories are carved up, those who occupy InfoLandscapes hold that ground as a part of an InfoTribe<sup>7</sup>. Viewed in this way, the online flame wars we’ve become all too accustomed to form part of the initial staking out of territory in these new InfoLandscapes. Anthropologists have long talked about tribes as being formed around symbols of group membership, symbols that unite a people, like totem animals, flags, or&#8230; online content.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13689\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/03/AdobeStock_123489033-1048x667.jpeg\" /></figure>\\n\\n\\n\\n<h2>Reality Brokers, Reality Splintering</h2>\\n\\n\\n\\n<p><em>The platforms that “decide” what we see and when we see it are reality brokers in a serious sense: they guide how individuals construct their sense of the world, their own identities, what they consider ground truth, and the communities they become a part of.</em></p>\\n\\n\\n\\n<p>Arguably, many people aren’t particularly interested in the ground truth per se, they’re interested in narratives that support their pre-existing mental models of the world, narratives that help them sleep at night. This is something that 45 brilliantly, and perhaps unwittingly, played into and made starkly apparent, by continually sowing seeds of confusion, gaslighting the global community, and questioning the reality of anything that didn’t serve his own purposes.</p>\\n\\n\\n\\n<p>This trend isn’t confined to the US. The rise of populism more generally in the West can be seen as the result of diverging senses of reality, the first slice splitting people across ideological and party lines. Why are these divergences in a sense of shared reality becoming so exacerbated and apparent now? The unparalleled velocity at which we receive information is one reason, particularly as we likely haven’t evolved to even begin to process the vast amounts we consume. But it isn&#8217;t only the speed and amount, it&#8217;s the structure. The current media landscape is highly non-linear, as opposed to print and television. Our sense-making and reality-forming faculties are overwhelmed daily by the fractal-like nature of (social) media platforms and environments that are full of overlapping phenomena and patterns that occur at many different frequencies<sup>8</sup>. Moreover, the information we’re served is generally driven by opaque and obscure economic incentives of platforms, which are protected by even more obscure legislation in the form of <a href=\"https://www.theverge.com/21273768/section-230-explained-internet-speech-law-definition-guide-free-moderation\">Section</a> <a href=\"https://www.amazon.com/exec/obidos/ASIN/1501714414/oreillycom-20\">230</a> in the US (there are other incentives at play, themselves rarely surfaced, in the name of “trade secrets”). </p>\\n\\n\\n\\n<p>But let&#8217;s be careful here: it isn’t tech all the way down. We’re also deep in a several decades-long erosion of institutional knowledge, a mistrust in both science and government being the two most obvious. Neoliberalism has carved out the middle class while the fruits of top-down knowledge have left so many people unserved and behind. On top of this, ignorance has been actively cultivated and produced. Look no further than the recent manufacturing of ignorance from the top down with the goals of chaos creation, sowing the seeds of doubt, and delegitimizing the scientific method and data reporting (the study of culturally induced ignorance is known as <em>agnotology </em>and Proctor and Scheibinger&#8217;s book <a href=\"https://www.sup.org/books/title/?id=11232\"><em>Agnotology: The Making and Unmaking of Ignorance</em></a> is canonical). On top of this, we&#8217;ve seen the impact of bad actors and foreign influence (not mutually exclusive) on the dismantling of shared reality, such as Russian interference around the 2016 US election.</p>\\n\\n\\n\\n<p>This has left reality up for grabs and, in an InfoLandscape exacerbated by a global pandemic, those who control and guide the flow of information also control the building of InfoTribes, along with their shared realities. Viewed from another perspective, the internet is a space in which information is created and consumed, a many-sided marketplace of supply-and-demand in which the dominant currency is information, albeit driven by a shadow market of data, marketing collateral, clicks, cash, and crypto. The platforms that “decide” what we see and when we see it are <em>reality brokers </em>in a serious sense: they guide how individuals construct their sense of the world, their own identities, what they consider ground truth, and the communities they become a part of. In some cases, these reality brokers may be doing it completely by accident. They don&#8217;t necessarily care about the ground truth, just about engagement, attention, and profit: the breakdown of shared reality as collateral damage of a globalized, industrial-scale incentive system. In this framework, the rise of conspiracy theories is an artefact of this process: the reality brokered and formed, whether it be a flat earth or a cabal of Satan-worshipping pedophiles plotting against 45, is a direct result of the bottom-up sense-making of top-down <em>reality splintering</em>, the dissolution of ground truth and the implosion of a more general shared reality. Web 2.0 has had a serious part to play in this reality splintering but the current retreat away into higher signal and private platforms such as newsletters, Slack, Discord, WhatsApp, and Signal groups could be more harmful, in many ways.</p>\\n\\n\\n\\n<p>Shared reality is breaking down. But was it even real in the first place?</p>\\n\\n\\n\\n<h2>Shared Reality as Historical Quirk</h2>\\n\\n\\n\\n<p>Being born after World War Two could lead one to believe that shared reality is foundational for the functioning of the world and that it’s something that always existed. But there’s an argument that shared reality, on national levels, was really ushered in by the advent of broadcast media, first the radio, which was in over 50% of US households by the mid-1930s, and then the television, nuclear suburban families, and TV dinners. The hegemonic consolidation of the American dream was directly related to the projection of ABC, CBS, and NBC into each and every household.  When cable opened up TV to more than three major networks, <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1460-2466.2005.tb02677.x\">we began to witness the fragmentation and polarization of broadcast media into more camps</a>, including those split along party lines, modern exemplars being Fox News and CNN.  It is key to recognize that there were distinct and differing realities in this period, split along national lines (USA and Soviet Russia), ideological lines (pro- and anti-Vietnam), and scientific lines (the impact of smoking and asbestos). Even then, it was a large number of people with a small number of shared realities.</p>\\n\\n\\n\\n<p>The spread of national identity via broadcast media didn&#8217;t come out of the blue. It was a natural continuation of similar impacts of &#8220;The Printed Word,&#8221; which Marshall McLuhan refers to as an &#8220;Architect of Nationalism&#8221; in <a href=\"https://mitpress.mit.edu/books/understanding-media\"><em>Understanding Media</em></a>:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>Socially, the typographic extension of man brought in nationalism, industrialism, mass markets, and universal literacy and education. For print presented an image of repeatable precision that inspired totally new forms of extending social energies.</p></blockquote>\\n\\n\\n\\n<p>Note that the shared realities generated in the US in the 20th century weren&#8217;t only done so by national and governmental interests, but also by commercial and corporate interests: mass culture, the culture industries, culture at scale as a function of the rise of the corporation. There were strong incentives for commercial interests to create shared realities at scale across the nation because it&#8217;s easier to market and sell consumer goods, for example, to a homogeneous mass: one size fits all, one shape fits all. This was achieved through the convergence of mass media, modern marketing, and PR tactics.</p>\\n\\n\\n\\n<p>Look no further than Edward Bernays, a double nephew of Freud who was referred to in his obituary as &#8220;the Father of Public Relations.&#8221; Bernays famously &#8220;<a href=\"https://www.npr.org/templates/story/story.php?storyId=4612464\">used his Uncle Sigmund Freud&#8217;s ideas to help convince the public, among other things, that bacon and eggs was the true all-American breakfast</a>.&#8221; In the abstract of his 1928 paper &#8220;<a href=\"https://web.archive.org/web/20170407053758/http://w.truty.org/PDFs/Media/BERNAYS-ManipulatingPublicOpinion.pdf\">Manipulating Public Opinion: The Why and the How</a>,&#8221; Bernays wrote:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>If the general principles of swaying public opinion are understood, a technique can be developed which, with the correct appraisal of the specific problem and the specific audience, can and has been used effectively in such widely different situations as changing the attitudes of whites toward Negroes in America, changing the buying habits of American women from felt hats to velvet, silk, and straw hats, changing the impression which the American electorate has of its President, introducing new musical instruments, and a variety of others.</p></blockquote>\\n\\n\\n\\n<p>The Century of Marketing began, in some ways, with psychoanalytical tools, marketing as a mode of reality generation, societal homogenization, and behavioral modification. A paradigm of this is how <a href=\"https://www.theatlantic.com/international/archive/2015/02/how-an-ad-campaign-invented-the-diamond-engagement-ring/385376/\">DeBeers convinced the West to adopt diamonds as the necessary gem for engagement rings</a>. A horrifying and still relevant example is <a href=\"https://www.newyorker.com/magazine/2017/10/30/the-family-that-built-an-empire-of-pain\">Purdue Pharma and the Sackler dynasty&#8217;s marketing of OxyContin</a>.</p>\\n\\n\\n\\n<p>The channels used by marketers were all of the culture industries, including broadcast media, a theme most evident in the work of <a href=\"https://en.wikipedia.org/wiki/Frankfurt_School\">the Frankfurt School</a>, notably in that of Theodor Adorno and Max Horkheimer. Look no further than Adorno&#8217;s 1954 essay &#8220;<a href=\"https://users.clas.ufl.edu/burt/I%27mnotcrazy!/AdornoHowtoLookatTelevision.pdf\">How to Look at Television</a>&#8220;:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>The old cultured elite does not exist any more; the modern intelligentsia only partially corresponds to it. At the same time, huge strata of the population formerly unacquainted with art have become cultural &#8220;consumers.&#8221;</p></blockquote>\\n\\n\\n\\n<p>Although it was all the culture industries of the 20th century that worked to homogenize society at the behest of corporate interests, television was the one that we brought into our living rooms and that we eventually watched with family over dinner. Top-down reality-generation was centralized and projected into nuclear suburban homes.</p>\\n\\n\\n\\n<p>Fast forward to today, the post-broadcast era, in which information travels close to the speed of light, in the form of lasers along fiber-optic cables and it’s both multi-platformed and personalized and everyone is a potential creator: reality, <em>once again</em>, is decentralized. In this frame, the age of shared reality was the anomaly, the exception rather than the rule. It’s perhaps ironic that one of the final throes of the age of shared reality was the advent of reality TV, a hyper-simulation of reality filtered through broadcast media. So now, in a fractured and fractal InfoLandscape, who do we look to in our efforts to establish some semblance of ground truth?</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13690\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/03/AdobeStock_84736851-1048x704.jpeg\" /></figure>\\n\\n\\n\\n<h2>Verified Checkmarks and Village Elders</h2>\\n\\n\\n\\n<p><em>If our online communities are our InfoTribes, then the people we look to for ground truth are our village elders, those who tell stories around the campfire. </em></p>\\n\\n\\n\\n<p>When COVID-19 hit, we were all scrambling around for information about reality in order to make decisions, and not only were the stakes a matter of life and death but, for every piece of information somewhere, you could find the opposite somewhere else. The majority of information, for many, came through social media feeds. Even when the source was broadcast media, a lot of the time it would be surfaced in a social media feed. Who did I pay attention to? Who did I believe? How about you? For better or for worse, I looked to my local (in an online sense) community, those whom I considered closest to me in terms of shared values and shared reality. On top of this, I looked to those respected in my communities. On Twitter, for example, I paid attention to <a href=\"https://twitter.com/EpiEllie\">Dr Eleanor Murray</a> and <a href=\"https://twitter.com/NAChristakis\">Professor Nicholas Christakis</a>, among many others. And why? They’re both leaders in their fields with track records of deep expertise, for one. But they also have a lot of Twitter followers and have the coveted blue verified checkmarks: in an InfoLandscape of such increasing velocity, we use rules of thumbs and heuristics around what to believe and what to not, including the validity and verifiability of the content creator, signaled by the number of followers, who the followers are (do I follow any of them? And what do I think of them?), and whether or not the platform has verified them.</p>\\n\\n\\n\\n<p>If our online communities are our InfoTribes, then the people we look to for ground truth are our village elders, those who tell stories around the campfire. In the way they have insight into the nature of reality, we look to them as our illiterate ancestors looked to those who could read or as Pre-Reformation Christians looked to the Priests who could read Biblical Latin. With the emergence of these decentralized and fractured realities, we are seeing hand-in-hand those who rise up to define the realities of each InfoTribe. It’s no wonder the term <em>Thought Leader</em> rose to prominence as this landscape clarified itself. We are also arguably in the midst of a paradigm shift from content being the main object of verification online to content creators themselves being those verified. As Robyn Caplan points out astutely in <em><a href=\"https://slate.com/technology/2020/12/pornhub-verified-users-twitter.html\">Pornhub Is Just the Latest Example of the Move Toward a Verified Internet</a></em>:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>It is often said that pornography drives innovation in technology, so perhaps that’s why many outlets have framed Pornhub’s verification move as “unprecedented.” However, what is happening on Pornhub is part of a broader shift online: Many, even most, platforms are using “verification” as a way to distinguish between sources, often framing these efforts within concerns about safety or trustworthiness.</p></blockquote>\\n\\n\\n\\n<p>But mainstream journalists are more likely to be verified than independent journalists, men more likely than women, and, as Caplan points out “there is a dearth of publicly available information about the demographics of verification in general—for instance, whether BIPOC users are verified at the same rates as white users.” And it is key to note that many platforms are increasingly verifying and surfacing content created by “platform partners,“ an approach also driven by business incentives. Who decides who we listen to? And, as <a href=\"https://www.theguardian.com/books/2019/oct/04/shoshana-zuboff-surveillance-capitalism-assault-human-automomy-digital-privacy\">Shoshana Zuboff</a> continually asks, <em>Who decides who decides?</em></p>\\n\\n\\n\\n<p>This isn&#8217;t likely to get better anytime soon, with the retreat to private and higher signal communication channels, the next generation of personalized products, the advent of deep fakes, the increasing amount of information we&#8217;ll be getting from voice assistants over the coming 5-10 years, the proportion of information consumed via ephemeral voice-only apps such as Clubhouse, and the possibility of augmented reality playing an increasing role in our daily lives.</p>\\n\\n\\n\\n<p>So what to do? Perhaps instead of trying to convince people of what we believe to be true, we need to stop asking &#8220;What planet are you from?&#8221; and start looking for shared foundations in our conversations, a sense of shared reality. We also have a public awareness crisis on our hands as the old methods of media literacy and education have stopped working. We need to construct new methods for people to build awareness, educate, and create the ability to dissent. Public education will need to bring to light the true contours of the emergent InfoLandscapes, some key aspects of which I have attempted to highlight in this essay. It will also likely include developing awareness of all our information platforms as multi-sided marketplaces, a growing compendium of all the informational dark patterns at play, the development of informational diets and new ways to count InfoCalories, and bringing antitrust suits against the largest reality brokers. Watch these spaces.</p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<p><em>Many thanks to Angela Bowne, Anthony Gee, Katharine Jarmul, Jamie Joyce, Mike Loukides, Emanuel Moss, and Peter Wang for their valuable and critical feedback on drafts of this essay along the way.</em></p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<h3>Footnotes</h3>\\n\\n\\n\\n<p>1. A term first coined in 1990 by the playwright Steve Teisch and that was the Oxford Dictionaries 2016 Word of the Year (source: <a href=\"https://www.thenation.com/article/archive/post-truth-and-its-consequences-what-a-25-year-old-essay-tells-us-about-the-current-moment\">Post-Truth and Its Consequences: What a 25-Year-Old Essay Tells Us About the Current Moment)</a><br />2. See Benedict Anderson&#8217;s <a href=\"https://www.versobooks.com/books/2259-imagined-communities\"><em>Imagined Communities</em></a> for more about the making of nations through shared reading of print media and newspapers.<br />3. I discovered this reference in Fred Turner&#8217;s startling book&nbsp;<a href=\"https://press.uchicago.edu/ucp/books/book/chicago/F/bo3773600.html\" rel=\"noreferrer noopener\" target=\"_blank\"><em>From Counterculture to Cyberculture</em></a>, which traces the countercultural roots of the internet to movements such as the New Communalists, leading many tech pioneers to have a vision of the web as &#8220;a collaborative and digital utopia modeled on the communal ideals&#8221; and &#8220;reimagined computers as tools for personal [and societal] liberation.&#8221;<br />4. There is a growing movement recognizing the importance of information flows in society. See, for example, <a href=\"https://courses.openmined.org/\">OpenMined&#8217;s free online courses</a> which are framed around the theme that <a href=\"https://blog.openmined.org/society-runs-on-information-flows/\">&#8220;Society runs on information flows.&#8221;</a><br />5. Think Twitter, for example, which builds communities by surfacing specific tweets for specific groups of people, a surfacing that’s driven by economic incentives, among others; although do note that TweetDeck, owned by Twitter, does not show ads, surface tweets, or recommend follows: perhaps the demographic that mostly uses TweetDeck doesn&#8217;t click on ads?<br />6. Having said this, there are some ethical constraints in the physical publishing business, for example, you can&#8217;t run an ad for a product across from an article or review of the product; there are also forms of transparency and accountability in physical publishing: we can all see what any given broadsheet publishes, discuss it, and interrogate it collectively.<br />7. Related concepts are the <a href=\"https://en.wikipedia.org/wiki/Tribe_(internet)\">digital tribe</a>, a group of people who share common interests online, and the <a href=\"https://medium.com/s/world-wide-wtf/memetic-tribes-and-culture-war-2-0-14705c43f6bb\">memetic tribe</a>, &#8220;a group of agents with a meme complex, or memeplex, that directly or indirectly seeks to impose its distinct map of reality—along with its moral imperatives—on others.&#8221;<br />8. Is it a coincidence that we&#8217;re also currently seeing the rise of non-linear note-taking, knowledge base, and networked thought tools, such as <a href=\"https://roamresearch.com/\">Roam Research</a> and <a href=\"https://obsidian.md/\">Obsidian</a>?</p>\\n\\n\\n\\n<p></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/infotribes-reality-brokers/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'The End of Silicon Valley as We Know It?',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The End of Silicon Valley as We Know It?'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/the-end-of-silicon-valley-as-we-know-it/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/the-end-of-silicon-valley-as-we-know-it/',\n",
       "   'comments': 'https://www.oreilly.com/radar/the-end-of-silicon-valley-as-we-know-it/#respond',\n",
       "   'published': 'Thu, 11 Mar 2021 17:22:01 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=11, tm_hour=17, tm_min=22, tm_sec=1, tm_wday=3, tm_yday=70, tm_isdst=0),\n",
       "   'authors': [{'name': 'Tim O’Reilly'}],\n",
       "   'author': 'Tim O’Reilly',\n",
       "   'author_detail': {'name': 'Tim O’Reilly'},\n",
       "   'tags': [{'term': 'Radar Column', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13665',\n",
       "   'guidislink': False,\n",
       "   'summary': 'High-profile entrepreneurs like Elon Musk, venture capitalists like Peter Thiel and Keith Rabois, and big companies like Oracle and HP Enterprise are all leaving California. During COVID-19, Zoom-enabled tech workers have discovered the benefits of remote work from cheaper, less congested communities elsewhere. Is this the end of Silicon Valley as we know it? Perhaps. [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'High-profile entrepreneurs like Elon Musk, venture capitalists like Peter Thiel and Keith Rabois, and big companies like Oracle and HP Enterprise are all leaving California. During COVID-19, Zoom-enabled tech workers have discovered the benefits of remote work from cheaper, less congested communities elsewhere. Is this the end of Silicon Valley as we know it? Perhaps. [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>High-profile entrepreneurs like Elon Musk, venture capitalists like Peter Thiel and Keith Rabois, and big companies like Oracle and HP Enterprise are all leaving California. During COVID-19, Zoom-enabled tech workers have discovered the benefits of remote work from cheaper, less congested communities elsewhere. Is this the end of Silicon Valley as we know it? Perhaps. But other challenges to Silicon Valley’s preeminence are more fundamental than the tech diaspora.</p>\\n\\n\\n\\n<p>Understanding four trends that may shape the future of Silicon Valley is also a road map to some of the biggest technology-enabled opportunities of the next decades:</p>\\n\\n\\n\\n<ol><li>Consumer internet entrepreneurs lack many of the skills needed for the life sciences revolution.</li><li>Internet regulation is upon us.</li><li>Climate response is capital intensive, and inherently local.</li><li>The end of the betting economy.</li></ol>\\n\\n\\n\\n<h3>Inventing the future</h3>\\n\\n\\n\\n<p>“The best way to predict the future is to invent it,” <a href=\"https://quoteinvestigator.com/2012/09/27/invent-the-future/\">Alan Kay once said</a>. 2020 proved him both right and wrong. The coronavirus pandemic, or something worse, had long been predicted,&nbsp;but it still caught the world unprepared, a better future not yet invented. Climate change too has been on the radar, not just for decades but for over a century, since <a href=\"https://www.rsc.org/images/Arrhenius1896_tcm18-173546.pdf\">Arrhenius’s 1896 paper on the greenhouse effect</a>. And it has long been known that inequality and <a href=\"https://www.amazon.com/Caste-Origins-Discontents-Isabel-Wilkerson/dp/0593230256/\">caste</a> are corrosive to social stability and <a href=\"https://en.wikipedia.org/wiki/Why_Nations_Fail\">predict the fate of nations</a>. Yet again and again the crisis finds us unprepared when it comes.</p>\\n\\n\\n\\n<p>In each case, though, the long-predicted future is still not foreordained. <em>It is up to us whether we are steamrollered by events beyond our control or whether we have the collective power to invent a better future.</em> Awakening may have come later than we might have wished, but crises like the pandemic and climate change can still be massive drivers of innovation. If entrepreneurs, investors, and governments step up to solve the hard problems that we face today, the future remains bright. But one thing is certain: the inventions we most urgently need will take us in a very different direction than the consumer internet and social media revolution that is coming to an unsightly end.</p>\\n\\n\\n\\n<p>The coronavirus is a case in point. The explosion of biomedical invention that it has accelerated may well have impacts that extend well beyond the pandemic itself. <a href=\"https://www.nature.com/articles/nrd.2017.243\">mRNA vaccines</a> have given us a promising path to COVID immunity, developed in record time. <a href=\"https://nymag.com/intelligencer/2020/12/moderna-covid-19-vaccine-design.html\">Moderna’s vaccine was created within only two days</a> after Chinese scientist Yong-Zhen Zhang released the genetic sequence of the virus! And mRNA vaccines are also easily tweaked, raising the possibility of even quicker response to mutations, and even the creation of <a href=\"https://www.nature.com/articles/nrd.2017.243\">a framework for rapid development of many more vaccines.</a> We are starting to see the payoff of radically new approaches to biomedical innovation, and in particular, the way that machine learning is turbocharging research. During 2020, <a href=\"https://www.stateof.ai/\">more than 21,000 biomedical research papers made reference to AI and machine learning</a>.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large is-resized\"><img alt=\"\" class=\"wp-image-13666\" height=\"327\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/02/Tim_article-1048x591.png\" width=\"580\" /></figure>\\n\\n\\n\\n<p>The recent announcement by DeepMind that its AlphaFold technology is able to <a href=\"https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology\">predict protein structure with accuracy comparable to slow and costly experimental methods</a> is a harbinger of breakthroughs to come. As geneticist <a href=\"https://twitter.com/timjph/status/1333438139529048067\">Tim Hubbard wrote</a>, “The genomes we believed were blueprints for life were effectively encrypted—this will unlock them and transform biological and biomedical research.”</p>\\n\\n\\n\\n<p><strong>Prediction: The nexus of machine learning and medicine, biology, and materials science will be to the coming decades what Silicon Valley has been to the late 20th and early 21st century.</strong></p>\\n\\n\\n\\n<p>Why might this mark the end of Silicon Valley as we know it? First, the required skills are different. Yes, machine learning, statistical analysis, and programming are all needed, but so is deep knowledge of relevant science. The hubs where that knowledge can be found are not the special province of Silicon Valley, suggesting that other regions may take the lead. Second, many of the markets where fortunes will be made are regulated; navigating regulated markets also takes skills that are conspicuously missing in Silicon Valley. Finally, as <a href=\"https://en.wikipedia.org/wiki/Theranos\">Theranos</a> demonstrated so vividly, it is harder to sustain a hype balloon in a scientific enterprise than in many of the markets where Silicon Valley has prospered. Many Silicon Valley investors have been lucky rather than smart. They may not do so well in a world where capital must be directed toward solving hard problems rather than toward winning a popularity contest.</p>\\n\\n\\n\\n<h3>Mastering “the demons of our own design”</h3>\\n\\n\\n\\n<p>The opportunity of machine learning in scientific R&amp;D is profound. But machine learning also challenges our current approach to science, which relies on human theorizing and experiments. A machine learning model may be able to make successful predictions but not to explain them. When Arthur C. Clarke wrote <a href=\"https://en.wikipedia.org/wiki/Clarke%27s_three_laws\">“Any sufficiently advanced technology is indistinguishable from magic,”</a> was he imagining a future in which our own science would leave our understanding behind? As <a href=\"https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/\">Judea Pearl has noted</a>, excessive identification of correlations (i.e, &#8220;curve fitting&#8221;) makes the definition of authentic causal relationships more challenging. And &#8220;real science&#8221; needs causal relationships.</p>\\n\\n\\n\\n<p>I suspect that we will come to terms with machine learning-enabled science, just as we’ve come to terms with instruments that let us see far beyond the capabilities of the naked eye. But without a better understanding of our machine helpers, we may set them down paths that take us to the edge of a cliff, much as we’ve done with social media and our fractured information landscape.</p>\\n\\n\\n\\n<p>That fractured landscape is not what was predicted—internet pioneers expected freedom and the wisdom of crowds, not that we would all be under the thumb of giant corporations profiting from a market in disinformation. What we invented was not what we hoped for. The internet became the stuff of our nightmares rather than of our dreams. We can still recover, but at least so far, Silicon Valley appears to be part of the problem more than it is part of the solution.</p>\\n\\n\\n\\n<p>Can technology platforms rein in the demons of our own design (to use <a href=\"https://www.amazon.com/Demon-Our-Own-Design-Innovation/dp/0470393750\">Richard Bookstaber’s memorable phrase</a>)? That too will be one of the challenges that shape the coming decades.</p>\\n\\n\\n\\n<p>Government regulators in Europe and the US have set their sights on Facebook, Google, Amazon, and Apple, but the regulatory responses will be insufficient if they are based on old theories, old understandings that the platforms have already outstripped. The US theory of antitrust has largely been based on the question of consumer harm, which is difficult to prove in marketplaces where services are provided to consumers at zero cost and where the marginal cost of experimenting on those consumers is also close to zero. The emerging European regulatory effort is properly focused on the role of dominant tech firms as “<a href=\"https://ec.europa.eu/info/strategy/priorities-2019-2024/europe-fit-digital-age/digital-markets-act-ensuring-fair-and-open-digital-markets_en\">gatekeepers</a>.” It aims to systematically limit their ability to shape the market for their own advantage. Its remedies, though, are blunt, and the processes for assessing harms will most likely proceed more slowly than the harms themselves.</p>\\n\\n\\n\\n<p>Markets are ecosystems, and like other ecosystems, there are hidden dependencies everywhere. The harm of Google abusing its monopoly position will not show up first in harm to consumers, but in depressed profits, decreased R&amp;D investment, and lower wages at the web companies to whom Google once directed traffic. For Amazon, it will show up in the increased fees and advertising costs required to show up in product search.</p>\\n\\n\\n\\n<p>These harms to the supply side of marketplace platforms, with the majority of the gains being captured by the winner of <a href=\"https://qz.com/1540608/the-problem-with-silicon-valleys-obsession-with-blitzscaling-growth/\">the winner-takes-all model that Silicon Valley has encouraged</a>, do eventually cascade to consumers. But because the pain is widely distributed and because the platforms are not required to report the information that would make it visible, the problem will not be obvious until much of the damage is irreversible.</p>\\n\\n\\n\\n<p>When the “<a href=\"https://economics.mit.edu/files/12979\">superstar firms</a>” ruthlessly compete with smaller firms that come up with fresh ideas, not only starving them of talent but often introducing copycat products and services, there is decreased innovation from the market as a whole. Cities are dominated by a new class of highly paid big-company employees driving up housing costs and forcing out lower wage workers; wages and working conditions of workers in less profitable industries are squeezed to drive the growth of the giants. Their very jobs are made contingent and disposable, with inequality baked in from the beginning of their employment. Governments are starved of revenue by giant companies that have mastered the art of tax avoidance. The list is far longer than that.</p>\\n\\n\\n\\n<p>In the case of social media platforms, manipulation of users for profit has frayed the fabric of democracy and the respect for truth. Silicon Valley, which once harnessed the collective intelligence of its users, now uses its deep knowledge of its users to “trade against them.” (<a href=\"http://radar.oreilly.com/2007/12/trading-for-their-own-account.html\">I predicted the broad outline of this turn back in 2007</a>, after conversations with venture capitalist and economist Bill Janeway <a href=\"https://www.oreilly.com/data/free/files/release2-issue2.pdf\">about what we might learn from Wall Street about the future of the internet</a>.) </p>\\n\\n\\n\\n<p>Technology is far from the only offender. It is merely the most visible mirror of our values as a society. The extractive behavior the tech giants exhibit has been the norm for modern capitalism since Milton Friedman set its objective function in 1970: “<a href=\"https://www.nytimes.com/1970/09/13/archives/a-friedman-doctrine-the-social-responsibility-of-business-is-to.html\">The social responsibility of business is to increase its profits</a>.” This is all the sadder, though, since the tech industry set out to model something better. The generosity of open source software and the World Wide Web, the genius of algorithmically amplified collective intelligence are still there, pointing the way to <a href=\"https://www.oreilly.com/radar/topics/next-economy/\">the Next Economy</a>, but it is an economy we must actively choose, rather than riding the rails of a system that is taking us in the wrong direction.</p>\\n\\n\\n\\n<p><strong>Prediction: Because platform businesses have failed to regulate themselves, they will have limits placed on their potential for good as well as harm.</strong></p>\\n\\n\\n\\n<p>It’s a sad time for Silicon Valley, because we are seeing not only the death of its youthful idealism but a missed opportunity. <a href=\"https://www.sci.pitt.edu/people/paul-cohen\">Paul Cohen</a>, the former DARPA program manager for AI, made a powerful statement a few years ago at a meeting of the National Academy of Sciences that we both attended: “The opportunity of AI is to help humans model and manage complex interacting systems.”</p>\\n\\n\\n\\n<p>That statement sums up so much of the potential that is squandered when firms like Google, Amazon, and Facebook fall prey to the Friedman doctrine rather than setting more ambitious goals for their algorithms.</p>\\n\\n\\n\\n<p>I’m not talking about future breakthroughs in AI so much as I’m talking about the fundamental advances in market coordination that the internet gatekeepers have demonstrated. These powers can be used to better model and manage complex interacting systems for the good of all. Too often, though, they have been made subservient to the old extractive paradigm.</p>\\n\\n\\n\\n<p>To explain what I mean requires a small aside.</p>\\n\\n\\n\\n<p>Free market economists believe that the willingness of producers and consumers to agree on prices at which they will exchange goods or services (in idealized markets that are characterized by perfect competition with no asymmetries of power or information) leads to the best allocation of society’s resources. The solution to complex equations representing supply chains of self-interest is expressed in these market prices. Money, in effect, is the coordinating power behind Adam Smith’s “invisible hand.”</p>\\n\\n\\n\\n<p>Like the anonymous internet wag <a href=\"https://www.snopes.com/fact-check/practice-and-theory/\">who wrote</a>, “The difference between theory and practice is always greater in practice than it is in theory,” economists recognize that perfect competition exists only in theory, that “externalities” exist where costs are borne by people other than the buyer and the seller, and that few markets are completely efficient. The role of the state, in many ways, is to address the shortcomings of the market. Diane Coyle’s book <a href=\"https://press.princeton.edu/books/hardcover/9780691179261/markets-state-and-people\"><em>Markets, State, and People</em></a> gives an excellent account of how economic policy makers think about the trade-offs they make when they intervene. Even at their best, though, the available interventions—taxes, monetary policy, and regulations—are piecemeal and take years or decades to agree on and implement. (<a href=\"https://www.worldbank.org/en/programs/pricing-carbon\">Carbon pricing</a> is a case in point.)</p>\\n\\n\\n\\n<p>Google’s search engine has given us a convincing demonstration of a radically different method for managing an economic system. Constantly refined, dynamic, and infused with AI, Google’s algorithmic systems demonstrate that it is possible to manage an economy in ways not imagined by 20th century economists. 40,000 times a second, 3.5 billion times a day, Google’s centrally managed search performs the magic that, for so long, was thought to be the unique province of decentralized, self-interested actors transacting in priced markets.</p>\\n\\n\\n\\n<p>In a brilliant stroke, Google built an algorithmic system that uses hundreds of distinct information signals to make the best match between tens of millions of information providers and billions of information consumers—<em>but price is not one of those signals</em>. That is not to say that Google does not participate in the money economy. Far from it. But&nbsp; for Google’s first decade and a half, the priced market of pay-per-click advertising was a sidecar to the primary matching marketplace of search. The initial genius of Google was to run the market coordinated by collective intelligence (organic search) and the market coordinated by money (pay per click advertising) in parallel. And when producers with economic motivations manipulated organic search results for profit but to the detriment of Google’s users, producing pages that satisfied the algorithms but failed to satisfy consumers, <a href=\"https://martinwilson.info/history-of-google-algorithm-updates-killed-businesses/\">Google was ruthless in updating the algorithms</a> to focus on consumer benefit.</p>\\n\\n\\n\\n<p>To be sure, a great deal of content on the World Wide Web and in social media is produced and consumed with commercial intent, but a remarkable amount is produced entirely without a profit motive. Google economists have told me that only six percent of Google search result pages carry any advertising at all. The other 94% of pages are the product of the joyful exuberance of humanity, creating and sharing for the joy of it. If there has ever been a harbinger of a possible economy of abundance, we can see it in the best of the internet sharing economy.</p>\\n\\n\\n\\n<p>In recent years, though, Google has increasingly blurred the lines between the two information markets it manages (the price-free market of search and the priced market of advertising). <a href=\"https://www.washingtonpost.com/technology/2020/10/19/google-search-results-monopoly/\">And that has made commercially valuable search results less effective than those that have no purely economic value.</a> That is, Google appears to match information producers and consumers<em> more effectively</em> in the absence of the distorting power of money.</p>\\n\\n\\n\\n<p>So too Amazon. Unlike Google, Amazon has always used price as an important signal in its search rankings, but price was intelligently combined with measures of collective opinion—what other consumers thought was the best product—to create a market that was more efficient than any previous consumer goods marketplace. But in recent years, with the introduction of search advertising as a major new revenue line, Amazon too has turned away from using the tools of collective intelligence to find the best products for its customers. Its search is now dominated by “featured” products—that is, products that producers have paid to put in front of consumers. With advertising now one of the biggest drivers of Amazon’s profits, it is hard to imagine that the company can remain, as Jeff Bezos has proudly boasted, the most consumer-centric platform on earth. I wrote about this problem at length last year, in “<a href=\"https://qz.com/1666863/why-big-tech-keeps-outsmarting-antitrust-regulators/\">Antitrust regulators are using the wrong tools to regulate big tech</a>.”</p>\\n\\n\\n\\n<p>So many of the problems that antitrust actions and other regulations are now gearing up to address are, paradoxically, the result of the prime directive by which our economic and legal system governs its corporations: “Thou must maximize profits.”</p>\\n\\n\\n\\n<p>The notion of maximizing profit is so ingrained in our society that in 2014, when Facebook researchers published a paper called “<a href=\"https://www.pnas.org/content/111/24/8788\">Experimental Evidence of Massive-Scale Emotional Contagion Through Social Networks</a>,” the <a href=\"https://www.nytimes.com/2014/06/30/technology/facebook-tinkers-with-users-emotions-in-news-feed-experiment-stirring-outcry.html\">response was swift and savage</a>. It was considered a terrible breach of research ethics to test whether the mix of stories in the Facebook news feed made its readers happier or sadder. The reaction was particularly striking because no one seemed to notice that Silicon Valley explicitly celebrates and teaches its entrepreneurs how to manipulate the emotional state of users, calling it “<a href=\"https://smile.amazon.com/Hacking-Growth-Fastest-Growing-Companies-Breakout/dp/045149721X/\">growth hacking</a>” or “<a href=\"https://en.wikipedia.org/wiki/A/B_testing\">A/B testing</a>” or “<a href=\"http://amazon.com/Hooked-How-Build-Habit-Forming-Products/dp/1591847788/\">creating habit-forming products</a>.” No one complains about <em>these</em> experiments. It’s considered a best practice to experiment on your customers as long as it is in pursuit of growth and profits.</p>\\n\\n\\n\\n<p>Because the cost of those experiments is so low—it’s a sunk cost of the business—experimental mistakes and unforeseen consequences are only to be expected. They become a new class of externality little considered by economists and regulators.</p>\\n\\n\\n\\n<p>In retrospect, some formal experimentation on emotional contagion and reflection on its implications would have been a good idea. Instead, we continue to run global-scale unsupervised experiments on the power of social media to spread negative emotional contagion for profit, while any effort by the platforms to influence their users in positive directions is still considered by many to be inappropriate intervention, or is abandoned because it might reduce user activity and growth.</p>\\n\\n\\n\\n<p>For example, during the 2020 US presidential election, Facebook engineers reportedly trained a machine learning algorithm to recognize posts that their users would consider “<a href=\"https://www.nytimes.com/2020/11/24/technology/facebook-election-misinformation.html\">bad for the world</a>,” but the company found that showing fewer of them reduced the number of user sessions and thus, presumably revenue and profits. So they retrained the algorithm to find the point where “bad for the world” posts were reduced but not by so much that they impacted user sessions. Other changes to optimize for “news ecosystem quality” were put in place for a few weeks leading up to the election, but reversed thereafter.</p>\\n\\n\\n\\n<p>“Shareholder value” is so ingrained in corporate governance that a special class of corporation, “<a href=\"https://socialenterprise.us/resources/news/b-corps-public-benefit-corporations/\">the public benefit corporation</a>,” has been defined to protect companies that are managed to take other considerations than profit into account. All “normal” companies are expected to treat employees, the environment, and society as costs to be minimized, avoided, or eliminated.</p>\\n\\n\\n\\n<p><em>Silicon Valley is a mirror of what is wrong with our economy and corporate governance, not the cause of it, or even the worst exemplar.</em> (<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3490543/\">Tobacco</a>, <a href=\"https://www.greenpeace.org/usa/global-warming/exxon-and-the-oil-industry-knew-about-climate-change/exxons-climate-denial-history-a-timeline/\">oil</a>, and <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7357445/\">pharma</a> companies vie for the top spot.)</p>\\n\\n\\n\\n<p>In many ways, regulators can still learn from Silicon Valley. Our economy too is shaped by invisible algorithms and embedded objectives. If regulators can see the analogies between the way Google, Amazon, and Facebook’s algorithms shape their services and the way that law, tax, and monetary policy shape who gets what and why in our society, and why corporate leaders act the way they do, we can use the current moment to improve not only Silicon Valley but the fairness and the goals of our entire economy.</p>\\n\\n\\n\\n<p>As I wrote last year in “<a href=\"https://www.rockefellerfoundation.org/blog/we-have-already-let-the-genie-out-of-the-bottle/\">We Have Already Let the Genie Out of the Bottle</a>,” an essay for a Rockefeller Foundation workshop on regulating AI, our corporations and our government and our markets are what science fiction writer Charlie Stross calls “<a href=\"https://boingboing.net/2017/12/29/llcs-are-slow-ais.html\">slow AIs.</a>” I made the case that we cannot regulate them without rebuilding the rules by which they operate:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>“Attempts at governance…are futile until we recognize that we have built a machine and set it on its course. Instead, we pretend that the market is a natural phenomenon best left alone, and we fail to hold its mechanism designers to account. We need to tear down and rebuild that machine, reprogramming it so that human flourishing, not corporate profit, becomes its goal. We need to understand that we can’t just state our values. We must implement them in a way that our machines can understand and execute.”</p></blockquote>\\n\\n\\n\\n<p>Silicon Valley can still lead in this effort. The big platforms must understand their social responsibility to <a href=\"https://www.petershallard.com/create-more-value-than-you-capture/#:~:text=Creating%20more%20value%20than%20you%20capture%20is%20a%20philosophy%20of,don\\'t%20show%20up).\">create more value than they capture</a>, focus their algorithmic systems on improving human welfare, find ways to measure and communicate the value that they create, and help our broader society to better “model and manage complex interacting systems.”</p>\\n\\n\\n\\n<p>The danger of regulatory response that simply tries to turn back the clock and doesn’t take into account the ways technology done right could point the way forward is illustrated by the battle over <a href=\"https://en.wikipedia.org/wiki/2020_California_Proposition_22\">California’s Proposition 22</a>. Its passage overturned state regulations requiring gig economy companies to treat their workers as employees rather than independent contractors.</p>\\n\\n\\n\\n<p>Traditional labor protections and benefits assumed a world in which individuals worked for a single employer. An attempt to impose those assumptions on companies reliant on gig workers was seen as an existential threat by those companies, who mounted a massive campaign against the new rules. Their customers agreed, and regulations were rolled back by the will of the public.</p>\\n\\n\\n\\n<p>The gig economy companies have made some small steps toward flexible benefits on their own, but they are a pale shadow of what they might have been if the companies and their gig workers and their customers, not to mention their regulators, had been working together to build systems that would allow benefits to be managed as dynamically as employment. In the German model of stakeholder capitalism, workers are at the management table rather than pitted against the companies they work for. Is there a 21st century version of stakeholder capitalism yet to be designed, one that is not zero-sum but instead “models and manages complex interacting systems” to find better solutions for all?</p>\\n\\n\\n\\n<p>As I argued five years ago in “<a href=\"https://wtfeconomy.com/workers-in-a-world-of-continuous-partial-employment-4d7b53f18f96\">Workers in a World of Continuous Partial Employment</a>,” we need a much more robust benefit system that is centered on the worker, not on the company. The gig economy companies are not outliers. Continuous partial employment has become the norm in much of the economy. A combination of the rise of the Friedman doctrine and the demise of labor unions has reset the balance of power between companies and their workers. The legislative and regulatory response needs to address this power imbalance systematically, across the entire labor economy, using the capabilities of technology to create new models of cooperation between companies and their workers, and a safety net that catches everyone, not just a lucky few.</p>\\n\\n\\n\\n<h3>Climate change and the energy economy</h3>\\n\\n\\n\\n<p>The recent news that Elon Musk is one of the world’s richest people is also a harbinger of the biggest opportunity of the 21st century: to avert climate change. Electric vehicles are the tip of the iceberg. Heating and cooling, agriculture, raw materials and manufacturing—all need reinvention. Climate will reshape residential and office construction, insurance, finance, and where and how food is produced. <a href=\"https://www.nytimes.com/interactive/2020/07/23/magazine/climate-migration.html\">Massive climate migrations have only just begun</a>; tens or hundreds of millions of people will need to be resettled. Will we offer them shantytowns, or will we help them become settlers building a new, better world?</p>\\n\\n\\n\\n<p><strong>Prediction: There will be more climate billionaires created in the next two decades than in the internet boom.</strong></p>\\n\\n\\n\\n<p>With the exception of Musk, many of the already-minted climate billionaires are outside the US, highlighting the way that other countries already have the lead in these industries of the future. <a href=\"https://www.bloomberg.com/features/2020-green-billionaires/\">Bloomberg recently named a few</a>: China’s Zeng Yuqun, Huang Shilin, Pei Zhenhua, and Li Ping (electric vehicle batteries), Li Zhenguo, Li Chunan, and Li Xiyan (solar panels and films), Lin Jianhua (solar panels and films), and Wang Chuanfu (electric vehicles); Germany’s Aloys Wobben (wind turbines); and Spain’s Jose Manuel Entrecanales (renewable power generation).</p>\\n\\n\\n\\n<p>There are great fortunes yet to be made, of course. While <a href=\"https://www.impossiblefoods.com/\">Impossible Foods</a> CEO Patrick Brown and <a href=\"https://www.beyondmeat.com/\">Beyond Meat</a> founder Ethan Brown (no relation) and <a href=\"https://www.plenty.ag/about-us/\">Plenty</a>’s Matt Barnard, <a href=\"https://boweryfarming.com/\">Bowery</a>’s Irving Fain, or <a href=\"https://www.digitaltrends.com/news/nordic-harvest-hydroponic-farms/\">Nordic Harvest&#8217;s Anders Riemann</a> are not yet billionaires, it is quite possible that they will be. But for the most part, Silicon Valley entrepreneurs and investors are not leaders in this sector.</p>\\n\\n\\n\\n<p>In any case, who will get rich helping us transition to a new energy economy is unimportant compared to the question of whether we will summon the political will to make the transition in time to avoid the most disastrous consequences of climate change, which could, at their worst, bring an end to civilization as we know it.</p>\\n\\n\\n\\n<p>A strong argument can be made that only a crash mobilization of the economy to <a href=\"https://www.vox.com/2016/9/19/12938086/electrify-everything\">electrify everything</a> can get us there in time. Saul Griffith, Alex Laskey, and Sam Calisch of the nonprofit <a href=\"http://rewiringamerica.org/\">Rewiring America</a> have made just that argument. And here, the algorithms that guide our economy to focus on “efficiency” need to be questioned. As economist and former venture capitalist Bill Janeway said to me, mobilizations can get hung up and stalled out due to excessive concern with efficiency as the dominant metric of value.&nbsp; “World War II was won on ‘the&nbsp; momentum of production,’ “ he noted, quoting from <a href=\"https://www.amazon.com/Struggle-Survival-Elliott-Janeway/dp/0911548521\"><em>The Struggle for Survival</em></a>, his father Eliot Janeway’s book about the World War II mobilization. “Similarly the WPA put millions to work during the Depression precisely because effective employment—not efficiency—was the dominant goal.”</p>\\n\\n\\n\\n<p>There are five pillars to Rewiring America’s case for electrification as the answer to our urgent need to limit greenhouse gas emissions:</p>\\n\\n\\n\\n<p>1. <strong>Electrifying everything requires only half as much energy as our current system.</strong> Saul and his team worked with the US Department of Energy in 2018 to create a<a href=\"http://departmentof.energy/\">n interactive map</a> of <a href=\"https://www.otherlab.com/blog-posts/us-energy-flow-super-sankey\">all the source-to-use energy flows in America</a>. This map of our energy economy was started under the Nixon administration, but its true implications are only now being realized. One of the surprising consequences of their analysis is that half the energy we use is spent collectively on things like mining and transporting fossil fuels, and in thermoelectric losses from converting them to electricity, to heat, or to movement. Direct electrification of as much of our economy as possible is not only achievable but also the fastest way to avert climate disaster.</p>\\n\\n\\n\\n<p>2. <strong>We need to reconceive solar panels, batteries, electric cars, and electric appliances as part of our national energy infrastructure</strong>, even when they are on or in people&#8217;s homes, rather than thinking of infrastructure as something owned only by utilities or the government. Electric heat pumps can be used for both hot water and home heating; hot water storage can in effect act as a battery, heating up with solar electricity during the day and giving heat back at night. We won&#8217;t balance a future renewables-heavy grid without using local (i.e., home and business) batteries and thermal loads (water and space heat) as part of the overall demand response and storage.</p>\\n\\n\\n\\n<p>3. <strong>Markets won&#8217;t move fast enough without a World War II-style mobilization of private industry.</strong> We need a heroic 4–5 year effort to get to 100% transformation of our energy infrastructure. Otherwise, we will have to wait for the natural replacement rate on infrastructure, which will take decades that we don’t have. That heroic 4–5 year effort gets us to the scale of production appropriate to enable 100% adoption of the solution technologies, which will then require a consistent 10–20 year rollout beyond that initial ramp-up period.</p>\\n\\n\\n\\n<p>4. <strong>Electrifying the US will create jobs—lots of them.</strong> Rewiring America estimates that such an effort could, at peak, <a href=\"https://www.fastcompany.com/90533448/how-to-create-25-million-jobs-by-decarbonizing-the-economy\">create as many as 25 million US jobs</a>, and 5 million ongoing jobs in the new industries. The cost of the retrofit will be high, but so will the payoff, in both jobs and in savings to consumers.</p>\\n\\n\\n\\n<p>Rooftop solar can produce at most 25% of the total needs of a fully electrified economy, so there&#8217;s still plenty of room and need for grid-scale solar—the electrified economy will require 3x the capacity of the current grid—but local is the cheapest energy and the best way to pass savings to the consumer, as well as to create highly localized jobs across the country.</p>\\n\\n\\n\\n<p>Rooftop solar jobs are of necessity geographically decentralized, potentially enabling an ecosystem of small local firms rather than rewarding a few giants.</p>\\n\\n\\n\\n<p>5. <strong>Who gets the financial benefit of this massive investment—utilities, solar installers, or consumers—depends on interest rates.</strong><br />&#8220;The miracle technology is much more likely to be finance than it is to be fusion,&#8221; Saul said in a recent presentation. Arguably, it was the invention of the auto loan by Alfred P. Sloan of General Motors and the later financial innovation by the Roosevelt administration of the Federal Housing Authority and the home mortgage that created the US middle class, he noted. &#8220;Mortgages are time machines that let you have the future you want today.&#8221; We need something similar for the electrification transformation. Otherwise, &#8220;only rich people can afford to decarbonize today.&#8221;</p>\\n\\n\\n\\n<p>Utilities already have access to low-cost loans. But consumers don&#8217;t, and if you want to create both jobs and cost savings for consumers, <a href=\"https://www.rewiringamerica.org/household-savings-report\">low-cost interest rates for home electrification are the best way to do it</a>. Otherwise, the savings all get captured by middlemen, or by utilities, and adoption is much slower.</p>\\n\\n\\n\\n<p>This observation is entirely in line with my broader point that regulations and the tax code play much the same role in shaping who gets what and why in markets as do the controlling algorithms in online platforms.</p>\\n\\n\\n\\n<h3>The end of casino capitalism?</h3>\\n\\n\\n\\n<p>The final, and perhaps most important, reason why Silicon Valley as we know it may be over is that its current incarnation is a product of the extraordinarily cheap capital of the years since the global financial crisis of 2009.</p>\\n\\n\\n\\n<p>There are two economies, often confused: the operating economy, in which companies make and sell products and services, and the betting economy, in which wealthy people bet on which companies will win and which will lose in the beauty contest that stock markets have become. In the operating economy, the measure of success is, as Nick Hanauer and Eric Beinhocker memorably put it, “<a href=\"https://www.mckinsey.com/featured-insights/long-term-capitalism/redefining-capitalism\">the solution to human problems</a>.” Companies compete to solve those problems more effectively and earn a profit thereby. Along the way, they employ people productively, create valuable new goods and services, and contribute to their communities.</p>\\n\\n\\n\\n<p>In the betting economy, the measure of success is stock price, the higher the better. Fueled by massive money creation by central banks, capital is abundant (for those who, by virtue of existing wealth, already have access to it), and traditional sources of return, such as interest on loans or ROI on investment in plants and equipment or employees, are dwarfed by the potential returns that can be achieved by playing on the madness of crowds. What can you call it but a bubble when <a href=\"https://www.nytimes.com/2020/12/14/business/dealbook/roblox-tech-ipos.html\">the median valuation of this past year’s tech IPOs was 24 times trailing revenue</a>, while tech IPOs during most of the past decade were only valued at about six times trailing revenue. Data collected by University of Florida professor Jay Ritter shows that it’s even worse than it appears: <a href=\"https://site.warrington.ufl.edu/ritter/files/IPO-Statistics.pdf\">only 16% of 2020’s tech IPOs had any profits at all</a>.</p>\\n\\n\\n\\n<p>Capital markets do play an important role in our society. Bets on an unknown future are an important way to fund innovation and to build out infrastructure in advance of the prosperity that it will bring once that innovation has been widely deployed. But in today’s <a href=\"https://evonomics.com/financialization-hidden-illness-rana-foorohar/\">financialized economy</a>, the returns on betting for its own sake have grown far faster than the returns on true operating investment.</p>\\n\\n\\n\\n<p>There are many who will argue that the enormous payoffs coming to today’s entrepreneurs and investors are the result of their world-changing innovations. History suggests otherwise. There was plenty of innovation when the returns to investors and entrepreneurs were a fraction of what they are today.</p>\\n\\n\\n\\n<p>Silicon Valley is named for the semiconductor manufacturing companies that became the foundation of all that followed. Intel, one of the most successful of those companies, went public in 1971 with a valuation of about $58 million (<a href=\"https://www.in2013dollars.com/us/inflation/1971?amount=58\">about $372 million in today’s dollars</a>). Intel had a small profit when it went public, but it went on to earn hundreds of billions of dollars in operating profit over the succeeding decades. Apple and Microsoft, the standard bearers of the next generation of Silicon Valley companies, were also profitable at IPO. Two decades later, Google too was highly profitable when it went public, and while Amazon was one of the first companies to legitimize the profitless IPO, <a href=\"https://news.crunchbase.com/news/why-amazons-history-of-ipo-era-losses-means-little-for-todays-unprofitable-unicorns/\">its losses were falling as it grew</a>. All have turned into companies that generate enormous profits in the operating economy.</p>\\n\\n\\n\\n<p>Few of the companies in the recent crop of Silicon Valley companies can make that claim. At its IPO early in 2020, Palantir had <a href=\"https://www.computerworld.com/article/3562713/biggest-tech-ipos-2020.html\">prior year revenues of $743 million, on which it posted a loss of $576 million</a>. Uber went public in 2019 with <a href=\"https://www.sec.gov/Archives/edgar/data/1543151/000119312519103850/d647752ds1.htm#rom647752_8a\">an operating loss of over $3 billion on $11 billion in revenue</a>. When DoorDash went public, it had <a href=\"https://www.sec.gov/Archives/edgar/data/1792789/000119312520292381/d752207ds1.htm#rom752207_9\">revenues of $1.92 billion for the trailing nine months, on which it had a net loss of $149 million</a>. All these companies have valuations in the tens of billions, making their founders and investors very rich, despite not making any money at all in the operating economy. In many cases, the money invested in these companies was used to create the illusion of growth, acquiring customers below the cost of delivering services to them. It is money invested in the promise of more money, a kind of Ponzi scheme decoupled from the operating economy.</p>\\n\\n\\n\\n<p>Intel’s stock market investors were making a rational bet that a world-changing technology would earn a huge stream of future profits. Palantir’s, Uber’s, and DoorDash’s investors were betting on how other investors might value their stocks, much as 16th century Dutch investors bet on the “value” of unique tulips or mid-19th century British investors bet on the prospects for railroads in distant countries, many of which were never built. Some of these companies may eventually turn an operating profit, but it is likely that when they do, investors will realize that those profits don’t justify the sky-high valuations, which will then come back down to earth. As Benjamin Graham, the father of the style of value investing favored by Warren Buffett, is reported to have said, “In the short run, the market is a voting machine. In the long run, it is a weighing machine.”</p>\\n\\n\\n\\n<p>Were Gordon Moore and Robert Noyce, the founders of Intel, less motivated to build world-changing products because the proceeds were orders of magnitude less than they are for today’s Silicon Valley entrepreneurs? I suspect that it is the other way around. The easy profits from today’s financial betting markets encourage <a href=\"https://delong.typepad.com/baumol-1990-entrepreneurship.pdf\">unproductive innovation</a>. I’d take Gordon Moore over WeWork’s Adam Neumann any day. When investors and entrepreneurs who promise future innovation but are unable to deliver it still walk away with billions, something is seriously wrong.</p>\\n\\n\\n\\n<p>As John Maynard Keynes wrote in his <a href=\"https://en.wikipedia.org/wiki/The_General_Theory_of_Employment,_Interest_and_Money\"><em>General Theory</em></a> during the depths of the Great Depression, “Speculators may do no harm as bubbles on a steady stream of enterprise. But the position is serious when enterprise becomes the bubble on a whirlpool of speculation. When the capital development of a country becomes a by-product of the activities of a casino, the job is likely to be ill-done.”</p>\\n\\n\\n\\n<p>The problem is that money “invested” in the betting economy is not really invested. It is spent, just like money at the gaming table. When the WeWork bubble popped, the money SoftBank had spent propping up its valuation might just as well have gone up in smoke. The end of this process could look something like the financial crisis of 2009. Money invested in the collateralized debt obligations of the first decade of this century was not backed by true worth in the operating economy, so when the CDOs went bust, the money simply vanished.</p>\\n\\n\\n\\n<p><strong>Prediction: When the bubble ends, greater opportunities will remain.</strong></p>\\n\\n\\n\\n<p>One of the gifts—if you can call it that—of crises like the pandemic and climate change is that they may teach us that we no longer have time for frivolity. We need our investment capital to flow back to the operating economy.</p>\\n\\n\\n\\n<p>There is <a href=\"https://www.oreilly.com/library/view/welcome-to-the/9781492089247/\">a robust strategy</a> for investors and entrepreneurs: Work on stuff that matters. Invest in solving problems. Make a real difference in people’s lives. You will know you have done that when operating profits fairly earned, not stock market gains, are your measure of investment success.</p>\\n\\n\\n\\n<p>Two of the big areas of innovation that I highlight in this essay—life sciences and climate change—require large amounts of real investment capital. Unlike money invested in internet companies that used it to buy unprofitable growth, money invested in Tesla was used to build factories, to manufacture cars and electric batteries, and to roll out national charging networks.The path to high returns may take longer, but the need is real, and so is the value created.</p>\\n\\n\\n\\n<p>Solving global crises requires the best of what we have to offer. If the best way to predict the future is to invent it, it’s time we got busy. Which world do we want to invent? It’s up to us.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/the-end-of-silicon-valley-as-we-know-it/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'The Next Generation of AI',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The Next Generation of AI'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/the-next-generation-of-ai/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/the-next-generation-of-ai/',\n",
       "   'comments': 'https://www.oreilly.com/radar/the-next-generation-of-ai/#respond',\n",
       "   'published': 'Tue, 09 Mar 2021 13:46:41 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=9, tm_hour=13, tm_min=46, tm_sec=41, tm_wday=1, tm_yday=68, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Research', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13676',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Programs like AlphaZero and GPT-3 are massive accomplishments: they represent years of sustained work solving a difficult problem. But these problems are squarely within the domain of traditional AI. Playing Chess and Go or building ever-better language models have been AI projects for decades. The following projects have a different flavor: In February, PLOS Genetics [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Programs like AlphaZero and GPT-3 are massive accomplishments: they represent years of sustained work solving a difficult problem. But these problems are squarely within the domain of traditional AI. Playing Chess and Go or building ever-better language models have been AI projects for decades. The following projects have a different flavor: In February, PLOS Genetics [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Programs like <a href=\"https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go\">AlphaZero</a> and <a href=\"https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/\">GPT-3</a> are massive accomplishments: they represent years of sustained work solving a difficult problem. But these problems are squarely within the domain of traditional AI. Playing Chess and Go or building ever-better language models have been AI projects for decades. The following projects have a different flavor:</p>\\n\\n\\n\\n<ul><li>In February, PLOS Genetics published an article by researchers who are using GANs (Generative Adversarial Networks) to <a href=\"https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1009303\">create artificial human genomes</a>.</li></ul>\\n\\n\\n\\n<ul><li>Another group of researchers published an article about using NLP (natural language processing) to analyze viral genomes and, specifically, to <a href=\"https://www.technologyreview.com/2021/01/14/1016162/ai-language-nlp-coronavirus-hiv-flu-mutations-antinbodies-immune-vaccines/\">predict the behavior of mutations</a>. They were able to distinguish between errors in &#8220;syntax&#8221; (which make the gene non-viable), and changes in semantics (which result in a viable virus that functions differently).</li></ul>\\n\\n\\n\\n<ul><li>Yet another group of researchers modelled a small portion of a fruit fly&#8217;s brain (the part used for smell), and were able to train that to <a href=\"https://www.discovermagazine.com/the-sciences/fruit-fly-brain-network-hacked-for-language-processing\">create a model for natural language processing</a>. This new model appears to be orders of magnitude more efficient than state-of-the-art models like GPT-3.</li></ul>\\n\\n\\n\\n<p>The common thread through these advances is applying work in one field to another area that’s apparently unrelated—not sustained research at cracking a core AI problem. Using NLP to analyze mutations? That&#8217;s brilliant—and it&#8217;s one of those brilliant things that sounds so obvious once you think about it. And it&#8217;s an area where NLP may have a real significant advantage because it <em>doesn&#8217;t</em> actually understand language, any more than humans understand DNA.</p>\\n\\n\\n\\n<p>The ability to create artificial human genomes is important in the short term because the human genome data available to researchers is limited by privacy laws. Synthetic genomes aren&#8217;t subject to privacy laws, because they don&#8217;t belong to any person. Data limitations aren’t a new problem; AI researchers frequently face the problem of finding sufficient data to train a model. So they have developed a lot of techniques for generating &#8220;synthetic&#8221; data: for example, cropping, rotating, or distorting pictures to get more data for image recognition. Once you’ve realized that it’s possible to create synthetic data, the jump to creating synthetic genomes isn’t far-fetched; you just have to make the connection. Asking where it might lead in the long term is even more important.</p>\\n\\n\\n\\n<p>It&#8217;s not hard to come up with more examples of surprising work that comes from bringing techniques from one field into another. <a href=\"https://openai.com/blog/dall-e/\">DALL-E</a> (which combines NLP with image analysis to create a new image from a description) is another example. So is <a href=\"https://dl.acm.org/doi/10.1145/3432202\">ShadowSense</a>, which uses image analysis to let robots determine when they are touched.</p>\\n\\n\\n\\n<p>These results suggest that we&#8217;re at the start of something new. The world isn&#8217;t a better place because computers can play Go; but it may become a better place if we can understand how our genomes work. Using adversarial techniques outside of game play or NLP techniques outside of language will inevitably lead to solving the problems we <em>actually</em> need to solve. </p>\\n\\n\\n\\n<p>Unfortunately, that&#8217;s really only half the story. While we may be on the edge of making great advances in applications, we aren&#8217;t making the same advances in fairness and justice. Here are some key indicators:</p>\\n\\n\\n\\n<ul><li>Attempts to train models to predict the pain that Black patients will suffer as a result of medical procedures have largely failed. Recently, research discovered that the models were more successful if they got their training data by <a href=\"https://www.technologyreview.com/2021/01/22/1016577/ai-fairer-healthcare-patient-outcomes/\">actually listening to Black patients</a>, rather than just using records from their doctors.</li></ul>\\n\\n\\n\\n<ul><li>A study by MIT discovered that training predictive crime models on crime reports rather than arrests doesn&#8217;t make them less racist. </li></ul>\\n\\n\\n\\n<p>Fortunately, the doctors modeling medical pain decided to listen to their Black patients; unfortunately, that kind of listening is still rare. Listening to Black patients shouldn&#8217;t be a breakthrough akin to using NLP to analyze DNA. Why weren’t we listening to the patients in the first place? And why are the patients’ assessments of their pain so different from the doctors’?&nbsp; This is clearly progress, but more than that, it’s a sign of how much progress has yet to be made in treating minorities fairly.</p>\\n\\n\\n\\n<p>And I&#8217;m afraid that MIT has only discovered that there aren&#8217;t any historical data sources about crime that aren&#8217;t biased, something we already knew. If you look at so-called &#8220;white collar&#8221; crime, Midtown Manhattan is the most dangerous neighborhood in New York. But that&#8217;s not where the police are spending their time.&nbsp; The only somewhat tongue-in-cheek <a href=\"https://whitecollar.thenewinquiry.com/static/whitepaper.pdf\">paper</a> accompanying the map of <a href=\"https://whitecollar.thenewinquiry.com/\">White Collar Crime Risk Zones</a> suggests that their next step will be using “facial features to quantify the ‘criminality’ of the individual.”&nbsp; That would clearly be a joke if such techniques weren’t already <a href=\"https://www.bbc.com/news/technology-53165286\">under development</a>, and not just in China.</p>\\n\\n\\n\\n<p>It looks like we&#8217;re at the cusp of some breakthroughs in AI—not new algorithms or approaches, but new ways to use the algorithms we already have. But the more things change, the more they stay the same. Our ability to think about our responsibilities of ethics and justice—and, more specifically, to put&nbsp; in place mechanisms to redress harms caused by unfair decisions–are slow to catch up.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/the-next-generation-of-ai/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: March 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: March 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-march-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-march-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-march-2021/#respond',\n",
       "   'published': 'Mon, 01 Mar 2021 14:13:29 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=3, tm_mday=1, tm_hour=14, tm_min=13, tm_sec=29, tm_wday=0, tm_yday=60, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13672',\n",
       "   'guidislink': False,\n",
       "   'summary': 'For a short month, a lot happened in February–perhaps because the US elections are behind us, perhaps because COVID case numbers are dropping, perhaps for any number of reasons. Some of the most interesting articles I’ve seen have been about the Internet of Things, ranging from wireless peas to Elon Musk’s neural interfaces. AI and [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'For a short month, a lot happened in February–perhaps because the US elections are behind us, perhaps because COVID case numbers are dropping, perhaps for any number of reasons. Some of the most interesting articles I’ve seen have been about the Internet of Things, ranging from wireless peas to Elon Musk’s neural interfaces. AI and [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>For a short month, a lot happened in February–perhaps because the US elections are behind us, perhaps because COVID case numbers are dropping, perhaps for any number of reasons. Some of the most interesting articles I’ve seen have been about the Internet of Things, ranging from wireless peas to Elon Musk’s neural interfaces. </p>\\n\\n\\n\\n<h2>AI and ML</h2>\\n\\n\\n\\n<ul><li>An AI system is being used to <a href=\"https://www.technologyreview.com/2021/02/26/1020010/trevor-project-ai-suicide-hotline-training/\">train crisis counsellors</a>. Roleplaying plays a critical part in training staff at suicide prevention services. The AI plays the patient, freeing staff so that they can spend more time helping clients, rather than training other staff.<br /></li><li>Google, in <a href=\"https://www.cnet.com/news/google-fires-researcher-margaret-mitchell-amid-chaos-in-ai-division/\">firing Margaret Mitchell</a> weeks after Timnit Gebru, has abandoned any pretense of ethical leadership in AI. What signals does a company send when it fires both leaders of the best ethics research team in the industry?&nbsp; The paper Gebru and Mitchell co-authored with Emily Bender and Angelina McMillan-Major, <a href=\"http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf\">On the Danger of Stochastic Parrots</a>, is a must-read.<br /></li><li>How an AI algorithm learns has an impact on <a href=\"https://twitter.com/sarahookr/status/1361373527861915648\">bias and fairness</a>: it’s not just training data. Harder examples are “learned” later, and attempts to shorten training forego accuracy for these portions of the training data.<br /></li><li>Researchers are using <a href=\"https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1009303\">generative neural networks</a> to create synthetic human genomes.&nbsp; These genomes are then used for research in genetics.&nbsp; They aren’t subject to privacy restrictions because they don’t belong to anyone. Creating synthetic data isn’t a new idea, but this research pushes the limits in a spectacular way.<br /></li><li>It’s not really surprising, but MIT reports that <a href=\"https://www.technologyreview.com/2021/02/05/1017560/predictive-policing-racist-algorithmic-bias-data-crime-predpol/\">training predictive policing algorithms on crime reports</a> rather than arrests doesn’t make them less racist.<br /></li><li>Spotify has filed a patent on <a href=\"https://pitchfork.com/news/new-spotify-patent-involves-monitoring-users-speech-to-recommend-music/\">monitoring users’ speech</a> to help it make recommendations. They’re looking for gender, age, emotion, ethnicity (via accent), and whether the user is alone or with others. It’s possible that this patent will never be put into production.</li></ul>\\n\\n\\n\\n<h2>Ecology</h2>\\n\\n\\n\\n<ul><li>Building a <a href=\"https://ethz.ch/en/news-and-events/eth-news/news/2021/02/a-highly-accurate-digital-twin-of-our-planet.html\">digital twin for the Earth</a> as an aid to modeling and decision-making is an aid to making precise predictions about what the future holds. The model will incorporate data on all aspects of the earth, including the impact of human systems. Whether building and running this model will take more energy than is used to mine Bitcoin is a worthwhile question.<br /></li><li>The Texas power outages are a new chapter in the same old story, <a href=\"https://www.houstonchronicle.com/business/energy/article/Wholesale-power-prices-spiking-across-Texas-15951684.php\">lack of investment in infrastructure</a>: many of last year’s fires were due to infrastructure problems, as were massive outages in other states. We need to <a href=\"https://techxplore.com/news/2021-02-texas-crisis-biden-climate-fragile.html\">re-think the US power grid</a>, which is not ready for the transition to renewable resources.<br /></li><li><a href=\"https://www.technologyreview.com/2021/02/24/1017822/green-hydrogen-clean-energy/\">Hydrogen may play a role</a> in reducing carbon emissions. Using wind or solar power to produce hydrogen by electrolysis might be an effective way to store energy, though that begs the question of how hydrogen itself is stored.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Over the last decades, APIs have <a href=\"https://thenewstack.io/apis-evolution-future-and-vulnerabilities/\">evolved</a> from complex (RPC) interfaces to REST to GraphQL, and in doing so, have enabled new business models based on disaggregating services. Where is the evolution of APIs headed?<br /></li><li>Microsoft’s <a href=\"https://thenewstack.io/microsofts-dapr-introduces-cloud-native-development-to-the-enterprise/\">DAPR reaches 1.0</a>: Microsoft’s Distributed Application Runtime (DAPR) is an open-source attempt to make Kubernetes less difficult. Now that cloud services themselves have largely been commoditized, this is the level at which cloud vendors will try to control. <br /></li><li><a href=\"https://venturebeat.com/2021/02/15/what-are-low-code-databases/\">Low-code databases</a> have been around since Microsoft Access (1992); they’re proliferating as data democratizes, enabling people who need to work with data to build the tools they need. Joe Hellerstein’s <a href=\"https://www.youtube.com/embed/FeRg-7Sr1L8?autoplay=1\">New directions in cloud programming</a> is <a href=\"https://arxiv.org/abs/2101.01159\">proposing programming languages</a> that take cloud computing “beyond serverless.” The idea is to decouple semantics, availability, consistency, and optimization. This may free cloud computing from the complexity of Kubernetes and other orchestration technologies.<br /></li><li><a href=\"https://www.zdnet.com/article/who-needs-a-supercomputer-your-desktop-pc-and-a-gpu-might-be-enough-to-solve-some-of-the-largest-problems/\">Procedural Connectivity</a> is a technique that radically reduces the storage required for large simulations. Programs that required a supercomputer can now run on a laptop with a GPU.</li></ul>\\n\\n\\n\\n<h2>Web</h2>\\n\\n\\n\\n<ul><li>Web programming <a href=\"https://thenewstack.io/case-against-web-frameworks/\">without frameworks</a>: Is “<a href=\"https://stackless.community/\">the stackless way</a>” the route to simplification? For many web applications, JavaScript Modules and Web Components may be the path away from React and Angular.<br /></li><li><a href=\"https://hotwire.dev/\">Hotwire</a> is a new <a href=\"https://thenewstack.io/ruby-on-rails-creator-takes-on-javascript-frameworks-with-hotwire/\">minimal-JavaScript web framework</a> that relies on Rails for the backend. Developed by @dhh. Do we really need another JavaScript framework?<br /></li><li>No more third party tracking cookies: The Chrome browser will cease to support 3rd party cookies, in favor of a Google alternative called “federated learning of cohorts” (<a href=\"https://blog.google/products/ads-commerce/2021-01-privacy-sandbox/\">FLoC</a>). FLoC is a win for privacy; it also tips the balance of power in advertising further in Google’s direction.</li></ul>\\n\\n\\n\\n<h2>Medicine</h2>\\n\\n\\n\\n<ul><li>Will the r<a href=\"https://www.technologyreview.com/2021/02/24/1018094/lee-hood-precision-health-care-covid-pandemic/\">esponse to COVID</a> push us into the era of data-driven medicine? If nothing else, it has taught us what’s possible in a limited amount of time.<br /></li><li>Using <a href=\"https://dzone.com/articles/using-neural-networks-to-discover-antibiotics\">neural networks to discover antibiotics</a> isn’t a new idea, but researchers appear to be making progress, both in discovering new compounds and in discovering new mechanisms.<br /></li><li><a href=\"https://www.technologyreview.com/2021/02/05/1017366/messenger-rna-vaccines-covid-hiv/\">mRNA (messenger RNA)</a>, the basis for the Pfizer and Moderna COVID vaccines, is useful for many applications.&nbsp; There’s potential for treating genetic diseases (like Sickle Cell Anemia), HIV, and many other conditions. COVID may have pushed us to make a great leap forward.</li></ul>\\n\\n\\n\\n<h2>Things</h2>\\n\\n\\n\\n<ul><li><a href=\"https://sea.mashable.com/science/14617/scientists-have-engineered-spinach-plants-that-know-how-to-send-emails\">Spinach that can send email</a>: The spinach has been engineered to detect certain chemicals in the ground, and send a wireless signal to sensors. This clearly has big implications for precision agriculture and for an internet of (living) things.<br /></li><li>Computing touch: <a href=\"https://techxplore.com/news/2021-02-soft-robots-camera-shadows-human.html\">ShadowSense</a> can give soft robots the ability to <a href=\"https://dl.acm.org/doi/10.1145/3432202\">sense “touch”</a> using cameras to analyze shadows. Does this pave the way for interactions between robots and humans?<br /></li><li>France is requiring manufacturers to publish a “<a href=\"https://grist.org/climate/why-frances-new-repairability-index-is-a-big-deal/\">repairability index</a>” with their products to minimize the creation of waste.<br /></li><li><a href=\"https://www.techspot.com/news/88499-elon-musk-neuralink-hopes-begin-human-trials-year.html\">Elon Musk’s Neuralink</a> hopes to begin human trials of (wireless) direct computer-brain interfaces this year. Fixing neurological conditions like paralysis is one thing, but I worry about unmediated social media.<br /></li><li><a href=\"https://techxplore.com/news/2021-02-limit-cmos-based-transceiver-5g-applications.html\">Beyond 5G</a>: Transceivers for digital communication in the 300 GHz band.&nbsp; That is very unknown (and unused) territory. </li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li><a href=\"https://medium.com/@alex.birsan/dependency-confusion-4a5d60fec610\">More supply chain attacks</a>: a researcher demonstrated that it was possible to insert code into corporate projects by uploading modules to package managers (npm, Ruby Gems, pip) that matched the names of internal packages.<br /></li><li><a href=\"https://thenewstack.io/a-favored-target-for-attackers-apis-need-more-than-the-security-basics/\">API-first brings its own set of security problems</a>. APIs by definition have large attack surfaces. Developers need a better understanding of security basics, along with better systems for detecting attacks in real-time.</li></ul>\\n\\n\\n\\n<h2>Finance</h2>\\n\\n\\n\\n<ul><li>China is way ahead of the rest of the world (including the US) in <a href=\"https://www.theinformation.com/articles/china-is-winning-the-digital-currency-war-with-the-u-s\">developing a virtual currency</a>.&nbsp; Their goal is to replace the dollar and become the standard currency for the international monetary system.&nbsp; This would give them a highly detailed view of the flow of money (down to individual transactions), both within China and internationally. However, China also sees virtual currency as a means of <a href=\"https://www.ft.com/content/7511809e-827e-4526-81ad-ae83f405f623\">increasing social control</a> within the country. These two objectives seem mutually exclusive. It will be interesting to see how they bridge the gap.<br /></li><li>Major <a href=\"https://www.coindesk.com/mastercard-accepts-crypto-payments\">credit cards</a> and <a href=\"https://www.theverge.com/2020/10/21/21527288/paypal-cryptocurrency-support-buy-sell-venmo-bitcoin\">other institutions</a> are beginning to adopt cryptocurrencies for payment.<br /></li><li>The <a href=\"https://en.wikipedia.org/wiki/GameStop_short_squeeze\">Gamestop short squeeze</a> is a new phenomenon: a meme threatening Wall Street. Whether it was just a meme that grew without control, or an intentional movement to punish hedge funds, it’s once again apparent that social media can break the assumptions on which “business as usual” depends.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li>The biggest problem facing quantum computing is error correction.&nbsp; Is a fault-tolerant quantum computer possible?&nbsp; Some intriguing <a href=\"https://phys.org/news/2021-02-tackles-central-powerful-quantum.html\">results</a> show that it might be.</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-march-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Product Management for AI',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Product Management for AI'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/product-management-for-ai/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/product-management-for-ai/',\n",
       "   'comments': 'https://www.oreilly.com/radar/product-management-for-ai/#respond',\n",
       "   'published': 'Fri, 26 Feb 2021 19:40:39 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=26, tm_hour=19, tm_min=40, tm_sec=39, tm_wday=4, tm_yday=57, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13646',\n",
       "   'guidislink': False,\n",
       "   'summary': 'A couple of years ago, Pete Skomoroch, Roger Magoulas, and I talked about the problems of being a product manager for an AI product. We decided that would be a good topic for an article, and possibly more. After Pete and I wrote the first article for O’Reilly Radar, it was clear that there was [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'A couple of years ago, Pete Skomoroch, Roger Magoulas, and I talked about the problems of being a product manager for an AI product. We decided that would be a good topic for an article, and possibly more. After Pete and I wrote the first article for O’Reilly Radar, it was clear that there was [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>A couple of years ago, Pete Skomoroch, Roger Magoulas, and I talked about the problems of being a product manager for an AI product. We decided that would be a good topic for an article, and possibly more.</p>\\n\\n\\n\\n<p>After Pete and I wrote the first article for O’Reilly Radar, it was clear that there was “more”–a lot more.&nbsp; We then added Justin Norman, VP of Data Science at Yelp, to the team.&nbsp; Justin did the lion’s share of the work from that point on.&nbsp; He has a great perspective on product management and AI, with deep practical experience with real-world products: not just building and deploying them, but shepherding them through the process from the initial idea to maintaining them after employment–including interfacing with management.</p>\\n\\n\\n\\n<p>Many organizations start AI projects, but relatively few of those projects make it to production.&nbsp; These articles show you how to minimize your risk at every stage of the project, from initial planning through to post-deployment monitoring and testing.&nbsp; We’ve said that AI projects are inherently probabilistic. That’s true at every stage of the process.&nbsp; But there’s no better way to maximize your probability of success than to understand the challenges you’ll face.</p>\\n\\n\\n\\n<h2>Report</h2>\\n\\n\\n\\n<p><a href=\"https://learning.oreilly.com/library/view/product-management-for/9781098104207/\">Product Management for AI </a></p>\\n\\n\\n\\n<h2>Articles</h2>\\n\\n\\n\\n<p><a href=\"https://www.oreilly.com/radar/what-you-need-to-know-about-product-management-for-ai/\">What you need to know about product management for AI</a><br /><a href=\"https://www.oreilly.com/radar/practical-skills-for-the-ai-product-manager/\">Practical Skills for the AI Product Manager</a><br /><a href=\"https://www.oreilly.com/radar/bringing-an-ai-product-to-market/\">Bringing an AI Product to Market</a></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/product-management-for-ai/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': '5 things on our data and AI radar for 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': '5 things on our data and AI radar for 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/5-things-on-our-data-and-ai-radar-for-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/5-things-on-our-data-and-ai-radar-for-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/5-things-on-our-data-and-ai-radar-for-2021/#respond',\n",
       "   'published': 'Fri, 19 Feb 2021 15:23:14 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=23, tm_sec=14, tm_wday=4, tm_yday=50, tm_isdst=0),\n",
       "   'authors': [{}],\n",
       "   'author': '',\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13660',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Here are some of the most significant themes we see as we look toward 2021. Some of these are emerging topics and others are developments on existing concepts, but all of them will inform our thinking in the coming year. MLOps FTW MLOps attempts to bridge the gap between Machine Learning (ML) applications and the [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Here are some of the most significant themes we see as we look toward 2021. Some of these are emerging topics and others are developments on existing concepts, but all of them will inform our thinking in the coming year. MLOps FTW MLOps attempts to bridge the gap between Machine Learning (ML) applications and the [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Here are some of the most significant themes we see as we look toward 2021. Some of these are emerging topics and others are developments on existing concepts, but all of them will inform our thinking in the coming year.</p>\\n\\n\\n\\n<h2><strong>MLOps FTW</strong></h2>\\n\\n\\n\\n<p>MLOps attempts to bridge the gap between Machine Learning (ML) applications and the CI/CD pipelines that have become standard practice. ML presents a problem for CI/CD for several reasons. The data that powers ML applications is as important as code, making version control difficult; outputs are probabilistic rather than deterministic, making testing difficult; training a model is processor intensive and time consuming, making rapid build/deploy cycles difficult. None of these problems are unsolvable, but developing solutions will require substantial effort over the coming years.</p>\\n\\n\\n\\n<h2><strong>The Time Is Now to Adopt Responsible Machine Learning</strong></h2>\\n\\n\\n\\n<p>The era in which tech companies had a regulatory “free ride” has come to an end. Data use is no longer a “wild west” in which anything goes; there are legal and reputational consequences for using data improperly.&nbsp; Responsible Machine Learning (ML) is a movement to make AI systems accountable for the results they produce.&nbsp; Responsible ML includes explainable AI (systems that can explain why a decision was made), human-centered machine learning, regulatory compliance, ethics, interpretability, fairness, and building secure AI. Until now, corporate adoption of responsible ML has been lukewarm and reactive at best. In the next year, increased regulation (such as GDPR, CCPA), antitrust, and other legal forces will force companies to adopt responsible ML practices.</p>\\n\\n\\n\\n<h2><strong>The Right Solution for Your Data: Cloud Data Lakes and Data Lakehouses</strong></h2>\\n\\n\\n\\n<p>Data lakes have experienced a fairly robust resurgence over the last few years, specifically cloud data lakes. With more businesses migrating their data infrastructure to the cloud, as well as the increase of open source projects driving innovation in cloud data lakes, these will remain on the radar in 2021. Similarly, the data lakehouse, an architecture that features attributes of both the data lake and the data warehouse, gained traction in 2020 and will continue to grow in prominence in 2021. Cloud data warehouse engineering develops as a particular focus as database solutions move more and more to the cloud.</p>\\n\\n\\n\\n<h2><strong>A Wave of Cloud-Native, Distributed Data Frameworks</strong></h2>\\n\\n\\n\\n<p>Data science grew up with Hadoop and its vast ecosystem.&nbsp; Hadoop is now last decade’s news, and momentum has shifted to Spark, which now dominates the way Hadoop used to. But there are new challengers out there. New distributed computing frameworks like Ray and Dask are more flexible, and are cloud-native: they make it very simple to move workloads to the cloud.&nbsp; Both are seeing strong growth. What’s the next platform on the horizon?&nbsp; We’ll see in the coming year.</p>\\n\\n\\n\\n<h2><strong>Natural Language Processing Advances Significantly</strong></h2>\\n\\n\\n\\n<p>This year, the biggest story in AI was GPT-3, and its ability to generate almost human-sounding prose.&nbsp; What will that lead to in 2021? There are many possibilities, ranging from interactive assistants and automated customer service to automated fake news. Looking at GPT-3 more closely, here are the questions you should be asking. GPT-3 is being delivered via an API, not by incorporating the model directly into applications. Is “Language-as-a-service” the future? GPT-3 is great at creating English text, but has no concept of common sense or even facts; for example, it has recommended suicide as a cure for depression.&nbsp; Can more sophisticated language models overcome those limitations?&nbsp; GPT-3 reflects the biases and prejudices that are built into languages. How are those to be overcome, and is that the responsibility of the model or of the application developers?&nbsp; GPT-3 is the most exciting development to appear during the last year; in 2021, our attention will remain focused on it and its successors. We can’t help but be excited (and maybe a little scared) by GPT-4.</p>\\n\\n\\n\\n<p></p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<div class=\"wp-block-group has-very-light-gray-background-color has-background\"><div class=\"wp-block-group__inner-container\">\\n<p class=\"has-small-font-size\"><a href=\"https://www.oreilly.com/online-learning/teams.html\">O’Reilly’s online learning platform</a> can give your employees the resources they need to upskill and stay up to date on AI, data and hundreds of other technology and business topics. <a href=\"https://get.oreilly.com/ent_demo-request.html?utm_medium=email&amp;utm_source=marketo&amp;utm_campaign=techlead+global+nurture&amp;utm_content=em1+radar+overview\">Request a demo.</a></p>\\n</div></div>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/5-things-on-our-data-and-ai-radar-for-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': '5 infrastructure and operations trends to watch in 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': '5 infrastructure and operations trends to watch in 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/5-infrastructure-and-operations-trends-to-watch-in-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/5-infrastructure-and-operations-trends-to-watch-in-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/5-infrastructure-and-operations-trends-to-watch-in-2021/#respond',\n",
       "   'published': 'Fri, 19 Feb 2021 15:22:52 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=19, tm_hour=15, tm_min=22, tm_sec=52, tm_wday=4, tm_yday=50, tm_isdst=0),\n",
       "   'authors': [{}],\n",
       "   'author': '',\n",
       "   'tags': [{'term': 'Infrastructure', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13648',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Change is the only constant in the technology world, and that’s particularly true in the realm of sysops, infrastructure, and security. Here’s a look ahead to 2021 and five of the trends we’re watching closely. Kubernetes Complexity To say that Kubernetes is the leading container orchestration platform is an understatement.&#160; It’s the only container orchestration [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Change is the only constant in the technology world, and that’s particularly true in the realm of sysops, infrastructure, and security. Here’s a look ahead to 2021 and five of the trends we’re watching closely. Kubernetes Complexity To say that Kubernetes is the leading container orchestration platform is an understatement.&#160; It’s the only container orchestration [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Change is the only constant in the technology world, and that’s particularly true in the realm of sysops, infrastructure, and security. Here’s a look ahead to 2021 and five of the trends we’re watching closely.</p>\\n\\n\\n\\n<h2><strong>Kubernetes Complexity</strong></h2>\\n\\n\\n\\n<p>To say that Kubernetes is the leading container orchestration platform is an understatement.&nbsp; It’s the only container orchestration platform that counts. However, to say that Kubernetes is complex is also an understatement.&nbsp; The learning curve is both steep and long. How will developers address Kubernetes’ complexity? We are starting to see some simpler alternatives for specific use cases–for example, K3S for edge computing.&nbsp; Will that trend continue?&nbsp; Or will Kubernetes be subsumed into cloud providers’ management consoles in a way that simplifies the options available to developers (aka “opinionated”)? We don’t know, but we believe that an important trend for the next year will be attempts to simplify cloud orchestration.</p>\\n\\n\\n\\n<h2><strong>Site Reliability and Observability</strong></h2>\\n\\n\\n\\n<p>The sea change in workplace dynamics brought about by Covid 19 has had a parallel effect on the world of site reliability engineering. Companies for whom an online presence was an afterthought are now finding it essential to survival. And they’re also finding it necessary to keep their online presence available 24&#215;7. So we foresee an increase in the demand for site reliability engineers–but beyond that, we expect an emphasis on the tools that SREs need. Look for a heavy emphasis on system observability and its fruits: high speed, actionable data allowing engineers to understand, prevent, and mitigate outages. Although it’s only part of the story, we’re particularly interested in OpenTelemetry, a vendor neutral standard for collecting system data. OpenTelementery promises an array of more refined and calibrated open source tools for observability in the years ahead.</p>\\n\\n\\n\\n<h2><strong>GitOps: The Future of DevOps</strong></h2>\\n\\n\\n\\n<p>For a decade or more, the slogan “Infrastructure as Code” has driven efforts to make configuration programmable. We’ve made lots of progress; and perhaps the best example of that progress is Kubernetes, which orchestrates the deployment, creation, and construction of containers. There’s one more piece (for now) to consider: how do you automate the configuration of Kubernetes itself? How do you make new deployments faster, while minimizing the possibility of human error at the same time? That’s achieved by using Git to manage Kubernetes’ configuration files and any other artifacts it needs to run. When anything changes, a Kubernetes operator manages the process of informing Kubernetes and related orchestration tools and gradually pushing the deployed system to the desired state. GitOps may be the ultimate expression of “Infrastructure as Code”; we expect it to have a big impact in the coming year.</p>\\n\\n\\n\\n<h2><strong>Cyber Resilience</strong></h2>\\n\\n\\n\\n<p>Saying that cyber threats will increase, and that attacks will become more dangerous, hardly qualifies as a prediction or a trend. The sophisticated <a href=\"https://krebsonsecurity.com/2020/12/u-s-treasury-commerce-depts-hacked-through-solarwinds-compromise/\">cyber attacks</a> that compromised the U.S. Treasure, Commerce, and Homeland Security departments are, sadly, hardly surprising. What’s more important is how organizations respond to those threats. In the past, most companies have taken a reactive approach to security: address breaches as they happen, and if nothing happens, they’ve spent too much on security. That approach has failed time and time again. In the coming year, we expect companies to take a dynamic, holistic approach that strengthens their security posture. Steps towards resilience include having a robust Identity and Access Management policy by implementing zero trust, MFA, and passwordless authentication.&nbsp; Expect to see increased use of AI and Machine Learning (ML) by both good and bad actors. Bad actors will use AI to find and exploit new vulnerabilities (including vulnerabilities in AI systems themselves); security teams will use AI and ML tools to detect and block attacks, and to automate routine tasks.</p>\\n\\n\\n\\n<h2><strong>Multi-cloud and Hybrid Clouds</strong></h2>\\n\\n\\n\\n<p>It’s too easy to think of “the cloud” as a place: a single virtual location, with a single provider. But that’s not reality.&nbsp; As IBM has said frequently, the cloud is a capability, not a destination.&nbsp; By the time most companies start thinking seriously about a “cloud strategy,” they already have pilot projects in multiple clouds.&nbsp; Mergers and acquisitions complicate the situation even more, as does data that has to remain on-premises for regulatory or security reasons. What counts isn’t moving applications to a specific provider, but having a uniform interface that lets you use capabilities regardless of their physical location. 2021 will be the year that companies (officially) adopt multi- and hybrid clouds, removing the operational and developmental barriers between their own, on-premises IT and cloud providers. We will discover what it really means to be “cloud-native.”</p>\\n\\n\\n\\n<p></p>\\n\\n\\n\\n<hr class=\"wp-block-separator\" />\\n\\n\\n\\n<div class=\"wp-block-group has-very-light-gray-background-color has-background\"><div class=\"wp-block-group__inner-container\">\\n<p class=\"has-text-align-left has-small-font-size\"><a href=\"https://www.oreilly.com/online-learning/teams.html\">O’Reilly’s online learning platform</a> can give your employees the resources they need to upskill and stay up to date on Kubernetes, SRE, cybersecurity, cloud, and hundreds of other technology and business topics. <a href=\"https://get.oreilly.com/ent_demo-request.html?utm_medium=email&amp;utm_source=marketo&amp;utm_campaign=techlead+global+nurture&amp;utm_content=em1+radar+overview\">Request a demo.</a></p>\\n</div></div>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/5-infrastructure-and-operations-trends-to-watch-in-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'The Wrong Question',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The Wrong Question'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/the-wrong-question/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/the-wrong-question/',\n",
       "   'comments': 'https://www.oreilly.com/radar/the-wrong-question/#respond',\n",
       "   'published': 'Tue, 09 Feb 2021 12:19:45 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=9, tm_hour=12, tm_min=19, tm_sec=45, tm_wday=1, tm_yday=40, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Intelligence matters: Artificial intelligence and algorithms',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13637',\n",
       "   'guidislink': False,\n",
       "   'summary': '“If they can get you asking the wrong questions, they don&#8217;t have to worry about answers.” Thomas Pynchon, Gravity’s Rainbow The deplatforming of Donald Trump and his alt-right coterie has led to many discussions of free speech.&#160; Some of the discussions make good points, most don’t, but it seems to me that all of them [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': '“If they can get you asking the wrong questions, they don&#8217;t have to worry about answers.” Thomas Pynchon, Gravity’s Rainbow The deplatforming of Donald Trump and his alt-right coterie has led to many discussions of free speech.&#160; Some of the discussions make good points, most don’t, but it seems to me that all of them [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<blockquote class=\"wp-block-quote\"><p>“If they can get you asking the wrong questions, they don&#8217;t have to worry about answers.” </p><cite><br />Thomas Pynchon, <a href=\"https://en.wikipedia.org/wiki/Gravity%27s_Rainbow\">Gravity’s Rainbow</a></cite></blockquote>\\n\\n\\n\\n<p>The deplatforming of Donald Trump and his alt-right coterie has led to many discussions of free speech.&nbsp; Some of the discussions make good points, most don’t, but it seems to me that all of them miss the real point.&nbsp; We shouldn’t be discussing “speech” at all; we should be discussing the way social platforms amplify certain kinds of speech.</p>\\n\\n\\n\\n<p>What is free speech, anyway?&nbsp; In a strictly legal sense, “free speech” is only a term that makes sense in the context of government regulation. The First Amendment to the US constitution says that the government can’t pass a law that restricts your speech. And neither Twitter nor Facebook are the US government, so whatever they do to block content isn’t a “free speech” issue, at least strictly interpreted.</p>\\n\\n\\n\\n<p>Admittedly, that narrow view leaves out a lot. Both the right and the left can agree that we don’t really want Zuck or @jack determining what kinds of speech are legitimate. And most of us can agree that there’s a time when abstract principles have to give way to concrete realities, such as terrorists storming the US capitol building. That situation resulted from years of abusive speech that the social platforms had ignored, so that when the corporate power finally stepped in, their actions were too little, too late.</p>\\n\\n\\n\\n<p>But as I said, the focus on “free speech” misframes the issue. The important issue here isn’t speech itself; it’s how and why speech is amplified—an amplification that can be used to drown out or intimidate other voices, or to selectively amplify voices for reasons that may be well-intended, self-interested, or even hostile to the public interest. The discussion we need, the discussion of amplification and its implications, has largely been supplanted by arguments about “free speech.”</p>\\n\\n\\n\\n<p>In the Third Amendment, the US Constitution also guarantees a “free press.” A free press is important because the press has the power of replication: of taking speech and making it available more broadly. In the 18th, 19th, and 20th centuries, that largely meant newspapers, which had the ability to reproduce tens of thousands of copies overnight. But freedom of the press has an important limitation. Anyone can talk, but to have freedom of the press you have to have a press–whether that’s a typewriter and a mimeograph, or all the infrastructure of a publisher like The New York TImes, CNN, or Fox News. And being a “press” has its own constraints: an editorial staff, an editorial policy, and so on. Because they’re in the business of replication, it’s probably more correct to think of Twitter and Facebook as exercising “press” functions.</p>\\n\\n\\n\\n<p>But what is the editorial function for Facebook, Twitter, YouTube, and most other social media platforms? There isn’t an editor who decides whether your writing is insightful. There’s no editorial viewpoint. There’s only the shallowest attempt to verify facts. The editorial function is driven entirely by the desire to increase engagement, and this is done algorithmically. And what algorithms have “learned” perhaps isn’t surprising: showing people content that makes them angry is the best way to keep them coming back for more. And the more they come back, the more ads are clicked, and the more income flows in. Over the past few years, that editorial strategy has certainly played into the hands of the alt-right and neo-Nazi groups, who learned quickly how to take advantage of it. Nor have left-leaning polemicists missed the opportunity. The battle of overheated rhetoric has cheapened the public discourse and made consensus almost unattainable. Indeed, it has made attention itself unattainable: and, as Peter Wang has <a href=\"https://medium.com/@pwang/52253dbfe627\">argued</a>, scarcity of attention–particularly the “synchronous attention of a group”–is the biggest problem we face, because it rules out thoughtful consensus.</p>\\n\\n\\n\\n<p>Again, that’s been discussed many times over the past few years, but we seem to have lost that thread. We’ve had reproduction—we’ve had a press—but with the worst possible kind of editorial values. There are plenty of discussions of journalistic values and ethics that might be appropriate; but an editorial policy that has no other value than increasing engagement doesn’t even pass the lowest bar. And that editorial policy has left the user communities of Facebook, Twitter, YouTube, and other media vulnerable to <a href=\"https://www.oreilly.com/radar/defusing-propaganda-feedback-loops-on-the-social-web/\">deafening feedback loops</a>. </p>\\n\\n\\n\\n<p>Social media feedback loops can be manipulated in many ways: by automated systems that reply or “like” certain kinds of content, as well as by individual users who can also reply and “like” by the thousands.&nbsp; And those loops are aided by the platforms’ recommendation systems: either by recommending specific inflammatory posts, or by recommending that users join specific groups. An internal Facebook report showed that, by their own reckoning, 70% of all “civic” groups on Facebook contained “<a href=\"https://arstechnica.com/tech-policy/2021/02/70-of-top-civic-facebook-groups-are-toxic-or-violent-report-finds/\">hate speech, misinformation, violent rhetoric, or other toxic behavior</a>”; and the company has been aware of that since 2016.</p>\\n\\n\\n\\n<p>So where are we left?&nbsp; I would rather not have Zuck and @jack determine what kinds of speech are acceptable. That’s not the editorial policy we want.&nbsp; And we certainly need protections for people saying unpopular things on social media; eliminating those protections cuts both ways. What needs to be controlled is different altogether: it’s the optimization function that maximizes engagement, measured by time spent on the platform. And we do want to hold Zuck and @jack responsible for that optimization function, just as we want the publisher of a newspaper or a television news channel to be responsible for the headlines they write and what they put on their front page. </p>\\n\\n\\n\\n<p>Simply stripping Section 230 protection strikes me as irrelevant to dealing with what Shoshana Zuboff terms an “<a href=\"https://www.nytimes.com/2021/01/29/opinion/sunday/facebook-surveillance-society-technology.html\">epistemic coup</a>.” Is the right solution to do away with algorithmic engagement enhancement entirely?&nbsp; Facebook’s decision to <a href=\"https://www.reuters.com/article/us-facebook-groups/facebook-says-it-will-permanently-stop-recommending-political-groups-to-users-idUSKBN29X00C\">stop recommending political groups to users</a> is a step forward. But they need to go much farther in stripping algorithmic enhancement from their platform. Detecting bots would be a start; a better algorithm for “engagement,” one that promotes well-being rather than anger, would be a great ending point. As Apple CEO Tim Cook, clearly thinking about Facebook, recently <a href=\"https://www.inc.com/justin-bariso/tim-cook-may-have-just-ended-facebook.html\">said</a>, &#8220;A social dilemma cannot be allowed to become a social catastrophe&#8230;We believe that ethical technology is technology that works for you… It&#8217;s technology that helps you sleep, not keeps you up. It tells you when you&#8217;ve had enough. It gives you space to create or draw or write or learn, not refresh just one more time.&#8221;&nbsp; This reflects Apple’s values rather than Facebook’s (and one would do well to reflect on Facebook’s origins at Harvard); but it is leading towards the right question.</p>\\n\\n\\n\\n<p>Making people angry might increase shareholder value short-term. But that probably isn’t a sustainable business; and if it is, it’s a business that does incredible social damage. The “solution” isn’t likely to be legislation; I can’t imagine laws that regulate algorithms effectively, and that can&#8217;t be gamed by people who are willing to work hard to game them. I guarantee that those people are out there. We can’t say that the solution is to “be better people,” because there are plenty of people who don’t want to be better; just look at the reaction to the pandemic. Just look at the frustration of the many Facebook and Twitter employees who realized that the time to lay aside abstract principles like “free speech” was long before the election. </p>\\n\\n\\n\\n<p>We could perhaps return to the original idea of “incorporation,” when incorporation <a href=\"https://www.directorsandboards.com/articles/singlepurpose-debate-social-good-uprooted\">meant</a> a “body created by law for the purpose of attaining public ends through an appeal to private interests”–one of Zuboff’s solutions is to “tie data collection to fundamental rights and data use to public services.” However, that would require legal bodies that made tough decisions about whether corporations were indeed working towards “public ends.”&nbsp; As Zuboff points out earlier in her article, it’s easy to look to antitrust, but the Sherman Antitrust Act was largely a failure.&nbsp; Would courts ruling on “public ends” be any different?</p>\\n\\n\\n\\n<p>In the end, we will get the social media we deserve. And that leads to the right question. How do we build social media that maintains social good, rather than destroying it?&nbsp; What kinds of business models are needed to support that kind of social good, rather than merely maximizing shareholder value?</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/the-wrong-question/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: February 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: February 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-february-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-february-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-february-2021/#respond',\n",
       "   'published': 'Mon, 01 Feb 2021 14:54:43 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=54, tm_sec=43, tm_wday=0, tm_yday=32, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13630',\n",
       "   'guidislink': False,\n",
       "   'summary': 'A lot happened in the last month, and not just in Washington. Important developments appeared all through the technology world. Perhaps the most spectacular was the use of Natural Language Processing techniques to analyze viral DNA. It’s actually sort of obvious once you think about it. If DNA is a language, then it should have [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'A lot happened in the last month, and not just in Washington. Important developments appeared all through the technology world. Perhaps the most spectacular was the use of Natural Language Processing techniques to analyze viral DNA. It’s actually sort of obvious once you think about it. If DNA is a language, then it should have [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>A lot happened in the last month, and not just in Washington. Important developments appeared all through the technology world. Perhaps the most spectacular was the use of Natural Language Processing techniques to analyze viral DNA. It’s actually sort of obvious once you think about it. If DNA is a language, then it should have syntax and semantics. And tools that don’t actually understand the language might have a unique ability to analyze it. </p>\\n\\n\\n\\n<h2>AI</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.discovermagazine.com/the-sciences/fruit-fly-brain-network-hacked-for-language-processing\">Can a fruit fly learn word embeddings</a>? <a href=\"https://arxiv.org/abs/2101.06887\">Researchers have modelled</a> the structure of the portion of a fruit-fly’s brain that is used for smell perception, and trained that model for natural language processing. It appears to work, and requires a fraction of the training time and power used by current approaches.<br /></li><li>Facebook is <a href=\"https://tech.fb.com/how-facebook-is-using-ai-to-improve-photo-descriptions-for-people-who-are-blind-or-visually-impaired/\">using AI to generate verbal descriptions of photos</a>, which can then be read back to blind or vision-impaired users.&nbsp; This application combines image recognition, concept recognition, natural language processing, and voice synthesis.<br /></li><li>To train AI systems to evaluate pain in Black patients correctly, <a href=\"https://www.technologyreview.com/2021/01/22/1016577/ai-fairer-healthcare-patient-outcomes/\">don’t train them to match doctors’ evaluations</a>; doctors systematically undervalue pain in Black patients. Take the patient’s assessment as truth. This shouldn’t need to be said, but it’s important that it has been said.<br /></li><li>The Allen Institute’s Genie is a <a href=\"https://venturebeat.com/2021/01/20/allen-institute-launches-genie-a-leaderboard-for-human-in-the-loop-language-model-benchmarking/\">human-in-the-loop tool for evaluation of synthetic texts</a> produced by NLP. Genie coordinates the work of crowdsourced humans who annotate NLP output, among other things, standardizing their annotations.<br /></li><li>Explainability is good, but it only goes part way. <a href=\"https://www.fastcompany.com/90595139/this-ai-can-explain-how-it-solves-rubiks-cube-and-thats-a-big-deal\">Can an AI system teach humans</a> how it solves problems like the Rubik’s Cube? This is a new frontier. <br /></li><li><a href=\"https://www.technologyreview.com/2021/01/14/1016162/ai-language-nlp-coronavirus-hiv-flu-mutations-antinbodies-immune-vaccines/\">Natural language algorithms can detect genetic mutations</a>, specifically in Coronavirus.&nbsp; Essentially, a mutation looks like a sentence that has changed its meaning. It’s a spectacular example of interdisciplinary AI applications.<br /></li><li>Startups are offering tools to help <a href=\"https://www.technologyreview.com/2021/01/15/1016183/ai-ethics-startups/\">monitor and audit AI systems</a> for ethical issues like fairness and bias. This kind of business has been needed for a long time; Cathy O’Neil has been a pioneer in AI auditing. The world may be ready now.<br /></li><li>Generating <a href=\"https://www.technologyreview.com/2021/01/05/1015754/avocado-armchair-future-ai-openai-deep-learning-nlp-gpt3-computer-vision-common-sense/\">pictures from descriptive text</a> with GPT-3: Another tour de force. If you can imagine it or describe something, <a href=\"https://openai.com/blog/dall-e/\">DALL:E</a> and <a href=\"https://openai.com/blog/clip/\">CLIP</a> might be able to draw it.&nbsp; (Still, I’d like to know how many bad drawings they had to discard before they came up with the avocado armchair.)<br /></li><li><a href=\"https://www.zdnet.com/article/expressive-robotics-is-breathing-life-into-machines/\">Expressive Robotics</a>: robots that understand (and can create) human expressions. This is an important step in making interactions between humans and robots less creepy. But more than that, it can be a safety issue. Can an autonomous vehicle read the expressions of bicyclists and pedestrians and use that to make predictions about what they will do? <br /></li><li><a href=\"https://thenewstack.io/mit-machine-learning-uses-graph-grammar-to-automate-and-optimize-robot-design/\">RoboGrammar</a> describes robot designs in a way that makes the physical design programmable and highly adaptable to different environments and applications.&nbsp; It’s a step towards machine-learning based design tools for robotics.</li></ul>\\n\\n\\n\\n<h2>Security and Privacy</h2>\\n\\n\\n\\n<ul><li>A government (probably North Korea) is <a href=\"https://blog.google/threat-analysis-group/new-campaign-targeting-security-researchers/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FMKuf+%28The+Keyword+%7C+Official+Google+Blog%29\">targeting security researchers</a> in the US and elsewhere, using various forms of social engineering (including asking researchers to collaborate on a research project) and malware.<br /></li><li>Guerilla tactics in the struggle against online surveillance: MIT Technology Review does a study of <a href=\"https://www.technologyreview.com/2021/01/06/1015784/adsense-google-surveillance-adnauseam-obfuscation/\">Ad Nauseam</a>, a browser extension to create random ad clicks, and its effectiveness. The goal of Ad Nauseam isn’t so much to protect individuals, though it may do that; it’s to disrupt the entire advertising ecosystem.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>The parent of all low-code languages, Excel, gets <a href=\"https://www.microsoft.com/en-us/research/blog/lambda-the-ultimatae-excel-worksheet-function/\">user definable functions</a>. It’s now Turing-complete. Not just that, it’s a functional language.\\xa0 (That is not a pun; functions are true lambdas.) <br /></li><li>The new Raspberry Pi Pico is a $4 microcontroller board that can be used for almost any kind of project. It’s very cheap, widely available, and programmable in MicroPython.<br /></li><li>Distributed systems from the command line: Posh is a <a href=\"https://thenewstack.io/posh-a-data-aware-shell-for-faster-distributed-text-processing/\">data-aware shell</a> that can send data-intensive processing tasks off to remote systems. It works by adding metadata to common UNIX commands for working with files.<br /></li><li><a href=\"https://thenewstack.io/swimm-helps-new-dev-hires-stay-afloat-with-continuous-documentation/\">Continuous documentation</a>? Continuous all the things! Integrating tutorial style documentation (and testing of documentation) with CI pipelines as a way of helping new hires is certainly a new idea. Very few companies take documentation seriously; could this be the start of a trend?<br /></li><li>RStudio is continuing to incorporate new <a href=\"https://www.r-bloggers.com/2021/01/rstudio-a-single-home-for-r-and-python-data-science/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+RBloggers+%28R+bloggers%29\">features to support Python</a>, including support for VSCode and Jupyter Notebooks. RStudio looks like it’s positioning itself as a general purpose (not language-specific) platform for data development.<br /></li><li><a href=\"https://www.hpcwire.com/2021/01/13/julia-update-adoption-keeps-climbing-is-it-a-python-challenger/\">Julia</a> adoption continues to grow. We’ve been watching Julia for a long time. It’s not going to displace Python or R in the near future, but it has definitely become a contender.</li></ul>\\n\\n\\n\\n<h2>Biology and Medicine</h2>\\n\\n\\n\\n<ul><li>The Pandemic Technology Project is <a href=\"https://www.technologyreview.com/2021/01/14/1014876/about-the-pandemic-technology-project/\">evaluating</a> how tools like exposure-tracking apps and algorithms for determining who should get vaccinations are working in practice.<br /></li><li>Senti Bio is building <a href=\"https://techcrunch.com/2021/01/06/senti-bio-raises-105-million-for-its-new-programmable-biology-platform-and-cancer-therapies/\">tools to make biology programmable</a>: literally building control flow into genetic circuits, with the goal of programming better vaccines and other drugs. This is the future that synthetic biology has been looking for: is it possible to build medications that actually incorporate complex logic?<br /></li><li>Japan’s COINS center is working on several moon-shot projects for medicine. <a href=\"https://www.nature.com/articles/d42473-018-00257-z\">A hospital in every body</a> aims to develop organic nanomachines that live permanently in your body and can treat diseases autonomously, or send data outside for diagnosis and treatment planning.</li></ul>\\n\\n\\n\\n<h2>Online</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.technologyreview.com/2021/01/25/1016723/the-future-of-social-networks-might-be-audio-clubhouse-twitter-spaces/\">Is the future of social media audio</a>?&nbsp; It’s an interesting thesis; even though Clubhouse has gotten poor reviews, there’s a new wave of apps designed for audio-based social networking. Discord is well-positioned; safety and content moderation are issues. <br /></li><li><a href=\"https://omar.website/tabfs/\">TabFS</a> is a browser extension that allows you to mount your browser tabs as a filesystem. While this seems like gratuitous hackery, it means that just about everything a browser can do becomes scriptable with standard Unix/Linux utilities.<br /></li><li><a href=\"https://webassembly.studio/\">Webassembly Studio</a>: There’s not much information, but this is clearly some kind of IDE for working with wasm, with support for projects in C, Rust, Web Assembly Script, and Wat (whatever that is). The existence of an IDE is more important than the IDE itself; wasm won’t succeed unless tools become widely available.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li><a href=\"https://www.quantamagazine.org/new-quantum-algorithms-finally-crack-nonlinear-equations-20210105/\">Quantum algorithms for nonlinear dynamics</a>: We are slowly expanding the domain in which quantum computers will be able to deliver useful results. Nonlinear systems show up everywhere (fluid flow, hence weather, for example), but are extremely difficult to model with classical techniques. <br /></li><li><a href=\"https://newatlas.com/telecommunications/quantum-internet-accurate-long-distance-teleportation/\">Towards a quantum interne</a>t: Next generation networking might be based on the recent advances in quantum teleportation.</li></ul>\\n\\n\\n\\n<h2>Miscellaneous</h2>\\n\\n\\n\\n<ul><li>Are <a href=\"https://techxplore.com/news/2021-01-ces-hologram-technology-star-wars.html\">hologram capabilities</a> the next step in smartphones?&nbsp; Hologram projectors don’t require goggles or headsets; they could be what makes “virtual reality” real.<br /></li><li><a href=\"https://www.theverge.com/2021/1/4/22212347/google-employees-contractors-announce-union-cwa-alphabet\">Google employees unionize</a>: This union is less about collective bargaining than about social issues, and about non-employee staff (contractors, etc.) who don’t benefit from traditional collective bargaining. </li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-february-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Where Programming, Ops, AI, and the Cloud are Headed in 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Where Programming, Ops, AI, and the Cloud are Headed in 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/where-programming-ops-ai-and-the-cloud-are-headed-in-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/where-programming-ops-ai-and-the-cloud-are-headed-in-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/where-programming-ops-ai-and-the-cloud-are-headed-in-2021/#respond',\n",
       "   'published': 'Mon, 25 Jan 2021 12:03:14 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=25, tm_hour=12, tm_min=3, tm_sec=14, tm_wday=0, tm_yday=25, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'AI & ML', 'scheme': None, 'label': None},\n",
       "    {'term': 'Operations', 'scheme': None, 'label': None},\n",
       "    {'term': 'Web Programming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Research', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13616',\n",
       "   'guidislink': False,\n",
       "   'summary': 'In this report, we look at the data generated by the O’Reilly online learning platform to discern trends in the technology industry—trends technology leaders need to follow. But what are “trends”? All too often, trends degenerate into horse races over languages and platforms. Look at all the angst heating up social media when TIOBE or [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'In this report, we look at the data generated by the O’Reilly online learning platform to discern trends in the technology industry—trends technology leaders need to follow. But what are “trends”? All too often, trends degenerate into horse races over languages and platforms. Look at all the angst heating up social media when TIOBE or [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>In this report, we look at the data generated by the <a href=\"https://learning.oreilly.com/home/\">O’Reilly online learning platform</a> to discern trends in the technology industry—trends technology leaders need to follow. </p>\\n\\n\\n\\n<p>But what are “trends”? All too often, trends degenerate into horse races over languages and platforms. Look at all the angst heating up social media when TIOBE or RedMonk releases their reports on language rankings. Those reports are valuable, but their value isn’t in knowing what languages are popular in any given month. And that’s what I’d like to get to here: the real trends that aren’t reflected (or at best, are indirectly reflected) by the horse races. Sometimes they’re only apparent if you look carefully at the data; sometimes it’s just a matter of keeping your ear to the ground.</p>\\n\\n\\n\\n<p>In either case, there’s a difference between “trends” and “trendy.” Trendy, fashionable things are often a flash in the pan, forgotten or regretted a year or two later (like <a href=\"https://en.wikipedia.org/wiki/Pet_Rock\">Pet Rocks</a> or <a href=\"https://en.wikipedia.org/wiki/Chia_Pet\">Chia Pets</a>). Real trends unfold on much longer time scales and may take several steps backward during the process: civil rights, for example. Something is happening and, over the long arc of history, it’s not going to stop. In our industry, cloud computing might be a good example.</p>\\n\\n\\n\\n<h3>Methodology</h3>\\n\\n\\n\\n<p>This study is based on title usage on O’Reilly online learning. The data includes all usage of our platform, not just content that O’Reilly has published, and certainly not just books. We’ve explored usage across all publishing partners and learning modes, from live training courses and online events to interactive functionality provided by Katacoda and Jupyter notebooks. We’ve included search data in the graphs, although we have avoided using search data in our analysis. Search data is distorted by how quickly customers find what they want: if they don’t succeed, they may try a similar search with many of the same terms. (But don’t even think of searching for R or C!) Usage data shows what content our members actually use, though we admit it has its own problems: usage is biased by the content that’s available, and there’s no data for topics that are so new that content hasn’t been developed.</p>\\n\\n\\n\\n<p>We haven’t combined data from multiple terms. Because we’re doing simple pattern matching against titles, usage for “AWS security” is a subset of the usage for “security.” We made a (very) few exceptions, usually when there are two different ways to search for the same concept. For example, we combined “SRE” with “site reliability engineering,” and “object oriented” with “object-oriented.”</p>\\n\\n\\n\\n<p>The results are, of course, biased by the makeup of the user population of O’Reilly online learning itself. Our members are a mix of individuals (professionals, students, hobbyists) and corporate users (employees of a company with a corporate account). We suspect that the latter group is somewhat more conservative than the former. In practice, this means that we may have less meaningful data on the latest JavaScript frameworks or the newest programming languages. New frameworks appear every day (literally), and our corporate clients won’t suddenly tell their staff to reimplement the ecommerce site just because last year’s hot framework is no longer fashionable.</p>\\n\\n\\n\\n<p>Usage and query data for each group are normalized to the highest value in each group. Practically, this means that you can compare topics within a group, but you can’t compare the groups with each other. Year-over-year (YOY) growth compares January through September 2020 with the same months of 2019. Small fluctuations (under 5% or so) are likely to be noise rather than a sign of a real trend.</p>\\n\\n\\n\\n<p>Enough preliminaries. Let’s look at the data, starting at the highest level: O’Reilly online learning itself.</p>\\n\\n\\n\\n<h3>O’Reilly Online Learning</h3>\\n\\n\\n\\n<p>Usage of O’Reilly online learning grew steadily in 2020, with 24% growth since 2019. That may not be surprising, given the COVID-19 pandemic and the resulting changes in the technology industry. Companies that once resisted working from home were suddenly shutting down their offices and asking their staff to work remotely. Many have said that remote work will remain an option indefinitely. COVID had a significant effect on training: in-person training (whether on- or off-site) was no longer an option, so organizations of all sizes increased their participation in live online training, which grew by 96%. More traditional modes also saw increases: usage of books increased by 11%, while videos were up 24%. We also added two new learning modes, Katacoda scenarios and Jupyter notebooks, during the year; we don’t yet have enough data to see how they’re trending. </p>\\n\\n\\n\\n<p>It’s important to place our growth data in this context. We frequently say that 10% growth in a topic is “healthy,” and we’ll stand by that, but remember that O’Reilly online learning itself showed 24% growth. So while a technology whose usage is growing 10% annually is healthy, it’s not keeping up with the platform.</p>\\n\\n\\n\\n<p>As travel ground to a halt, so did traditional in-person conferences. We closed our conference business in March, replacing it with live virtual Superstreams. While we can’t compare in-person conference data with virtual event data, we can make a few observations. The most successful superstream series focused on <a href=\"https://learning.oreilly.com/live-training/courses/software-architecture-superstream-series/0636920444961/\">software architecture</a> and <a href=\"https://learning.oreilly.com/live-training/courses/oreilly-infrastructure-ops-superstream-series/0636920410027/\">infrastructure and operations</a>. Why? The in-person O’Reilly Software Architecture Conference was small but growing. But when the pandemic hit, companies found out that they really were online businesses—and if they weren’t, they had to become online to survive. Even small restaurants and farm markets were adding online ordering features to their websites. Suddenly, the ability to design, build, and operate applications at scale wasn’t optional; it was necessary for survival. </p>\\n\\n\\n\\n<h3><strong>Programming Languages</strong></h3>\\n\\n\\n\\n<p>Although we’re not fans of the language horse race, programming languages are as good a place as any to start. Figure 1 shows usage, year-over-year growth in usage, and the number of search queries for several popular languages. The top languages for O’Reilly online learning are Python (up 27%), Java (down 3%), C++ (up 10%), C (up 12%), and JavaScript (up 40%). Looking at 2020 usage rather than year-over-year changes, it’s surprising to see JavaScript so far behind Python and Java. (JavaScript usage is 20% of Python’s, and 33% of Java’s.) </p>\\n\\n\\n\\n<p>Past the top five languages, we see healthy growth in Go (16%) and Rust (94%). Although we believe that Rust’s popularity will continue to grow, don’t get too excited; it’s easy to grow 94% when you’re starting from a small base. Go has clearly established itself, particularly as a language for concurrent programming, and Rust is likely to establish itself for “system programming”: building new operating systems and tooling for cloud operations. Julia, a language designed for mathematical computation, is an interesting wild card. It’s slightly down over the past year, but we’re optimistic about its long term chances.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13620\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-1-1048x748.png\" /><figcaption><br /><em>Figure 1. Programming languages</em></figcaption></figure>\\n\\n\\n\\n<p>We shouldn’t separate usage of titles specifically aimed at learning a programming language from titles applying the language or using frameworks based on it. After all, many Java developers use Spring, and searching for “Java” misses content only has the word “Spring” in the title. The same is true for JavaScript, with the React, Angular, and Node.js frameworks. With Python, the most heavily used libraries are PyTorch and scikit-learn. Figure 2 shows what happens when you add the use of content about Python, Java, and JavaScript to the most important frameworks for those languages.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13621\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-2-1048x758.png\" /><figcaption><br /><em>Figure 2. Programming languages and frameworks combined</em></figcaption></figure>\\n\\n\\n\\n<p>It probably isn’t a surprise that the results are similar, but there are some key differences. Adding usage and search query data for Spring (up 7%) reverses Java’s apparent decline (net-zero growth). Zero growth isn’t inappropriate for an established enterprise language, particularly one owned by a company that has mired the language in controversy. Looking further at JavaScript, if you add in usage for the most popular frameworks (React, Angular, and Node.js), JavaScript usage on O’Reilly online learning rises to 50% of Python’s, only slightly behind Java and its frameworks. However, Python, when added to the heavily used frameworks PyTorch and scikit-learn, remains the clear leader.</p>\\n\\n\\n\\n<p>It’s important to understand what we’ve done though. We’re trying to build a more comprehensive picture of language use that includes the use of various frameworks. We’re not pretending the frameworks themselves are comparable—Spring is primarily for backend and middleware development (though it includes a web framework); React and Angular are for frontend development; and scikit-learn and PyTorch are machine learning libraries. And although it’s widely used, we didn’t assign TensorFlow to any language; it has bindings for Python, Java, C++, and JavaScript, and it’s not clear which language predominates. (Google Trends suggests C++.) We also ignored thousands (literally) of minor platforms, frameworks, and libraries for all these languages; once you get past the top few, you’re into the noise.</p>\\n\\n\\n\\n<p>We aren’t advocating for Python, Java, or any other language. None of these top languages are going away, though their stock may rise or fall as fashions change and the software industry evolves. We’re just saying that when you make comparisons, you have to be careful about exactly what you’re comparing. The horse race? That’s just what it is. Fun to watch, and have a mint julep when it’s over, but don’t bet your savings (or your job) on it.</p>\\n\\n\\n\\n<p>If the horse race isn’t significant, just what <em>are </em>the important trends for programming languages? We see several factors changing pro‐ gramming in significant ways:</p>\\n\\n\\n\\n<ul><li><em>Multiparadigm languages</em><br />Since last year, O’Reilly online learning has seen a 14% increase in the use of content on functional programming. However, Haskell and Erlang, the classic functional languages, aren’t where the action is; neither shows significant usage, and both are headed down (roughly 20% decline year over year). Object oriented programming is up even more than functional programming: 29% growth since last year. This suggests that the real story is the integration of functional features into procedural and object-oriented languages. Starting with Python 3.0 in 2008 and continuing with Java 8 in 2014, programming languages have added higher-order functions (lambdas) and other “functional” features. Several popular languages (including JavaScript and Go) have had functional features from the beginning. This trend started over 20 years ago (with the Standard Template Library for C++), and we expect it to continue.<br /></li><li><em>Concurrent programming</em><br />Platform data for concurrency shows an 8% year-over-year increase. This isn’t a large number, but don’t miss the story because the numbers are small. Java was the first widely used language to support concurrency as part of the language. In the mid-’90s, thread support was a luxury; Moore’s law had plenty of room to grow. That’s no longer the case, and support for concurrency, like support for functional programming, has become table stakes. Go, Rust, and most other modern languages have built-in support for concurrency. Concurrency has always been one of Python’s weaknesses.<br /></li><li><em>Dynamic versus static typing </em><br />This is another important paradigmatic axis. The distinction between languages with dynamic typing (like Ruby and JavaScript) and statically typed languages (like Java and Go) is arguably more important than the distinction between functional and object-oriented languages. Not long ago, the idea of adding static typing to dynamic languages would have started a brawl. No longer. Combining paradigms to form a hybrid is taking a hold here too. Python 3.5 added type hinting, and more recent versions have added additional static typing features. TypeScript, which adds static typing to JavaScript, is coming into its own (12% year-over-year increase).<br /></li><li><em>Low-code and no-code computing</em><br />It’s hard for a learning platform to gather data about a trend that minimizes the need to learn, but low-code is real and is bound to have an effect. Spreadsheets were the forerunner of low-code computing. When VisiCalc was first released in 1979, it enabled millions to do significant and important computation without learning a programming language. Democratization is an important trend in many areas of technology; it would be surprising if programming were any different. </li></ul>\\n\\n\\n\\n<p>What’s important isn’t the horse race so much as the features that languages are acquiring, and why. Given that we’ve run to the end of <a href=\"https://en.wikipedia.org/wiki/Moore%27s_law\">Moore’s law</a>, concurrency will be central to the future of programming. We can’t just get faster processors. We’ll be working with microservices and serverless/functions-as-a-service in the cloud for a long time–and these are inherently concurrent systems. Functional programming doesn’t solve the problem of concurrency—but the discipline of immutability certainly helps avoid pitfalls. (And who doesn’t love first-class functions?) As software projects inevitably become larger and more complex, it makes eminent sense for languages to extend themselves by mixing in functional features. We need programmers who are thinking about how to use functional and object-oriented features together; what practices and patterns make sense when building enterprise-scale concurrent software?</p>\\n\\n\\n\\n<p>Low-code and no-code programming will inevitably change the nature of programming and programming languages:</p>\\n\\n\\n\\n<ul><li>There will be new languages, new libraries, and new tools to support no- or low-code programmers. They’ll be very simple. (Horrors, will they look like BASIC? Please no.) Whatever form they take, it will take programmers to build and maintain them.<br /></li><li>We’ll certainly see sophisticated computer-aided coding as an aid to experienced programmers. Whether that means &#8220;<a href=\"https://www.oreilly.com/radar/pair-programming-with-ai/\">pair programming with a machine</a>&#8221; or algorithms that can write <a href=\"https://www.oreilly.com/radar/automated-coding-and-the-future-of-programming/\">simple programs on their own</a> remains to be seen. These tools won’t eliminate programmers; they’ll make programmers more productive.</li></ul>\\n\\n\\n\\n<p>There will be a predictable <a href=\"https://www.wired.com/story/databases-coding-real-programming-myth/\">backlash against letting the great unwashed</a> into the programmers’ domain. Ignore it. Low-code is part of a democratization movement that puts the power of computing into more peoples’ hands, and that’s almost always a good thing. Programmers who realize what this movement means won’t be put out of jobs by nonprogrammers. They’ll be the ones becoming more productive and writing the tools that others will use.</p>\\n\\n\\n\\n<p>Whether you’re a technology leader or a new programmer, pay attention to these slow, long-term trends. They’re the ones that will change the face of our industry. </p>\\n\\n\\n\\n<h3><strong>Operations or DevOps or SRE</strong></h3>\\n\\n\\n\\n<p>The science (or art) of IT operations has changed radically in the last decade. There’s been a lot of discussion about operations culture (the movement frequently known as DevOps), continuous integration and deployment (CI/CD), and site reliability engineering (SRE). Cloud computing has replaced data centers, colocation facilities, and in-house machine rooms. Containers allow much closer integration between developers and operations and do a lot to standardize deployment.</p>\\n\\n\\n\\n<p>Operations isn’t going away; there’s no such thing as <a href=\"http://radar.oreilly.com/2012/06/what-is-devops.html\">NoOps</a>. Technologies like Function as a Service (a.k.a. FaaS, a.k.a. serverless, a.k.a. AWS Lambda) only change the nature of the beast. The number of people needed to manage an infrastructure of a given size has shrunk, but the infrastructures we’re building have expanded, sometimes by orders of magnitude. It’s easy to round up tens of thousands of nodes to train or deploy a complex AI application. Even if those machines are all in Amazon’s giant data centers and managed in bulk using highly automated tools, operations staff still need to keep systems running smoothly, monitoring, troubleshooting, and ensuring that you’re not <a href=\"https://thenewstack.io/is-cloud-waste-inevitable-as-companies-move-to-the-cloud/\">paying for resources you don’t need</a>. Serverless and other cloud technologies allow the same operations team to manage much larger infrastructures; they don’t make operations go away.</p>\\n\\n\\n\\n<p>The terminology used to describe this job fluctuates, but we don’t see any real changes. The term “DevOps” has fallen on hard times. Usage of DevOps-titled content in O’Reilly online learning has dropped by 17% in the past year, while SRE (including “site reliability engineering”) has climbed by 37%, and the term “operations” is up 25%. While SRE and DevOps are distinct concepts, for many customers SRE is DevOps at Google scale–and who doesn’t want that kind of growth? Both SRE and DevOps emphasize similar practices: version control (62% growth for GitHub, and 48% for Git), testing (high usage, though no year-over-year growth), continuous deployment (down 20%), monitoring (up 9%), and observability (up 128%). <a href=\"https://en.wikipedia.org/wiki/Terraform_(software)\">Terraform</a>, HashiCorp’s open source tool for automating the configuration of cloud infrastructure, also shows strong (53%) growth.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13622\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-3-1048x788.png\" /><figcaption><br /><em>Figure 3. Operations, DevOps, and SRE </em></figcaption></figure>\\n\\n\\n\\n<p>It’s more interesting to look at the story the data tells about the tools. Docker is close to flat (5% decline year over year), but usage of content about containers skyrocketed by 99%. So yes, containerization is clearly a big deal. Docker itself may have stalled—we’ll know more next year—but Kubernetes’s dominance as the tool for container orchestration keeps containers central. Docker was the enabling technology, but Kubernetes made it possible to deploy containers at scale.</p>\\n\\n\\n\\n<p>Kubernetes itself is the other superstar, with 47% growth, along with the highest usage (and the most search queries) in this group. Kubernetes isn’t just an orchestration tool; it’s the <a href=\"https://www.itproportal.com/features/kubernetes-as-a-cloud-native-operating-system/\">cloud’s operating system</a> (or, as Kelsey Hightower has <a href=\"https://twitter.com/kelseyhightower/status/775487754868133888\">said</a>, “Kubernetes will be the Linux of distributed systems”). But the data doesn’t show the number of conversations we’ve had with people who think that Kubernetes is just “too complex.” We see three possible solutions:</p>\\n\\n\\n\\n<ul><li>A “simplified” version of Kubernetes that isn’t as flexible, but trades off a lot of the complexity. <a href=\"https://k3s.io/\">K3s</a> is a possible step in this direction. The question is, What’s the trade-off? Here’s my version of the <a href=\"https://en.wikipedia.org/wiki/Pareto_principle\">Pareto principle</a>, also known as the 80/20 rule. Given any system (like Kubernetes), it’s usually possible to build something simpler by keeping the most widely used 80% of the features and cutting the other 20%. And some applications will fit within the 80% of the features that were kept. But most applications (maybe 80% of them?) will require at least one of the features that were sacrificed to make the system simpler.<br /></li><li>An entirely new approach, some tool that isn’t yet on the horizon. We have no idea what that tool is. In Yeats’s words, “What rough beast&#8230;slouches towards Bethlehem to be born”? <br /></li><li>An integrated solution from a cloud vendor (for example, Microsoft’s open source <a href=\"https://thenewstack.io/the-dapr-distributed-runtime-nears-production-readiness/\">Dapr distributed runtime</a>). I don’t mean cloud vendors that provide Kubernetes as a service; we already have those. What if the cloud vendors integrate Kubernetes’s functionality into their stack in such a way that that functionality disappears into some kind of management console? Then the question becomes, What features do you lose, and do you need them? And what kind of vendor lock-in games do you want to play? </li></ul>\\n\\n\\n\\n<p>The rich ecosystem of tools surrounding Kubernetes (Istio, Helm, and others) shows how valuable it is. But where do we go from here? Even if Kubernetes is the right tool to manage the complexity of modern applications that run in the cloud, the desire for simpler solutions will eventually lead to higher-level abstractions. Will they be adequate?</p>\\n\\n\\n\\n<p><a href=\"https://thenewstack.io/observability-a-3-year-retrospective/\">Observability</a> saw the greatest growth in the past year (128%), while monitoring is only up 9%. While observability is a richer, more powerful capability than monitoring—observability is the ability to find the information you need to analyze or debug software, while monitoring requires predicting in advance what data will be useful—we suspect that this shift is largely cosmetic. “Observability” risks becoming the new name for monitoring. And that’s <a href=\"https://www.honeycomb.io/blog/observability-whats-in-a-name/\">unfortunate</a>. If you think observability is merely a more fashionable term for monitoring, you’re missing its value. Complex systems running in the cloud will need true observability to be manageable.</p>\\n\\n\\n\\n<p>Infrastructure is code, and we’ve seen plenty of tools for automating configuration. But Chef and Puppet, two leaders in this movement, are both significantly down (49% and 40% respectively), as is Salt. Ansible is the only tool from this group that’s up (34%). Two trends are responsible for this. Ansible appears to have supplanted Chef and Puppet, possibly because Ansible is multilingual, while Chef and Puppet are tied to Ruby. Second, Docker and Kubernetes have changed the configuration game. Our data shows that Chef and Puppet peaked in 2017, when Kubernetes started an almost exponential growth spurt, as Figure 4 shows. (Each curve is normalized separately to 1; we wanted to emphasize the inflection points rather than compare usage.) Containerized deployment appears to minimize the problem of reproducible configuration, since a container is a complete software package. You have a container; you can deploy it many times, getting the same result each time. In reality, it’s never that simple, but it certainly looks that simple–and that apparent simplicity reduces the need for tools like Chef and Puppet.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13623\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-4-1048x782.png\" /><figcaption><br /><em>Figure 4. Docker and Kubernetes versus Chef and Puppet</em></figcaption></figure>\\n\\n\\n\\n<p>The biggest challenge facing operations teams in the coming year, and the biggest challenge facing data engineers, will be learning how to deploy AI systems effectively. In the past decade, a lot of ideas and technologies have come out of the DevOps movement: the source repository as the single source of truth, rapid automated deployment, constant testing, and more. They’ve been very effective, but AI breaks the assumptions that lie behind them, and deployment is frequently the greatest barrier to AI success.</p>\\n\\n\\n\\n<p>AI breaks these assumptions because data is more important than code. We don’t yet have adequate tools for versioning data (though <a href=\"https://dvc.org/\">DVC</a> is a start). Models are neither code nor data, and we don’t have adequate tools for versioning models either (though tools like <a href=\"https://mlflow.org/\">MLflow</a> are a start). Frequent deployment assumes that the software can be built relatively quickly, but training a model can take days. It’s been suggested that model training doesn’t need to be part of the build process, but that’s really the most important part of the application. Testing is critical to continuous deployment, but the behavior of AI systems is probabilistic, not deterministic, so it’s harder to say that this test or that test failed. It’s particularly difficult if testing includes issues like fairness and bias.</p>\\n\\n\\n\\n<p>Although there is a nascent <a href=\"https://en.wikipedia.org/wiki/MLOps\">MLOps</a> movement, our data doesn’t show that people are using (or searching for) content in these areas in significant numbers. Usage is easily explainable; in many of these areas, content doesn’t exist yet. But users will search for content whether or not it exists, so the small number of searches shows that most of our users aren’t yet aware of the problem. Operations staff too frequently assume that an AI system is just another application—but they’re wrong. And AI developers too frequently assume that an operations team will be able to deploy their software, and they’ll be able to move on to the next project—but they’re also wrong. This situation is a train wreck in slow motion, and the big question is whether we can stop the trains before they crash. These problems will be solved eventually, with a new generation of tools—indeed, those tools are already being built—but we’re not there yet.</p>\\n\\n\\n\\n<h3><strong>AI, Machine Learning, and Data</strong></h3>\\n\\n\\n\\n<p>Healthy growth in artificial intelligence has continued: machine learning is up 14%, while AI is up 64%; data science is up 16%, and statistics is up 47%. While AI and machine learning are distinct concepts, there’s enough confusion about definitions that they’re frequently used interchangeably. We informally define machine learning as “the part of AI that works”; AI itself is more research oriented and aspirational. If you accept that definition, it’s not surprising that content about machine learning has seen the heaviest usage: it’s about taking research out of the lab and putting it into practice. It’s also not surprising that we see solid growth for AI, because that’s where bleeding-edge engineers are looking for new ideas to turn into machine learning.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13624\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-5-1048x760.png\" /><figcaption><br /><em>Figure 5. Artificial intelligence, machine learning, and data</em></figcaption></figure>\\n\\n\\n\\n<p>Have the skepticism, fear, and criticism surrounding AI taken a toll, or are “reports of AI’s death greatly exaggerated”? We don’t see that in our data, though there are certainly some metrics to say that <a href=\"https://science.sciencemag.org/content/368/6494/927\">artificial intelligence has stalled</a>. Many projects never make it to production, and while the last year has seen amazing progress in natural language processing (up 21%), such as OpenAI’s GPT-3, we’re seeing fewer spectacular results like winning Go games. It’s possible that AI (along with machine learning, data, big data, and all their fellow travelers) is descending into the trough of the hype cycle. We don’t think so, but we’re prepared to be wrong. As <a href=\"https://www.linkedin.com/in/benlorica/\">Ben Lorica</a> has said (in conversation), many years of work will be needed to bring current research into commercial products.</p>\\n\\n\\n\\n<p>It’s certainly true that there’s been a (deserved) backlash over heavy handed use of AI. A backlash is only to be expected when deep learning applications are used to justify <a href=\"https://www.npr.org/2020/06/24/882683463/the-computer-got-it-wrong-how-facial-recognition-led-to-a-false-arrest-in-michig\">arresting the wrong people</a>, and when some police departments are comfortable using software with a <a href=\"https://www.theverge.com/2018/7/5/17535814/uk-face-recognition-police-london-accuracy-completely-comfortable\">98% false positive rate</a>. A backlash is only to be expected when software systems designed to maximize “engagement” end up spreading misinformation and conspiracy theories. A backlash is only to be expected when software developers don’t take into account issues of power and abuse. And a backlash is only to be expected when too many executives see AI as a “magic sauce” that will turn their organization around without pain or, frankly, a whole lot of work.</p>\\n\\n\\n\\n<p>But we don’t think those issues, as important as they are, say a lot about the future of AI. The future of AI is less about breathtaking breakthroughs and creepy face or voice recognition than it is about small, mundane applications. Think quality control in a factory; think intelligent search <a href=\"https://learning.oreilly.com/answers/search/\">on O’Reilly online learning</a>; think <a href=\"https://www.dpreview.com/news/5756257699/nvidia-research-develops-a-neural-network-to-replace-traditional-video-compression\">optimizing data compression</a>; think <a href=\"https://www.technologyreview.com/2020/10/16/1010617/ai-image-recognition-construction-computer-vision-costs-delays/\">tracking progress on a construction site</a>. I’ve seen too many articles saying that AI hasn’t helped in the struggle against COVID, as if someone was going to click a button on their MacBook and a superdrug was going to pop out of a USB-C port. (And AI has played a huge role in <a href=\"https://spectrum.ieee.org/artificial-intelligence/medical-ai/what-ai-can-and-cant-do-in-the-race-for-a-coronavirus-vaccine\">COVID vaccine development</a>.) AI is playing an important supporting role—and that’s exactly the role we should expect. It’s enabling researchers to navigate tens of thousands of research papers and reports, design drugs and engineer genes that might work, and <a href=\"https://theconversation.com/teaching-computers-to-read-health-records-is-helping-fight-covid-19-heres-how-147385\">analyze millions of health records</a>. Without automating these tasks, getting to the end of the pandemic will be impossible.</p>\\n\\n\\n\\n<p>So here’s the future we see for AI and machine learning:</p>\\n\\n\\n\\n<ul><li>Natural language has been (and will continue to be) a big deal. GPT-3 has changed the world. We’ll see AI being used to create “fake news,” and we’ll find that AI gives us the best tools for detecting what’s fake and what isn’t.<br /></li><li>Many companies are placing significant bets on using AI to automate customer service. We’ve made great strides in our ability to synthesize speech, generate realistic answers, and search for solutions.<br /></li><li>We’ll see lots of tiny, embedded AI systems in everything from medical sensors to appliances to factory floors. Anyone interested in the future of technology should watch <a href=\"https://learning.oreilly.com/library/view/tinyml/9781492052036/\">Pete Warden’s work on TinyML</a> very carefully.<br /></li><li>We still haven’t faced squarely the issue of user interfaces for collaboration between humans and AI. We don’t want AI oracles that just replace human errors with machine-generated errors at scale; we want the ability to collaborate with AI to produce results better than either humans or machines could alone. Researchers are <a href=\"http://jessylin.com/2020/06/08/rethinking-human-ai-interaction/\">starting to catch on</a>.</li></ul>\\n\\n\\n\\n<p>TensorFlow is the leader among machine learning platforms; it gets the most searches, while usage has stabilized at 6% growth. Content about scikit-learn, Python’s machine learning library, is used almost as heavily, with 11% year-over-year growth. PyTorch is in third place (yes, this is a horse race), but usage of PyTorch content has gone up 159% year over year. That increase is no doubt influenced by the popularity of Jeremy Howard’s <a href=\"https://course.fast.ai/\">Practical Deep Learning for Coders</a> course and the PyTorch-based fastai library (no data for 2019). It also appears that PyTorch is more popular among researchers, while TensorFlow remains dominant in production. But as Jeremy’s students move into industry, and as researchers migrate toward production positions, we expect to see the balance between PyTorch and TensorFlow shift. </p>\\n\\n\\n\\n<p><a href=\"https://kafka.apache.org/\">Kafka</a> is a crucial tool for building data pipelines; it’s stable, with 6% growth and usage similar to Spark. Pulsar, Kafka’s “next generation” competition, isn’t yet on the map.</p>\\n\\n\\n\\n<p>Tools for automating AI and machine learning development (IBM’s <a href=\"https://www.ibm.com/cloud/watson-studio/autoai\">AutoAI</a>, Google’s <a href=\"https://cloud.google.com/automl\">Cloud AutoML</a>, Microsoft’s <a href=\"https://www.microsoft.com/en-us/research/project/automl/\">AutoML</a>, and Amazon’s <a href=\"https://aws.amazon.com/sagemaker/\">SageMaker</a>) have gotten a lot of press attention in the past year, but we don’t see any signs that they’re making a significant dent in the market. That content usage is nonexistent isn’t a surprise; O’Reilly members can’t use content that doesn’t exist. But our members aren’t searching for these topics either. It may be that AutoAI is relatively new or that users don’t think they need to search for supplementary training material.</p>\\n\\n\\n\\n<p>What about data science? The report <em>What Is Data Science </em>is a decade old, but surprisingly for a 10-year-old paper, views are up 142% over 2019. The tooling has changed though. Hadoop was at the center of the data science world a decade ago. It’s still around, but now it’s a legacy system, with a 23% decline since 2019. Spark is now the dominant data platform, and it’s certainly the tool engineers want to learn about: usage of Spark content is about three times that of Hadoop. But even Spark is down 11% since last year. <a href=\"https://ray.io/\">Ray</a>, a newcomer that promises to make it easier to build distributed applications, doesn’t yet show usage to match Spark (or even Hadoop), but it does show 189% growth. And there are other tools on the horizon: <a href=\"https://dask.org/\">Dask</a> has seen nearly 400% growth.</p>\\n\\n\\n\\n<p>It’s been exciting to watch the discussion of data ethics and activism in the past year. Broader societal movements (such as #BlackLivesMatter), along with increased industry awareness of diversity and inclusion, have made it more difficult to ignore issues like fairness, power, and transparency. What’s sad is that our data shows little evidence that this is more than a discussion. Usage of general content (not specific to AI and ML) about diversity and inclusion is up significantly (87%), but the absolute numbers are still small. Topics like ethics, fairness, transparency, and explainability don’t make a dent in our data. That may be because few books have been published and few training courses have been offered—but that’s a problem in itself.</p>\\n\\n\\n\\n<h3><strong>Web Development</strong></h3>\\n\\n\\n\\n<p>Since the invention of HTML in the early 1990s, the first web servers, and the first browsers, the web has exploded (or degenerated) into a proliferation of platforms. Those platforms make web development infinitely more flexible: They make it possible to support a host of devices and screen sizes. They make it possible to build sophisticated applications that run in the browser. And with every new year, “desktop” applications look more old-fashioned.</p>\\n\\n\\n\\n<p>So what does the world of web frameworks look like? React leads in usage of content and also shows significant growth (34% year over year). Despite rumors that Angular is fading, it’s the #2 platform, with 10% growth. And usage of content about the server-side platform Node.js is just behind Angular, with 15% growth. None of this is surprising.</p>\\n\\n\\n\\n<p>It’s more surprising that Ruby on Rails shows extremely strong growth (77% year over year) after several years of moderate, stable performance. Likewise, Django (which appeared at roughly the same time as Rails) shows both heavy usage and 63% growth. You might wonder whether this growth holds for all older platforms; it doesn’t. Usage of content about PHP is relatively low and declining (8% drop), even though it’s still used by <a href=\"https://w3techs.com/technologies/details/pl-php\">almost 80%</a> of all websites. (It will be interesting to see how <a href=\"https://www.php.net/archive/2020.php\">PHP 8</a> changes the picture.) And while jQuery shows healthy 18% growth, usage of jQuery content was lower than any other platform we looked at. (Keep in mind, though, that there are literally thousands of web platforms. A complete study would be either heroic or foolish. Or both.)</p>\\n\\n\\n\\n<p><a href=\"https://vuejs.org/\">Vue</a> and <a href=\"https://palletsprojects.com/p/flask/\">Flask</a> make surprisingly weak showings: for both platforms, content usage is about one-eighth of React’s. Usage of Vue-related content declined 13% in the past year, while Flask grew 10%. Neither is challenging the dominant players. It’s tempting to think of Flask and Vue as “new” platforms, but they were released in 2010 and 2014, respectively; they’ve had time to establish themselves. Two of the most promising new platforms, <a href=\"https://svelte.dev/\">Svelte</a> and <a href=\"https://nextjs.org/\">Next.js</a>, don’t yet produce enough data to chart—possibly because there isn’t yet much content to use. Likewise, <a href=\"https://webassembly.org/\">WebAssembly</a> (Wasm) doesn’t show up. (It’s also too new, with little content or training material available.) But WebAssembly represents a major rethinking of web programming and bears watching closely. Could WebAssembly turn JavaScript’s dominance of web development on its head? We suspect that nothing will happen quickly. Enterprise customers will be reluctant to bear the cost of moving from an older framework like PHP to a more fashionable JavaScript framework. It costs little to stick with an old stalwart.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13625\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-6-1048x761.png\" /><figcaption><br /><em>Figure 6. Web development</em></figcaption></figure>\\n\\n\\n\\n<p>The foundational technologies HTML, CSS, and JavaScript are all showing healthy growth in usage (22%, 46%, and 40%, respectively), though they’re behind the leading frameworks. We’ve already noted that JavaScript is one of the top programming languages—and the modern web platforms are nothing if not the apotheosis of JavaScript. We find that chilling. The original vision for the World Wide Web was radically empowering and democratizing. You didn’t need to be a techno-geek; you didn’t even need to program—you could just click “view source” in the browser and copy bits you liked from other sites. Twenty-five years later, that’s no longer true: you can still “view source,” but all you’ll see is a lot of incomprehensible JavaScript. Ironically, just as other technologies are democratizing, web development is increasingly the domain of programmers. Will that trend be reversed by a new generation of platforms, or by a reformulation of the web itself? We shall see.</p>\\n\\n\\n\\n<h3><strong>Clouds of All Kinds</strong></h3>\\n\\n\\n\\n<p>It’s no surprise that the cloud is growing rapidly. Usage of content about the cloud is up 41% since last year. Usage of cloud titles that don’t mention a specific vendor (e.g., Amazon Web Services, Microsoft Azure, or Google Cloud) grew at an even faster rate (46%). Our customers don’t see the cloud through the lens of any single platform. We’re only at the beginning of cloud adoption; while <a href=\"https://www.oreilly.com/radar/cloud-adoption-in-2020/\">most companies</a> are using cloud services in some form, and many have moved significant business-critical applications and datasets to the cloud, we have a long way to go. If there’s one technology trend you need to be on top of, this is it.</p>\\n\\n\\n\\n<p>The horse race between the leading cloud vendors, AWS, Azure, and Google Cloud, doesn’t present any surprises. Amazon is winning, even ahead of the generic “cloud”—but Microsoft and Google are catching up, and Amazon’s growth has stalled (only 5%). Use of content about Azure shows 136% growth—more than any of the competitors—while Google Cloud’s 84% growth is hardly shabby. When you dominate a market the way AWS dominates the cloud, there’s nowhere to go but down. But with the growth that Azure and Google Cloud are showing, Amazon’s dominance could be short-lived.</p>\\n\\n\\n\\n<p>What’s behind this story? Microsoft has done an excellent job of reinventing itself as a cloud company. In the past decade, it’s rethought every aspect of its business: Microsoft has become a leader in open source; it owns GitHub; it owns LinkedIn. It’s hard to think of any corporate transformation so radical. This clearly isn’t the Microsoft that declared Linux a “cancer,” and that Microsoft could never have succeeded with Azure.</p>\\n\\n\\n\\n<p>Google faces a different set of problems. Twelve years ago, the company arguably delivered serverless with App Engine. It open sourced Kubernetes and bet very heavily on its leadership in AI, with the leading AI platform TensorFlow highly optimized to run on Google hardware. So why is it in third place? Google’s problem hasn’t been its ability to deliver leading-edge technology but rather its ability to reach customers—a problem that Thomas Kurian, Google Cloud’s CEO, is <a href=\"https://www.crn.com/news/cloud/how-thomas-kurian-s-quite-simple-strategy-is-transforming-google-cloud\">attempting to address</a>. Ironically, part of Google’s customer problem is its focus on engineering to the detriment of the customers themselves. Any number of people have told us that they stay away from Google because they’re too likely to say, “Oh, that service you rely on? We’re shutting it down; we have a better solution.” Amazon and Microsoft don’t do that; they understand that a cloud provider has to support legacy software, and that all software is legacy the moment it’s released.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13626\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-7-1048x776.png\" /><figcaption><br /><em>Figure 7. Cloud usage </em></figcaption></figure>\\n\\n\\n\\n<p>While our data shows very strong growth (41%) in usage for content about the cloud, it doesn’t show significant usage for terms like “multicloud” and “hybrid cloud” or for specific hybrid cloud products like Google’s <a href=\"https://cloud.google.com/anthos\">Anthos</a> or Microsoft’s <a href=\"https://azure.microsoft.com/en-us/services/azure-arc/\">Azure Arc</a>. These are new products, for which little content exists, so low usage isn’t surprising. But the usage of specific cloud technologies isn’t that important in this context; what’s more important is that usage of all the cloud platforms is growing, particularly content that isn’t tied to any vendor. We also see that our corporate clients are using content that spans all the cloud vendors; it’s difficult to find anyone who’s looking at a single vendor.</p>\\n\\n\\n\\n<p>Not long ago, we were skeptical about hybrid and multicloud. It’s easy to assume that these concepts are pipe dreams springing from the minds of vendors who are in second, third, fourth, or fifth place: if you can’t win customers from Amazon, at least you can get a slice of their business. That story isn’t compelling—but it’s also the wrong story to tell. Cloud computing is hybrid by nature. Think about how companies “get into the cloud.” It’s often a chaotic grassroots process rather than a carefully planned strategy. An engineer can’t get the resources for some project, so they create an AWS account, billed to the company credit card. Then someone in another group runs into the same problem, but goes with Azure. Next there’s an acquisition, and the new company has built its infrastructure on Google Cloud. And there’s petabytes of data on-premises, and that data is subject to regulatory requirements that make it difficult to move. The result? Companies have hybrid clouds long before anyone at the C-level perceives the need for a coherent cloud strategy. By the time the C suite is building a master plan, there are already mission-critical apps in marketing, sales, and product development. And the one way to fail is to dictate that “we’ve decided to unify on cloud X.”</p>\\n\\n\\n\\n<p>All the cloud vendors, including Amazon (which until recently<a href=\"https://www.crn.com.au/news/aws-forbids-partners-even-mentioning-multi-cloud-529598\"> didn’t even allow its partners to use the word multicloud</a>), are being drawn to a strategy based not on locking customers into a specific cloud but on facilitating management of a hybrid cloud, and all offer tools to support hybrid cloud development. They know that support for hybrid clouds is key to cloud adoption–and, if there is any lock in, it will be around management. As IBM’s Rob Thomas has frequently said, “<a href=\"https://learning.oreilly.com/library/view/the-ai-ladder/9781492073420/ch04.html\">Cloud is a capability, not a location</a>.”</p>\\n\\n\\n\\n<p>As expected, we see a lot of interest in microservices, with a 10% year-over-year increase—not large, but still healthy. Serverless (a.k.a. functions as a service) also shows a 10% increase, but with lower usage. That’s important: while it “feels like” serverless adoption has stalled, our data suggests that it’s growing in parallel with microservices.</p>\\n\\n\\n\\n<h3><strong>Security and Privacy</strong></h3>\\n\\n\\n\\n<p>Security has always been a problematic discipline: defenders have to get thousands of things right, while an attacker only has to discover one mistake. And that mistake might have been made by a careless user rather than someone on the IT staff. On top of that, companies have often underinvested in security: when the best sign of success is that “nothing bad happened,” it’s very difficult to say whether money was well spent. Was the team successful or just lucky?</p>\\n\\n\\n\\n<p>Yet the last decade has been full of high-profile break-ins that have cost billions of dollars (including increasingly hefty penalties) and led to the <a href=\"https://www.csoonline.com/article/3510640/7-security-incidents-that-cost-cisos-their-jobs.html\">resignations and firings of C-suite executives</a>. Have companies learned their lessons?</p>\\n\\n\\n\\n<p>The data doesn’t tell a clear story. While we’ve avoided discussing absolute usage, usage of content about security is very high—higher than for any other topic except for the major programming languages like Java and Python. Perhaps a better comparison would be to compare security with a general topic like programming or cloud. If we take that approach, programming usage is heavier than security, and security is only slightly behind cloud. So the usage of content about security is high, indeed, with year-over-year growth of 35%.</p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img alt=\"\" class=\"wp-image-13627\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2021/01/76572_ORM_Platform_Analysis_Report_Data_Viz_Figure-8-1048x764.png\" /><figcaption><br /><em>Figure 8. Security and privacy</em></figcaption></figure>\\n\\n\\n\\n<p>But what content are people using? Certification resources, certainly: CISSP content and training is 66% of general security content, with a slight (2%) decrease since 2019. Usage of content about the CompTIA Security+ certification is about 33% of general security, with a strong 58% increase.</p>\\n\\n\\n\\n<p>There’s a fair amount of interest in hacking, which shows 16% growth. Interestingly, ethical hacking (a subset of hacking) shows about half as much usage as hacking, with 33% growth. So we’re evenly split between good and bad actors, but the good guys are increasing more rapidly. Penetration testing, which should be considered a kind of ethical hacking, shows a 14% decrease; this shift may only reflect which term is more popular.</p>\\n\\n\\n\\n<p>Beyond those categories, we get into the long tail: there’s only minimal usage of content about specific topics like phishing and ransomware, though ransomware shows a huge year-over-year increase (155%); that increase no doubt reflects the frequency and severity of ransomware attacks in the past year. There’s also a 130% increase in content about “zero trust,” a technology used to build defensible networks—though again, usage is small.</p>\\n\\n\\n\\n<p>It’s disappointing that we see so little interest in content about privacy, including content about specific regulatory requirements such as GDPR. We don’t see heavy usage; we don’t see growth; we don’t even see significant numbers of search queries. This doesn’t bode well.</p>\\n\\n\\n\\n<h3><strong>Not the End of the Story</strong></h3>\\n\\n\\n\\n<p>We’ve taken a tour through a significant portion of the technology landscape. We’ve reported on the horse races along with the deeper stories underlying those races. Trends aren’t just the latest fashions; they’re also long-term processes. Containerization goes back to <a href=\"https://www.section.io/engineering-education/history-of-container-technology/\">Unix version 7 in 1979</a>; and didn’t Sun Microsystems invent the cloud in the 1990s with its workstations and <a href=\"https://en.wikipedia.org/wiki/Sun_Ray\">Sun Ray</a> terminals? We may talk about “internet time,” but the most important trends span decades, not months or years—and often involve reinventing technology that was useful but forgotten, or technology that surfaced before its time.</p>\\n\\n\\n\\n<p>With that in mind, let’s take several steps back and think about the big picture. How are we going to harness the computing power needed for AI applications? We’ve talked about concurrency for decades, but it was only an exotic capability important for huge number-crunching tasks. That’s no longer true; we’ve run out of Moore’s law, and concurrency is table stakes. We’ve talked about system administration for decades, and during that time, the ratio of IT staff to computers managed has gone from many-to-one (one mainframe, many operators) to one-to-thousands (monitoring infrastructure in the cloud). As part of that evolution, automation has also gone from an option to a necessity. </p>\\n\\n\\n\\n<p>We’ve all heard that “everyone should learn to program.” This may be correct&#8230;or maybe not. It doesn’t mean that everyone should be a professional programmer but that everyone should be able to use computers effectively, and that requires programming. Will that be true in the future? No-code and low-code products are reaching the market, allowing users to build everything from business applications to AI prototypes. Again, this trend goes way back: in the late 1950s, the first modern programming languages made programming much easier. And yes, even back then there were those who said “real men use machine language.” (And that sexism was no doubt intentional, since the first generation of programmers included many women.) Will our future bring further democratization? Or a return to a cult of “wizards”? Low-code AI and complex JavaScript web platforms offer conflicting visions of what the future may bring.</p>\\n\\n\\n\\n<p>Finally, the most important trend may not yet appear in our data at all. Technology has largely gotten a free ride as far as regulation and legislation are concerned. Yes, there are heavily regulated sectors like healthcare and finance, but social media, much of machine learning, and even much of online commerce have only been lightly regulated. That free ride is coming to an end. Between <a href=\"https://en.wikipedia.org/wiki/General_Data_Protection_Regulation\">GDPR</a>, the <a href=\"https://oag.ca.gov/privacy/ccpa\">California Consumer Privacy Act</a> (which will probably be copied by many states), California Propositions <a href=\"https://voterguide.sos.ca.gov/propositions/22/\">22</a> and <a href=\"https://voterguide.sos.ca.gov/propositions/24/\">24</a>, many <a href=\"https://www.portland.gov/smart-city-pdx/news/2020/9/9/city-council-approves-ordinances-banning-use-face-recognition\">city ordinances</a> regarding the use of face recognition, and rethinking the meaning of <a href=\"https://www.lawfareblog.com/whats-next-section-230-roundup-proposals\">Section 230</a> of the Communications Decency Act, laws and regulations will play a big role in shaping technology in the coming years. Some of that regulation was inevitable, but a lot of it is a direct response to an industry that moved too fast and broke too many things. In this light, the lack of interest in privacy and related topics is unhealthy. Twenty years ago, we built a future that we don’t really want to live in. The question facing us now is simple:<br /><br />What future will we build? </p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/where-programming-ops-ai-and-the-cloud-are-headed-in-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Seven Legal Questions for Data Scientists',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Seven Legal Questions for Data Scientists'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/seven-legal-questions-for-data-scientists/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/seven-legal-questions-for-data-scientists/',\n",
       "   'comments': 'https://www.oreilly.com/radar/seven-legal-questions-for-data-scientists/#respond',\n",
       "   'published': 'Tue, 19 Jan 2021 12:21:18 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=19, tm_hour=12, tm_min=21, tm_sec=18, tm_wday=1, tm_yday=19, tm_isdst=0),\n",
       "   'authors': [{'name': 'Patrick Hall and Ayoub Ouederni'}],\n",
       "   'author': 'Patrick Hall and Ayoub Ouederni',\n",
       "   'author_detail': {'name': 'Patrick Hall and Ayoub Ouederni'},\n",
       "   'tags': [{'term': 'Artificial Intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'Deep Dive', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13610',\n",
       "   'guidislink': False,\n",
       "   'summary': '“[T]he threats to consumers arising from data abuse, including those posed by algorithmic harms, are mounting and urgent.” FTC Commissioner Rebecca K. Slaughter Variants of artificial intelligence (AI), such as predictive modeling, statistical learning, and machine learning (ML), can create new value for organizations. AI can also cause costly reputational damage, get your organization slapped [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': '“[T]he threats to consumers arising from data abuse, including those posed by algorithmic harms, are mounting and urgent.” FTC Commissioner Rebecca K. Slaughter Variants of artificial intelligence (AI), such as predictive modeling, statistical learning, and machine learning (ML), can create new value for organizations. AI can also cause costly reputational damage, get your organization slapped [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<blockquote class=\"wp-block-quote\"><p><em>“[T]he threats to consumers arising from data abuse, including those posed by algorithmic harms, are mounting and urgent.”</em></p><cite><br /><a href=\"https://www.ftc.gov/system/files/documents/public_statements/1564883/remarks_of_commissioner_rebecca_kelly_slaughter_on_algorithmic_and_economic_justice_01-24-2020.pdf\"><em>FTC Commissioner Rebecca K. Slaughter</em></a></cite></blockquote>\\n\\n\\n\\n<p>Variants of artificial intelligence (AI), such as predictive modeling, statistical learning, and machine learning (ML), can create new value for organizations. AI can also cause costly reputational damage, get your organization slapped with a lawsuit, and run afoul of local, federal, or international regulations. Difficult questions about compliance and legality often pour cold water on late-stage AI deployments as well, because data scientists rarely get attorneys or oversight personnel involved in the build-stages of AI systems. Moreover, like many powerful commercial technologies, AI is likely to be highly regulated in the future.</p>\\n\\n\\n\\n<p>This article poses seven legal questions that data scientists should address before they deploy AI. This article is not legal advice. However, these questions and answers should help you better align your organization’s technology with existing and future laws, leading to less discriminatory and invasive customer interactions, fewer regulatory or litigation headwinds, and better return on AI investments. As the questions below indicate, it’s important to think about the legal implications of your AI system as you’re building it. Although many organizations wait until there’s an incident to call in legal help, compliance by design saves resources and reputations.</p>\\n\\n\\n\\n<h3><strong>Fairness: </strong>Are there outcome or accuracy differences in model decisions across protected groups? Are you documenting efforts to find and fix these differences?</h3>\\n\\n\\n\\n<p><strong>Examples: </strong><a href=\"https://www.nbcnews.com/tech/apple/ny-regulator-investigating-apple-card-possible-gender-bias-n1079581\">Alleged discrimination in credit lines</a>; <a href=\"https://www.startribune.com/regulators-probe-racial-bias-with-unitedhealth-algorithm/563997722/\">Poor experimental design in healthcare algorithms</a></p>\\n\\n\\n\\n<p>Federal regulations require non-discrimination in consumer finance, employment, and other practices in the U.S. Local laws often extend these protections or define separate protections. Even if your AI isn’t directly affected by existing laws today, algorithmic discrimination can lead to <a href=\"https://algorithmwatch.org/en/story/google-vision-racism/\">reputational damage</a> and <a href=\"https://news.bloomberglaw.com/class-action/youtube-sued-for-race-discrimination-profiting-from-hate-speech\">lawsuits</a>, and the current political winds are blowing toward broader regulation of AI. To deal with the issue of algorithmic discrimination and to prepare for pending future regulations, organizations must improve cultural competencies, business processes, and tech stacks.</p>\\n\\n\\n\\n<p>Technology alone cannot solve algorithmic discrimination problems. Solid technology must be paired with culture and process changes, like increased demographic and professional diversity on the teams that build AI systems and better audit processes for those systems. Some additional non-technical solutions involve ethical principles for organizational AI usage, and a general mindset change. Going fast and breaking things isn’t the best idea when what you&#8217;re breaking are people’s loans, jobs, and healthcare.</p>\\n\\n\\n\\n<p>From a technical standpoint, you’ll need to start with careful experimental design and data that truly represents modeled populations. After your system is trained, all aspects of AI-based decisions should be tested for disparities across demographic groups: the system’s primary outcome, follow-on decisions, such as limits for credit cards, and manual overrides of automated decisions, along with the accuracy of all these decisions. In many cases, discrimination tests and any subsequent remediation must also be conducted using legally sanctioned techniques—not just your new favorite Python package. Measurements like adverse impact ratio, marginal effect, and standardized mean difference, along with prescribed methods for fixing discovered discrimination, are enshrined in regulatory commentary. Finally, you should document your efforts to address algorithmic discrimination. Such documentation shows your organization takes accountability for its AI systems seriously and can be invaluable if legal questions arise after deployment.</p>\\n\\n\\n\\n<h3><strong>Privacy</strong>: Is your model complying with relevant privacy regulations?</h3>\\n\\n\\n\\n<p><strong>Examples: </strong><a href=\"https://www.biometricupdate.com/202007/facial-biometrics-training-dataset-leads-to-bipa-lawsuits-against-amazon-alphabet-and-microsoft\">Training data violates new state privacy laws</a></p>\\n\\n\\n\\n<p>Personal data is highly regulated, <a href=\"https://www.dlapiperdataprotection.com/\">even in the U.S.</a>, and nothing about using data in an AI system changes this fact. If you are using personal data in your AI system, you need to be mindful of existing laws and watch evolving state regulations, like the <a href=\"https://www.natlawreview.com/article/illinois-biometric-information-privacy-act-bipa-when-will-companies-heed-warning\">Biometric Information Privacy Act</a> (BIPA) in Illinois or the new <a href=\"https://www.manatt.com/insights/newsletters/client-alert/the-california-privacy-rights-act-has-passed\">California Privacy Rights Act</a> (CPRA). </p>\\n\\n\\n\\n<p>To cope with the reality of privacy regulations, teams that are engaged in AI also need to comply with organizational data privacy policies. Data scientists should familiarize themselves with these policies from the early stages of an AI project to help avoid privacy problems. At a minimum, these policies will likely address:</p>\\n\\n\\n\\n<ul><li><strong>Consent for use:</strong> how consumer consent for data-use is obtained; the types of information collected; and ways for consumers to opt-out of data collection and processing.<br /></li><li><strong>Legal basis:</strong> any applicable privacy regulations to which your data or AI are adhering; why you’re collecting certain information; and associated consumer rights.<br /></li><li><strong>Anonymization requirements:</strong> how consumer data is aggregated and anonymized.<br /></li><li><strong>Retention requirements:</strong> how long you store consumer data; the security you have to protect that data; and if and how consumers can request that you delete their data. </li></ul>\\n\\n\\n\\n<p>Given that most AI systems will change over time, you should also regularly audit your AI to ensure that it remains in compliance with your privacy policy over time. Consumer requests to delete data, or the addition of new data-hungry functionality, can cause legal problems, even for AI systems that were in compliance at the time of their initial deployment.</p>\\n\\n\\n\\n<p>One last general tip is to have an incident response plan. This is a lesson learned from general IT security. Among many other considerations, that plan should detail systematic ways to inform regulators and consumers if data has been breached or misappropriated.</p>\\n\\n\\n\\n<h3><strong>Security:</strong> Have you incorporated applicable security standards in your model? Can you detect if and when a breach occurs?</h3>\\n\\n\\n\\n<p><strong>Examples: </strong><a href=\"https://www.pcmag.com/news/report-ai-company-leaks-over-25m-medical-records\">Poor physical security for AI systems</a>; <a href=\"https://www.wired.com/2016/09/how-to-steal-an-ai/\">Security attacks on ML</a>; <a href=\"https://www.engadget.com/2019-12-16-facial-recognition-fooled-masks.html\">Evasion attacks</a></p>\\n\\n\\n\\n<p>As consumer software systems, AI systems likely fall under various security standards and breach reporting laws. You’ll need to update your organization’s IT security procedures to apply to AI systems, and you’ll need to make sure that you can report if AI systems—data or algorithms—are compromised. </p>\\n\\n\\n\\n<p>Luckily, the basics of IT security are <a href=\"https://www.ftc.gov/system/files/attachments/cybersecurity-small-business/cybersecuirty_sb_factsheets_all.pdf\">well-understood</a>. First, ensure that these are applied uniformly across your IT assets, including that super-secret new AI project and the rock-star data scientists working on it. Second, start preparing for <a href=\"https://github.com/mitre/advmlthreatmatrix\">inevitable attacks on AI</a>. These attacks tend to involve adversarial manipulation of AI-based decisions or the exfiltration of sensitive data from AI system endpoints. While these attacks are not common today, you don’t want to be the object lesson in AI security for years to come. So update your IT security policies to consider these new attacks. Standard counter-measures such as authentication and throttling at system endpoints go a long way toward promoting AI security, but newer approaches such as robust ML, differential privacy, and federated learning can make AI hacks even more difficult for bad actors.</p>\\n\\n\\n\\n<p>Finally, you’ll need to report breaches if they occur in your AI systems. If your AI system is a labyrinthian black-box, that could be difficult. Avoid overly complex, black-box algorithms whenever possible, monitor AI systems in real-time for performance, security, and discrimination problems, and ensure system documentation is applicable for incident response and breach reporting purposes.</p>\\n\\n\\n\\n<h3><strong>Agency:</strong> Is your AI system making unauthorized decisions on behalf of your organization?</h3>\\n\\n\\n\\n<p><strong>Examples: </strong><a href=\"https://www.bbc.com/news/business-54698858\">Gig economy robo-firing</a>; <a href=\"https://futurism.com/investing-lawsuit-ai-trades-cost-millions\">AI executing equities trades</a></p>\\n\\n\\n\\n<p>If your AI system is making material decisions, it is crucial to ensure that it cannot make unauthorized decisions. If your AI is based on ML, as most are today, your system&#8217;s outcome is probabilistic: it <em>will</em> make wrong decisions. Wrong AI-based decisions about material matters—lending, financial transactions, employment, healthcare, or criminal justice, among others—can cause serious legal liabilities (see <strong>Negligence</strong> below). Worse still, using AI to mislead consumers can put your organization on the wrong side of an FTC enforcement action or a class action. </p>\\n\\n\\n\\n<p>Every organization approaches risk management differently, so setting necessary limits on automated predictions is a business decision that requires input from many stakeholders. Furthermore, humans should review any AI decisions that implicate such limits before a customer&#8217;s final decision is issued. And don&#8217;t forget to routinely test your AI system with edge cases and novel situations to ensure it stays within those preset limits.</p>\\n\\n\\n\\n<p>Relatedly, and to quote the FTC, &#8220;[d]on&#8217;t deceive consumers about how you use automated tools.&#8221; In their <a href=\"https://www.ftc.gov/news-events/blogs/business-blog/2020/04/using-artificial-intelligence-algorithms\"><em>Using Artificial Intelligence and Algorithms</em></a> guidance, the FTC specifically called out companies for manipulating consumers with digital avatars posing as real people. To avoid this kind of violation, always inform your consumers that they are interacting with an automated system. It&#8217;s also a best practice to implement recourse interventions directly into your AI-enabled customer interactions. Depending on the context, an intervention might involve options to interact with a human instead, options to avoid similar content in the future, or a full-blown appeals process.</p>\\n\\n\\n\\n<h3><strong>Negligence:</strong> How are you ensuring your AI is safe and reliable?</h3>\\n\\n\\n\\n<p><strong>Examples: </strong><a href=\"https://www.thedailyjournal.com/story/news/2019/07/10/nj-vineland-jules-black-christian-rodgers-june-district-court-rodriquez-product-liability-decision/1698558001/\">Releasing the wrong person from jail</a>; <a href=\"https://www.reuters.com/article/us-uber-crash/in-review-of-fatal-arizona-crash-u-s-agency-says-uber-software-had-flaws-idUSKBN1XF2HA\">autonomous vehicle kills pedestrian</a></p>\\n\\n\\n\\n<p>AI decision-making can lead to serious safety issues, including physical injuries. To keep your organization’s AI systems in check, the practice of model risk management–based roughly on the Federal Reserve’s <a href=\"https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf\">SR 11-7 letter</a>–is among the most tested frameworks for safeguarding predictive models against stability and performance failures.</p>\\n\\n\\n\\n<p>For more advanced AI systems, a lot can go wrong. When creating autonomous vehicle or robotic process automation (RPA) systems, be sure to incorporate practices from the nascent discipline of <a href=\"https://arxiv.org/abs/1904.07204\">safe and reliable machine learning</a>. Diverse teams, including domain experts, should think through possible incidents, compare their designs to <a href=\"https://arxiv.org/pdf/2011.08512.pdf\">known past incidents</a>, document steps taken to prevent such incidents, and develop response plans to prevent inevitable glitches from spiraling out of control. </p>\\n\\n\\n\\n<h3><strong>Transparency:</strong> Can you explain how your model arrives at a decision?</h3>\\n\\n\\n\\n<p><strong>Examples: </strong>Proprietary algorithms hide data errors in <a href=\"https://washingtonmonthly.com/magazine/junejulyaugust-2017/code-of-silence/\">criminal sentencing</a> and <a href=\"https://www.wired.com/story/trueallele-software-transforming-how-courts-treat-dna-evidence/\">DNA testing</a></p>\\n\\n\\n\\n<p>Federal law already requires explanations for certain consumer finance decisions. Beyond meeting regulatory requirements, interpretability of AI system mechanisms enables human trust and understanding of these high-impact technologies, meaningful recourse interventions, and proper system documentation. Over recent years, two promising technological approaches have increased AI systems&#8217; interpretability: interpretable ML models and post-hoc explanations. Interpretable ML models (<em>e.g.</em>, <a href=\"https://github.com/interpretml/interpret\">explainable boosting machines</a>) are algorithms that are both highly accurate and highly transparent. Post-hoc explanations (<em>e.g.</em>, <a href=\"https://github.com/slundberg/shap\">Shapley values</a>) attempt to summarize ML model mechanisms and decisions. These two tools can be used together to increase your AI’s transparency. Given both the fundamental importance of interpretability and the technological process made toward this goal, it&#8217;s not surprising that new regulatory initiatives, like the FTC&#8217;s AI guidance and the CPRA, prioritize both consumer-level explanations and overall transparency of AI systems.</p>\\n\\n\\n\\n<h3><strong>Third Parties:</strong> Does your AI system depend on third-party tools, services, or personnel? Are they addressing these questions?</h3>\\n\\n\\n\\n<p><strong>Examples:</strong><a href=\"https://fortune.com/2020/09/29/artificial-intelligence-openai-gpt3-toxic/\">Natural language processing tools</a> and <a href=\"https://venturebeat.com/2020/11/03/researchers-show-that-computer-vision-algorithms-pretrained-on-imagenet-exhibit-multiple-distressing-biases/\">training data images</a> conceal discriminatory biases</p>\\n\\n\\n\\n<p>It is rare for an AI system to be built entirely in-house without dependencies on third-party software, data, or consultants. When you use these third-party resources, third-party risk is introduced into your AI system. And, as the old saying goes, a chain is only as strong as its weakest link. Even if your organization takes the utmost precaution, any incidents involving your AI system, even if they stem from a third-party you relied on, can potentially be blamed on you. Therefore, it is essential to ensure that any parties involved in the design, implementation, review, or maintenance of your AI systems follow all applicable laws, policies, and regulations. </p>\\n\\n\\n\\n<p>Before contracting with a third party, due diligence is required. Ask third parties for documentary proof that they take discrimination, privacy, security, and transparency seriously. And be on the lookout for signs of negligence, such as shoddy documentation, erratic software release cadences, lack of warranty, or unreasonably broad exceptions in terms of service or end-user license agreements (EULAs). You should also have contingency plans, including technical redundancies, incident response plans, and insurance covering third-party dependencies. Finally, don&#8217;t be shy about grading third-party vendors on a risk-assessment report card. Make sure these assessments happen over time, and not just at the beginning of the third-party contract. While these precautions may increase costs and delay your AI implementation in the short-term, they are the only way to mitigate third-party risks in your system consistently over time.</p>\\n\\n\\n\\n<h4>Looking Ahead</h4>\\n\\n\\n\\n<p>Several U.S. states and federal agencies have telegraphed their intentions regarding the future regulation of AI. Three of the broadest efforts to be aware of include the <a href=\"https://www.theverge.com/2019/4/10/18304960/congress-algorithmic-accountability-act-wyden-clarke-booker-bill-introduced-house-senate\">Algorithmic Accountability Act</a>, the FTC’s AI guidance, and the CPRA. Numerous other industry-specific guidance documents are being drafted, such as the FDA’s proposed <a href=\"https://www.fda.gov/media/122535/download?mod=article_inline\">framework</a> for AI in medical devices and FINRA’s <a href=\"https://www.finra.org/sites/default/files/2020-06/ai-report-061020.pdf\"><em>Artificial Intelligence (AI) in the Securities Industry</em></a>. Furthermore, other countries are setting examples for U.S. policymakers and regulators to follow. <a href=\"https://www.priv.gc.ca/en/about-the-opc/what-we-do/consultations/completed-consultations/consultation-ai/reg-fw_202011/\">Canada</a>, <a href=\"https://www.europarl.europa.eu/doceo/document/TA-9-2020-0276_EN.pdf\">the European Union</a>, <a href=\"https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AI-Governance-Framework\">Singapore</a>, and the <a href=\"https://ico.org.uk/about-the-ico/news-and-events/ai-blog-an-overview-of-the-auditing-framework-for-artificial-intelligence-and-its-core-components/\">United Kingdom</a>, among others, have all drafted or implemented detailed regulations for different aspects of AI and automated decision-making systems. In light of this government movement, and the growing public and government distrust of big tech, now is the perfect time to start minimizing AI system risk and prepare for future regulatory compliance.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/seven-legal-questions-for-data-scientists/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Patterns',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Patterns'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/patterns/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/patterns/',\n",
       "   'comments': 'https://www.oreilly.com/radar/patterns/#respond',\n",
       "   'published': 'Tue, 12 Jan 2021 12:56:01 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=12, tm_hour=12, tm_min=56, tm_sec=1, tm_wday=1, tm_yday=12, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Column', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13601',\n",
       "   'guidislink': False,\n",
       "   'summary': 'A few months ago, I said that &#8220;making everything into a design pattern is a sign that you don&#8217;t know what design patterns really are.&#8221; So now, I feel obliged to say something about what design patterns are. Design patterns are frequently observed solutions to common problems. The idea comes from the work of Christopher [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'A few months ago, I said that &#8220;making everything into a design pattern is a sign that you don&#8217;t know what design patterns really are.&#8221; So now, I feel obliged to say something about what design patterns are. Design patterns are frequently observed solutions to common problems. The idea comes from the work of Christopher [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>A few months ago, I said that &#8220;making everything into a design pattern is a sign that you don&#8217;t know what design patterns really are.&#8221; So now, I feel obliged to say something about what design patterns are.</p>\\n\\n\\n\\n<p>Design patterns are frequently observed solutions to common problems. The idea comes from the work of <a href=\"https://en.wikipedia.org/wiki/Christopher_Alexander\">Christopher Alexander</a> in architecture; patterns are things like &#8220;rooms on both sides of a hallway&#8221; or &#8220;door on the front of a building.&#8221;&nbsp; There’s a lot we can unpack from this simple definition:</p>\\n\\n\\n\\n<ul><li>Design patterns are not invented.&nbsp; They are observed. They aren’t about inventing (or re-inventing) wheels; they’re about noticing “I’ve put wheels on three things lately. Might be a good idea…” The first time you put wheels on something is an invention.&nbsp; It becomes a pattern when you observe that you’re re-inventing the wheel, and that’s a good thing. The wheel becomes part of your repertoire of solutions.<br /></li><li>Design patterns are not algorithms, which are specific solutions to generalized problems.&nbsp;Quicksort isn’t a pattern–nor is sorting itself.&nbsp; Patterns have more to do with how software is organized. They are more like stories, in which a problem leads to a solution that coordinates a number of different parts.<br /></li><li>Design patterns are often used without thinking; they feel natural, not clever, and that’s why they’re common. You’ll find them in your code; you’ll find them in the code of others.&nbsp; You can find them even if they weren’t put there consciously; patterns are often no more than a common solution to a certain kind of problem, something that looks obvious in retrospect. Patterns become a problem when programmers try to force the issue–to use patterns where they don’t quite fit, because they’ve heard that design patterns make their code better.<br /></li><li>Design patterns aren&#8217;t inherently good–and if you read Alexander, you’ll find that there are plenty of architectural patterns that he really doesn’t like. A corridor with rooms on both sides is a solution to certain architectural problems. It is frequently found in very boring hotels and offices.<br /></li><li>&#8220;Anti-patterns&#8221; may be worth avoiding, but that doesn&#8217;t mean they aren&#8217;t patterns. Frequently observed bad solutions to common problems are still frequently observed solutions to common problems. And sometimes, anti-patterns will be the best possible solution to an otherwise intractable problem. That’s the kind of technical debt that enables you to ship, as <a href=\"https://www.oreilly.com/radar/on-exactitude-in-technical-debt/\">Kevlin Henney</a> and <a href=\"https://c2.com/doc/oopsla92.html\">Ward Cunningham</a> have written.</li></ul>\\n\\n\\n\\n<p>There isn’t any magic here. While the book <a href=\"https://learning.oreilly.com/library/view/design-patterns-elements/0201633612/\">Design Patterns: Elements of Reusable Object-Oriented Software</a> by Gamma, Helm, Johnson, and Vlissides (the “Gang of Four”) is a classic, design patterns really aren’t things you look up in books. Design patterns are things you find in your code; they’d probably be there whether or not they had a name. So what’s the value?</p>\\n\\n\\n\\n<p>The biggest value in design patterns is that it gives us a common language for talking about software and how it’s organized. That’s why Alexander named one of his books <a href=\"https://www.amazon.com/Pattern-Language-Buildings-Construction-Environmental/dp/0195019199/\">A Pattern Language</a>. We’ve all spent hours making diagrams on black- or white-boards to show how some software we’re writing is organized. Design patterns give a common vocabulary so that we can discuss software with some certainty that we all mean the same thing. I eventually realized that UML had the same aim: UML diagrams are like architectural blueprints, in which one kind of line represents a brick wall, another wood, another plasterboard. Unfortunately, UML was never quite standard enough, and like design patterns, was perceived as a good in itself. In the end, a common vocabulary (whether a pattern catalog or UML) is a tool, and any tool can be abused.</p>\\n\\n\\n\\n<p>Since the Gang of Four, design patterns have been associated with object-oriented programming, but the idea that patterns aren’t applicable to functional languages is itself meaningless. It’s certainly true that in functional languages, some well-known patterns (like strategy or map/reduce) are either primitives or simple library functions; but saying that there aren’t patterns in functional programming is equivalent to saying that there are no common solutions to common problems. It’s still useful to point out that the “strategy” pattern is equivalent to passing a function as a parameter to another function. That language gives you an intuitive and descriptive way to discuss solutions to a problem.</p>\\n\\n\\n\\n<p>Patterns change over time, as problems change; there’s nothing special to the patterns the Gang of Four observed in the 1990s. In the 2020s, we should be building a pattern language for concurrent programming–and we may find that our patterns for the enterprise software of the 90s are less relevant.</p>\\n\\n\\n\\n<p>You may find that you use patterns without thinking about it; you may discover patterns in your code; you may realize you&#8217;re facing a problem that a pattern will help you to solve; or you may use patterns to describe solutions to someone else. When solving a problem, sometimes the only thing you’re missing is a name; having a name for your solution crystallizes it. Studying patterns is useful because it gives you a larger vocabulary with which to think about problems and solutions. But using patterns for their own sake leads you nowhere. I remember hearing about programmers boasting about how many Gang of Four patterns they used, and managers telling programmers to use more patterns.&nbsp; That’s not productive.</p>\\n\\n\\n\\n<p>Like any good thing in programming, using design patterns should help you solve complex problems more simply. But there&#8217;s no guarantee that they&#8217;ll do that. And if you find that they aren&#8217;t, then you should research for some other solutions.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/patterns/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: January 2021',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: January 2021'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-january-2021/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-january-2021/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-january-2021/#respond',\n",
       "   'published': 'Tue, 05 Jan 2021 11:40:19 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2021, tm_mon=1, tm_mday=5, tm_hour=11, tm_min=40, tm_sec=19, tm_wday=1, tm_yday=5, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13596',\n",
       "   'guidislink': False,\n",
       "   'summary': 'The last month of the old year showed a lot of activity on the border of AI and biology. The advances in protein folding with deep learning are a huge breakthrough that could revolutionize drug design. It’s important to remember the role AI had in developing the vaccine for COVID—and also worth remembering that we [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The last month of the old year showed a lot of activity on the border of AI and biology. The advances in protein folding with deep learning are a huge breakthrough that could revolutionize drug design. It’s important to remember the role AI had in developing the vaccine for COVID—and also worth remembering that we [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>The last month of the old year showed a lot of activity on the border of AI and biology. The advances in protein folding with deep learning are a huge breakthrough that could revolutionize drug design. It’s important to remember the role AI had in developing the vaccine for COVID—and also worth remembering that we still don’t have an anti-viral. And while I didn’t list them, the other big trend has been all the lawyers lining up to take shots at Google, Facebook, et al. Some of these are political posturing; others address real issues. We said recently the tech industry has had a free ride as far as the law goes; that’s clearly over. </p>\\n\\n\\n\\n<h2>AI, ML, and Data</h2>\\n\\n\\n\\n<ul><li>IBM has demonstrated that neural networks can be <a href=\"https://www.technologyreview.com/2020/12/11/1014102/ai-trains-on-4-bit-computers/\">trained on 4-bit computers</a> with minimal loss of accuracy and significant savings in power.<br /></li><li>AI ethics researcher <a href=\"https://www.bloomberg.com/news/articles/2020-12-03/google-s-co-head-of-ethical-ai-says-she-was-fired-over-email\">Timnit Gebru</a> was fired from Google. Her contributions include the papers <a href=\"https://arxiv.org/abs/1803.09010\">Datasheets for Datasets</a>, <a href=\"https://arxiv.org/abs/1810.03993\">Model Cards for Model Reporting</a>, <a href=\"http://proceedings.mlr.press/v81/buolamwini18a.html\">Gender Shades</a> (with Joy Buolamwini), and founding the group <a href=\"https://www.facebook.com/blackinai/\">Black in AI</a>.&nbsp; This is a severe blow to Google’s commitment to ethics in artificial intelligence.<br /></li><li><a href=\"https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/\">Debt, poverty, and algorithms</a>: Opaque algorithms used for credit scoring, loan approval, and other tasks will increasingly trap people in poverty without explanation.<br /></li><li>The past month’s biggest success in AI had nothing to do with language. <a href=\"https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/\">DeepFold</a>, DeepMind’s application of deep learning to protein folding, has made significant progress in predicting the structure of proteins. Predicting protein structure is computationally very difficult, and critical to drug discovery.<br /></li><li>Microsoft points out that <a href=\"https://thenewstack.io/microsoft-machine-learning-models-can-be-easily-reverse-engineered/\">reverse engineering ML models</a> are easily copied and reverse-engineered. Part of the solution may be setting up a deployment pipeline that allows you to change the system easily.<br /></li><li>Integration between <a href=\"https://www.kdnuggets.com/2020/11/tabpy-combining-python-tableau.html\">Python and Tableau</a>: Tableau has proven itself as a platform for data visualization and business analytics.&nbsp; Python is well-established as a language for data analysis and machine learning. What could be more natural than integration?</li></ul>\\n\\n\\n\\n<h2>Security</h2>\\n\\n\\n\\n<ul><li>An <a href=\"https://arstechnica.com/information-technology/2020/12/russian-hackers-hit-us-government-using-widespread-supply-chain-attack/\">attack</a> (now known as Sunburst) by Russian’s CozyBear organization have penetrated the U.S. Commerce, Treasury, and <a href=\"https://www.reuters.com/article/us-global-cyber-usa-dhs/suspected-russian-hackers-breached-u-s-department-of-homeland-security-sources-idUSKBN28O2LY\">Homeland Security</a> departments, in addition to an unknown number of corporations. The attack came through malware planted in a security product from SolarWinds. It still isn’t known exactly what data has been accessed, or how to rebuild infrastructure that has been compromised. The attack may well be the most serious in cyber-history. <br /></li><li><a href=\"https://www.lightbluetouchpaper.org/2020/12/02/pushing-the-limits-acoustic-side-channels/\">Acoustic side channels</a>: A new and important front in the struggle for privacy and data security. It’s possible for an Alexa-like device to discover what someone typed on their phone by listening to the taps.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li>Some serious streaming: The world’s highest volume real-time streaming system is <a href=\"https://hackernoon.com/we-built-the-worlds-largest-real-time-high-frequency-low-latency-streaming-system-on-golang-xf4r346e\">built with Go</a>.&nbsp; It streams stock quotes at up to 3 million messages per second.<br /></li><li>Are Dart and Flutter catching on? I’ve been very skeptical.&nbsp; But <a href=\"https://www.businessinsider.com/dart-programming-language-flutter-google-ebay-2020-11\">Business Insider thinks so</a>.&nbsp; (Forgive the paywall.) In any case, we need alternatives for web development.<br /></li><li><a href=\"https://www.nature.com/articles/s41598-020-77617-7\">Solving the travelling salesman problem in linear time</a>: not with a quantum computer, but with an analog computer that models the behavior of amoebae! It’s an unexpected way to solve an NP-hard problem, and begs the question of whether analog computers can be integrated with digital ones–a suggestion that Von Neumann made early in the history of computing.</li></ul>\\n\\n\\n\\n<h2>Operating Systems</h2>\\n\\n\\n\\n<ul><li>Google’s FuschiaOS, a possible replacement for the Android’s Linux kernel, is now “<a href=\"https://arstechnica.com/gadgets/2020/12/googles-secretive-fuchsia-os-is-open-for-contributions/\">open for contributions</a>.” We see new programming languages almost on a daily basis, but new operating systems are rare. This could be an important event.<br /></li><li><a href=\"https://arstechnica.com/gadgets/2020/12/centos-shifts-from-red-hat-unbranded-to-red-hat-beta/#p3\">The end of CentOS Linux</a>?&nbsp; RedHat is killing CentOS Linux, and wants to move users to CentOS Stream, which appears to be a pre-release of the next RHEL (Red Hat Enterprise Linux) version–not a stable release. <a href=\"https://thenewstack.io/red-hat-deprecates-linux-centos-in-favor-of-a-streaming-edition/\">The community isn’t buying it</a>.&nbsp; CentOS may live on independently as <a href=\"https://rockylinux.org/\">Rocky Linux</a>.</li></ul>\\n\\n\\n\\n<h2>Quantum Computing</h2>\\n\\n\\n\\n<ul><li>Quantum Supremacy with <a href=\"https://www.scottaaronson.com/blog/?p=5122\">BosonSampling</a>: Boson sampling is another computation that exists only to demonstrate quantum supremacy. It’s not useful, aside from showing that quantum computing is definitely on the way!</li></ul>\\n\\n\\n\\n<h2>Biology and Medicine</h2>\\n\\n\\n\\n<ul><li>A new drug appears to restart the brain’s processes for creating new proteins and, as a result, <a href=\"https://www.ucsf.edu/news/2020/12/419201/drug-reverses-age-related-mental-decline-within-days\">reverses cognitive decline</a> due to aging. So far, experiments have only been performed on mice.<br /></li><li><a href=\"https://www.technologyreview.com/2020/12/11/1013176/crispr-pigs-prrs-cd163-genus/\">CRISPR is being used</a> to engineer pigs so that they’re immune to a fatal and widespread virus called PRRS. Accuracy isn’t great (CRISPR is harder in practice than in theory), but there’s the potential for creating a breed of pigs that aren’t vulnerable to the disease.<br /></li><li>The one bit of good news in the coronavirus story is that we’re seeing the fastest vaccine rollout in history.&nbsp; But the Moderna (and Pfizer) vaccines were developed within days after the virus’ DNA was sequenced. The rest of the time has been spent testing. Can testing regimes be designed that are <a href=\"https://nymag.com/intelligencer/2020/12/moderna-covid-19-vaccine-design.html\">safe, effective, and much faster</a>?<br /></li><li>A sort of cyborg: <a href=\"https://newatlas.com/drones/smellicopter-drone-moth-antenna/\">drones using live moth antennas to detect scent</a>. This could be used to detect explosives, trapped humans, gas leaks, anything identifiable by smell.&nbsp; The antenna lives for a few hours after being removed from the moth. Presumably the moth doesn’t.<br /></li><li>NextMind is shipping a relatively inexpensive ($399) development kit for <a href=\"https://venturebeat.com/2020/12/07/nextmind-real-time-brain-computer-interface-dev-kit/\">brain interfaces</a>. Their interface is non-invasive and relatively small: a headband with a lump on the back. Still no killer app, though.<br /></li><li><a href=\"https://www.androidauthority.com/trinamix-molecular-analysis-smartphones-1182669/\">Molecular analysis with Smart Phones</a>: We thought that phone vendors had run out of sensors to add. We were wrong. Near infrared spectroscopy enables many health applications.</li></ul>\\n\\n\\n\\n<h2>Miscellaneous</h2>\\n\\n\\n\\n<ul><li>Leaving Silicon Valley: <a href=\"https://techxplore.com/news/2020-12-oracle-hq-silicon-valley-texas.html\">Tesla, now Oracle</a>. Who’s next? And what will departing companies do to the real estate market? <br /></li><li>Twitter’s proposal for <a href=\"https://www.tbray.org/ongoing/When/202x/2020/12/01/Bluesky-Identity\">Bluesky Identity</a>, portable identity between social media platforms, was greeted with some skepticism when it launched roughly a year ago.&nbsp; Tim Bray’s take on it is worth reading; it’s the “simplest thing that could possibly work” to enable cross-provider conversations.<br /></li><li>Facebook’s cryptocurrency, <a href=\"https://arstechnica.com/tech-policy/2020/11/facebooks-libra-currency-to-launch-next-year-in-limited-format/\">Libra</a>, is finally due to launch, possibly this month, if anyone cares.&nbsp; And its name has changed to <a href=\"https://www.cnbc.com/2020/12/01/facebook-backed-libra-digital-currency-has-been-renamed-diem.html\">Diem</a>. It’s much less ambitious and still faces regulatory issues, particularly in Europe.</li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-january-2021/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 14 Dec 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 14 Dec 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-14-dec-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-14-dec-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-14-dec-2020/#respond',\n",
       "   'published': 'Tue, 15 Dec 2020 14:52:18 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=15, tm_hour=14, tm_min=52, tm_sec=18, tm_wday=1, tm_yday=350, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13589',\n",
       "   'guidislink': False,\n",
       "   'summary': 'End-to-end Entity Resolution for Big Data — Introduction to the entity resolution pipeline and the algorithms at the different stages. Includes a summary of open source tools and their features. (via Adrian Colyer) 33 Engineering Challenges of Building Mobile Apps at Scale — Part 1, covering the first 10, is up. They are: 1. State [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'End-to-end Entity Resolution for Big Data — Introduction to the entity resolution pipeline and the algorithms at the different stages. Includes a summary of open source tools and their features. (via Adrian Colyer) 33 Engineering Challenges of Building Mobile Apps at Scale — Part 1, covering the first 10, is up. They are: 1. State [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol><li><a href=\"https://dl.acm.org/doi/abs/10.1145/3418896\">End-to-end Entity Resolution for Big Data</a> — <em>Introduction to the entity resolution pipeline and the algorithms at the different stages. Includes a summary of open source tools and their features.</em> (via <a href=\"https://blog.acolyer.org/2020/12/14/entity-resolution/\">Adrian Colyer</a>)</li><li><a href=\"https://blog.pragmaticengineer.com/10-engineering-challenges-due-to-the-nature-of-mobile-applications/\">33 Engineering Challenges of Building Mobile Apps at Scale</a> — <em>Part 1, covering the first 10, is up. They are: </em><i>1. State management; 2. Mistakes are hard to revert; 3. The long tail of old app versions; 4. Deeplinks; 5. Push and background notifications; 6. App crashes; 7. Offline support; 8. Accessibility; 9. CI/CD and the build train; 10. Device &amp; OS fragmentation.</i> </li><li><a href=\"https://elifesciences.org/articles/59410\">Cognitive Effort vs Physical Pain</a> — <i>We found that cognitive effort can be traded off for physical pain and that people generally avoid exerting high levels of cognitive effort.</i> This explains why more people don&#8217;t use (your favourite editor).</li><li><a href=\"https://github.com/ericfischer/if-then-else/blob/master/if-then-else.md\">If-Then-Else Had to be Invented</a> — The history of where &#8220;else&#8221; came from, and it&#8217;s a fascinating archaeological romp through the ages of programming. E.g., <i>Flow-Matic, Grace Murray Hopper&#8217;s predecessor to COBOL, made the three-way if a little easier to think about by talking about comparing two numbers instead of about the signs of numbers. It introduced the name &#8220;otherwise&#8221; for the case where the comparison wasn&#8217;t what you were looking for.</i></li></ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-14-dec-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 8 Dec 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 8 Dec 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-8-dec-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-8-dec-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-8-dec-2020/#respond',\n",
       "   'published': 'Tue, 15 Dec 2020 14:49:14 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=15, tm_hour=14, tm_min=49, tm_sec=14, tm_wday=1, tm_yday=350, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13584',\n",
       "   'guidislink': False,\n",
       "   'summary': 'TextAttack — Framework for generating adversarial examples for NLP models. (Paper) (via The Data Exchange) Measuring Developer Productivity — There is no useful measure that operates at a finer grain than “tasks multiplied by complexity.” Measuring commits, lines of code, or hours spent coding, as some tools do, is no more useful at a team [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'TextAttack — Framework for generating adversarial examples for NLP models. (Paper) (via The Data Exchange) Measuring Developer Productivity — There is no useful measure that operates at a finer grain than “tasks multiplied by complexity.” Measuring commits, lines of code, or hours spent coding, as some tools do, is no more useful at a team [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol><li><a href=\"https://github.com/QData/TextAttack\">TextAttack</a> — <em>Framework for generating adversarial examples for NLP models.</em> (<a href=\"https://arxiv.org/abs/2005.05909\">Paper</a>) (via <a href=\"https://thedataexchange.media/increasing-the-robustness-of-natural-language-applications/\">The Data Exchange</a>)</li><li><a href=\"https://stackoverflow.blog/2020/12/07/measuring-developer-productivity/\">Measuring Developer Productivity</a> — <i>There is no useful measure that operates at a finer grain than “tasks multiplied by complexity.” Measuring commits, lines of code, or hours spent coding, as some tools do, is no more useful at a team scale than it is at an individual scale. There simply is no relation between the number of code artifacts a team produces, or the amount of time they spend on them, and the value of their contributions.</i> When engineering managers gather in the hotel bar after the conference day ends, this is one of the subjects they will debate endlessly.</li><li><a href=\"https://understandlegacycode.com/blog/key-points-of-beyond-legacy-code/\">Legacy Code</a> — <em>All the things I wish I&#8217;d known twenty years ago. The top-level bullet-points: (1) Writing code isn’t the limiting factor; (2) Start with “why”; (3) Reduce the feedback loop; (4) Make people collaborate; (5) Different strategies to approach Legacy Code.</em></li><li><a href=\"https://dancres.github.io/Pages/\">Distributed Systems Reading List</a> — <i>I often argue that the toughest thing about distributed systems is changing the way you think. Here is a collection of material I&#8217;ve found useful for motivating these changes.</i></li></ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-8-dec-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'O’Reilly’s top 20 live online training courses of 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'O’Reilly’s top 20 live online training courses of 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/oreillys-top-20-live-online-training-courses-of-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/oreillys-top-20-live-online-training-courses-of-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/oreillys-top-20-live-online-training-courses-of-2020/#respond',\n",
       "   'published': 'Wed, 09 Dec 2020 14:36:14 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=9, tm_hour=14, tm_min=36, tm_sec=14, tm_wday=2, tm_yday=344, tm_isdst=0),\n",
       "   'authors': [{}],\n",
       "   'author': '',\n",
       "   'tags': [{'term': \"O'Reilly Insights\", 'scheme': None, 'label': None},\n",
       "    {'term': \"O'Reilly Learning\", 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13546',\n",
       "   'guidislink': False,\n",
       "   'summary': '2020 has been a year of great challenges for so many, but it’s not all negative. Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally. With the uptick in virtual conferencing, remote work, and, [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': '2020 has been a year of great challenges for so many, but it’s not all negative. Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally. With the uptick in virtual conferencing, remote work, and, [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>2020 has been a year of great challenges for so many, but it’s not all negative. Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally. With the uptick in virtual conferencing, remote work, and, for some, reentering the job market, new technology adoption was accelerated, driving the workforce to build new skills. While 2020 was the year of the global COVID-19 pandemic, it will also be commemorated as the year online learning prevailed. As vaccine development persists and life gets back to normal, with it will come a more future-proof workforce ready to share their new knowledge with the world.&nbsp;</p>\\n\\n\\n\\n<p>Since the onset of the pandemic, online courses and programs have seen dramatic spikes in consumption and enrollment, and O’Reilly has been no different. A big contributor to O’Reilly’s continued success during these unprecedented times has been its live virtual training courses. This year, more than 900,000 users have registered for live events through O’Reilly online learning—a 96% increase from last year. This functionality also allowed O’Reilly to introduce its <a href=\"https://www.oreilly.com/pub/pr/3299\">Superstream Series</a>, a new lineup of virtual conferences featuring expert speakers delivering talks and training sessions on the most important topics and emerging trends in technology.&nbsp;</p>\\n\\n\\n\\n<p>So what are the trends driving this uptick in learning? Companies are increasingly interested in understanding how to successfully adjust to remote work and effectively manage time. And individual O’Reilly members are looking to build and expand on their technical skills in everything from software architecture and microservices to AI and programming languages. But which topics are the brightest minds in technology most focused on? We’ve compiled the top 20 live online training courses of 2020 to shed some light on what those in the know want to know.</p>\\n\\n\\n\\n<p><strong>Top 20 live online training courses of 2020</strong></p>\\n\\n\\n\\n<ol><li>Software Architecture Superstream Series: Software Architecture Fundamentals</li><li>Microservice Fundamentals</li><li>Kubernetes in Three Weeks</li><li>O&#8217;Reilly Infrastructure &amp; Ops Superstream: SRE Edition</li><li>Fundamentals of Learning: Learn Faster and Better Using Neuroscience</li><li>Strata Data &amp; AI Superstream Series: Deep Learning</li><li>Microservices Architecture and Design</li><li>Machine Learning from Scratch</li><li>Leadership Communication Skills for Managers</li><li>Design Patterns Boot Camp</li><li>Strata Data and AI Superstream</li><li>Getting Started with Python 3</li><li>Python Data Science Full Throttle with Paul Deitel: Introductory Artificial Intelligence (AI), Big Data, and Cloud Case Studies</li><li>Getting Started with Amazon Web Services (AWS)</li><li>Architectural Katas</li><li>Introduction to Critical Thinking</li><li>Python Full Throttle with Paul Deitel</li><li>Microservice Collaboration</li><li>OSCON Open Source Software Superstream Series: Live Coding—Go, Rust, and Python</li><li>SOLID Principles of Object-Oriented and Agile Design</li></ol>\\n\\n\\n\\n<p>For a more in-depth analysis of the hot technology topics of 2020, based on data from O’Reilly online learning, stay tuned for our upcoming report, <em>Wrapping Up 2020 (and What to Expect for 2021): Trends on O’Reilly online learning</em>. </p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/oreillys-top-20-live-online-training-courses-of-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'What is functional programming?',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'What is functional programming?'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/what-is-functional-programming/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/what-is-functional-programming/',\n",
       "   'comments': 'https://www.oreilly.com/radar/what-is-functional-programming/#respond',\n",
       "   'published': 'Tue, 08 Dec 2020 17:19:36 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=8, tm_hour=17, tm_min=19, tm_sec=36, tm_wday=1, tm_yday=343, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Column', 'scheme': None, 'label': None},\n",
       "    {'term': 'Software Engineering', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13562',\n",
       "   'guidislink': False,\n",
       "   'summary': 'It has long seemed to me that functional programming is, essentially, programming viewed as mathematics. Many ideas in functional programming came from Alonzo Church&#8217;s Lambda Calculus, which significantly predates anything that looks remotely like a modern computer. Though the actual history of computing runs differently: in the early days of computing, Von Neumann’s ideas were [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'It has long seemed to me that functional programming is, essentially, programming viewed as mathematics. Many ideas in functional programming came from Alonzo Church&#8217;s Lambda Calculus, which significantly predates anything that looks remotely like a modern computer. Though the actual history of computing runs differently: in the early days of computing, Von Neumann’s ideas were [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>It has long seemed to me that functional programming is, essentially, programming viewed as mathematics. Many ideas in functional programming came from Alonzo Church&#8217;s Lambda Calculus, which significantly predates anything that looks remotely like a modern computer. Though the actual history of computing runs differently: in the early days of computing, Von Neumann’s ideas were more important than Church’s, and had a tremendous influence on the design of early computers—an influence that continues to the present. Von Neumann’s thinking was essentially imperative: a program is a list of commands that run on a machine designed to execute those commands.&nbsp;</p>\\n\\n\\n\\n<p>So, what does it mean to say that functional programming is programming &#8220;viewed as mathematics&#8221;? Von Neumann was a “mathematician,” and programming of all kinds found its first home in Mathematics departments. So, if functional programming is mathematical, what does that mean? What kind of math?</p>\\n\\n\\n\\n<p>I’m not thinking of any specific branch of mathematics. Yes, the Lambda Calculus has significant ties to set theory, logic, category theory, and many other branches of mathematics. But let’s start with grade school mathematics and assignment statements; they&#8217;re basic to any programming language. We&#8217;re all familiar with code like this:</p>\\n\\n\\n\\n<pre class=\"wp-block-preformatted\">&nbsp;&nbsp;i = i+1 # or, more simply\\n&nbsp; i += 1&nbsp; # or, even more simply\\n&nbsp; i++ &nbsp; &nbsp; # C, Java, but not Python or Ruby</pre>\\n\\n\\n\\n<p>Mathematically, this is nonsense. An equation is a statement about a relationship that holds true. <code>i</code> can equal <code>i</code>; it can&#8217;t equal <code>i+1</code>. And while <code>i++</code> and <code>i+=1</code> no longer look like equations, they are equally nonsensical; once you&#8217;ve said that <code>i</code> equals something, you can&#8217;t say it equals something else. &#8220;Variables&#8221; don&#8217;t change values; they&#8217;re immutable.</p>\\n\\n\\n\\n<p>Immutability is one of the most important principles of functional programming. Once you&#8217;ve defined a variable, you can&#8217;t change it. (You can create a new one in a different function scope, but that&#8217;s a different matter.) Variables, in functional programming, are invariant; and that&#8217;s important. You may be wondering &#8220;what about loops? How can I write a <code>for</code> loop?&#8221; Not only do you have to do without index variables, you can’t modify any of the variables in the loop body.&nbsp;</p>\\n\\n\\n\\n<p>Setting aside the (solvable) problem of iteration, there’s no reason you can&#8217;t write code in (almost) any non-functional language that has this same effect. Just declare all your variables <code>final</code> or <code>const</code>. In the long run, functional programming is more about a specific kind of discipline than about language features. Programming languages can enforce certain rules, but in just about any modern language it&#8217;s possible to follow those rules without language support.</p>\\n\\n\\n\\n<p>Another important principle of functional programming is that functions are &#8220;first class entities.&#8221; That is, there are minimal restrictions about where you can use a function. You can also have functions without names, often called &#8220;lambdas” (which refers directly to the Lambda Calculus, in which functions were unnamed).&nbsp; In Python, you can write code like this:</p>\\n\\n\\n\\n<pre class=\"wp-block-preformatted\">&nbsp;&nbsp;data.sort(key=lambda r: r[COLUMN])</pre>\\n\\n\\n\\n<p>The &#8220;key&#8221; is an anonymous function that returns a specific column of an array; that function is then used for sorting. Personally, I&#8217;m not overly fond of &#8220;anonymous functions&#8221;; it&#8217;s often clearer to write the anonymous function as a regular, named function. So I might write this:</p>\\n\\n\\n\\n<pre class=\"wp-block-preformatted\">&nbsp;&nbsp;def sortbycolumn(r): return r[COLUMN]\\n&nbsp; data.sort(k=sortbycolumn)</pre>\\n\\n\\n\\n<p>The ability to use functions as arguments to functions gives you a very nice way to implement the &#8220;strategy pattern&#8221;:</p>\\n\\n\\n\\n<pre class=\"wp-block-preformatted\">&nbsp;&nbsp;def squareit(x): &nbsp; return x*x\\n&nbsp; def cubeit(x): &nbsp; &nbsp; return x*x*x\\n  def rootit(x): &nbsp; &nbsp; import math; return math.sqrt(x)\\n&nbsp; def do_something(strategy, x) ...\\n\\n  do_something(cubeit, 42)\\n  weird = lambda x : cubeit(rootit(x))\\n  do_something(weird, 42)</pre>\\n\\n\\n\\n<p>I often get the sense that all programmers really<em> </em>want from functional programming is first-class functions and lambdas. Lambdas were added to Python very early on (1.0) but didn&#8217;t reach Java until Java 8.&nbsp;</p>\\n\\n\\n\\n<p>Another consequence of thinking mathematically (and possibly a more important one) is that functions can&#8217;t have side-effects and, given the same arguments, will always return the same value. If a mathematician (or a high school trig student) writes</p>\\n\\n\\n\\n<pre class=\"wp-block-preformatted\">&nbsp;&nbsp;y = sin(x)</pre>\\n\\n\\n\\n<p>they don&#8217;t have to deal with the possibility that <code>sin(x)</code> sets some global variable to 42, or will return a different value every time it’s called. That just can&#8217;t happen; in math, the idea of a &#8220;side-effect&#8221; is meaningless. All the information that <code>sin(x)</code> provides is encapsulated in the return value. In most programming languages, side-effects happen all too easily, and in some, they&#8217;re almost an obsession. Again, creating functions that have no side-effects is a matter of exercising discipline. A programming language can enforce this rule, but you can follow it whether or not your language makes you do it. We don’t have cartoon devils looking over our shoulders saying &#8220;Go ahead; make a side effect. No one will notice.&#8221;</p>\\n\\n\\n\\n<p>Functional languages vary the degree to which they enforce the lack of side-effects. If you&#8217;re a purist, anything that interacts with the real world is a side-effect. Printing a document? Changing a row in a database? Displaying a value on the user&#8217;s screen? Those are all side-effects (they aren&#8217;t completely encapsulated in the value returned by the function), and they have to be &#8220;hidden&#8221; using a mechanism like monads in Haskell. And that&#8217;s the point at which many programmers get confused and throw up their hands in despair. (I&#8217;ll only point you to <a href=\"https://learning.oreilly.com/library/view/real-world-haskell/9780596155339/\">Real World Haskell</a>.) In both Java and Python, lambda functions can have side-effects, which means that, strictly speaking, they aren’t really “functional.” Guido van Rossum&#8217;s discussion of the addition of Lambdas to Python is worth reading; among other things, he\\xa0<a href=\"http://python-history.blogspot.com/2009/04/origins-of-pythons-functional-features.html\" rel=\"noreferrer noopener\" target=\"_blank\">says</a>\\xa0&#8220;I have never considered Python to be heavily influenced by functional languages, no matter what people say or think.&#8221;</p>\\n\\n\\n\\n<p>Streams are often associated with functional languages; they’re essentially long (perhaps infinite) lists that are evaluated lazily—meaning that elements of the string are only evaluated as they&#8217;re needed. Maps apply a function to every element of a list, returning a new list—and that includes streams, which (for these purposes) are specialized lists. That&#8217;s an incredibly useful feature; it&#8217;s a great way to write a loop without having to write a loop—and without even knowing how much data you have. You can also create “filters” that choose whether to pass any element of the stream to the output, and you can chain maps and filters together. If you think this sounds like a Unix pipeline, you’re right. Streams, maps, filters, and the act of chaining them together really have as much to do with the Unix shell as they do with functional languages.</p>\\n\\n\\n\\n<p>Another way to avoid writing loops is to use &#8220;comprehensions,&#8221; a feature of Python. It&#8217;s easy to get very fond of list comprehensions; they&#8217;re compact, they eliminate off-by-one errors, and they&#8217;re very flexible. Although comprehensions look like a compact notation for a traditional loop, they really come from set theory—and their closest computational “relatives” are to be found in relational databases, rather than functional programming. Here’s a comprehension that applies a function to every element of a list:</p>\\n\\n\\n\\n<pre class=\"wp-block-preformatted\">&nbsp;&nbsp;# pythonic examples.&nbsp; First, list comprehension \\n&nbsp; newlist = [ somefunction(thing) for thing in things ] </pre>\\n\\n\\n\\n<p>The most general way to avoid traditional loops is to use recursion: a function that calls itself. Here’s the recursive equivalent to the previous comprehension:</p>\\n\\n\\n\\n<pre class=\"wp-block-preformatted\">def iterate(t, l) :\\n    if len(t) == 0 : return l     # stop when all elements are done\\n    return iterate(t[1:],l + [somefunction(t[0])]) # process remainder</pre>\\n\\n\\n\\n<p>Recursion is a mainstay of functional languages: you don’t have indices being modified, and you’re not even modifying the resulting list (assuming that append doesn’t count as modification).&nbsp;</p>\\n\\n\\n\\n<p>However, recursion has its own problems. It&#8217;s hard to wrap your mind around recursion; you still need to do a lot of your own bookkeeping (in this case, passing in a vector so a result can be returned); and except in one (common) special case, called &#8220;tail recursion,&#8221; it can be a performance nightmare.</p>\\n\\n\\n\\n<p>I started by saying that functional programming was programming considered as “math,” and that’s at least partially correct. But is that claim useful? There are many branches of mathematics that map onto programming concepts in different ways. Functional programming only represents one of them. If you’re a topologist, you may well like graph databases. But discussing which branch of mathematics corresponds to which programming practices isn’t really helpful. Remembering high school algebra may help when thinking about immutability, statelessness, and the absence of side-effects; but most programmers will never study the real mathematical origins of functional programing. Lambdas are great; functions as arguments in method calls is great; even recursion is (sometimes) great; but we’re fooling ourselves if we think programmers are going to start using Java as if it were Haskell. But that’s OK; for Java programmers, the value of Lambdas isn’t some mathematical notion of “functional,” but in providing a huge improvement over anonymous inner classes. The tools to be functional are there, should you choose to use them.</p>\\n\\n\\n\\n<p>In college, I learned that engineering was about making tradeoffs. Since then, I’ve heard very few programmers talk about tradeoffs—but those tradeoffs are still central to good engineering. And while engineering uses a lot of mathematics, engineering isn’t mathematics, in part because mathematics doesn’t deal in tradeoffs. Using “mathematics” as a way to think about a particular style of disciplined coding maybe be useful, particularly if that discipline leads to fewer bugs. It’s also useful to use the tools of mathematics to make good tradeoffs between rigor, performance, and practicality—which may lead you in an entirely different direction. Be as functional as you need to (but no more).&nbsp;<br /></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/what-is-functional-programming/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 4 Dec 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 4 Dec 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-4-dec-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-4-dec-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-4-dec-2020/#respond',\n",
       "   'published': 'Fri, 04 Dec 2020 20:56:00 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=4, tm_hour=20, tm_min=56, tm_sec=0, tm_wday=4, tm_yday=339, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13536',\n",
       "   'guidislink': False,\n",
       "   'summary': 'NAND Game &#8212; You start with a single component, the nand gate. Using this as the fundamental building block, you will build all other components necessary. (See also NAND to Tetris) Facebook&#8217;s Game AI &#8212; today we are unveiling Recursive Belief-based Learning (ReBeL), a general RL+Search algorithm that can work in all two-player zero-sum games, [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'NAND Game &#8212; You start with a single component, the nand gate. Using this as the fundamental building block, you will build all other components necessary. (See also NAND to Tetris) Facebook&#8217;s Game AI &#8212; today we are unveiling Recursive Belief-based Learning (ReBeL), a general RL+Search algorithm that can work in all two-player zero-sum games, [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol><li><a href=\"http://nandgame.com/\">NAND Game</a> &#8212; <i>You start with a single component, the nand gate. Using this as the fundamental building block, you will build all other components necessary.</i> (See also <a href=\"https://www.nand2tetris.org/\">NAND to Tetris</a>)</li><li><a href=\"https://ai.facebook.com/blog/rebel-a-general-game-playing-ai-bot-that-excels-at-poker-and-more/\">Facebook&#8217;s Game AI</a> &#8212; <i>today we are unveiling Recursive Belief-based Learning (ReBeL), a general RL+Search algorithm that can work in all two-player zero-sum games, including imperfect-information games. ReBeL builds on the RL+Search algorithms like AlphaZero that have proved successful in perfect-information games. Unlike those previous AIs, however, ReBeL makes decisions by factoring in the probability distribution of different beliefs each player might have about the current state of the game, which we call a public belief state (PBS). In other words, ReBeL can assess the chances that its poker opponent thinks it has, for example, a pair of aces.</i></li><li><a href=\"https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf\">In-Database Machine Learning</a> &#8212; <i>We demonstrate our claim by implementing tensor algebra and stochastic gradient descent using lambda expressions for loss functions as a pipelined operator in a main memory database system. Our approach enables common machine learning tasks to be performed faster than by extended disk-based database systems or as well as dedicated tools by eliminating the time needed for data extraction. This work aims to incorporate gradient descent and tensor data types into database systems, allowing them to handle a wider range of computational tasks.</i></li><li><a href=\"https://slack.engineering/scaling-datastores-at-slack-with-vitess/\">Scaling Datastores at Slack with Vitess</a> &#8212; <a href=\"https://vitess.io/\">Vitess</a> is YouTube&#8217;s MySQL horizontal-scaling solution. This article is a really good write-up of what they were doing, why it didn&#8217;t work, how they tested the waters with Vitess, and how it&#8217;s working for them so far.</li></ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-4-dec-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 1 Dec 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 1 Dec 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-1-dec-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-1-dec-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-1-dec-2020/#respond',\n",
       "   'published': 'Tue, 01 Dec 2020 20:54:00 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=1, tm_hour=20, tm_min=54, tm_sec=0, tm_wday=1, tm_yday=336, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13533',\n",
       "   'guidislink': False,\n",
       "   'summary': 'AlphaFold &#8212; This is astonishing: protein-folding solved by Google&#8217;s DeepMind. Figuring out what shapes proteins fold into is known as the “protein folding problem”, and has stood as a grand challenge in biology for the past 50 years. In a major scientific advance, the latest version of our AI system AlphaFold has been recognised as [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'AlphaFold &#8212; This is astonishing: protein-folding solved by Google&#8217;s DeepMind. Figuring out what shapes proteins fold into is known as the “protein folding problem”, and has stood as a grand challenge in biology for the past 50 years. In a major scientific advance, the latest version of our AI system AlphaFold has been recognised as [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol><li><a href=\"https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology\">AlphaFold</a> &#8212; This is astonishing: protein-folding solved by Google&#8217;s DeepMind. <i>Figuring out what shapes proteins fold into is known as the “protein folding problem”, and has stood as a grand challenge in biology for the past 50 years. In a major scientific advance, the latest version of our AI system AlphaFold has been recognised as a solution to this grand challenge by the organisers of the biennial Critical Assessment of protein Structure Prediction (CASP).</i> And from <a href=\"https://www.sciencemag.org/news/2020/11/game-has-changed-ai-triumphs-solving-protein-structures\">Science</a>: <i>The organizers even worried DeepMind may have been cheating somehow. So Lupas set a special challenge: a membrane protein from a species of archaea, an ancient group of microbes. For 10 years, his research team tried every trick in the book to get an x-ray crystal structure of the protein. &#8220;We couldn’t solve it.&#8221; But AlphaFold had no trouble. It returned a detailed image of a three-part protein with two long helical arms in the middle. The model enabled Lupas and his colleagues to make sense of their x-ray data; within half an hour, they had fit their experimental results to AlphaFold’s predicted structure. &#8220;It’s almost perfect,&#8221; Lupas says. &#8220;They could not possibly have cheated on this. I don’t know how they do it.&#8221; Far more useful (and to me, more impressive) than AlphaGo.</i></li><li><i><a href=\"https://computinged.wordpress.com/2020/11/30/purpose-first-programming-a-programming-learning-approach-for-learners-who-care-most-about-what-code-achieves-katie-cunninghams-defense/\">Purpose-First Programming</a> &#8212; Some students resist the cognitively-heavy tasks of simulating program execution. The secret to teaching those folks to program may be &#8220;purpose-first programming&#8221;: <i>She used Github repositories and expert interviews to identify a few programming plans (just like Elliot Soloway and Jim Spohrer studied years ago) that were in common use in a domain that her participants cared about. She then taught those plans. Students modified and combined the plans to create programs that the students found useful. Rather than start with syntax or semantics, she started with the program’s purpose.</i> Very reminiscent of the late 90s Perl and PHP copy-and-change coding boom that got orders of magnitude more people programming than were coming through CS courses at the time.</i></li><li><a href=\"https://ftrain.medium.com/web-conversations-with-the-year-2000-f0c40fb8b19c\">Conversations with The Year 2000</a>&nbsp;— Paul Ford is a genius.<br /><em>’00: How does HTML work now?<br />’20: It’s pretty simple, you define app logic as unidirectional dataflow, then fake up pseudo-HTML components that mirror state, and a controller mounts fake-page deltas onto the browser surface.<br />’00: How do you change the title?<br />’20: You can’t.</em></li><li><a href=\"https://github.com/pallada-92/dna-3d-engine\">cube3d.dna</a>&nbsp;— A raytracer implemented in DNA.&nbsp;<em>How to deploy: (1) Synthesize the oligonucleotides from the cube3d.dna file. (2) Arrange the test tubes as shown in the diagram below. (3) Don’t forget to provide the initial concentrations according to the table below. (4) Use a pipette to encode the position (row and column) of each tube to start the computation.</em></li></ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-1-dec-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: December 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: December 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-december-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-december-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-december-2020/#respond',\n",
       "   'published': 'Tue, 01 Dec 2020 17:33:00 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=1, tm_hour=17, tm_min=33, tm_sec=0, tm_wday=1, tm_yday=336, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13427',\n",
       "   'guidislink': False,\n",
       "   'summary': 'This month’s collection of interesting articles that point to important trends is dominated by AI. That’s not surprising; AI has probably been the biggest single category all year. But its dominance over other topics seems to be increasing. That’s partly because there’s more research into why AI fails; partly because we’re beginning to see AI [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'This month’s collection of interesting articles that point to important trends is dominated by AI. That’s not surprising; AI has probably been the biggest single category all year. But its dominance over other topics seems to be increasing. That’s partly because there’s more research into why AI fails; partly because we’re beginning to see AI [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>This month’s collection of interesting articles that point to important trends is dominated by AI. That’s not surprising; AI has probably been the biggest single category all year. But its dominance over other topics seems to be increasing. That’s partly because there’s more research into why AI fails; partly because we’re beginning to see AI in embedded systems, ranging from giant gas and oil wells to the tiny devices that Pete Warden is working with.</p>\\n\\n\\n\\n<h2>Artificial Intelligence</h2>\\n\\n\\n\\n<ul><li><a href=\"https://arxiv.org/pdf/2010.00685.pdf\">Teaching AI to manipulate and persuade</a>: Combine NLP with reinforcement learning, and train in a multiplayer role-playing game. This is where AI gets scary, particularly since AI systems don’t understand what they’re doing (see the next item).</li><li>GPT-3 is great at producing human-like language, but that’s as far as it goes; it has no sense of what an appropriate response to any prompt might be. For example, suggesting <a href=\"https://www.nabla.com/blog/gpt-3/\">suicide as a solution to depression</a>. This isn’t a surprise, but it means that GPT-3 really can’t be incorporated into applications.</li><li><a href=\"https://www.technologyreview.com/2020/11/18/1012234/training-machine-learning-broken-real-world-heath-nlp-computer-vision/\">Why machine learning models fail</a><a href=\"https://arxiv.org/pdf/2011.03395.pdf\"> in the real world</a>, and why it’s a very difficult problem to fix: Any set of training data can lead to a huge number of models with similar behavior on the training data, but with very different performance on real-world data. Deciding which of these models is “best” (and in which situations) is a difficult, and unstudied, problem.</li><li><a href=\"https://techxplore.com/news/2020-11-deep-internet-devices.html\">Tiny NAS</a>: Neural Architecture Search designed to automate building Tiny Neural Networks.&nbsp;Machine Learning on small devices will be an increasingly important topic in the coming years.</li><li>Pete Warden on the <a href=\"https://petewarden.com/2020/11/14/why-do-i-think-there-will-be-hundreds-of-billions-of-tinyml-devices-within-a-few-years/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+typepad%2Fpetewarden+%28PeteSearch%29\">future of TinyML</a>: There will be hundreds of billions of devices in the next few years. Many of them won’t be “smart”; they’ll be more intelligent versions of dumb devices. We don’t need “smart refrigerators” that can order milk automatically, but we do need refrigerators that can use energy more efficiently and notify us when they’re about to fail.</li><li>The <a href=\"https://www.technologyreview.com/2020/11/12/1011944/artificial-intelligence-replication-crisis-science-big-tech-google-deepmind-facebook-openai/\">replication crisis in AI</a>: Too many academic AI papers are published without code or data, and using hardware that can’t be obtained by other researchers. Without access to code, data, and hardware, academic papers about groundbreaking results are little more than corporate marketing.</li><li><a href=\"https://www.sciencedaily.com/releases/2020/10/201029105038.htm\">Machine learning to detect gas leaks</a>: Granted, this is for oil-well scale natural gas leaks, but we should all be more aware of these invisible applications of machine learning. It’s not just autonomous vehicles and face recognition.&nbsp;And lest we forget, <a href=\"https://www.internetandtechnologylaw.com/algorithm-bias-ai/\">invisible applications of ML</a> also have problems with bias, fairness, and accountability.</li><li><a href=\"https://www.technologyreview.com/2020/11/06/1011726/ai-natural-language-processing-computer-vision/\">Vokens</a>: What happens when you combine computer vision with natural language processing? Is it possible to isolate the meaningful elements in a picture, then use that to inform language models like GPT-3 to add an element of “common sense”?</li><li>Using <a href=\"https://ieeexplore.ieee.org/document/9208795\">AI to diagnose COVID-19 via coughs</a>: MIT has developed an AI algorithm that detects features in a cough that indicate a COVID-19 infection. It is <a href=\"https://www.bbc.com/news/technology-54780460\">at least as accurate as current tests</a>, particularly for asymptomatic people, provides results in real time, and could easily be built into a cell phone app.</li><li>Over time, <a href=\"https://techxplore.com/news/2020-11-algorithms.html\">models in</a><a href=\"https://arxiv.org/abs/2009.06797\"> feedback loops</a> (e.g., economic competition) tend to become more accurate for a narrower slice of the population, and less accurate for the population as a whole. Essentially, a model that is constantly retraining on current input will, over time, make itself unfair. </li></ul>\\n\\n\\n\\n<h2>Robotics</h2>\\n\\n\\n\\n<ul><li><a href=\"https://arstechnica.com/information-technology/2020/11/robots-invade-the-construction-site/\">Robots in construction</a>: The construction industry has been resistant to automation.&nbsp;Canvas has built a robot that installs drywall. This robot is in use on several major sites, including the renovation of the Harvey Milk terminal at San Francisco Airport.</li><li>Simplifying the robot’s model of the external world is the route to <a href=\"https://www.technologyreview.com/2020/11/13/1012103/smarter-ai-robot-collaborators-may-be-simpler/\">better collaborations between robots and humans</a>.</li><li>Honda wins approval to sell a <a href=\"https://techxplore.com/news/2020-11-honda-world-first-autonomous-car.html\">level-3</a> autonomous vehicle. The vehicle is capable of completely taking over driving in certain situations, not just assisting. It should be on sale before March.</li></ul>\\n\\n\\n\\n<h2>Programming</h2>\\n\\n\\n\\n<ul><li><a href=\"https://github.blog/2020-11-20-nbdev-a-literate-programming-environment-that-democratizes-software-engineering-best-practices/\">Nbdev</a> is a literate programming environment for Python. It is based on Jupyter, but encompasses the entire software lifecycle and CI/CD pipeline, not just programming.</li><li>A <a href=\"https://graphqleditor.com/\">visual programming environment for GraphQL</a> is another step in getting beyond text-based programming.&nbsp;A visual environment seems like an obvious choice for working with graph data.</li><li><a href=\"https://www.php.net/releases/8.0/en.php\">PHP 8 is out</a>!&nbsp; PHP is an old language, and this release isn’t likely to put it onto the “trendy language” list.&nbsp; But with a huge portion of the Web built with PHP, this new release is important and definitely worth watching.</li></ul>\\n\\n\\n\\n<h2>Privacy and Security</h2>\\n\\n\\n\\n<ul><li><a href=\"https://arstechnica.com/gadgets/2020/11/google-is-testing-end-to-end-encryption-in-android-messages/\">Google is adding end-to-end encryption</a> to their implementation of RCS, which is a standard designed to replace SMS messaging. RCS hasn’t been adopted widely (and, given the dominance of the telephone system, may never be adopted widely), but standards for encrypted messaging are an important step forward.</li><li>Tim Berners-Lee’s privacy project, <a href=\"https://9to5mac.com/2020/11/09/solid/\">Solid</a>, has released its first project: an organizational privacy server.&nbsp;The idea behind Solid is that people (and organizations) store their own data in secure repositories called Pods that they control.&nbsp;<a href=\"https://www.schneier.com/blog/archives/2020/11/inrupts-solid-announcement.html\">Bruce Schneier has joined Inrupt</a>, the company commercializing Solid.</li><li>CMU <a href=\"https://www.cylab.cmu.edu/news/2020/10/20-passwordpolicy.html\">has shown that</a> passwords with minimum length of 12 characters and that pass some simple tests can be remembered and resist attack. We can move on from password policies that require obscure combinations of upper and lowercase, punctuation and numerals, and that don’t require changing passwords regularly.</li></ul>\\n\\n\\n\\n<h2>Infrastructure</h2>\\n\\n\\n\\n<ul><li>Remember <a href=\"https://techxplore.com/news/2020-11-dns-cache-poisoning-ready-comeback.html\">DNS cache poisoning</a>?\\xa0It’s back.\\xa0Unfortunately. </li><li>A <a href=\"https://www.technologyreview.com/2020/10/21/1009454/new-york-mesh-wifi-pandemic/\">public mesh WiFi</a> network for New York City: Mesh networks can provide Internet access in locations where established providers don’t care to go–but making them work at scale is difficult.\\xa0Technology we first heard about in Cory Doctorow’s very strange <a href=\"https://craphound.com/category/someone/\">Someone Comes To Town, Someone Leaves Town</a>.</li><li><a href=\"https://blog.acolyer.org/2020/10/26/helios-part-1/\">Hyper-scale indexing</a>: Helios is Microsoft’s reference architecture for the next generation of cloud systems. It is capable of handling extremely large data sets (even by modern standards) and combines centralized cloud computing with edge computing.</li></ul>\\n\\n\\n\\n<h2>Hardware</h2>\\n\\n\\n\\n<ul><li>The <a href=\"https://www.raspberrypi.org/products/raspberry-pi-400/?resellerType=home\">Raspberry Pi 400</a> looks like a LOT of fun.&nbsp;It’s Raspberry Pi 4 built into a keyboard (like the very early Personal Computers); 1.8 GHz ARM processor, 4 GB RAM, more I/O ports than a MacBook Pro; just needs a monitor. I just hope the keyboard is good.</li><li>I should say something positive about Apple’s M1, but I won’t.&nbsp;I’m disenchanted enough with them as a company that I really don’t care how good the processor is.</li></ul>\\n\\n\\n\\n<h2>Covid</h2>\\n\\n\\n\\n<ul><li>Amazon reviews about <a href=\"https://twitter.com/TerriDrawsStuff/status/1331362372179554304\">scented candles </a>that don’t smell correlate to Covid. A nice application of data analysis using publicly available sources. Data science wins. </li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-december-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 27 Nov 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 27 Nov 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-27-nov-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-27-nov-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-27-nov-2020/#respond',\n",
       "   'published': 'Fri, 27 Nov 2020 20:51:00 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=27, tm_hour=20, tm_min=51, tm_sec=0, tm_wday=4, tm_yday=332, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13525',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Brian Kernighan Interviews Ken Thompson &#8212; From a fun interview: McIlroy keeps coming up. He&#8217;s the smartest of all of us and the least remembered (or written down)&#8230; McIlroy sat there and wrote &#8212;on a piece of paper, now, not on a computer&#8212; TMG [a proprietary yacc-like program] written in TMG&#8230; And then! He now [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Brian Kernighan Interviews Ken Thompson &#8212; From a fun interview: McIlroy keeps coming up. He&#8217;s the smartest of all of us and the least remembered (or written down)&#8230; McIlroy sat there and wrote &#8212;on a piece of paper, now, not on a computer&#8212; TMG [a proprietary yacc-like program] written in TMG&#8230; And then! He now [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p><ol>\\n<li><a href=\"https://www.youtube.com/watch?v=EY6q5dv_B-o&amp;feature=youtu.be&amp;t=2314\">Brian Kernighan Interviews Ken Thompson</a> &#8212; From a fun interview: <i>McIlroy keeps coming up. He&#8217;s the smartest of all of us and the least remembered (or written down)&#8230; McIlroy sat there and wrote &#8212;on a piece of paper, now, not on a computer&#8212; TMG [a proprietary yacc-like program] written in TMG&#8230; And then! He now has TMG written in TMG, he decided to give his piece of paper to his piece of paper and write down what came out (the code). Which he did. And then he came over to my editor and he typed in his code, assembled it, and (I won&#8217;t say without error, but with so few errors you&#8217;d be astonished) he came up with a TMG compiler, on the PDP-7, written in TMG. And it&#8217;s the most basic, bare, impressive self-compilation I&#8217;ve ever seen in my life.</i> (via <a href=\"https://news.ycombinator.com/item?id=25182238\">Hacker News</a>)</li>\\n<li><a href=\"https://discourse.ros.org/t/ros-world-talks-are-posted/17436\">ROS World 2020 Videos</a> &#8212; <i>all of the ROS World videos, including all the lightning talks</i>. ROS = Robot Operating System.</li>\\n<li><a href=\"http://ai.stanford.edu/blog/learning-from-language/\">Learning from Language</a> &#8212; <i>we propose a simple approach called Language Shaped Learning (LSL): if we have access to explanations at training time, we encourage the model to learn representations that are not only helpful for classification, but are predictive of the language explanations.</i> (<a href=\"https://arxiv.org/abs/1911.02683\">Paper</a>)</li>\\n<li><a href=\"https://www.easytheory.org/\">Easy Theory</a> &#8212; YouTube lectures on computer science theory. <i>Mondays: Algorithms; Wednesdays: Theory of Computation; Fridays: Theory of Computation; Sundays: Livestream/bonus</i>. </li>\\n</ol></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-27-nov-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 24 Nov 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 24 Nov 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-24-nov-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-24-nov-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-24-nov-2020/#respond',\n",
       "   'published': 'Tue, 24 Nov 2020 12:44:17 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=24, tm_hour=12, tm_min=44, tm_sec=17, tm_wday=1, tm_yday=329, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13424',\n",
       "   'guidislink': False,\n",
       "   'summary': 'OpenStreetMap is Having a Moment &#8212; Apple was responsible for more edits in 2019 than Mapbox accounted for in its entire corporate history. See also the 2020: Curious Cases of Corporations in OpenStreetMap talk from State of the Map. (via Simon Willison) Drone Warfare &#8212; The second point, &#8220;SkyNet&#8221;, is the interesting bit. Azerbaijan and [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'OpenStreetMap is Having a Moment &#8212; Apple was responsible for more edits in 2019 than Mapbox accounted for in its entire corporate history. See also the 2020: Curious Cases of Corporations in OpenStreetMap talk from State of the Map. (via Simon Willison) Drone Warfare &#8212; The second point, &#8220;SkyNet&#8221;, is the interesting bit. Azerbaijan and [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol>\\n<li><a href=\"https://joemorrison.medium.com/openstreetmap-is-having-a-moment-dcc7eef1bb01\">OpenStreetMap is Having a Moment</a> &#8212; <i>Apple was responsible for more edits in 2019 than Mapbox accounted for in its entire corporate history. See also the <a href=\"https://www.youtube.com/watch?v=BI0VrPyAtcQ\">2020: Curious Cases of Corporations in OpenStreetMap</a> talk from State of the Map. (via <a href=\"https://simonwillison.net/2020/Nov/20/joe-morrison/\">Simon Willison</a>)</i></li>\\n<p><i></i></p>\\n<p><i></p>\\n<li><a href=\"https://thetriad.thebulwark.com/p/why-wont-republicans-take-the-next?token=eyJ1c2VyX2lkIjo0MDU1OTAxLCJwb3N0X2lkIjoxOTU5NTE3NywiXyI6IkhqQVpRIiwiaWF0IjoxNjA2MTc0NDQ3LCJleHAiOjE2MDYxNzgwNDcsImlzcyI6InB1Yi04NzI3NCIsInN1YiI6InBvc3QtcmVhY3Rpb24ifQ.qjeFm1Vh_VHi8fB5xAZhJBqcT5nJqtHYRdeTZ8qHGXQ\">Drone Warfare</a> &#8212; The second point, &#8220;SkyNet&#8221;, is the interesting bit. Azerbaijan and Armenia fought a war and drones enabled some very asymmetric outcomes. Quoting a Washington Post story, <i>Azerbaijan, frustrated at a peace process that it felt delivered nothing, used its Caspian Sea oil wealth to buy arms, including a fleet of Turkish Bayraktar TB2 drones and Israeli kamikaze drones (also called loitering munitions, designed to hover in an area before diving on a target). [&#8230;] Azerbaijan used surveillance drones to spot targets and sent armed drones or kamikaze drones to destroy them, analysts said. [&#8230;] Their tally, which logs confirmed losses with photographs or videos, listed Armenian losses at 185 T-72 tanks; 90 armored fighting vehicles; 182 artillery pieces; 73 multiple rocket launchers; 26 surface-to-air missile systems, including a Tor system and five S-300s; 14 radars or jammers; one SU-25 war plane; four drones and 451 military vehicles.</i> (via <a href=\"https://cheeseburgergothic.substack.com/p/the-rise-of-the-machines/comments\">John Birmingham</a>)</li>\\n<li><a href=\"https://github.com/pdclab/peregrine\">Peregrine</a> &#8212; <i>an efficient, single-machine system for performing data mining tasks on large graphs. Some graph mining applications include: Finding frequent subgraphs; Generating the motif/graphlet distribution; Finding all occurrences of a subgraph. Peregrine is highly programmable, so you can easily develop your own graph mining applications using its novel, declarative, graph-pattern-centric API. To write a Peregrine program, you describe which graph patterns you are interested in mining, and what to do with each occurrence of those patterns. You provide the what and the runtime handles the how.</i></li>\\n<li><a href=\"https://twitter.com/tamaybes/status/1330510091586588675\">Declining Marginal Returns of Researchers</a> &#8212; (Tamay Besiroglu) <i>I found that the marginal returns of researchers are rapidly declining. There is what’s called a “standing on toes” effect: researcher productivity declines as the field grows. Because ML has recently grown very quickly, this makes better ML models much harder to find.</i> (<a href=\"https://static1.squarespace.com/static/5fb98ea9a787c521ab066091/t/5fba5c3ddb275d51d91825eb/1606048834827/AreModels.pdf\">Dissertation</a>)</li>\\n<p></i><i></i></ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-24-nov-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 20 Nov 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 20 Nov 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-20-nov-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-20-nov-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-20-nov-2020/#respond',\n",
       "   'published': 'Fri, 20 Nov 2020 12:25:49 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=20, tm_hour=12, tm_min=25, tm_sec=49, tm_wday=4, tm_yday=325, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13421',\n",
       "   'guidislink': False,\n",
       "   'summary': 'epr &#8212; Terminal/CLI Epub reader. I Should Have Loved Biology &#8212; Conveys well the magic of the field. Notable also for the reference to A Computer Scientist&#8217;s Guide to Cell Biology, which I didn&#8217;t realise existed. Ur-Technical Debt &#8212; Reviving Ward Cunningham&#8217;s take on technical debt. Simply put, ur-technical debt arises when my ideas diverge [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'epr &#8212; Terminal/CLI Epub reader. I Should Have Loved Biology &#8212; Conveys well the magic of the field. Notable also for the reference to A Computer Scientist&#8217;s Guide to Cell Biology, which I didn&#8217;t realise existed. Ur-Technical Debt &#8212; Reviving Ward Cunningham&#8217;s take on technical debt. Simply put, ur-technical debt arises when my ideas diverge [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol>\\n<li><a href=\"https://github.com/wustho/epr\">epr</a> &#8212; <i>Terminal/CLI Epub reader</i>.</li>\\n<li><a href=\"https://jsomers.net/i-should-have-loved-biology/\">I Should Have Loved Biology</a> &#8212; Conveys well the magic of the field. Notable also for the reference to <a href=\"https://www.springer.com/gp/book/9780387482750\">A Computer Scientist&#8217;s Guide to Cell Biology</a>, which I didn&#8217;t realise existed.</li>\\n<li><a href=\"https://ieeexplore.ieee.org/document/9121630\">Ur-Technical Debt</a> &#8212; Reviving Ward Cunningham&#8217;s take on technical debt. <i>Simply put, ur-technical debt arises when my ideas diverge from my code. That divergence is inevitable with an iterative process. [&#8230;] &#8220;[I]f you develop a program for a long period of time by only adding features and never reorganizing it to reflect your understanding of those features, then eventually that program simply does not contain any understanding and all efforts to work on it take longer and longer.&#8221;</i></li>\\n<li><a href=\"https://github.com/directus/directus\">Directus</a> &#8212; <i>a real-time [REST and GraphQL] API and App dashboard for managing SQL database content.</i></li>\\n</ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-20-nov-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'On Exactitude in Technical Debt',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'On Exactitude in Technical Debt'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/on-exactitude-in-technical-debt/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/on-exactitude-in-technical-debt/',\n",
       "   'comments': 'https://www.oreilly.com/radar/on-exactitude-in-technical-debt/#respond',\n",
       "   'published': 'Tue, 17 Nov 2020 12:23:15 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=17, tm_hour=12, tm_min=23, tm_sec=15, tm_wday=1, tm_yday=322, tm_isdst=0),\n",
       "   'authors': [{'name': 'Kevlin Henney'}],\n",
       "   'author': 'Kevlin Henney',\n",
       "   'author_detail': {'name': 'Kevlin Henney'},\n",
       "   'tags': [{'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13412',\n",
       "   'guidislink': False,\n",
       "   'summary': 'If software is such stuff as dreams are made on, how do we talk about nightmares? Software is not the tangible, kickable stuff our senses are tuned to, so we draw on metaphor to communicate and reason about it. The 1970s offered up spaghetti code to describe the tangle of unstructured control flow. This has [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'If software is such stuff as dreams are made on, how do we talk about nightmares? Software is not the tangible, kickable stuff our senses are tuned to, so we draw on metaphor to communicate and reason about it. The 1970s offered up spaghetti code to describe the tangle of unstructured control flow. This has [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>If software is such stuff as dreams are made on, how do we talk about nightmares? Software is not the tangible, kickable stuff our senses are tuned to, so we draw on metaphor to communicate and reason about it.</p>\\n\\n\\n\\n<p>The 1970s offered up <em>spaghetti code</em> to describe the tangle of unstructured control flow. This has inspired many software-as-pasta descriptions, from lasagne for layered architectures to ravioli for—pick a decade—objects, components, modules, services, and microservices. Beyond its disordered arrangement, however, spaghetti has little to offer us as a metaphor. It doesn&#8217;t provide us with a useful mental model for talking about code, and has far too many positive associations. If you love both ravioli and spaghetti, it&#8217;s not obvious that one of these is worse for your software architecture than the other.</p>\\n\\n\\n\\n<p>A metaphor is a mapping that we use to describe one thing in terms of another—sometimes because we want to show something familiar from an unfamiliar angle, as in poetry, but sometimes because we want to show something unfamiliar or abstract in a more familiar light, as in software. To be considered good, a metaphor has to offer a number of points of useful correspondence with what is being described. Pasta doesn&#8217;t quite do this.</p>\\n\\n\\n\\n<p>Another quality of a good metaphor is that it should not have too many obvious points of conflict. It will never map its target perfectly—a metaphor is a conceit not an identity—but a good metaphor is one whose key qualities don&#8217;t contradict the very thing we are trying to say, whose points of difference don&#8217;t distract from the mental model being shared.</p>\\n\\n\\n\\n<p>We sometimes talk about <em>code decay</em> and <em>software rot</em>. These terms give a sense of degradation over time. This seems accurate and relatable. They also suggest a response: cleaning (we brush our teeth to reduce the chance of tooth decay) or treatment (we treat wood to avoid it rotting). So far so good… but the problem with these metaphors is they refer to natural processes that happen independently of anything we do. If you don&#8217;t brush your teeth, you will experience decay. If you don&#8217;t touch code, it doesn&#8217;t intrinsically degrade.</p>\\n\\n\\n\\n<p>The third quality of a metaphor that makes it effective is familiarity to its audience. Explaining something unfamiliar in terms of something else that is also unfamiliar can be a long road to travel a short distance (or to end up where you started). If you are familiar with the concept of entropy in statistical mechanics, with the second law of thermodynamics, and with the idea that work is needed to reduce entropy and increase order in a system, then <em>software entropy</em> might strike you as a descriptive metaphor—and not simply because the word <em>work</em> transfers happily from the world of thermodynamics to the day-to-day experience of developers. If, however, these concepts are not accessible and require explanation, then, regardless of its other merits, <em>software entropy</em> may not be the best way to talk about accidental complexity in code.</p>\\n\\n\\n\\n<p>Perhaps the most popular metaphor in use is based on financial debt, originating with Ward Cunningham in <a href=\"http://c2.com/doc/oopsla92.html\">1992</a>. As Martin Fowler described in <a href=\"http://web.archive.org/web/20030919182513/http://martinfowler.com:80/bliki/TechnicalDebt.html\">2003</a>:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>Technical Debt is a wonderful metaphor developed by Ward Cunningham to help us think about this problem. In this metaphor, doing things the quick and dirty way sets us up with a technical debt, which is similar to a financial debt. Like a financial debt, the technical debt incurs interest payments, which come in the form of the extra effort that we have to do in future development because of the quick and dirty design choice.</p></blockquote>\\n\\n\\n\\n<p>When we look at <em>technical debt</em>, we see a metaphor that checks all three boxes: it has a number of useful points of correspondence; the points of difference don&#8217;t overwhelm the core idea; it is familiar. Furthermore, it brings with it a useful working vocabulary. For example, consider what the following debt-related words suggest to you in a software context: repayment, consolidation, creditworthiness, write-off, borrowing.</p>\\n\\n\\n\\n<p>Although we know that by definition no metaphor is perfect, there are two common ways in which the metaphor is misapplied: assuming technical debt is necessarily something bad; equating technical debt with a financial debt value. The emphasis of the former is misaligned and the latter is a category error.</p>\\n\\n\\n\\n<p>If we are relying on the common experience of our audience, financial debt is almost always thought of as a burden. If we take that together with the common experience of code quality and nudge it with leading descriptions such as &#8220;quick and dirty,&#8221; it is easy to see how in everyday use <em>technical debt</em> has become synonymous with poor code and poor practice. We are, however, drawing too heavily on the wrong connotation.</p>\\n\\n\\n\\n<p>Rather than reckless debt, such as from gambling, we should be thinking more along the lines of prudent debt, such as a mortgage. A mortgage should be offered based on our credit history and our ability to pay and, in return, we are able to buy a house that might otherwise have been beyond our reach. Similarly, Ward&#8217;s original motivation was to highlight how debt in code can be used for competitive advantage:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>Shipping first time code is like going into debt. A little debt speeds development so long as it is paid back promptly with a rewrite.</p></blockquote>\\n\\n\\n\\n<p>This comes with a clear caveat and implication: a debt is a loan. A debt is for repayment, not for running up:</p>\\n\\n\\n\\n<blockquote class=\"wp-block-quote\"><p>The danger occurs when the debt is not repaid. Every minute spent on not-quite-right code counts as interest on that debt. Entire engineering organizations can be brought to a stand-still under the debt load of an unconsolidated implementation.</p></blockquote>\\n\\n\\n\\n<p>As in the real world, how we run up debt and how we manage it turn out to be more complex than the simplicity of our best intentions. There are teams that make time-saving decisions wisely, revisiting and addressing them later in a timely manner. But in most cases where debt is incurred, discussed, and lamented, codebases reflect the firefight of different priorities, skills, and people. It&#8217;s still technical debt, but it lacks the prudence and intention of Ward&#8217;s original purpose.</p>\\n\\n\\n\\n<p>There are also teams and tools that embrace the debt metaphor so tightly that they forget it&#8217;s a metaphor. They treat it literally and numerically, converting code quality into a currency value on a spreadsheet or dashboard. The consequences of this <a href=\"https://en.wiktionary.org/wiki/thinko\">thinko</a> range from being a harmless fiction largely ignored by developers and managers to a more damaging numerology that, even though it&#8217;s well intentioned, can mislead development effort.</p>\\n\\n\\n\\n<p>If we&#8217;re going to quantify it, what is it we&#8217;re quantifying? Do we list off code smells? What is the debt value of a code smell? Is it constant per kind of code smell? For example, is duplicate code characterised by a single cost? And are code smells independent of one another? Consider that, for example, duplication is sometimes used to reduce coupling, so the debit becomes a credit in that context. We can conclude that a code smell is not an isolated thing with a single look-up debt value, so this is clearly a more complex problem dependent on many factors. As a multivariable problem, what does it depend on? And how? And how do we know? And what would the value or—more likely—value distribution reflect? The cost of fixing? Or, more honestly, an estimate of the cost of fixing?</p>\\n\\n\\n\\n<p>But even if we are somehow able to conjure a number out of this ever-growing list of considerations—and even if that number has some relation to observed reality—we have put a number to the wrong quantity. We have, in fact, missed the whole point of the metaphor.</p>\\n\\n\\n\\n<p>Technical debt is not the cost of repaying the debt: it is the cost of owning the debt. These are not the same. That is the message of the technical debt metaphor: it is not simply a measure of the specific work needed to repay the debt; it is the additional time and effort added to all past, present, and future work that comes from having the debt in the first place.</p>\\n\\n\\n\\n<p>By taking the metaphor literally, we have robbed it of its value. Its value is to offer us a figure of speech not of currency, a mental model for talking and reasoning about qualities of our code that are not simply stated in code. No matter how well meant, pushing any metaphor beyond its applicability leads to <a href=\"https://weeklysift.com/2011/10/24/expand-your-vocabulary-metaphor-shear/\">metaphor shear</a>. It is, after all, metaphor and not identity.</p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/on-exactitude-in-technical-debt/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 17 Nov 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 17 Nov 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-17-nov-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-17-nov-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-17-nov-2020/#respond',\n",
       "   'published': 'Tue, 17 Nov 2020 12:21:43 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=17, tm_hour=12, tm_min=21, tm_sec=43, tm_wday=1, tm_yday=322, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13414',\n",
       "   'guidislink': False,\n",
       "   'summary': 'NDSS Symposium 2020 Papers &#8212; Large pile of security research from the 2020 Network and Distributed System Security Symposium, including papers on topics as wide-reaching as hypervisor fuzzing and The Attack of the Clones Against Proof-of-Authority which sounds like a very niche Star Wars sequel indeed. Liquid Information Flow Control &#8212; We present Lifty, a [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'NDSS Symposium 2020 Papers &#8212; Large pile of security research from the 2020 Network and Distributed System Security Symposium, including papers on topics as wide-reaching as hypervisor fuzzing and The Attack of the Clones Against Proof-of-Authority which sounds like a very niche Star Wars sequel indeed. Liquid Information Flow Control &#8212; We present Lifty, a [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol>\\n<li><a href=\"https://www.ndss-symposium.org/ndss-program/2020-program/\">NDSS Symposium 2020 Papers</a> &#8212; Large pile of security research from the 2020 <i>Network and Distributed System Security Symposium</i>, including papers on topics as wide-reaching as <a href=\"https://www.ndss-symposium.org/ndss-paper/hyper-cube-high-dimensional-hypervisor-fuzzing/\">hypervisor fuzzing</a> and <a href=\"https://www.ndss-symposium.org/ndss-paper/the-attack-of-the-clones-against-proof-of-authority/\">The Attack of the Clones Against Proof-of-Authority</a> which sounds like a very niche Star Wars sequel indeed.</li>\\n<li><a href=\"https://cseweb.ucsd.edu/~npolikarpova/publications/icfp20-lifty.pdf\">Liquid Information Flow Control</a> &#8212; <i>We present Lifty, a domain-specific language for data-centric applications that manipulate sensitive data. A Lifty programmer annotates the sources of sensitive data with declarative security policies, and the language statically and automatically verifies that the application handles the data according to the policies. Moreover, if verification fails, Lifty suggests a provably correct repair, thereby easing the programmer burden of implementing policy enforcing code throughout the application.</i></li>\\n<li><a href=\"https://meta.wikimedia.org/wiki/So_you%27ve_made_a_mistake_and_it%27s_public...\">So You&#8217;ve Made a Mistake and It&#8217;s Public</a> &#8212; Wikipedians&#8217; excellent advice for what to do when you&#8217;ve been busted making a mistake.</li>\\n<li><a href=\"https://github.com/graphql-editor/graphql-editor\">GraphQL Editor</a> &#8212; <i>Create a schema by using visual blocks system. GraphQL Editor will transform them into code.</i></li>\\n</ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-17-nov-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 13 Nov 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 13 Nov 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-13-nov-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-13-nov-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-13-nov-2020/#respond',\n",
       "   'published': 'Fri, 13 Nov 2020 12:20:52 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=13, tm_hour=12, tm_min=20, tm_sec=52, tm_wday=4, tm_yday=318, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13409',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Advanced System on a Chip Lecture Notes (2016) &#8212; Topics: 1. Basic Processor &#38; Memory hierarchy; 2. Advanced Out-of-Order Processor; 3. Data-parallel processors; 4. Micro-controller introduction; 5. Multicore; 6. RISC-V core; 7. Advanced Multicore; 8. Multicore programming; 9. Graphics Processing Unit (GPU); 10. Heterogeneous SoC; 11. GPU Programming; 12. Application-Specific Instruction-Set Processor (ASIP); 13 PULP: [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Advanced System on a Chip Lecture Notes (2016) &#8212; Topics: 1. Basic Processor &#38; Memory hierarchy; 2. Advanced Out-of-Order Processor; 3. Data-parallel processors; 4. Micro-controller introduction; 5. Multicore; 6. RISC-V core; 7. Advanced Multicore; 8. Multicore programming; 9. Graphics Processing Unit (GPU); 10. Heterogeneous SoC; 11. GPU Programming; 12. Application-Specific Instruction-Set Processor (ASIP); 13 PULP: [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol>\\n<li><a href=\"https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/\">Advanced System on a Chip Lecture Notes (2016)</a> &#8212; Topics: <i>1. Basic Processor &amp; Memory hierarchy; 2. Advanced Out-of-Order Processor; 3. Data-parallel processors; 4. Micro-controller introduction; 5. Multicore;  6. RISC-V core; 7. Advanced Multicore; 8. Multicore programming; 9. Graphics Processing Unit (GPU); 10. Heterogeneous SoC; 11. GPU Programming; 12. Application-Specific Instruction-Set Processor (ASIP); 13 PULP: Parallel Ultra-Low-Power Computing; 14. Architecture in the Future &#8211; Wrap-up</i> (via <a href=\"https://news.ycombinator.com/item?id=25057889\">Hacker News</a>).</li>\\n<li><a href=\"https://flix.dev/\">Flix</a> &#8212; <i>Next-generation reliable, safe, concise, and functional-first programming language.<br />\\nFlix is a principled and flexible functional-, logic-, and imperative- programming language that takes inspiration from F#, Go, OCaml, Haskell, Rust, and Scala. Flix looks like Scala, but its type system is closer to that of OCaml and Haskell. Its concurrency model is inspired by Go-style processes and channels. Flix compiles to JVM bytecode, runs on the Java Virtual Machine, and supports full tail call elimination.</i> And <i>supports first-class Datalog constraints enriched with lattice semantics.</i></li>\\n<li><a href=\"https://peterhdiamandis.medium.com/metatrends-shaping-the-next-decade-d09718144961\">20 Megatrends for the 2020s</a> &#8212; <i>Abundance, connectivity, healthspan, capital, AR and Spatial Web, smart devices, human-level AI, AI-Human collaboration, software shells, renewable energy, insurance industry switches to prevention, autonomous vehicles and flying cars, on-demand production and delivery, knowledge, advertising, cellular agriculture, brain-computer interfaces, VR, sustainability/environment, and CRISPR.</i> Even if you don&#8217;t believe these are the trends of the future, it&#8217;s worth knowing what your customers/partners are being told.</li>\\n<li><a href=\"https://devopsdirective.com/posts/2020/11/credential-management/\">Credential Management</a> &#8212; <i>Level -2: No Authentication; Level -1: All Passwords = “password”; Level 0: Hardcode Everywhere; Level +1: Move Secrets into a Config File; Level +2: Encrypt the Config File; Level +3: Use a Secret Manager; Level +4: Dynamic Ephemeral Credentials</i>.</li>\\n</ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-13-nov-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Multi-Paradigm Languages',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Multi-Paradigm Languages'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/multi-paradigm-languages/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/multi-paradigm-languages/',\n",
       "   'comments': 'https://www.oreilly.com/radar/multi-paradigm-languages/#respond',\n",
       "   'published': 'Tue, 10 Nov 2020 13:29:21 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=10, tm_hour=13, tm_min=29, tm_sec=21, tm_wday=1, tm_yday=315, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Software Engineering', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commentary', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13406',\n",
       "   'guidislink': False,\n",
       "   'summary': 'The programming world used to be split into functional languages, object-oriented languages, and everything else (mostly procedural languages). One &#8220;was&#8221; a functional programmer (at least as a hobby) writing Lisp, Haskell, or Erlang; or one &#8220;was&#8221; an OO programmer (at least professionally), writing code in Java or C++.\\xa0 (One never called oneself a “procedural programmer”; [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The programming world used to be split into functional languages, object-oriented languages, and everything else (mostly procedural languages). One &#8220;was&#8221; a functional programmer (at least as a hobby) writing Lisp, Haskell, or Erlang; or one &#8220;was&#8221; an OO programmer (at least professionally), writing code in Java or C++.\\xa0 (One never called oneself a “procedural programmer”; [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>The programming world used to be split into functional languages, object-oriented languages, and everything else (mostly procedural languages). One &#8220;was&#8221; a functional programmer (at least as a hobby) writing Lisp, Haskell, or Erlang; or one &#8220;was&#8221; an OO programmer (at least professionally), writing code in Java or C++.\\xa0 (One never called oneself a “procedural programmer”; when these names escaped from academia in the 1990s, calling yourself a “procedural programmer” would be akin to wearing wide ties and bell-bottom jeans.)</p>\\n\\n\\n\\n<p>But this world has been changing. Over the past two decades, we&#8217;ve seen the rise of hybrid programming languages that combine both functional and object-oriented features. Some of these languages (like Scala) were multi-paradigm from the beginning. Others, like Python (in the transition from Python 2 to 3) or Java (with the introduction of Lambdas in Java 8) are object-oriented or procedural languages to which functional features were added. Although we think of C++ as an object-oriented language, it has also been multi-paradigm from the beginning. It started with C, a procedural language, and added object-oriented features. Later, beginning with the Standard Template Library, C++ was influenced by many ideas from Scheme, a descendant of LISP.\\xa0 JavaScript was also heavily influenced by Scheme, and popularized the idea of anonymous functions and functions as first class objects. And JavaScript was object-oriented from the start, with a prototype-based object model and syntax (though not semantics) that gradually evolved to become similar to Java’s.</p>\\n\\n\\n\\n<p>We’ve also seen the rise of languages combining static and dynamic typing (TypeScript in the JavaScript world; the addition of optional type hinting in Python 3.5; Rust has some limited dynamic typing features). Typing is another dimension in paradigm space. Dynamic typing leads to languages that make programming fun and where it’s easy to be productive, while strict typing makes it significantly easier to build, understand, and debug large systems. It’s always been easy to find people praising dynamic languages, but, except for a few years in the late 00s, the dynamic-static paradigmatic hasn’t attracted as much attention.</p>\\n\\n\\n\\n<p>Why do we still see holy wars between advocates of functional and object-oriented programming? That strikes me as a huge missed opportunity. What might &#8220;multi-paradigm programming&#8221; mean? What would it mean to reject purity and use whatever set of features provide the best solution in any given context? Most significant software is substantial enough that it certainly has components where an object-oriented paradigm makes more sense, and components where a functional paradigm is superior.\\xa0 For example, look at a “functional” feature like recursion.\\xa0 There are certainly algorithms that make much more sense recursively (Towers of Hanoi, or printing a sorted binary tree in order); there are algorithms where it doesn’t make much of a difference whether you use loops or recursion (whenever tail recursion optimizations will work); and there are certainly cases where recursion will be slow and memory-hungry. How many programmers know which solution is best in any situation?</p>\\n\\n\\n\\n<p>These are the sort of questions we need to start asking. Design patterns have been associated with object-oriented programming from the beginning. What kinds of design patterns make sense in a multi-paradigm world? Remember that design patterns aren&#8217;t &#8220;invented&#8221;; they&#8217;re observed, they&#8217;re solutions to problems that show up again and again, and that should become part of your repertoire. It&#8217;s unfortunate that functional programmers tend not to talk about design patterns; when you realize that patterns are observed solutions, statements like &#8220;patterns aren&#8217;t needed in functional languages&#8221; cease to make sense. Functional programmers certainly solve problems, and certainly see the same solutions show up repeatedly. We shouldn’t expect those problems and solutions to be the same problems and solutions that OO programmers observe. What patterns yield the best of both paradigms? What patterns might help to determine which approach is most appropriate in a given situation?</p>\\n\\n\\n\\n<p>Programming languages represent ways of thinking about problems. Over the years, the paradigms have multiplied, along with the problems we’re interested in solving. We now talk about event-driven programming, and many software systems are event-driven, at least on the front end. Metaprogramming was popularized by JUnit, the first widely used tool to rely on this feature that’s more often associated with functional languages; since then, several drastically different versions of metaprogramming have made new things possible in Java, Ruby, and other languages.</p>\\n\\n\\n\\n<p>We&#8217;ve never really addressed the problem of how to make these paradigms play well together; so far, languages that support multiple paradigms have left it to the programmers to figure out how to use them. But simply mixing paradigms ad hoc probably isn’t the ideal way to build large systems–and we&#8217;re now building software at scales and speeds that were hard to imagine only a few years ago. Our tools have improved; now we need to learn how to use them well. And that will inevitably involve blending paradigms that we’ve long viewed as distinct, or even in conflict.</p>\\n\\n\\n\\n<p></p>\\n\\n\\n\\n<p><em>Thanks to Kevlin Henney for ideas and suggestions!</em></p>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/multi-paradigm-languages/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 10 November 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 10 November 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-10-november-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-10-november-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-10-november-2020/#respond',\n",
       "   'published': 'Tue, 10 Nov 2020 12:13:23 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=10, tm_hour=12, tm_min=13, tm_sec=23, tm_wday=1, tm_yday=315, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13404',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Hypothesis as Liability &#8212; Would the mental focus on a specific hypothesis prevent us from making a discovery? To test this, we made up a dataset and asked students to analyze it. [&#8230;] The most notable “discovery” in the dataset was that if you simply plotted the number of steps versus the BMI, you would [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Hypothesis as Liability &#8212; Would the mental focus on a specific hypothesis prevent us from making a discovery? To test this, we made up a dataset and asked students to analyze it. [&#8230;] The most notable “discovery” in the dataset was that if you simply plotted the number of steps versus the BMI, you would [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol>\\n<li><a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02133-w\">Hypothesis as Liability</a> &#8212; <i>Would the mental focus on a specific hypothesis prevent us from making a discovery? To test this, we made up a dataset and asked students to analyze it. [&#8230;] The most notable “discovery” in the dataset was that if you simply plotted the number of steps versus the BMI, you would see an image of a gorilla waving at you (Fig. 1b).</i></li>\\n<li><a href=\"https://www.reddit.com/r/EnoughMuskSpam/comments/99sbwa/former_tesla_programmers_anecdotes_about_problems/\">Tesla Engineering Inside Goss</a> &#8212; Lots and lots of inside engineering horror stories (2 years old by now). <i>my issue was the fact that the systems doing the flashing were running the yocto images and perl and the guy writing the perl was also responsible for writing the thing that actually updates the car. that thing (the car-side updater) is about ~100k lines of C in a single file. code reviews were always a laugh riot.</i></li>\\n<li><a href=\"https://smalldata.tech/blog/2019/02/09/teach-testing-first\">Teach Testing First</a> &#8212; An extremely good idea. Testers and security specialists have a different mindset to regular programmers: they look to pervert and break the software, not simply to find the golden path whereby it produces the right behaviour for the right inputs. Perhaps if more people learned testing first, we&#8217;d end up with more secure software.</li>\\n<li><a href=\"https://www.youtube.com/watch?v=D8_VmWWRJgE\">Realistic and Interactive Robotic Gaze</a> &#8212; Astonishingly creepy prototype with astonishingly life-like eyeballs. Great work from Disney Research. (<a href=\"https://la.disneyresearch.com/publication/realistic-and-interactive-robot-gaze/\">Paper</a>)</li>\\n</ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-10-november-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 6 Nov 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 6 Nov 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-6-nov-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-6-nov-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-6-nov-2020/#respond',\n",
       "   'published': 'Fri, 06 Nov 2020 11:59:34 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=6, tm_hour=11, tm_min=59, tm_sec=34, tm_wday=4, tm_yday=311, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13399',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Dealing with Security Holes in Chips &#8212; system security starts at the hardware layer. Ubooquity &#8212; free home server for your comics and ebooks library. &#8220;Like plex for books.&#8221; Noisepage &#8212; a relational database management system developed by the Carnegie Mellon Database Group. The research goal of the NoisePage project is to develop high-performance system [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Dealing with Security Holes in Chips &#8212; system security starts at the hardware layer. Ubooquity &#8212; free home server for your comics and ebooks library. &#8220;Like plex for books.&#8221; Noisepage &#8212; a relational database management system developed by the Carnegie Mellon Database Group. The research goal of the NoisePage project is to develop high-performance system [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol>\\n<li><a href=\"https://semiengineering.com/dealing-with-security-holes-in-chips/\">Dealing with Security Holes in Chips</a> &#8212; <i>system security starts at the hardware layer</i>.</li>\\n<li><a href=\"https://vaemendis.net/ubooquity/\">Ubooquity</a> &#8212; <i>free home server for your comics and ebooks library</i>. &#8220;Like plex for books.&#8221;</li>\\n<li><a href=\"https://github.com/cmu-db/noisepage\">Noisepage</a> &#8212; <i>a relational database management system developed by the Carnegie Mellon Database Group. The research goal of the NoisePage project is to develop high-performance system components that support autonomous operation and optimization as a first-class design principle.</i>  Also interesting in databases this week: <a href=\"https://joe.schafer.dev/procella-youtube-analytical-database/\">a rundown on Procella</a>, YouTube&#8217;s analytical database.</li>\\n<li><a href=\"https://daverupert.com/2020/11/technical-debt-as-a-lack-of-understanding/\">Technical Debt</a> &#8212; Where I first found this excellent description of technical debt, by Ward Cunningham: &#8220;If you develop a program for a long period of time by only adding features but never reorganizing it to reflect your understanding of those features, then eventually that program simply does not contain any understanding and all efforts to work on it take longer and longer.&#8221;</li>\\n</ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-6-nov-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Four short links: 4 Nov 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Four short links: 4 Nov 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/four-short-links-4-nov-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/four-short-links-4-nov-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/four-short-links-4-nov-2020/#respond',\n",
       "   'published': 'Wed, 04 Nov 2020 11:46:23 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=4, tm_hour=11, tm_min=46, tm_sec=23, tm_wday=2, tm_yday=309, tm_isdst=0),\n",
       "   'authors': [{'name': 'Nat Torkington'}],\n",
       "   'author': 'Nat Torkington',\n",
       "   'author_detail': {'name': 'Nat Torkington'},\n",
       "   'tags': [{'term': 'Four Short Links', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13396',\n",
       "   'guidislink': False,\n",
       "   'summary': 'The AI Who Mistook a Bald Head for a Football &#8212; Second-tier Scottish football club Inverness Caledonian Thistle doesn’t have a camera operator for matches at their stadium so the club uses an AI-controlled camera that’s programmed to follow the ball for their broadcasts. But in a recent match against Ayr United, the AI controller [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'The AI Who Mistook a Bald Head for a Football &#8212; Second-tier Scottish football club Inverness Caledonian Thistle doesn’t have a camera operator for matches at their stadium so the club uses an AI-controlled camera that’s programmed to follow the ball for their broadcasts. But in a recent match against Ayr United, the AI controller [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<ol>\\n<li><a href=\"https://kottke.org/20/11/the-ai-who-mistook-a-bald-head-for-a-soccer-ball\">The AI Who Mistook a Bald Head for a Football</a> &#8212; <i>Second-tier Scottish football club Inverness Caledonian Thistle doesn’t have a camera operator for matches at their stadium so the club uses an AI-controlled camera that’s programmed to follow the ball for their broadcasts. But in a recent match against Ayr United, the AI controller kept moving the camera off the ball to focus on the bald head of the linesman, making the match all but unwatchable. No fans allowed in the stadium either, so the broadcast was the only way to watch.</i> Watch the video, it is hilarious and tragic. I&#8217;m sure there&#8217;s a serious lesson to be drawn from this, but I&#8217;m too busy snickering to draw it.</li>\\n<li><a href=\"https://stackoverflow.com/questions/6841333/why-is-subtracting-these-two-times-in-1927-giving-a-strange-result\">Why Is Subtracting These Two Times (in 1927) Giving a Strange Result?</a> &#8212; You already knew timezones are a hellmouth, but now you have another example of how deep the hellmouth goes. <i>Basically at midnight at the end of 1927, the clocks went back 5 minutes and 52 seconds.</i> (via Jarkko Hietaniemi)</li>\\n<li><a href=\"https://www.nngroup.com/articles/ux-gains-shrinking/\">Average UX Improvements Are Shrinking Over Time</a> &#8212; <i>On average, UX improvements have substantially decreased since 2006–2008: from 247% to 75% (a 69% decrease). This difference is statistically significant (p = 0.01) — we can be quite confident that average improvement scores are lower now than they were 12–14 years ago.</i></li>\\n<li><a href=\"http://schasins.com/cs294-usable-programming-2020/\">CS294: Building User-Centred Programming Tools</a> &#8212; <i>This hands-on course explores a selection of techniques from Programming Languages and Human-Computer Interaction that can help us create useful, usable programming languages and programming tools. We will cover strategies for designing programming systems—e.g., need finding, formative studies, user-centered design broadly. We will also cover tools and techniques that help us build user-friendly programming systems—e.g., program synthesis, structure editors, abstraction design, program slicing. For the final project, individuals or teams will develop a usable abstraction, language, or programming tool of their own design.</i> What looks like an awesome course at Berkeley. The readings alone are excellent.</li>\\n</ol>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/four-short-links-4-nov-2020/feed/',\n",
       "   'slash_comments': '0'},\n",
       "  {'title': 'Radar trends to watch: November 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Radar trends to watch: November 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2020/'}],\n",
       "   'link': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2020/',\n",
       "   'comments': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2020/#respond',\n",
       "   'published': 'Mon, 02 Nov 2020 12:28:14 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=2, tm_hour=12, tm_min=28, tm_sec=14, tm_wday=0, tm_yday=307, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Loukides'}],\n",
       "   'author': 'Mike Loukides',\n",
       "   'author_detail': {'name': 'Mike Loukides'},\n",
       "   'tags': [{'term': 'Radar Trends', 'scheme': None, 'label': None},\n",
       "    {'term': 'Signals', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.oreilly.com/radar/?p=13388',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Perhaps the most important event this month isn’t technical, but the start of the US Justice Dept.’s lawsuit against Google. That will certainly play out over years rather than months, but it’s significance is less about this particular case than the idea that legal and regulatory systems will play a large role in the evolution [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "    'value': 'Perhaps the most important event this month isn’t technical, but the start of the US Justice Dept.’s lawsuit against Google. That will certainly play out over years rather than months, but it’s significance is less about this particular case than the idea that legal and regulatory systems will play a large role in the evolution [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "     'value': '<p>Perhaps the most important event this month isn’t technical, but the start of the US Justice Dept.’s lawsuit against Google. That will certainly play out over years rather than months, but it’s significance is less about this particular case than the idea that legal and regulatory systems will play a large role in the evolution of technology in the US. In the short term, it’s worth watching the CPPA, GDPR, California’s Props 22 and 24, and FCC interference with social media’s enforcement of rules around community behavior.&nbsp; Long term, this is only the beginning.</p>\\n\\n\\n\\n<h3>Artificial Intelligence and Machine Learning</h3>\\n\\n\\n\\n<ul><li>Partial differential equations are the key to a number of difficult and important problems.&nbsp;In a surprising breakthrough, it’s been shown that deep learning can be used to <a href=\"https://www.technologyreview.com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-equations/\">solve PDEs</a>, and that they are orders of magnitude faster than typical numerical methods.<br /></li><li><a href=\"https://www.agence.ai/\">Agence</a> is a dynamic film/multiplayer VR game with intelligent agents. AI might not be what pushes VR to commercial success, but it will certainly be a part.<br /></li><li><a href=\"https://www.udel.edu/udaily/2020/october/artificial-intelligence-model-dion-vlachos-josh-lansford/\">Towards more trustworthy models</a>: Research on models that can take into account physical laws, error, and missing information makes <a href=\"https://advances.sciencemag.org/content/6/42/eabc3204/tab-article-info\">AI more trustworthy</a>.<br /></li><li>“<a href=\"https://arxiv.org/abs/2009.08449\">Less than one shot learning</a>”: when the number of classes is larger than the number of sample. The key idea here is “soft labelling,” which allows labels to represent characteristics shared between multiple items in the sample.<br /></li><li><a href=\"https://www.nature.com/articles/s42256-020-00237-3\">Very small neural networks</a> adapted from worms’ nervous systems are able to perform tasks as well as networks thousands of times larger.<br /></li><li>A device that can <a href=\"https://spectrum.ieee.org/nanoclast/semiconductors/devices/memristor-first-single-device-to-act-like-a-neuron\">mimic the behavior of a neuron</a> might eventually make it possible to emulate a brain, without requiring a lot of power.<br /></li><li>AI is not magic, even when it is effective. <a href=\"https://datasociety.net/library/repairing-innovation/\">Integrating AI into medical practice</a> requires work–serious human work in rethinking social structures, communications, and hierarchies. This work frequently falls to the nursing staff, whose contribution is often undervalued.<br /></li><li><a href=\"https://github.com/daviddao/awful-ai\">Awful-AI</a> is a GitHub repo for tracking “awful uses of AI.”&nbsp; Autonomous weapons, racist AI, social credit, and scams: they’re all here. It would be funny if it wasn’t sad (and real).<br /></li><li>Pattern-exploited training (<a href=\"https://arxiv.org/abs/2001.07676\">PET</a>) is a new NLP technique that, on some benchmarks, <a href=\"https://www.infoq.com/news/2020/10/training-exceeds-gpt3/\">exceeds GPT-3 performance</a> while only using 223 million parameters (as opposed to 175 billion). While 223 million is still a large number, that’s a factor of almost 1000 less than GPT-3.<br /></li><li>Does explainable AI actually increase trust?&nbsp; <a href=\"https://techxplore.com/news/2020-10-explanations-data-based-users-ai.html\">Perhaps not</a>. Explanations can be distortions (lies).&nbsp; Auditing is a more trustworthy approach.</li></ul>\\n\\n\\n\\n<h3>Infrastructure and Operations</h3>\\n\\n\\n\\n<ul><li>Microsoft’s Open Source <a href=\"https://thenewstack.io/the-dapr-distributed-runtime-nears-production-readiness/\">Dapr Distributed Runtime</a> is an abstraction layer on top of Kubernetes (and much more) to simplify building software that runs in a distributed multi-cloud environment.<br /></li><li><a href=\"https://thenewstack.io/is-cloud-waste-inevitable-as-companies-move-to-the-cloud/\">Cloud waste</a>: How much cloud spending is actually used? Perhaps as much as 45% is wasted on overprovisioning, unexpected costs, and resources that go unused.<br /></li><li>Building <a href=\"https://thenewstack.io/adrian-cockcroft-on-failover-theater-and-achieving-true-continuous-resilience/\">continuously resilient</a> systems starts with chaos engineering: Adrian Cockroft on failover theater, the cloud, and reliability.</li></ul>\\n\\n\\n\\n<h3>Programming</h3>\\n\\n\\n\\n<ul><li><a href=\"https://dev.to/karthik2206/no-it-is-not-shameful-for-a-developer-to-use-no-code-8pe\">An all no-code startup</a>: Yes, it’s possible.&nbsp; It’s time to start thinking about the no-code “stack.”<br /></li><li>The kernel within the Linux kernel: <a href=\"https://thenewstack.io/how-ebpf-turns-linux-into-a-programmable-kernel/\">eBPF</a> can run sandboxed programs within the kernel’s memory space; it’s a convenient way to write kernel extensions and, conceivably, to replace much of the existing kernel with an eBPF-based microkernel.<br /></li><li>It’s worth reading @sogrady’s thoughts on how <a href=\"https://redmonk.com/sogrady/2020/10/06/developer-experience-gap/?utm_source=feedly&amp;utm_medium=rss&amp;utm_campaign=developer-experience-gap\">developer experience</a> needs to change in order to build more tightly integrated software across multiple platforms.</li></ul>\\n\\n\\n\\n<h3>Security and Privacy</h3>\\n\\n\\n\\n<ul><li>Botched <a href=\"https://thenewstack.io/palo-alto-networks-botched-access-management-an-easy-opening-for-cloud-attacks/\">identity and access management (IAM)</a> configuration is a huge problem for cloud security. Understanding security configuration is nearly impossible for humans.<br /></li><li><a href=\"https://arstechnica.com/gadgets/2020/10/future-of-collaboration-01/\">Redesigning corporate networks for working at home</a>: Corporate networks need to be re-thought; working from home raises new security issues and increases bandwidth requirements.<br /></li><li><a href=\"https://krebsonsecurity.com/2020/10/microsoft-uses-copyright-law-to-disrupt-trickbot-botnet/\">Microsoft disables Trickbot</a>, a ransomware network that was targeting the US election. What’s particularly interesting is that Microsoft used trademark law to get a court order allowing them to take control over the Trickbot servers.<br /></li><li>Have IoT vendors learned anything about security yet?&nbsp; Apparently not.&nbsp; <a href=\"https://arstechnica.com/information-technology/2020/09/how-a-hacker-turned-a-250-coffee-maker-into-ransom-machine/\">Your coffee maker on ransomware</a>.</li></ul>\\n\\n\\n\\n<h3>Economies</h3>\\n\\n\\n\\n<ul><li><a href=\"https://www.technologyreview.com/2020/10/13/1009497/singapore-vertical-farming-food-security/\">Indoor farming, food security, climate and COVID in Singapore</a>: how do you guarantee a food supply in the face of supply chain breakdowns and an increasingly erratic climate, in a densely populated country with almost no arable land?<br /></li><li><a href=\"https://www.ecb.europa.eu/euro/html/digitaleuro.en.html\">Towards a digital Euro</a>: The European Central Bank is taking the first steps towards a digital version of the Euro.&nbsp; It’s behind China (but ahead of the US) in its steps towards digital currency.</li></ul>\\n\\n\\n\\n<h3>Hardware</h3>\\n\\n\\n\\n<ul><li>Quantum fast fourier transform (<a href=\"https://link.springer.com/article/10.1007/s11128-020-02776-5\">QFFT</a>): Want to reinvent digital signal processing on quantum computers? This is another game changer, and one of the few classical algorithms that have been reinvented for quantum computers.<br /></li><li><a href=\"https://techxplore.com/news/2020-10-multi-state-storage-binary.html\">Multi-state memory:</a> not just zeros and ones. Moore’s law applies to memory, too, and the best way to get around the fundamental limitation (ever-smaller features) might be to design memory that goes <a href=\"https://pubs.acs.org/doi/10.1021/acsami.0c10184\">beyond binary</a>. Multi-state memory might also be a big step forward in neuromorphic computing.<br /></li><li><a href=\"https://techxplore.com/news/2020-10-wearable-sensors-skin.html\">Printing sensors directly on the body without heat</a>: Who needs an iPhone? These sensors could be revolutionary for tasks like COVID monitoring and personalized medicine.<br /></li><li><a href=\"https://www.techspot.com/news/86943-yale-scientists-have-developed-flexible-robotic-fabric.html\">Robotic fabric</a>: Developers have made fabric that can change its shape programmably.&nbsp; Robotic clothes? </li></ul>\\n\\n\\n\\n<h3>Web</h3>\\n\\n\\n\\n<ul><li>Do Not Track failed. <a href=\"https://arstechnica.com/tech-policy/2020/10/coming-to-a-browser-near-you-a-new-way-to-keep-sites-from-selling-your-data/\">Global Privacy Control</a> (GPC) is essentially Do Not Track with legal teeth. Will it succeed?&nbsp; Currently implemented by the Brave browser and some plugins for other browsers.<br /></li><li>Firefox’s campaign to “<a href=\"https://www.mozilla.org/en-US/firefox/unfck/\">Unfck the Internet</a>” gives us a reason to return to Firefox.&nbsp; The campaign is built around a set of plugins for controlling political ads, social media surveillance, warning others about inappropriate YouTube recommendations, and more. Putting social media control in the browser? It might work. </li></ul>'}],\n",
       "   'wfw_commentrss': 'https://www.oreilly.com/radar/radar-trends-to-watch-november-2020/feed/',\n",
       "   'slash_comments': '0'}],\n",
       " 'feed': {'title': 'Radar',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "   'value': 'Radar'},\n",
       "  'links': [{'rel': 'alternate',\n",
       "    'type': 'text/html',\n",
       "    'href': 'https://www.oreilly.com/radar'},\n",
       "   {'rel': 'self',\n",
       "    'type': 'application/rss+xml',\n",
       "    'href': 'http://feeds.feedburner.com/oreilly/radar/atom'},\n",
       "   {'rel': 'hub',\n",
       "    'href': 'http://pubsubhubbub.appspot.com/',\n",
       "    'type': 'text/html'}],\n",
       "  'link': 'https://www.oreilly.com/radar',\n",
       "  'subtitle': 'Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology',\n",
       "  'subtitle_detail': {'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       "   'value': 'Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology'},\n",
       "  'updated': 'Tue, 16 Nov 2021 13:45:00 +0000',\n",
       "  'updated_parsed': time.struct_time(tm_year=2021, tm_mon=11, tm_mday=16, tm_hour=13, tm_min=45, tm_sec=0, tm_wday=1, tm_yday=320, tm_isdst=0),\n",
       "  'language': 'en-US',\n",
       "  'sy_updateperiod': 'hourly',\n",
       "  'sy_updatefrequency': '1',\n",
       "  'generator_detail': {'name': 'https://wordpress.org/?v=5.3.10'},\n",
       "  'generator': 'https://wordpress.org/?v=5.3.10',\n",
       "  'feedburner_info': {'uri': 'oreilly/radar/atom'},\n",
       "  'geo_lat': '38.393314',\n",
       "  'geo_long': '-122.836667',\n",
       "  'feedburner_emailserviceid': 'oreilly/radar/atom',\n",
       "  'feedburner_feedburnerhostname': 'https://feedburner.google.com'},\n",
       " 'headers': {'content-type': 'text/xml; charset=UTF-8',\n",
       "  'etag': 'Qc7EqDBhUt89GygAkifhfbhWyxQ',\n",
       "  'last-modified': 'Thu, 25 Nov 2021 22:26:37 GMT',\n",
       "  'content-encoding': 'gzip',\n",
       "  'transfer-encoding': 'chunked',\n",
       "  'date': 'Thu, 25 Nov 2021 22:27:02 GMT',\n",
       "  'expires': 'Thu, 25 Nov 2021 22:27:02 GMT',\n",
       "  'cache-control': 'private, max-age=0',\n",
       "  'x-content-type-options': 'nosniff',\n",
       "  'x-xss-protection': '1; mode=block',\n",
       "  'server': 'GSE',\n",
       "  'connection': 'close'},\n",
       " 'etag': 'Qc7EqDBhUt89GygAkifhfbhWyxQ',\n",
       " 'updated': 'Thu, 25 Nov 2021 22:26:37 GMT',\n",
       " 'updated_parsed': time.struct_time(tm_year=2021, tm_mon=11, tm_mday=25, tm_hour=22, tm_min=26, tm_sec=37, tm_wday=3, tm_yday=329, tm_isdst=0),\n",
       " 'href': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
       " 'status': 200,\n",
       " 'encoding': 'UTF-8',\n",
       " 'version': 'rss20',\n",
       " 'namespaces': {'content': 'http://purl.org/rss/1.0/modules/content/',\n",
       "  'wfw': 'http://wellformedweb.org/CommentAPI/',\n",
       "  'dc': 'http://purl.org/dc/elements/1.1/',\n",
       "  '': 'http://www.w3.org/2005/Atom',\n",
       "  'sy': 'http://purl.org/rss/1.0/modules/syndication/',\n",
       "  'slash': 'http://purl.org/rss/1.0/modules/slash/',\n",
       "  'geo': 'http://www.w3.org/2003/01/geo/wgs84_pos#',\n",
       "  'feedburner': 'http://rssnamespace.org/feedburner/ext/1.0'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = feedparser.parse(url)\n",
    "parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Obtain a list of components (keys) that are available for this feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bozo', 'entries', 'feed', 'headers', 'etag', 'updated', 'updated_parsed', 'href', 'status', 'encoding', 'version', 'namespaces'])\n"
     ]
    }
   ],
   "source": [
    "keys = parser.keys()\n",
    "print (keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obtain a list of components (keys) that are available for the *feed* component of this RSS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'title_detail', 'links', 'link', 'subtitle', 'subtitle_detail', 'updated', 'updated_parsed', 'language', 'sy_updateperiod', 'sy_updatefrequency', 'generator_detail', 'generator', 'feedburner_info', 'geo_lat', 'geo_long', 'feedburner_emailserviceid', 'feedburner_feedburnerhostname'])\n"
     ]
    }
   ],
   "source": [
    "feed_keys = parser.feed.keys()\n",
    "print (feed_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract and print the feed title, subtitle, author, and link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radar Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology https://www.oreilly.com/radar\n"
     ]
    }
   ],
   "source": [
    "title = parser.feed.title\n",
    "subtitle = parser.feed.subtitle\n",
    "link = parser.feed.link\n",
    "print (title, subtitle, link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Count the number of entries that are contained in this RSS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parser['entries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Obtain a list of components (keys) available for an entry.\n",
    "\n",
    "*Hint: Remember to index first before requesting the keys*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'title_detail', 'links', 'link', 'comments', 'published', 'published_parsed', 'authors', 'author', 'tags', 'id', 'guidislink', 'summary', 'summary_detail', 'content', 'wfw_commentrss', 'slash_comments'])\n"
     ]
    }
   ],
   "source": [
    "feed_keys = parser.entries[0].keys()\n",
    "print (feed_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Extract a list of entry titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Low-Code and the Democratization of Programming',\n",
       " 'Remote Teams in ML/AI',\n",
       " 'Radar trends to watch: November 2021',\n",
       " 'The Sobering Truth About the Impact of Your Business Ideas',\n",
       " 'MLOps and DevOps: Why Data Makes It Different',\n",
       " 'The Quality of Auto-Generated Code',\n",
       " 'Radar trends to watch: October 2021',\n",
       " 'Ethical Social Media: Oxymoron or Attainable Goal?',\n",
       " '2021 Data/AI Salary Survey',\n",
       " 'Radar trends to watch: September 2021',\n",
       " 'Rebranding Data',\n",
       " 'A Way Forward with Communal Computing',\n",
       " 'Defending against ransomware is all about the basics',\n",
       " 'Radar trends to watch: August 2021',\n",
       " 'Communal Computing’s Many Problems',\n",
       " 'Thinking About Glue',\n",
       " 'Radar trends to watch: July 2021',\n",
       " 'Hand Labeling Considered Harmful',\n",
       " 'Two economies. Two sets of rules.',\n",
       " 'Communal Computing',\n",
       " 'Code as Infrastructure',\n",
       " 'Radar trends to watch: June 2021',\n",
       " 'AI Powered Misinformation and Manipulation at Scale #GPT-3',\n",
       " 'DeepCheapFakes',\n",
       " 'Radar trends to watch: May 2021',\n",
       " 'Checking Jeff Bezos’s Math',\n",
       " 'AI Adoption in the Enterprise 2021',\n",
       " 'NFTs: Owning Digital Art',\n",
       " 'Radar trends to watch: April 2021',\n",
       " 'InfoTribes, Reality Brokers',\n",
       " 'The End of Silicon Valley as We Know It?',\n",
       " 'The Next Generation of AI',\n",
       " 'Radar trends to watch: March 2021',\n",
       " 'Product Management for AI',\n",
       " '5 things on our data and AI radar for 2021',\n",
       " '5 infrastructure and operations trends to watch in 2021',\n",
       " 'The Wrong Question',\n",
       " 'Radar trends to watch: February 2021',\n",
       " 'Where Programming, Ops, AI, and the Cloud are Headed in 2021',\n",
       " 'Seven Legal Questions for Data Scientists',\n",
       " 'Patterns',\n",
       " 'Radar trends to watch: January 2021',\n",
       " 'Four short links: 14 Dec 2020',\n",
       " 'Four short links: 8 Dec 2020',\n",
       " 'O’Reilly’s top 20 live online training courses of 2020',\n",
       " 'What is functional programming?',\n",
       " 'Four short links: 4 Dec 2020',\n",
       " 'Four short links: 1 Dec 2020',\n",
       " 'Radar trends to watch: December 2020',\n",
       " 'Four short links: 27 Nov 2020',\n",
       " 'Four short links: 24 Nov 2020',\n",
       " 'Four short links: 20 Nov 2020',\n",
       " 'On Exactitude in Technical Debt',\n",
       " 'Four short links: 17 Nov 2020',\n",
       " 'Four short links: 13 Nov 2020',\n",
       " 'Multi-Paradigm Languages',\n",
       " 'Four short links: 10 November 2020',\n",
       " 'Four short links: 6 Nov 2020',\n",
       " 'Four short links: 4 Nov 2020',\n",
       " 'Radar trends to watch: November 2020']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = []\n",
    "for x in parser.entries:\n",
    "    titles.append(x.title)\n",
    "    \n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate the percentage of \"Four short links\" entry titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 12\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "four_shots = []\n",
    "for x in titles:\n",
    "    if (\"Four short links:\" in x):\n",
    "        four_shots.append(x)\n",
    "\n",
    "num_titles = (len(titles))\n",
    "num_four = (len(four_shots))\n",
    "\n",
    "print (num_titles,num_four)\n",
    "\n",
    "print ((num_four*100)/num_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Create a Pandas data frame from the feed's entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>comments</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>content</th>\n",
       "      <th>wfw_commentrss</th>\n",
       "      <th>slash_comments</th>\n",
       "      <th>author_detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low-Code and the Democratization of Programming</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/low-code-and-the...</td>\n",
       "      <td>https://www.oreilly.com/radar/low-code-and-the...</td>\n",
       "      <td>Tue, 16 Nov 2021 12:36:18 +0000</td>\n",
       "      <td>(2021, 11, 16, 12, 36, 18, 1, 320, 0)</td>\n",
       "      <td>[{}]</td>\n",
       "      <td></td>\n",
       "      <td>[{'term': 'Programming', 'scheme': None, 'labe...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14083</td>\n",
       "      <td>False</td>\n",
       "      <td>In the past decade, the growth in low-code and...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/low-code-and-the...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remote Teams in ML/AI</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/remote-teams-in-...</td>\n",
       "      <td>https://www.oreilly.com/radar/remote-teams-in-...</td>\n",
       "      <td>Tue, 09 Nov 2021 14:05:48 +0000</td>\n",
       "      <td>(2021, 11, 9, 14, 5, 48, 1, 313, 0)</td>\n",
       "      <td>[{'name': 'Q McCallum'}]</td>\n",
       "      <td>Q McCallum</td>\n",
       "      <td>[{'term': 'Building a data culture', 'scheme':...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14075</td>\n",
       "      <td>False</td>\n",
       "      <td>I&amp;#8217;m well-versed in the ups and downs of ...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/remote-teams-in-...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'name': 'Q McCallum'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radar trends to watch: November 2021</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>Tue, 02 Nov 2021 11:40:17 +0000</td>\n",
       "      <td>(2021, 11, 2, 11, 40, 17, 1, 306, 0)</td>\n",
       "      <td>[{'name': 'Mike Loukides'}]</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>[{'term': 'Radar Trends', 'scheme': None, 'lab...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14066</td>\n",
       "      <td>False</td>\n",
       "      <td>While October’s news was dominated by Facebook...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/radar-trends-to-...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'name': 'Mike Loukides'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sobering Truth About the Impact of Your Bu...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/the-sobering-tru...</td>\n",
       "      <td>https://www.oreilly.com/radar/the-sobering-tru...</td>\n",
       "      <td>Tue, 26 Oct 2021 13:07:58 +0000</td>\n",
       "      <td>(2021, 10, 26, 13, 7, 58, 1, 299, 0)</td>\n",
       "      <td>[{'name': 'Eric Colson, Daragh Sibley and Dave...</td>\n",
       "      <td>Eric Colson, Daragh Sibley and Dave Spiegel</td>\n",
       "      <td>[{'term': 'Business', 'scheme': None, 'label':...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14041</td>\n",
       "      <td>False</td>\n",
       "      <td>The introduction of data science into the busi...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/the-sobering-tru...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'name': 'Eric Colson, Daragh Sibley and Dave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLOps and DevOps: Why Data Makes It Different</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'hr...</td>\n",
       "      <td>https://www.oreilly.com/radar/mlops-and-devops...</td>\n",
       "      <td>https://www.oreilly.com/radar/mlops-and-devops...</td>\n",
       "      <td>Tue, 19 Oct 2021 14:17:38 +0000</td>\n",
       "      <td>(2021, 10, 19, 14, 17, 38, 1, 292, 0)</td>\n",
       "      <td>[{'name': 'Ville Tuulos and Hugo Bowne-Anderso...</td>\n",
       "      <td>Ville Tuulos and Hugo Bowne-Anderson</td>\n",
       "      <td>[{'term': 'AI &amp; ML', 'scheme': None, 'label': ...</td>\n",
       "      <td>https://www.oreilly.com/radar/?p=14018</td>\n",
       "      <td>False</td>\n",
       "      <td>Much has been written about struggles of deplo...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base'...</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base...</td>\n",
       "      <td>https://www.oreilly.com/radar/mlops-and-devops...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'name': 'Ville Tuulos and Hugo Bowne-Anderson'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Low-Code and the Democratization of Programming   \n",
       "1                              Remote Teams in ML/AI   \n",
       "2               Radar trends to watch: November 2021   \n",
       "3  The Sobering Truth About the Impact of Your Bu...   \n",
       "4      MLOps and DevOps: Why Data Makes It Different   \n",
       "\n",
       "                                        title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base...   \n",
       "2  {'type': 'text/plain', 'language': None, 'base...   \n",
       "3  {'type': 'text/plain', 'language': None, 'base...   \n",
       "4  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                                               links  \\\n",
       "0  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "1  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "2  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "3  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "4  [{'rel': 'alternate', 'type': 'text/html', 'hr...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.oreilly.com/radar/low-code-and-the...   \n",
       "1  https://www.oreilly.com/radar/remote-teams-in-...   \n",
       "2  https://www.oreilly.com/radar/radar-trends-to-...   \n",
       "3  https://www.oreilly.com/radar/the-sobering-tru...   \n",
       "4  https://www.oreilly.com/radar/mlops-and-devops...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  https://www.oreilly.com/radar/low-code-and-the...   \n",
       "1  https://www.oreilly.com/radar/remote-teams-in-...   \n",
       "2  https://www.oreilly.com/radar/radar-trends-to-...   \n",
       "3  https://www.oreilly.com/radar/the-sobering-tru...   \n",
       "4  https://www.oreilly.com/radar/mlops-and-devops...   \n",
       "\n",
       "                         published                       published_parsed  \\\n",
       "0  Tue, 16 Nov 2021 12:36:18 +0000  (2021, 11, 16, 12, 36, 18, 1, 320, 0)   \n",
       "1  Tue, 09 Nov 2021 14:05:48 +0000    (2021, 11, 9, 14, 5, 48, 1, 313, 0)   \n",
       "2  Tue, 02 Nov 2021 11:40:17 +0000   (2021, 11, 2, 11, 40, 17, 1, 306, 0)   \n",
       "3  Tue, 26 Oct 2021 13:07:58 +0000   (2021, 10, 26, 13, 7, 58, 1, 299, 0)   \n",
       "4  Tue, 19 Oct 2021 14:17:38 +0000  (2021, 10, 19, 14, 17, 38, 1, 292, 0)   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                               [{}]   \n",
       "1                           [{'name': 'Q McCallum'}]   \n",
       "2                        [{'name': 'Mike Loukides'}]   \n",
       "3  [{'name': 'Eric Colson, Daragh Sibley and Dave...   \n",
       "4  [{'name': 'Ville Tuulos and Hugo Bowne-Anderso...   \n",
       "\n",
       "                                        author  \\\n",
       "0                                                \n",
       "1                                   Q McCallum   \n",
       "2                                Mike Loukides   \n",
       "3  Eric Colson, Daragh Sibley and Dave Spiegel   \n",
       "4         Ville Tuulos and Hugo Bowne-Anderson   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [{'term': 'Programming', 'scheme': None, 'labe...   \n",
       "1  [{'term': 'Building a data culture', 'scheme':...   \n",
       "2  [{'term': 'Radar Trends', 'scheme': None, 'lab...   \n",
       "3  [{'term': 'Business', 'scheme': None, 'label':...   \n",
       "4  [{'term': 'AI & ML', 'scheme': None, 'label': ...   \n",
       "\n",
       "                                       id  guidislink  \\\n",
       "0  https://www.oreilly.com/radar/?p=14083       False   \n",
       "1  https://www.oreilly.com/radar/?p=14075       False   \n",
       "2  https://www.oreilly.com/radar/?p=14066       False   \n",
       "3  https://www.oreilly.com/radar/?p=14041       False   \n",
       "4  https://www.oreilly.com/radar/?p=14018       False   \n",
       "\n",
       "                                             summary  \\\n",
       "0  In the past decade, the growth in low-code and...   \n",
       "1  I&#8217;m well-versed in the ups and downs of ...   \n",
       "2  While October’s news was dominated by Facebook...   \n",
       "3  The introduction of data science into the busi...   \n",
       "4  Much has been written about struggles of deplo...   \n",
       "\n",
       "                                      summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base'...   \n",
       "1  {'type': 'text/html', 'language': None, 'base'...   \n",
       "2  {'type': 'text/html', 'language': None, 'base'...   \n",
       "3  {'type': 'text/html', 'language': None, 'base'...   \n",
       "4  {'type': 'text/html', 'language': None, 'base'...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [{'type': 'text/html', 'language': None, 'base...   \n",
       "1  [{'type': 'text/html', 'language': None, 'base...   \n",
       "2  [{'type': 'text/html', 'language': None, 'base...   \n",
       "3  [{'type': 'text/html', 'language': None, 'base...   \n",
       "4  [{'type': 'text/html', 'language': None, 'base...   \n",
       "\n",
       "                                      wfw_commentrss slash_comments  \\\n",
       "0  https://www.oreilly.com/radar/low-code-and-the...              0   \n",
       "1  https://www.oreilly.com/radar/remote-teams-in-...              0   \n",
       "2  https://www.oreilly.com/radar/radar-trends-to-...              0   \n",
       "3  https://www.oreilly.com/radar/the-sobering-tru...              0   \n",
       "4  https://www.oreilly.com/radar/mlops-and-devops...              0   \n",
       "\n",
       "                                       author_detail  \n",
       "0                                                NaN  \n",
       "1                             {'name': 'Q McCallum'}  \n",
       "2                          {'name': 'Mike Loukides'}  \n",
       "3  {'name': 'Eric Colson, Daragh Sibley and Dave ...  \n",
       "4   {'name': 'Ville Tuulos and Hugo Bowne-Anderson'}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(parser.entries)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Count the number of entries per author and sort them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nat Torkington</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris Butler</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tim O’Reilly</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q McCallum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eric Colson, Daragh Sibley and Dave Spiegel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hugo Bowne-Anderson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kevlin Henney</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mike Barlow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mike Loukides and Kevlin Henney</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nitesh Dhanjani</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Patrick Hall and Ayoub Ouederni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shayan Mohanty and Hugo Bowne-Anderson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ville Tuulos and Hugo Bowne-Anderson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         author  entries\n",
       "6                                 Mike Loukides       27\n",
       "8                                Nat Torkington       12\n",
       "0                                                      4\n",
       "1                                  Chris Butler        3\n",
       "13                                 Tim O’Reilly        3\n",
       "11                                   Q McCallum        2\n",
       "2   Eric Colson, Daragh Sibley and Dave Spiegel        1\n",
       "3                           Hugo Bowne-Anderson        1\n",
       "4                                 Kevlin Henney        1\n",
       "5                                   Mike Barlow        1\n",
       "7               Mike Loukides and Kevlin Henney        1\n",
       "9                               Nitesh Dhanjani        1\n",
       "10              Patrick Hall and Ayoub Ouederni        1\n",
       "12       Shayan Mohanty and Hugo Bowne-Anderson        1\n",
       "14         Ville Tuulos and Hugo Bowne-Anderson        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autores = df.groupby('author', as_index=False).agg({'title':'count'})\n",
    "autores.columns = ['author', 'entries']\n",
    "autores.sort_values('entries', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Add a new column to the data frame that contains the length (number of characters) of each entry title. Return a data frame that contains the title, author, and title length of each entry in descending order (longest title length at the top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Where Programming, Ops, AI, and the Cloud are ...</td>\n",
       "      <td>Mike Loukides</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sobering Truth About the Impact of Your Bu...</td>\n",
       "      <td>Eric Colson, Daragh Sibley and Dave Spiegel</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AI Powered Misinformation and Manipulation at ...</td>\n",
       "      <td>Nitesh Dhanjani</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5 infrastructure and operations trends to watc...</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>O’Reilly’s top 20 live online training courses...</td>\n",
       "      <td></td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "38  Where Programming, Ops, AI, and the Cloud are ...   \n",
       "3   The Sobering Truth About the Impact of Your Bu...   \n",
       "22  AI Powered Misinformation and Manipulation at ...   \n",
       "35  5 infrastructure and operations trends to watc...   \n",
       "44  O’Reilly’s top 20 live online training courses...   \n",
       "\n",
       "                                         author  title_length  \n",
       "38                                Mike Loukides            60  \n",
       "3   Eric Colson, Daragh Sibley and Dave Spiegel            58  \n",
       "22                              Nitesh Dhanjani            58  \n",
       "35                                                         55  \n",
       "44                                                         54  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_length'] = df['title'].apply(len)\n",
    "df[['title', 'author', 'title_length']].sort_values('title_length', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Create a list of entry titles whose summary includes the phrase \"machine learning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLOps and DevOps: Why Data Makes It Different',\n",
       " 'Hand Labeling Considered Harmful',\n",
       " 'Radar trends to watch: April 2021',\n",
       " 'Seven Legal Questions for Data Scientists']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title[df.summary.str.contains('machine learning.')].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
